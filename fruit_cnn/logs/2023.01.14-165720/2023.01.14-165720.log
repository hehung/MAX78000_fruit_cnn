2023-01-14 16:57:20,315 - Log file for this run: /home/hehung/AI/ai8x-training/logs/2023.01.14-165720/2023.01.14-165720.log
2023-01-14 16:57:31,593 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2023-01-14 16:57:31,603 - Optimizer Args: {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.001, 'amsgrad': False}
2023-01-14 16:57:31,701 - Dataset sizes:
	training=1338
	validation=148
	test=114
2023-01-14 16:57:31,701 - Reading compression schedule from: policies/schedule-fruit.yaml
2023-01-14 16:57:31,713 - 

2023-01-14 16:57:31,714 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:57:38,250 - Epoch: [0][    6/    6]    Overall Loss 2.284054    Objective Loss 2.284054    Top1 22.751323    Top5 73.015873    LR 0.001000    Time 1.088778    
2023-01-14 16:57:38,299 - --- validate (epoch=0)-----------
2023-01-14 16:57:38,300 - 148 samples (240 per mini-batch)
2023-01-14 16:57:38,856 - Epoch: [0][    1/    1]    Loss 2.248162    Top1 16.891892    Top5 72.972973    
2023-01-14 16:57:38,900 - ==> Top1: 16.892    Top5: 72.973    Loss: 2.248

2023-01-14 16:57:38,922 - ==> Best [Top1: 16.892   Top5: 72.973   Sparsity:0.00   Params: 80608 on epoch: 0]
2023-01-14 16:57:38,923 - Saving checkpoint to: logs/2023.01.14-165720/checkpoint.pth.tar
2023-01-14 16:57:39,177 - 

2023-01-14 16:57:39,177 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:57:42,734 - Epoch: [1][    6/    6]    Overall Loss 2.146428    Objective Loss 2.146428    Top1 27.777778    Top5 74.867725    LR 0.001000    Time 0.592598    
2023-01-14 16:57:42,775 - --- validate (epoch=1)-----------
2023-01-14 16:57:42,776 - 148 samples (240 per mini-batch)
2023-01-14 16:57:43,234 - Epoch: [1][    1/    1]    Loss 2.122152    Top1 22.972973    Top5 71.621622    
2023-01-14 16:57:43,285 - ==> Top1: 22.973    Top5: 71.622    Loss: 2.122

2023-01-14 16:57:43,297 - ==> Best [Top1: 22.973   Top5: 71.622   Sparsity:0.00   Params: 80608 on epoch: 1]
2023-01-14 16:57:43,298 - Saving checkpoint to: logs/2023.01.14-165720/checkpoint.pth.tar
2023-01-14 16:57:43,338 - 

2023-01-14 16:57:43,339 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:57:46,387 - Epoch: [2][    6/    6]    Overall Loss 2.002334    Objective Loss 2.002334    Top1 44.973545    Top5 82.804233    LR 0.001000    Time 0.507771    
2023-01-14 16:57:46,430 - --- validate (epoch=2)-----------
2023-01-14 16:57:46,430 - 148 samples (240 per mini-batch)
2023-01-14 16:57:46,914 - Epoch: [2][    1/    1]    Loss 1.991354    Top1 41.891892    Top5 74.324324    
2023-01-14 16:57:46,963 - ==> Top1: 41.892    Top5: 74.324    Loss: 1.991

2023-01-14 16:57:46,973 - ==> Best [Top1: 41.892   Top5: 74.324   Sparsity:0.00   Params: 80608 on epoch: 2]
2023-01-14 16:57:46,975 - Saving checkpoint to: logs/2023.01.14-165720/checkpoint.pth.tar
2023-01-14 16:57:47,031 - 

2023-01-14 16:57:47,032 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:57:50,215 - Epoch: [3][    6/    6]    Overall Loss 1.872143    Objective Loss 1.872143    Top1 54.761905    Top5 81.481481    LR 0.001000    Time 0.530368    
2023-01-14 16:57:50,264 - --- validate (epoch=3)-----------
2023-01-14 16:57:50,265 - 148 samples (240 per mini-batch)
2023-01-14 16:57:50,762 - Epoch: [3][    1/    1]    Loss 1.857597    Top1 54.054054    Top5 77.027027    
2023-01-14 16:57:50,799 - ==> Top1: 54.054    Top5: 77.027    Loss: 1.858

2023-01-14 16:57:50,810 - ==> Best [Top1: 54.054   Top5: 77.027   Sparsity:0.00   Params: 80608 on epoch: 3]
2023-01-14 16:57:50,810 - Saving checkpoint to: logs/2023.01.14-165720/checkpoint.pth.tar
2023-01-14 16:57:50,854 - 

2023-01-14 16:57:50,856 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:57:54,560 - Epoch: [4][    6/    6]    Overall Loss 1.726801    Objective Loss 1.726801    Top1 57.936508    Top5 87.037037    LR 0.001000    Time 0.616984    
2023-01-14 16:57:54,604 - --- validate (epoch=4)-----------
2023-01-14 16:57:54,605 - 148 samples (240 per mini-batch)
2023-01-14 16:57:55,090 - Epoch: [4][    1/    1]    Loss 1.724897    Top1 57.432432    Top5 82.432432    
2023-01-14 16:57:55,132 - ==> Top1: 57.432    Top5: 82.432    Loss: 1.725

2023-01-14 16:57:55,142 - ==> Best [Top1: 57.432   Top5: 82.432   Sparsity:0.00   Params: 80608 on epoch: 4]
2023-01-14 16:57:55,143 - Saving checkpoint to: logs/2023.01.14-165720/checkpoint.pth.tar
2023-01-14 16:57:55,192 - 

2023-01-14 16:57:55,193 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:57:57,936 - Epoch: [5][    6/    6]    Overall Loss 1.601406    Objective Loss 1.601406    Top1 57.671958    Top5 86.507937    LR 0.001000    Time 0.456842    
2023-01-14 16:57:57,992 - --- validate (epoch=5)-----------
2023-01-14 16:57:57,993 - 148 samples (240 per mini-batch)
2023-01-14 16:57:58,463 - Epoch: [5][    1/    1]    Loss 1.571677    Top1 62.837838    Top5 85.135135    
2023-01-14 16:57:58,507 - ==> Top1: 62.838    Top5: 85.135    Loss: 1.572

2023-01-14 16:57:58,517 - ==> Best [Top1: 62.838   Top5: 85.135   Sparsity:0.00   Params: 80608 on epoch: 5]
2023-01-14 16:57:58,517 - Saving checkpoint to: logs/2023.01.14-165720/checkpoint.pth.tar
2023-01-14 16:57:58,570 - 

2023-01-14 16:57:58,571 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:58:01,629 - Epoch: [6][    6/    6]    Overall Loss 1.464701    Objective Loss 1.464701    Top1 65.873016    Top5 90.211640    LR 0.001000    Time 0.509419    
2023-01-14 16:58:01,684 - --- validate (epoch=6)-----------
2023-01-14 16:58:01,685 - 148 samples (240 per mini-batch)
2023-01-14 16:58:02,147 - Epoch: [6][    1/    1]    Loss 1.446240    Top1 65.540541    Top5 85.135135    
2023-01-14 16:58:02,190 - ==> Top1: 65.541    Top5: 85.135    Loss: 1.446

2023-01-14 16:58:02,198 - ==> Best [Top1: 65.541   Top5: 85.135   Sparsity:0.00   Params: 80608 on epoch: 6]
2023-01-14 16:58:02,199 - Saving checkpoint to: logs/2023.01.14-165720/checkpoint.pth.tar
2023-01-14 16:58:02,259 - 

2023-01-14 16:58:02,259 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:58:05,119 - Epoch: [7][    6/    6]    Overall Loss 1.319262    Objective Loss 1.319262    Top1 71.693122    Top5 93.915344    LR 0.001000    Time 0.476401    
2023-01-14 16:58:05,168 - --- validate (epoch=7)-----------
2023-01-14 16:58:05,169 - 148 samples (240 per mini-batch)
2023-01-14 16:58:05,640 - Epoch: [7][    1/    1]    Loss 1.334891    Top1 70.945946    Top5 88.513514    
2023-01-14 16:58:05,689 - ==> Top1: 70.946    Top5: 88.514    Loss: 1.335

2023-01-14 16:58:05,698 - ==> Best [Top1: 70.946   Top5: 88.514   Sparsity:0.00   Params: 80608 on epoch: 7]
2023-01-14 16:58:05,698 - Saving checkpoint to: logs/2023.01.14-165720/checkpoint.pth.tar
2023-01-14 16:58:05,746 - 

2023-01-14 16:58:05,747 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:58:08,647 - Epoch: [8][    6/    6]    Overall Loss 1.213075    Objective Loss 1.213075    Top1 73.809524    Top5 95.502646    LR 0.001000    Time 0.482981    
2023-01-14 16:58:08,689 - --- validate (epoch=8)-----------
2023-01-14 16:58:08,689 - 148 samples (240 per mini-batch)
2023-01-14 16:58:09,182 - Epoch: [8][    1/    1]    Loss 1.228119    Top1 71.621622    Top5 90.540541    
2023-01-14 16:58:09,245 - ==> Top1: 71.622    Top5: 90.541    Loss: 1.228

2023-01-14 16:58:09,254 - ==> Best [Top1: 71.622   Top5: 90.541   Sparsity:0.00   Params: 80608 on epoch: 8]
2023-01-14 16:58:09,255 - Saving checkpoint to: logs/2023.01.14-165720/checkpoint.pth.tar
2023-01-14 16:58:09,300 - 

2023-01-14 16:58:09,300 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:58:12,543 - Epoch: [9][    6/    6]    Overall Loss 1.102158    Objective Loss 1.102158    Top1 76.719577    Top5 96.296296    LR 0.001000    Time 0.540169    
2023-01-14 16:58:12,617 - --- validate (epoch=9)-----------
2023-01-14 16:58:12,618 - 148 samples (240 per mini-batch)
2023-01-14 16:58:13,159 - Epoch: [9][    1/    1]    Loss 1.123140    Top1 75.000000    Top5 91.891892    
2023-01-14 16:58:13,210 - ==> Top1: 75.000    Top5: 91.892    Loss: 1.123

2023-01-14 16:58:13,218 - ==> Best [Top1: 75.000   Top5: 91.892   Sparsity:0.00   Params: 80608 on epoch: 9]
2023-01-14 16:58:13,219 - Saving checkpoint to: logs/2023.01.14-165720/checkpoint.pth.tar
2023-01-14 16:58:13,522 - 

2023-01-14 16:58:13,523 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:58:16,505 - Epoch: [10][    6/    6]    Overall Loss 0.808446    Objective Loss 0.808446    Top1 78.042328    Top5 98.677249    LR 0.001000    Time 0.496706    
2023-01-14 16:58:16,551 - --- validate (epoch=10)-----------
2023-01-14 16:58:16,552 - 148 samples (240 per mini-batch)
2023-01-14 16:58:17,073 - Epoch: [10][    1/    1]    Loss 0.924829    Top1 72.297297    Top5 95.945946    
2023-01-14 16:58:17,119 - ==> Top1: 72.297    Top5: 95.946    Loss: 0.925

2023-01-14 16:58:17,126 - ==> Best [Top1: 72.297   Top5: 95.946   Sparsity:0.00   Params: 80608 on epoch: 10]
2023-01-14 16:58:17,126 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 16:58:17,164 - 

2023-01-14 16:58:17,165 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:58:20,415 - Epoch: [11][    6/    6]    Overall Loss 0.635208    Objective Loss 0.635208    Top1 81.481481    Top5 97.089947    LR 0.001000    Time 0.541320    
2023-01-14 16:58:20,457 - --- validate (epoch=11)-----------
2023-01-14 16:58:20,458 - 148 samples (240 per mini-batch)
2023-01-14 16:58:20,926 - Epoch: [11][    1/    1]    Loss 0.652701    Top1 78.378378    Top5 97.297297    
2023-01-14 16:58:20,977 - ==> Top1: 78.378    Top5: 97.297    Loss: 0.653

2023-01-14 16:58:20,987 - ==> Best [Top1: 78.378   Top5: 97.297   Sparsity:0.00   Params: 80608 on epoch: 11]
2023-01-14 16:58:20,988 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 16:58:21,042 - 

2023-01-14 16:58:21,043 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:58:24,282 - Epoch: [12][    6/    6]    Overall Loss 0.550999    Objective Loss 0.550999    Top1 82.804233    Top5 97.354497    LR 0.001000    Time 0.539633    
2023-01-14 16:58:24,360 - --- validate (epoch=12)-----------
2023-01-14 16:58:24,363 - 148 samples (240 per mini-batch)
2023-01-14 16:58:24,944 - Epoch: [12][    1/    1]    Loss 0.633960    Top1 81.081081    Top5 96.621622    
2023-01-14 16:58:24,984 - ==> Top1: 81.081    Top5: 96.622    Loss: 0.634

2023-01-14 16:58:24,992 - ==> Best [Top1: 81.081   Top5: 96.622   Sparsity:0.00   Params: 80608 on epoch: 12]
2023-01-14 16:58:24,993 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 16:58:25,030 - 

2023-01-14 16:58:25,030 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:58:27,725 - Epoch: [13][    6/    6]    Overall Loss 0.522532    Objective Loss 0.522532    Top1 84.126984    Top5 98.941799    LR 0.001000    Time 0.448828    
2023-01-14 16:58:27,770 - --- validate (epoch=13)-----------
2023-01-14 16:58:27,770 - 148 samples (240 per mini-batch)
2023-01-14 16:58:28,283 - Epoch: [13][    1/    1]    Loss 0.621546    Top1 79.729730    Top5 97.972973    
2023-01-14 16:58:28,325 - ==> Top1: 79.730    Top5: 97.973    Loss: 0.622

2023-01-14 16:58:28,334 - ==> Best [Top1: 81.081   Top5: 96.622   Sparsity:0.00   Params: 80608 on epoch: 12]
2023-01-14 16:58:28,334 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 16:58:28,386 - 

2023-01-14 16:58:28,387 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:58:32,291 - Epoch: [14][    6/    6]    Overall Loss 0.466571    Objective Loss 0.466571    Top1 85.978836    Top5 99.470899    LR 0.001000    Time 0.650197    
2023-01-14 16:58:32,335 - --- validate (epoch=14)-----------
2023-01-14 16:58:32,336 - 148 samples (240 per mini-batch)
2023-01-14 16:58:32,977 - Epoch: [14][    1/    1]    Loss 0.589419    Top1 80.405405    Top5 97.297297    
2023-01-14 16:58:33,013 - ==> Top1: 80.405    Top5: 97.297    Loss: 0.589

2023-01-14 16:58:33,023 - ==> Best [Top1: 81.081   Top5: 96.622   Sparsity:0.00   Params: 80608 on epoch: 12]
2023-01-14 16:58:33,024 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 16:58:33,060 - 

2023-01-14 16:58:33,060 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:58:35,729 - Epoch: [15][    6/    6]    Overall Loss 0.412693    Objective Loss 0.412693    Top1 86.243386    Top5 98.941799    LR 0.001000    Time 0.444489    
2023-01-14 16:58:35,787 - --- validate (epoch=15)-----------
2023-01-14 16:58:35,788 - 148 samples (240 per mini-batch)
2023-01-14 16:58:36,320 - Epoch: [15][    1/    1]    Loss 0.610491    Top1 83.783784    Top5 97.972973    
2023-01-14 16:58:36,381 - ==> Top1: 83.784    Top5: 97.973    Loss: 0.610

2023-01-14 16:58:36,393 - ==> Best [Top1: 83.784   Top5: 97.973   Sparsity:0.00   Params: 80608 on epoch: 15]
2023-01-14 16:58:36,394 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 16:58:36,451 - 

2023-01-14 16:58:36,452 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:58:39,805 - Epoch: [16][    6/    6]    Overall Loss 0.395930    Objective Loss 0.395930    Top1 85.978836    Top5 99.206349    LR 0.001000    Time 0.558600    
2023-01-14 16:58:39,858 - --- validate (epoch=16)-----------
2023-01-14 16:58:39,858 - 148 samples (240 per mini-batch)
2023-01-14 16:58:40,357 - Epoch: [16][    1/    1]    Loss 0.549107    Top1 85.135135    Top5 97.972973    
2023-01-14 16:58:40,400 - ==> Top1: 85.135    Top5: 97.973    Loss: 0.549

2023-01-14 16:58:40,410 - ==> Best [Top1: 85.135   Top5: 97.973   Sparsity:0.00   Params: 80608 on epoch: 16]
2023-01-14 16:58:40,410 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 16:58:40,476 - 

2023-01-14 16:58:40,476 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:58:44,326 - Epoch: [17][    6/    6]    Overall Loss 0.359144    Objective Loss 0.359144    Top1 88.888889    Top5 100.000000    LR 0.001000    Time 0.641299    
2023-01-14 16:58:44,378 - --- validate (epoch=17)-----------
2023-01-14 16:58:44,379 - 148 samples (240 per mini-batch)
2023-01-14 16:58:45,023 - Epoch: [17][    1/    1]    Loss 0.479148    Top1 84.459459    Top5 99.324324    
2023-01-14 16:58:45,092 - ==> Top1: 84.459    Top5: 99.324    Loss: 0.479

2023-01-14 16:58:45,105 - ==> Best [Top1: 85.135   Top5: 97.973   Sparsity:0.00   Params: 80608 on epoch: 16]
2023-01-14 16:58:45,105 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 16:58:45,238 - 

2023-01-14 16:58:45,239 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:58:48,356 - Epoch: [18][    6/    6]    Overall Loss 0.326321    Objective Loss 0.326321    Top1 88.624339    Top5 100.000000    LR 0.001000    Time 0.519119    
2023-01-14 16:58:48,406 - --- validate (epoch=18)-----------
2023-01-14 16:58:48,406 - 148 samples (240 per mini-batch)
2023-01-14 16:58:48,889 - Epoch: [18][    1/    1]    Loss 0.599888    Top1 81.756757    Top5 97.297297    
2023-01-14 16:58:48,926 - ==> Top1: 81.757    Top5: 97.297    Loss: 0.600

2023-01-14 16:58:48,934 - ==> Best [Top1: 85.135   Top5: 97.973   Sparsity:0.00   Params: 80608 on epoch: 16]
2023-01-14 16:58:48,935 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 16:58:48,980 - 

2023-01-14 16:58:48,981 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:58:52,433 - Epoch: [19][    6/    6]    Overall Loss 0.356200    Objective Loss 0.356200    Top1 86.772487    Top5 98.412698    LR 0.001000    Time 0.575204    
2023-01-14 16:58:52,483 - --- validate (epoch=19)-----------
2023-01-14 16:58:52,483 - 148 samples (240 per mini-batch)
2023-01-14 16:58:53,053 - Epoch: [19][    1/    1]    Loss 0.474003    Top1 85.135135    Top5 98.648649    
2023-01-14 16:58:53,114 - ==> Top1: 85.135    Top5: 98.649    Loss: 0.474

2023-01-14 16:58:53,123 - ==> Best [Top1: 85.135   Top5: 98.649   Sparsity:0.00   Params: 80608 on epoch: 19]
2023-01-14 16:58:53,127 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 16:58:53,207 - 

2023-01-14 16:58:53,208 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:58:56,659 - Epoch: [20][    6/    6]    Overall Loss 0.369735    Objective Loss 0.369735    Top1 87.566138    Top5 99.206349    LR 0.001000    Time 0.574783    
2023-01-14 16:58:56,726 - --- validate (epoch=20)-----------
2023-01-14 16:58:56,727 - 148 samples (240 per mini-batch)
2023-01-14 16:58:57,249 - Epoch: [20][    1/    1]    Loss 0.587257    Top1 82.432432    Top5 98.648649    
2023-01-14 16:58:57,296 - ==> Top1: 82.432    Top5: 98.649    Loss: 0.587

2023-01-14 16:58:57,305 - ==> Best [Top1: 85.135   Top5: 98.649   Sparsity:0.00   Params: 80608 on epoch: 19]
2023-01-14 16:58:57,305 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 16:58:57,344 - 

2023-01-14 16:58:57,344 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:59:00,927 - Epoch: [21][    6/    6]    Overall Loss 0.350944    Objective Loss 0.350944    Top1 87.301587    Top5 100.000000    LR 0.001000    Time 0.596913    
2023-01-14 16:59:00,989 - --- validate (epoch=21)-----------
2023-01-14 16:59:00,990 - 148 samples (240 per mini-batch)
2023-01-14 16:59:01,723 - Epoch: [21][    1/    1]    Loss 0.540981    Top1 83.108108    Top5 98.648649    
2023-01-14 16:59:01,774 - ==> Top1: 83.108    Top5: 98.649    Loss: 0.541

2023-01-14 16:59:01,792 - ==> Best [Top1: 85.135   Top5: 98.649   Sparsity:0.00   Params: 80608 on epoch: 19]
2023-01-14 16:59:01,795 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 16:59:01,848 - 

2023-01-14 16:59:01,849 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:59:05,353 - Epoch: [22][    6/    6]    Overall Loss 0.324101    Objective Loss 0.324101    Top1 91.269841    Top5 99.470899    LR 0.001000    Time 0.583825    
2023-01-14 16:59:05,413 - --- validate (epoch=22)-----------
2023-01-14 16:59:05,413 - 148 samples (240 per mini-batch)
2023-01-14 16:59:05,940 - Epoch: [22][    1/    1]    Loss 0.493288    Top1 83.783784    Top5 98.648649    
2023-01-14 16:59:05,995 - ==> Top1: 83.784    Top5: 98.649    Loss: 0.493

2023-01-14 16:59:06,007 - ==> Best [Top1: 85.135   Top5: 98.649   Sparsity:0.00   Params: 80608 on epoch: 19]
2023-01-14 16:59:06,007 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 16:59:06,041 - 

2023-01-14 16:59:06,041 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:59:08,727 - Epoch: [23][    6/    6]    Overall Loss 0.295922    Objective Loss 0.295922    Top1 88.095238    Top5 99.470899    LR 0.001000    Time 0.447488    
2023-01-14 16:59:08,772 - --- validate (epoch=23)-----------
2023-01-14 16:59:08,772 - 148 samples (240 per mini-batch)
2023-01-14 16:59:09,299 - Epoch: [23][    1/    1]    Loss 0.441000    Top1 85.810811    Top5 99.324324    
2023-01-14 16:59:09,373 - ==> Top1: 85.811    Top5: 99.324    Loss: 0.441

2023-01-14 16:59:09,394 - ==> Best [Top1: 85.811   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 23]
2023-01-14 16:59:09,394 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 16:59:09,444 - 

2023-01-14 16:59:09,445 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:59:12,483 - Epoch: [24][    6/    6]    Overall Loss 0.274773    Objective Loss 0.274773    Top1 88.888889    Top5 100.000000    LR 0.001000    Time 0.506163    
2023-01-14 16:59:12,554 - --- validate (epoch=24)-----------
2023-01-14 16:59:12,554 - 148 samples (240 per mini-batch)
2023-01-14 16:59:13,147 - Epoch: [24][    1/    1]    Loss 0.476246    Top1 83.783784    Top5 98.648649    
2023-01-14 16:59:13,195 - ==> Top1: 83.784    Top5: 98.649    Loss: 0.476

2023-01-14 16:59:13,203 - ==> Best [Top1: 85.811   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 23]
2023-01-14 16:59:13,204 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 16:59:13,241 - 

2023-01-14 16:59:13,241 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:59:16,804 - Epoch: [25][    6/    6]    Overall Loss 0.256978    Objective Loss 0.256978    Top1 90.476190    Top5 100.000000    LR 0.001000    Time 0.593456    
2023-01-14 16:59:16,862 - --- validate (epoch=25)-----------
2023-01-14 16:59:16,863 - 148 samples (240 per mini-batch)
2023-01-14 16:59:17,350 - Epoch: [25][    1/    1]    Loss 0.485522    Top1 87.162162    Top5 99.324324    
2023-01-14 16:59:17,399 - ==> Top1: 87.162    Top5: 99.324    Loss: 0.486

2023-01-14 16:59:17,406 - ==> Best [Top1: 87.162   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 25]
2023-01-14 16:59:17,407 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 16:59:17,452 - 

2023-01-14 16:59:17,453 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:59:20,512 - Epoch: [26][    6/    6]    Overall Loss 0.242814    Objective Loss 0.242814    Top1 91.534392    Top5 100.000000    LR 0.001000    Time 0.509584    
2023-01-14 16:59:20,558 - --- validate (epoch=26)-----------
2023-01-14 16:59:20,559 - 148 samples (240 per mini-batch)
2023-01-14 16:59:21,039 - Epoch: [26][    1/    1]    Loss 0.457095    Top1 87.162162    Top5 98.648649    
2023-01-14 16:59:21,081 - ==> Top1: 87.162    Top5: 98.649    Loss: 0.457

2023-01-14 16:59:21,090 - ==> Best [Top1: 87.162   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 25]
2023-01-14 16:59:21,091 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 16:59:21,134 - 

2023-01-14 16:59:21,135 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:59:23,786 - Epoch: [27][    6/    6]    Overall Loss 0.218768    Objective Loss 0.218768    Top1 94.444444    Top5 100.000000    LR 0.001000    Time 0.441555    
2023-01-14 16:59:23,832 - --- validate (epoch=27)-----------
2023-01-14 16:59:23,833 - 148 samples (240 per mini-batch)
2023-01-14 16:59:24,375 - Epoch: [27][    1/    1]    Loss 0.449168    Top1 83.783784    Top5 98.648649    
2023-01-14 16:59:24,433 - ==> Top1: 83.784    Top5: 98.649    Loss: 0.449

2023-01-14 16:59:24,443 - ==> Best [Top1: 87.162   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 25]
2023-01-14 16:59:24,444 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 16:59:24,486 - 

2023-01-14 16:59:24,486 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:59:26,842 - Epoch: [28][    6/    6]    Overall Loss 0.217406    Objective Loss 0.217406    Top1 94.444444    Top5 99.735450    LR 0.001000    Time 0.392407    
2023-01-14 16:59:26,916 - --- validate (epoch=28)-----------
2023-01-14 16:59:26,917 - 148 samples (240 per mini-batch)
2023-01-14 16:59:27,555 - Epoch: [28][    1/    1]    Loss 0.408202    Top1 85.810811    Top5 99.324324    
2023-01-14 16:59:27,594 - ==> Top1: 85.811    Top5: 99.324    Loss: 0.408

2023-01-14 16:59:27,605 - ==> Best [Top1: 87.162   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 25]
2023-01-14 16:59:27,605 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 16:59:27,665 - 

2023-01-14 16:59:27,666 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:59:30,575 - Epoch: [29][    6/    6]    Overall Loss 0.199480    Objective Loss 0.199480    Top1 93.121693    Top5 100.000000    LR 0.001000    Time 0.484580    
2023-01-14 16:59:30,622 - --- validate (epoch=29)-----------
2023-01-14 16:59:30,623 - 148 samples (240 per mini-batch)
2023-01-14 16:59:31,087 - Epoch: [29][    1/    1]    Loss 0.399496    Top1 85.135135    Top5 99.324324    
2023-01-14 16:59:31,130 - ==> Top1: 85.135    Top5: 99.324    Loss: 0.399

2023-01-14 16:59:31,140 - ==> Best [Top1: 87.162   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 25]
2023-01-14 16:59:31,141 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 16:59:31,188 - 

2023-01-14 16:59:31,189 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:59:33,822 - Epoch: [30][    6/    6]    Overall Loss 0.203720    Objective Loss 0.203720    Top1 93.650794    Top5 100.000000    LR 0.001000    Time 0.438621    
2023-01-14 16:59:33,874 - --- validate (epoch=30)-----------
2023-01-14 16:59:33,875 - 148 samples (240 per mini-batch)
2023-01-14 16:59:34,420 - Epoch: [30][    1/    1]    Loss 0.440334    Top1 86.486486    Top5 99.324324    
2023-01-14 16:59:34,462 - ==> Top1: 86.486    Top5: 99.324    Loss: 0.440

2023-01-14 16:59:34,471 - ==> Best [Top1: 87.162   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 25]
2023-01-14 16:59:34,472 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 16:59:34,519 - 

2023-01-14 16:59:34,520 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:59:37,095 - Epoch: [31][    6/    6]    Overall Loss 0.188853    Objective Loss 0.188853    Top1 94.708995    Top5 99.735450    LR 0.001000    Time 0.428948    
2023-01-14 16:59:37,137 - --- validate (epoch=31)-----------
2023-01-14 16:59:37,138 - 148 samples (240 per mini-batch)
2023-01-14 16:59:37,625 - Epoch: [31][    1/    1]    Loss 0.402982    Top1 86.486486    Top5 98.648649    
2023-01-14 16:59:37,669 - ==> Top1: 86.486    Top5: 98.649    Loss: 0.403

2023-01-14 16:59:37,680 - ==> Best [Top1: 87.162   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 25]
2023-01-14 16:59:37,681 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 16:59:37,720 - 

2023-01-14 16:59:37,721 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:59:40,568 - Epoch: [32][    6/    6]    Overall Loss 0.174655    Objective Loss 0.174655    Top1 93.915344    Top5 100.000000    LR 0.001000    Time 0.474225    
2023-01-14 16:59:40,614 - --- validate (epoch=32)-----------
2023-01-14 16:59:40,614 - 148 samples (240 per mini-batch)
2023-01-14 16:59:41,139 - Epoch: [32][    1/    1]    Loss 0.425242    Top1 87.162162    Top5 99.324324    
2023-01-14 16:59:41,181 - ==> Top1: 87.162    Top5: 99.324    Loss: 0.425

2023-01-14 16:59:41,191 - ==> Best [Top1: 87.162   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 32]
2023-01-14 16:59:41,192 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 16:59:41,234 - 

2023-01-14 16:59:41,235 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:59:43,819 - Epoch: [33][    6/    6]    Overall Loss 0.155822    Objective Loss 0.155822    Top1 95.502646    Top5 100.000000    LR 0.001000    Time 0.430508    
2023-01-14 16:59:43,865 - --- validate (epoch=33)-----------
2023-01-14 16:59:43,866 - 148 samples (240 per mini-batch)
2023-01-14 16:59:44,331 - Epoch: [33][    1/    1]    Loss 0.380767    Top1 86.486486    Top5 99.324324    
2023-01-14 16:59:44,368 - ==> Top1: 86.486    Top5: 99.324    Loss: 0.381

2023-01-14 16:59:44,379 - ==> Best [Top1: 87.162   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 32]
2023-01-14 16:59:44,379 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 16:59:44,419 - 

2023-01-14 16:59:44,419 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:59:47,125 - Epoch: [34][    6/    6]    Overall Loss 0.149324    Objective Loss 0.149324    Top1 94.973545    Top5 100.000000    LR 0.001000    Time 0.450648    
2023-01-14 16:59:47,169 - --- validate (epoch=34)-----------
2023-01-14 16:59:47,169 - 148 samples (240 per mini-batch)
2023-01-14 16:59:47,680 - Epoch: [34][    1/    1]    Loss 0.392425    Top1 87.162162    Top5 99.324324    
2023-01-14 16:59:47,731 - ==> Top1: 87.162    Top5: 99.324    Loss: 0.392

2023-01-14 16:59:47,739 - ==> Best [Top1: 87.162   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 34]
2023-01-14 16:59:47,740 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 16:59:47,775 - 

2023-01-14 16:59:47,775 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:59:50,219 - Epoch: [35][    6/    6]    Overall Loss 0.153081    Objective Loss 0.153081    Top1 96.031746    Top5 100.000000    LR 0.001000    Time 0.407027    
2023-01-14 16:59:50,261 - --- validate (epoch=35)-----------
2023-01-14 16:59:50,261 - 148 samples (240 per mini-batch)
2023-01-14 16:59:50,829 - Epoch: [35][    1/    1]    Loss 0.421711    Top1 85.135135    Top5 98.648649    
2023-01-14 16:59:50,877 - ==> Top1: 85.135    Top5: 98.649    Loss: 0.422

2023-01-14 16:59:50,886 - ==> Best [Top1: 87.162   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 34]
2023-01-14 16:59:50,886 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 16:59:50,927 - 

2023-01-14 16:59:50,927 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:59:53,692 - Epoch: [36][    6/    6]    Overall Loss 0.173524    Objective Loss 0.173524    Top1 95.502646    Top5 100.000000    LR 0.001000    Time 0.460596    
2023-01-14 16:59:53,733 - --- validate (epoch=36)-----------
2023-01-14 16:59:53,734 - 148 samples (240 per mini-batch)
2023-01-14 16:59:54,213 - Epoch: [36][    1/    1]    Loss 0.397981    Top1 85.135135    Top5 99.324324    
2023-01-14 16:59:54,254 - ==> Top1: 85.135    Top5: 99.324    Loss: 0.398

2023-01-14 16:59:54,266 - ==> Best [Top1: 87.162   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 34]
2023-01-14 16:59:54,267 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 16:59:54,325 - 

2023-01-14 16:59:54,326 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 16:59:57,139 - Epoch: [37][    6/    6]    Overall Loss 0.174722    Objective Loss 0.174722    Top1 94.973545    Top5 100.000000    LR 0.001000    Time 0.468585    
2023-01-14 16:59:57,184 - --- validate (epoch=37)-----------
2023-01-14 16:59:57,185 - 148 samples (240 per mini-batch)
2023-01-14 16:59:57,722 - Epoch: [37][    1/    1]    Loss 0.390674    Top1 87.162162    Top5 98.648649    
2023-01-14 16:59:57,766 - ==> Top1: 87.162    Top5: 98.649    Loss: 0.391

2023-01-14 16:59:57,775 - ==> Best [Top1: 87.162   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 34]
2023-01-14 16:59:57,775 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 16:59:57,820 - 

2023-01-14 16:59:57,821 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:00:00,458 - Epoch: [38][    6/    6]    Overall Loss 0.171084    Objective Loss 0.171084    Top1 95.238095    Top5 100.000000    LR 0.001000    Time 0.439405    
2023-01-14 17:00:00,509 - --- validate (epoch=38)-----------
2023-01-14 17:00:00,509 - 148 samples (240 per mini-batch)
2023-01-14 17:00:01,064 - Epoch: [38][    1/    1]    Loss 0.420110    Top1 85.135135    Top5 98.648649    
2023-01-14 17:00:01,118 - ==> Top1: 85.135    Top5: 98.649    Loss: 0.420

2023-01-14 17:00:01,127 - ==> Best [Top1: 87.162   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 34]
2023-01-14 17:00:01,128 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:00:01,171 - 

2023-01-14 17:00:01,171 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:00:04,137 - Epoch: [39][    6/    6]    Overall Loss 0.135643    Objective Loss 0.135643    Top1 97.089947    Top5 100.000000    LR 0.001000    Time 0.494006    
2023-01-14 17:00:04,180 - --- validate (epoch=39)-----------
2023-01-14 17:00:04,180 - 148 samples (240 per mini-batch)
2023-01-14 17:00:04,742 - Epoch: [39][    1/    1]    Loss 0.343417    Top1 88.513514    Top5 99.324324    
2023-01-14 17:00:04,782 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.343

2023-01-14 17:00:04,791 - ==> Best [Top1: 88.514   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 39]
2023-01-14 17:00:04,791 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:00:04,840 - 

2023-01-14 17:00:04,840 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:00:07,704 - Epoch: [40][    6/    6]    Overall Loss 0.138882    Objective Loss 0.138882    Top1 96.825397    Top5 100.000000    LR 0.001000    Time 0.476883    
2023-01-14 17:00:07,748 - --- validate (epoch=40)-----------
2023-01-14 17:00:07,749 - 148 samples (240 per mini-batch)
2023-01-14 17:00:08,266 - Epoch: [40][    1/    1]    Loss 0.365586    Top1 87.837838    Top5 99.324324    
2023-01-14 17:00:08,310 - ==> Top1: 87.838    Top5: 99.324    Loss: 0.366

2023-01-14 17:00:08,320 - ==> Best [Top1: 88.514   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 39]
2023-01-14 17:00:08,320 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:00:08,368 - 

2023-01-14 17:00:08,369 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:00:10,970 - Epoch: [41][    6/    6]    Overall Loss 0.135001    Objective Loss 0.135001    Top1 96.560847    Top5 100.000000    LR 0.001000    Time 0.433176    
2023-01-14 17:00:11,014 - --- validate (epoch=41)-----------
2023-01-14 17:00:11,015 - 148 samples (240 per mini-batch)
2023-01-14 17:00:11,605 - Epoch: [41][    1/    1]    Loss 0.426026    Top1 85.135135    Top5 99.324324    
2023-01-14 17:00:11,646 - ==> Top1: 85.135    Top5: 99.324    Loss: 0.426

2023-01-14 17:00:11,653 - ==> Best [Top1: 88.514   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 39]
2023-01-14 17:00:11,653 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:00:11,698 - 

2023-01-14 17:00:11,698 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:00:14,893 - Epoch: [42][    6/    6]    Overall Loss 0.121455    Objective Loss 0.121455    Top1 96.825397    Top5 100.000000    LR 0.001000    Time 0.532225    
2023-01-14 17:00:14,951 - --- validate (epoch=42)-----------
2023-01-14 17:00:14,952 - 148 samples (240 per mini-batch)
2023-01-14 17:00:15,471 - Epoch: [42][    1/    1]    Loss 0.390460    Top1 87.162162    Top5 99.324324    
2023-01-14 17:00:15,518 - ==> Top1: 87.162    Top5: 99.324    Loss: 0.390

2023-01-14 17:00:15,525 - ==> Best [Top1: 88.514   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 39]
2023-01-14 17:00:15,525 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:00:15,566 - 

2023-01-14 17:00:15,567 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:00:18,754 - Epoch: [43][    6/    6]    Overall Loss 0.110128    Objective Loss 0.110128    Top1 97.089947    Top5 100.000000    LR 0.001000    Time 0.530933    
2023-01-14 17:00:18,801 - --- validate (epoch=43)-----------
2023-01-14 17:00:18,801 - 148 samples (240 per mini-batch)
2023-01-14 17:00:19,317 - Epoch: [43][    1/    1]    Loss 0.383628    Top1 88.513514    Top5 99.324324    
2023-01-14 17:00:19,363 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.384

2023-01-14 17:00:19,374 - ==> Best [Top1: 88.514   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 43]
2023-01-14 17:00:19,374 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:00:19,423 - 

2023-01-14 17:00:19,424 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:00:22,366 - Epoch: [44][    6/    6]    Overall Loss 0.101830    Objective Loss 0.101830    Top1 98.677249    Top5 100.000000    LR 0.001000    Time 0.490191    
2023-01-14 17:00:22,412 - --- validate (epoch=44)-----------
2023-01-14 17:00:22,413 - 148 samples (240 per mini-batch)
2023-01-14 17:00:23,003 - Epoch: [44][    1/    1]    Loss 0.348113    Top1 86.486486    Top5 100.000000    
2023-01-14 17:00:23,048 - ==> Top1: 86.486    Top5: 100.000    Loss: 0.348

2023-01-14 17:00:23,056 - ==> Best [Top1: 88.514   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 43]
2023-01-14 17:00:23,057 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:00:23,097 - 

2023-01-14 17:00:23,098 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:00:25,977 - Epoch: [45][    6/    6]    Overall Loss 0.097767    Objective Loss 0.097767    Top1 96.825397    Top5 100.000000    LR 0.001000    Time 0.479668    
2023-01-14 17:00:26,020 - --- validate (epoch=45)-----------
2023-01-14 17:00:26,021 - 148 samples (240 per mini-batch)
2023-01-14 17:00:26,522 - Epoch: [45][    1/    1]    Loss 0.348693    Top1 89.189189    Top5 97.972973    
2023-01-14 17:00:26,562 - ==> Top1: 89.189    Top5: 97.973    Loss: 0.349

2023-01-14 17:00:26,570 - ==> Best [Top1: 89.189   Top5: 97.973   Sparsity:0.00   Params: 80608 on epoch: 45]
2023-01-14 17:00:26,571 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:00:26,608 - 

2023-01-14 17:00:26,609 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:00:28,986 - Epoch: [46][    6/    6]    Overall Loss 0.091984    Objective Loss 0.091984    Top1 98.148148    Top5 100.000000    LR 0.001000    Time 0.396001    
2023-01-14 17:00:29,034 - --- validate (epoch=46)-----------
2023-01-14 17:00:29,034 - 148 samples (240 per mini-batch)
2023-01-14 17:00:29,542 - Epoch: [46][    1/    1]    Loss 0.326795    Top1 89.189189    Top5 100.000000    
2023-01-14 17:00:29,585 - ==> Top1: 89.189    Top5: 100.000    Loss: 0.327

2023-01-14 17:00:29,596 - ==> Best [Top1: 89.189   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 46]
2023-01-14 17:00:29,597 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:00:29,644 - 

2023-01-14 17:00:29,644 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:00:33,224 - Epoch: [47][    6/    6]    Overall Loss 0.083965    Objective Loss 0.083965    Top1 98.941799    Top5 100.000000    LR 0.001000    Time 0.596415    
2023-01-14 17:00:33,272 - --- validate (epoch=47)-----------
2023-01-14 17:00:33,272 - 148 samples (240 per mini-batch)
2023-01-14 17:00:33,737 - Epoch: [47][    1/    1]    Loss 0.348012    Top1 85.810811    Top5 100.000000    
2023-01-14 17:00:33,790 - ==> Top1: 85.811    Top5: 100.000    Loss: 0.348

2023-01-14 17:00:33,799 - ==> Best [Top1: 89.189   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 46]
2023-01-14 17:00:33,800 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:00:33,839 - 

2023-01-14 17:00:33,840 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:00:36,564 - Epoch: [48][    6/    6]    Overall Loss 0.089731    Objective Loss 0.089731    Top1 98.148148    Top5 100.000000    LR 0.001000    Time 0.453845    
2023-01-14 17:00:36,608 - --- validate (epoch=48)-----------
2023-01-14 17:00:36,608 - 148 samples (240 per mini-batch)
2023-01-14 17:00:37,079 - Epoch: [48][    1/    1]    Loss 0.356481    Top1 87.162162    Top5 98.648649    
2023-01-14 17:00:37,122 - ==> Top1: 87.162    Top5: 98.649    Loss: 0.356

2023-01-14 17:00:37,134 - ==> Best [Top1: 89.189   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 46]
2023-01-14 17:00:37,134 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:00:37,176 - 

2023-01-14 17:00:37,176 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:00:39,695 - Epoch: [49][    6/    6]    Overall Loss 0.081854    Objective Loss 0.081854    Top1 98.677249    Top5 100.000000    LR 0.001000    Time 0.419522    
2023-01-14 17:00:39,743 - --- validate (epoch=49)-----------
2023-01-14 17:00:39,743 - 148 samples (240 per mini-batch)
2023-01-14 17:00:40,259 - Epoch: [49][    1/    1]    Loss 0.393117    Top1 85.810811    Top5 98.648649    
2023-01-14 17:00:40,302 - ==> Top1: 85.811    Top5: 98.649    Loss: 0.393

2023-01-14 17:00:40,310 - ==> Best [Top1: 89.189   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 46]
2023-01-14 17:00:40,312 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:00:40,357 - 

2023-01-14 17:00:40,358 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:00:43,055 - Epoch: [50][    6/    6]    Overall Loss 0.078182    Objective Loss 0.078182    Top1 98.677249    Top5 100.000000    LR 0.001000    Time 0.449297    
2023-01-14 17:00:43,100 - --- validate (epoch=50)-----------
2023-01-14 17:00:43,101 - 148 samples (240 per mini-batch)
2023-01-14 17:00:43,610 - Epoch: [50][    1/    1]    Loss 0.379123    Top1 88.513514    Top5 99.324324    
2023-01-14 17:00:43,651 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.379

2023-01-14 17:00:43,662 - ==> Best [Top1: 89.189   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 46]
2023-01-14 17:00:43,663 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:00:43,703 - 

2023-01-14 17:00:43,703 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:00:46,953 - Epoch: [51][    6/    6]    Overall Loss 0.074827    Objective Loss 0.074827    Top1 98.677249    Top5 100.000000    LR 0.001000    Time 0.541410    
2023-01-14 17:00:46,999 - --- validate (epoch=51)-----------
2023-01-14 17:00:47,000 - 148 samples (240 per mini-batch)
2023-01-14 17:00:47,468 - Epoch: [51][    1/    1]    Loss 0.370136    Top1 88.513514    Top5 100.000000    
2023-01-14 17:00:47,504 - ==> Top1: 88.514    Top5: 100.000    Loss: 0.370

2023-01-14 17:00:47,514 - ==> Best [Top1: 89.189   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 46]
2023-01-14 17:00:47,515 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:00:47,558 - 

2023-01-14 17:00:47,558 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:00:50,319 - Epoch: [52][    6/    6]    Overall Loss 0.060646    Objective Loss 0.060646    Top1 99.470899    Top5 100.000000    LR 0.001000    Time 0.459966    
2023-01-14 17:00:50,367 - --- validate (epoch=52)-----------
2023-01-14 17:00:50,368 - 148 samples (240 per mini-batch)
2023-01-14 17:00:50,968 - Epoch: [52][    1/    1]    Loss 0.375443    Top1 86.486486    Top5 98.648649    
2023-01-14 17:00:51,016 - ==> Top1: 86.486    Top5: 98.649    Loss: 0.375

2023-01-14 17:00:51,023 - ==> Best [Top1: 89.189   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 46]
2023-01-14 17:00:51,023 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:00:51,057 - 

2023-01-14 17:00:51,058 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:00:54,259 - Epoch: [53][    6/    6]    Overall Loss 0.067415    Objective Loss 0.067415    Top1 98.941799    Top5 100.000000    LR 0.001000    Time 0.533068    
2023-01-14 17:00:54,309 - --- validate (epoch=53)-----------
2023-01-14 17:00:54,310 - 148 samples (240 per mini-batch)
2023-01-14 17:00:54,836 - Epoch: [53][    1/    1]    Loss 0.379195    Top1 87.162162    Top5 97.972973    
2023-01-14 17:00:54,882 - ==> Top1: 87.162    Top5: 97.973    Loss: 0.379

2023-01-14 17:00:54,891 - ==> Best [Top1: 89.189   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 46]
2023-01-14 17:00:54,891 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:00:54,933 - 

2023-01-14 17:00:54,933 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:00:57,734 - Epoch: [54][    6/    6]    Overall Loss 0.071608    Objective Loss 0.071608    Top1 98.941799    Top5 100.000000    LR 0.001000    Time 0.466587    
2023-01-14 17:00:57,786 - --- validate (epoch=54)-----------
2023-01-14 17:00:57,787 - 148 samples (240 per mini-batch)
2023-01-14 17:00:58,335 - Epoch: [54][    1/    1]    Loss 0.321040    Top1 90.540541    Top5 99.324324    
2023-01-14 17:00:58,378 - ==> Top1: 90.541    Top5: 99.324    Loss: 0.321

2023-01-14 17:00:58,389 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:00:58,389 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:00:58,441 - 

2023-01-14 17:00:58,441 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:01:01,170 - Epoch: [55][    6/    6]    Overall Loss 0.074210    Objective Loss 0.074210    Top1 98.941799    Top5 100.000000    LR 0.001000    Time 0.454586    
2023-01-14 17:01:01,229 - --- validate (epoch=55)-----------
2023-01-14 17:01:01,229 - 148 samples (240 per mini-batch)
2023-01-14 17:01:01,708 - Epoch: [55][    1/    1]    Loss 0.337890    Top1 88.513514    Top5 99.324324    
2023-01-14 17:01:01,748 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.338

2023-01-14 17:01:01,756 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:01:01,756 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:01:01,799 - 

2023-01-14 17:01:01,800 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:01:04,877 - Epoch: [56][    6/    6]    Overall Loss 0.099932    Objective Loss 0.099932    Top1 96.296296    Top5 100.000000    LR 0.001000    Time 0.512478    
2023-01-14 17:01:04,926 - --- validate (epoch=56)-----------
2023-01-14 17:01:04,927 - 148 samples (240 per mini-batch)
2023-01-14 17:01:05,399 - Epoch: [56][    1/    1]    Loss 0.386254    Top1 85.810811    Top5 99.324324    
2023-01-14 17:01:05,440 - ==> Top1: 85.811    Top5: 99.324    Loss: 0.386

2023-01-14 17:01:05,448 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:01:05,448 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:01:05,495 - 

2023-01-14 17:01:05,495 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:01:07,797 - Epoch: [57][    6/    6]    Overall Loss 0.103604    Objective Loss 0.103604    Top1 97.883598    Top5 100.000000    LR 0.001000    Time 0.383420    
2023-01-14 17:01:07,844 - --- validate (epoch=57)-----------
2023-01-14 17:01:07,845 - 148 samples (240 per mini-batch)
2023-01-14 17:01:08,399 - Epoch: [57][    1/    1]    Loss 0.527114    Top1 83.108108    Top5 97.297297    
2023-01-14 17:01:08,449 - ==> Top1: 83.108    Top5: 97.297    Loss: 0.527

2023-01-14 17:01:08,459 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:01:08,460 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:01:08,519 - 

2023-01-14 17:01:08,520 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:01:11,260 - Epoch: [58][    6/    6]    Overall Loss 0.100904    Objective Loss 0.100904    Top1 97.354497    Top5 100.000000    LR 0.001000    Time 0.456417    
2023-01-14 17:01:11,303 - --- validate (epoch=58)-----------
2023-01-14 17:01:11,304 - 148 samples (240 per mini-batch)
2023-01-14 17:01:11,765 - Epoch: [58][    1/    1]    Loss 0.325552    Top1 89.189189    Top5 99.324324    
2023-01-14 17:01:11,813 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.326

2023-01-14 17:01:11,821 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:01:11,822 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:01:11,864 - 

2023-01-14 17:01:11,864 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:01:14,934 - Epoch: [59][    6/    6]    Overall Loss 0.070035    Objective Loss 0.070035    Top1 98.412698    Top5 100.000000    LR 0.001000    Time 0.511143    
2023-01-14 17:01:14,992 - --- validate (epoch=59)-----------
2023-01-14 17:01:14,992 - 148 samples (240 per mini-batch)
2023-01-14 17:01:15,597 - Epoch: [59][    1/    1]    Loss 0.350403    Top1 86.486486    Top5 100.000000    
2023-01-14 17:01:15,646 - ==> Top1: 86.486    Top5: 100.000    Loss: 0.350

2023-01-14 17:01:15,654 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:01:15,654 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:01:15,691 - 

2023-01-14 17:01:15,691 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:01:18,622 - Epoch: [60][    6/    6]    Overall Loss 0.067723    Objective Loss 0.067723    Top1 98.412698    Top5 100.000000    LR 0.001000    Time 0.488143    
2023-01-14 17:01:18,680 - --- validate (epoch=60)-----------
2023-01-14 17:01:18,681 - 148 samples (240 per mini-batch)
2023-01-14 17:01:19,274 - Epoch: [60][    1/    1]    Loss 0.325868    Top1 89.189189    Top5 99.324324    
2023-01-14 17:01:19,317 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.326

2023-01-14 17:01:19,324 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:01:19,325 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:01:19,367 - 

2023-01-14 17:01:19,368 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:01:22,018 - Epoch: [61][    6/    6]    Overall Loss 0.055031    Objective Loss 0.055031    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.441356    
2023-01-14 17:01:22,062 - --- validate (epoch=61)-----------
2023-01-14 17:01:22,063 - 148 samples (240 per mini-batch)
2023-01-14 17:01:22,641 - Epoch: [61][    1/    1]    Loss 0.338305    Top1 87.837838    Top5 100.000000    
2023-01-14 17:01:22,680 - ==> Top1: 87.838    Top5: 100.000    Loss: 0.338

2023-01-14 17:01:22,689 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:01:22,689 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:01:22,738 - 

2023-01-14 17:01:22,739 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:01:25,734 - Epoch: [62][    6/    6]    Overall Loss 0.050642    Objective Loss 0.050642    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.498998    
2023-01-14 17:01:25,785 - --- validate (epoch=62)-----------
2023-01-14 17:01:25,786 - 148 samples (240 per mini-batch)
2023-01-14 17:01:26,335 - Epoch: [62][    1/    1]    Loss 0.353854    Top1 88.513514    Top5 98.648649    
2023-01-14 17:01:26,382 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.354

2023-01-14 17:01:26,393 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:01:26,394 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:01:26,436 - 

2023-01-14 17:01:26,437 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:01:29,458 - Epoch: [63][    6/    6]    Overall Loss 0.046504    Objective Loss 0.046504    Top1 99.470899    Top5 100.000000    LR 0.001000    Time 0.503080    
2023-01-14 17:01:29,499 - --- validate (epoch=63)-----------
2023-01-14 17:01:29,500 - 148 samples (240 per mini-batch)
2023-01-14 17:01:30,025 - Epoch: [63][    1/    1]    Loss 0.340445    Top1 87.837838    Top5 100.000000    
2023-01-14 17:01:30,080 - ==> Top1: 87.838    Top5: 100.000    Loss: 0.340

2023-01-14 17:01:30,091 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:01:30,091 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:01:30,126 - 

2023-01-14 17:01:30,127 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:01:32,655 - Epoch: [64][    6/    6]    Overall Loss 0.040936    Objective Loss 0.040936    Top1 99.735450    Top5 100.000000    LR 0.001000    Time 0.421189    
2023-01-14 17:01:32,699 - --- validate (epoch=64)-----------
2023-01-14 17:01:32,700 - 148 samples (240 per mini-batch)
2023-01-14 17:01:33,213 - Epoch: [64][    1/    1]    Loss 0.325674    Top1 89.864865    Top5 99.324324    
2023-01-14 17:01:33,256 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.326

2023-01-14 17:01:33,267 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:01:33,268 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:01:33,316 - 

2023-01-14 17:01:33,317 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:01:36,228 - Epoch: [65][    6/    6]    Overall Loss 0.039479    Objective Loss 0.039479    Top1 99.735450    Top5 100.000000    LR 0.001000    Time 0.484790    
2023-01-14 17:01:36,278 - --- validate (epoch=65)-----------
2023-01-14 17:01:36,279 - 148 samples (240 per mini-batch)
2023-01-14 17:01:36,746 - Epoch: [65][    1/    1]    Loss 0.370319    Top1 87.837838    Top5 98.648649    
2023-01-14 17:01:36,790 - ==> Top1: 87.838    Top5: 98.649    Loss: 0.370

2023-01-14 17:01:36,799 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:01:36,799 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:01:36,847 - 

2023-01-14 17:01:36,848 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:01:39,921 - Epoch: [66][    6/    6]    Overall Loss 0.040199    Objective Loss 0.040199    Top1 99.206349    Top5 100.000000    LR 0.001000    Time 0.511918    
2023-01-14 17:01:39,969 - --- validate (epoch=66)-----------
2023-01-14 17:01:39,969 - 148 samples (240 per mini-batch)
2023-01-14 17:01:40,551 - Epoch: [66][    1/    1]    Loss 0.341077    Top1 87.162162    Top5 99.324324    
2023-01-14 17:01:40,595 - ==> Top1: 87.162    Top5: 99.324    Loss: 0.341

2023-01-14 17:01:40,606 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:01:40,607 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:01:40,646 - 

2023-01-14 17:01:40,646 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:01:43,440 - Epoch: [67][    6/    6]    Overall Loss 0.039861    Objective Loss 0.039861    Top1 99.470899    Top5 100.000000    LR 0.001000    Time 0.465278    
2023-01-14 17:01:43,483 - --- validate (epoch=67)-----------
2023-01-14 17:01:43,484 - 148 samples (240 per mini-batch)
2023-01-14 17:01:43,954 - Epoch: [67][    1/    1]    Loss 0.326730    Top1 87.837838    Top5 98.648649    
2023-01-14 17:01:44,001 - ==> Top1: 87.838    Top5: 98.649    Loss: 0.327

2023-01-14 17:01:44,010 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:01:44,011 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:01:44,057 - 

2023-01-14 17:01:44,058 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:01:46,948 - Epoch: [68][    6/    6]    Overall Loss 0.036032    Objective Loss 0.036032    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.480929    
2023-01-14 17:01:47,008 - --- validate (epoch=68)-----------
2023-01-14 17:01:47,009 - 148 samples (240 per mini-batch)
2023-01-14 17:01:47,589 - Epoch: [68][    1/    1]    Loss 0.345002    Top1 89.864865    Top5 98.648649    
2023-01-14 17:01:47,641 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.345

2023-01-14 17:01:47,652 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:01:47,652 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:01:47,686 - 

2023-01-14 17:01:47,686 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:01:50,530 - Epoch: [69][    6/    6]    Overall Loss 0.035296    Objective Loss 0.035296    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.473713    
2023-01-14 17:01:50,576 - --- validate (epoch=69)-----------
2023-01-14 17:01:50,577 - 148 samples (240 per mini-batch)
2023-01-14 17:01:51,137 - Epoch: [69][    1/    1]    Loss 0.337455    Top1 86.486486    Top5 99.324324    
2023-01-14 17:01:51,181 - ==> Top1: 86.486    Top5: 99.324    Loss: 0.337

2023-01-14 17:01:51,193 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:01:51,196 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:01:51,245 - 

2023-01-14 17:01:51,247 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:01:54,165 - Epoch: [70][    6/    6]    Overall Loss 0.033965    Objective Loss 0.033965    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.485845    
2023-01-14 17:01:54,210 - --- validate (epoch=70)-----------
2023-01-14 17:01:54,211 - 148 samples (240 per mini-batch)
2023-01-14 17:01:54,800 - Epoch: [70][    1/    1]    Loss 0.296769    Top1 88.513514    Top5 100.000000    
2023-01-14 17:01:54,850 - ==> Top1: 88.514    Top5: 100.000    Loss: 0.297

2023-01-14 17:01:54,861 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:01:54,861 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:01:54,901 - 

2023-01-14 17:01:54,902 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:01:57,262 - Epoch: [71][    6/    6]    Overall Loss 0.033951    Objective Loss 0.033951    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.393089    
2023-01-14 17:01:57,316 - --- validate (epoch=71)-----------
2023-01-14 17:01:57,316 - 148 samples (240 per mini-batch)
2023-01-14 17:01:57,847 - Epoch: [71][    1/    1]    Loss 0.366408    Top1 87.162162    Top5 98.648649    
2023-01-14 17:01:57,887 - ==> Top1: 87.162    Top5: 98.649    Loss: 0.366

2023-01-14 17:01:57,894 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:01:57,895 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:01:57,932 - 

2023-01-14 17:01:57,932 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:02:00,799 - Epoch: [72][    6/    6]    Overall Loss 0.029840    Objective Loss 0.029840    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.477507    
2023-01-14 17:02:00,849 - --- validate (epoch=72)-----------
2023-01-14 17:02:00,850 - 148 samples (240 per mini-batch)
2023-01-14 17:02:01,371 - Epoch: [72][    1/    1]    Loss 0.329288    Top1 87.837838    Top5 100.000000    
2023-01-14 17:02:01,418 - ==> Top1: 87.838    Top5: 100.000    Loss: 0.329

2023-01-14 17:02:01,429 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:02:01,430 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:02:01,477 - 

2023-01-14 17:02:01,477 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:02:03,943 - Epoch: [73][    6/    6]    Overall Loss 0.027567    Objective Loss 0.027567    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.410731    
2023-01-14 17:02:03,988 - --- validate (epoch=73)-----------
2023-01-14 17:02:03,989 - 148 samples (240 per mini-batch)
2023-01-14 17:02:04,535 - Epoch: [73][    1/    1]    Loss 0.364116    Top1 87.837838    Top5 99.324324    
2023-01-14 17:02:04,579 - ==> Top1: 87.838    Top5: 99.324    Loss: 0.364

2023-01-14 17:02:04,588 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:02:04,590 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:02:04,644 - 

2023-01-14 17:02:04,644 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:02:08,236 - Epoch: [74][    6/    6]    Overall Loss 0.028148    Objective Loss 0.028148    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.598429    
2023-01-14 17:02:08,288 - --- validate (epoch=74)-----------
2023-01-14 17:02:08,289 - 148 samples (240 per mini-batch)
2023-01-14 17:02:08,884 - Epoch: [74][    1/    1]    Loss 0.316194    Top1 88.513514    Top5 100.000000    
2023-01-14 17:02:08,935 - ==> Top1: 88.514    Top5: 100.000    Loss: 0.316

2023-01-14 17:02:08,944 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:02:08,945 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:02:08,991 - 

2023-01-14 17:02:08,992 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:02:11,434 - Epoch: [75][    6/    6]    Overall Loss 0.026687    Objective Loss 0.026687    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.406780    
2023-01-14 17:02:11,486 - --- validate (epoch=75)-----------
2023-01-14 17:02:11,487 - 148 samples (240 per mini-batch)
2023-01-14 17:02:12,071 - Epoch: [75][    1/    1]    Loss 0.332597    Top1 88.513514    Top5 100.000000    
2023-01-14 17:02:12,109 - ==> Top1: 88.514    Top5: 100.000    Loss: 0.333

2023-01-14 17:02:12,121 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:02:12,122 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:02:12,175 - 

2023-01-14 17:02:12,176 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:02:16,098 - Epoch: [76][    6/    6]    Overall Loss 0.025604    Objective Loss 0.025604    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.653511    
2023-01-14 17:02:16,149 - --- validate (epoch=76)-----------
2023-01-14 17:02:16,149 - 148 samples (240 per mini-batch)
2023-01-14 17:02:16,763 - Epoch: [76][    1/    1]    Loss 0.330725    Top1 89.189189    Top5 99.324324    
2023-01-14 17:02:16,816 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.331

2023-01-14 17:02:16,825 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:02:16,826 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:02:16,870 - 

2023-01-14 17:02:16,870 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:02:19,770 - Epoch: [77][    6/    6]    Overall Loss 0.025881    Objective Loss 0.025881    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.483067    
2023-01-14 17:02:19,812 - --- validate (epoch=77)-----------
2023-01-14 17:02:19,812 - 148 samples (240 per mini-batch)
2023-01-14 17:02:20,304 - Epoch: [77][    1/    1]    Loss 0.330991    Top1 89.864865    Top5 99.324324    
2023-01-14 17:02:20,355 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.331

2023-01-14 17:02:20,365 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:02:20,366 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:02:20,408 - 

2023-01-14 17:02:20,409 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:02:22,795 - Epoch: [78][    6/    6]    Overall Loss 0.026001    Objective Loss 0.026001    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.397304    
2023-01-14 17:02:22,843 - --- validate (epoch=78)-----------
2023-01-14 17:02:22,844 - 148 samples (240 per mini-batch)
2023-01-14 17:02:23,325 - Epoch: [78][    1/    1]    Loss 0.338003    Top1 88.513514    Top5 98.648649    
2023-01-14 17:02:23,376 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.338

2023-01-14 17:02:23,386 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:02:23,386 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:02:23,428 - 

2023-01-14 17:02:23,428 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:02:26,266 - Epoch: [79][    6/    6]    Overall Loss 0.028285    Objective Loss 0.028285    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.472642    
2023-01-14 17:02:26,319 - --- validate (epoch=79)-----------
2023-01-14 17:02:26,320 - 148 samples (240 per mini-batch)
2023-01-14 17:02:26,829 - Epoch: [79][    1/    1]    Loss 0.343978    Top1 89.189189    Top5 97.972973    
2023-01-14 17:02:26,870 - ==> Top1: 89.189    Top5: 97.973    Loss: 0.344

2023-01-14 17:02:26,880 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:02:26,881 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:02:26,925 - 

2023-01-14 17:02:26,925 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:02:29,871 - Epoch: [80][    6/    6]    Overall Loss 0.022321    Objective Loss 0.022321    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.490714    
2023-01-14 17:02:29,920 - --- validate (epoch=80)-----------
2023-01-14 17:02:29,920 - 148 samples (240 per mini-batch)
2023-01-14 17:02:30,493 - Epoch: [80][    1/    1]    Loss 0.372407    Top1 86.486486    Top5 98.648649    
2023-01-14 17:02:30,537 - ==> Top1: 86.486    Top5: 98.649    Loss: 0.372

2023-01-14 17:02:30,548 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:02:30,549 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:02:30,592 - 

2023-01-14 17:02:30,592 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:02:33,363 - Epoch: [81][    6/    6]    Overall Loss 0.021647    Objective Loss 0.021647    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.461352    
2023-01-14 17:02:33,407 - --- validate (epoch=81)-----------
2023-01-14 17:02:33,408 - 148 samples (240 per mini-batch)
2023-01-14 17:02:33,870 - Epoch: [81][    1/    1]    Loss 0.323523    Top1 89.864865    Top5 98.648649    
2023-01-14 17:02:33,915 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.324

2023-01-14 17:02:33,923 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:02:33,923 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:02:33,973 - 

2023-01-14 17:02:33,973 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:02:36,692 - Epoch: [82][    6/    6]    Overall Loss 0.019927    Objective Loss 0.019927    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.452835    
2023-01-14 17:02:36,736 - --- validate (epoch=82)-----------
2023-01-14 17:02:36,737 - 148 samples (240 per mini-batch)
2023-01-14 17:02:37,218 - Epoch: [82][    1/    1]    Loss 0.321198    Top1 89.864865    Top5 99.324324    
2023-01-14 17:02:37,271 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.321

2023-01-14 17:02:37,284 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:02:37,284 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:02:37,337 - 

2023-01-14 17:02:37,337 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:02:39,792 - Epoch: [83][    6/    6]    Overall Loss 0.020358    Objective Loss 0.020358    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.408747    
2023-01-14 17:02:39,839 - --- validate (epoch=83)-----------
2023-01-14 17:02:39,840 - 148 samples (240 per mini-batch)
2023-01-14 17:02:40,386 - Epoch: [83][    1/    1]    Loss 0.350002    Top1 88.513514    Top5 98.648649    
2023-01-14 17:02:40,429 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.350

2023-01-14 17:02:40,440 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:02:40,440 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:02:40,482 - 

2023-01-14 17:02:40,483 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:02:43,144 - Epoch: [84][    6/    6]    Overall Loss 0.019298    Objective Loss 0.019298    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.443343    
2023-01-14 17:02:43,204 - --- validate (epoch=84)-----------
2023-01-14 17:02:43,205 - 148 samples (240 per mini-batch)
2023-01-14 17:02:43,741 - Epoch: [84][    1/    1]    Loss 0.319041    Top1 89.864865    Top5 98.648649    
2023-01-14 17:02:43,780 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.319

2023-01-14 17:02:43,791 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:02:43,792 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:02:43,828 - 

2023-01-14 17:02:43,829 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:02:46,733 - Epoch: [85][    6/    6]    Overall Loss 0.020383    Objective Loss 0.020383    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.483850    
2023-01-14 17:02:46,775 - --- validate (epoch=85)-----------
2023-01-14 17:02:46,776 - 148 samples (240 per mini-batch)
2023-01-14 17:02:47,275 - Epoch: [85][    1/    1]    Loss 0.346265    Top1 87.837838    Top5 98.648649    
2023-01-14 17:02:47,314 - ==> Top1: 87.838    Top5: 98.649    Loss: 0.346

2023-01-14 17:02:47,324 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:02:47,324 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:02:47,371 - 

2023-01-14 17:02:47,371 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:02:50,278 - Epoch: [86][    6/    6]    Overall Loss 0.019549    Objective Loss 0.019549    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.484215    
2023-01-14 17:02:50,327 - --- validate (epoch=86)-----------
2023-01-14 17:02:50,328 - 148 samples (240 per mini-batch)
2023-01-14 17:02:50,804 - Epoch: [86][    1/    1]    Loss 0.336966    Top1 89.864865    Top5 98.648649    
2023-01-14 17:02:50,861 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.337

2023-01-14 17:02:50,870 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:02:50,870 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:02:50,904 - 

2023-01-14 17:02:50,905 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:02:53,463 - Epoch: [87][    6/    6]    Overall Loss 0.018798    Objective Loss 0.018798    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.426091    
2023-01-14 17:02:53,511 - --- validate (epoch=87)-----------
2023-01-14 17:02:53,512 - 148 samples (240 per mini-batch)
2023-01-14 17:02:53,999 - Epoch: [87][    1/    1]    Loss 0.338378    Top1 87.162162    Top5 98.648649    
2023-01-14 17:02:54,037 - ==> Top1: 87.162    Top5: 98.649    Loss: 0.338

2023-01-14 17:02:54,045 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:02:54,045 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:02:54,092 - 

2023-01-14 17:02:54,092 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:02:57,338 - Epoch: [88][    6/    6]    Overall Loss 0.018981    Objective Loss 0.018981    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.540803    
2023-01-14 17:02:57,383 - --- validate (epoch=88)-----------
2023-01-14 17:02:57,385 - 148 samples (240 per mini-batch)
2023-01-14 17:02:57,975 - Epoch: [88][    1/    1]    Loss 0.329582    Top1 89.189189    Top5 97.972973    
2023-01-14 17:02:58,023 - ==> Top1: 89.189    Top5: 97.973    Loss: 0.330

2023-01-14 17:02:58,036 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:02:58,038 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:02:58,088 - 

2023-01-14 17:02:58,088 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:03:01,214 - Epoch: [89][    6/    6]    Overall Loss 0.018209    Objective Loss 0.018209    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.520713    
2023-01-14 17:03:01,256 - --- validate (epoch=89)-----------
2023-01-14 17:03:01,257 - 148 samples (240 per mini-batch)
2023-01-14 17:03:01,851 - Epoch: [89][    1/    1]    Loss 0.347705    Top1 89.189189    Top5 99.324324    
2023-01-14 17:03:01,893 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.348

2023-01-14 17:03:01,903 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:03:01,904 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:03:01,948 - 

2023-01-14 17:03:01,949 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:03:04,869 - Epoch: [90][    6/    6]    Overall Loss 0.018430    Objective Loss 0.018430    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.486423    
2023-01-14 17:03:04,913 - --- validate (epoch=90)-----------
2023-01-14 17:03:04,914 - 148 samples (240 per mini-batch)
2023-01-14 17:03:05,394 - Epoch: [90][    1/    1]    Loss 0.347269    Top1 90.540541    Top5 98.648649    
2023-01-14 17:03:05,432 - ==> Top1: 90.541    Top5: 98.649    Loss: 0.347

2023-01-14 17:03:05,445 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:03:05,446 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:03:05,497 - 

2023-01-14 17:03:05,498 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:03:08,429 - Epoch: [91][    6/    6]    Overall Loss 0.020138    Objective Loss 0.020138    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.488349    
2023-01-14 17:03:08,487 - --- validate (epoch=91)-----------
2023-01-14 17:03:08,489 - 148 samples (240 per mini-batch)
2023-01-14 17:03:09,067 - Epoch: [91][    1/    1]    Loss 0.325799    Top1 88.513514    Top5 99.324324    
2023-01-14 17:03:09,106 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.326

2023-01-14 17:03:09,115 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:03:09,116 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:03:09,159 - 

2023-01-14 17:03:09,160 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:03:12,080 - Epoch: [92][    6/    6]    Overall Loss 0.019263    Objective Loss 0.019263    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.486447    
2023-01-14 17:03:12,118 - --- validate (epoch=92)-----------
2023-01-14 17:03:12,119 - 148 samples (240 per mini-batch)
2023-01-14 17:03:12,741 - Epoch: [92][    1/    1]    Loss 0.327815    Top1 89.864865    Top5 97.972973    
2023-01-14 17:03:12,787 - ==> Top1: 89.865    Top5: 97.973    Loss: 0.328

2023-01-14 17:03:12,795 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:03:12,795 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:03:12,895 - 

2023-01-14 17:03:12,895 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:03:15,806 - Epoch: [93][    6/    6]    Overall Loss 0.018868    Objective Loss 0.018868    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.484756    
2023-01-14 17:03:15,863 - --- validate (epoch=93)-----------
2023-01-14 17:03:15,863 - 148 samples (240 per mini-batch)
2023-01-14 17:03:16,436 - Epoch: [93][    1/    1]    Loss 0.339526    Top1 88.513514    Top5 99.324324    
2023-01-14 17:03:16,494 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.340

2023-01-14 17:03:16,501 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:03:16,502 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:03:16,546 - 

2023-01-14 17:03:16,546 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:03:20,199 - Epoch: [94][    6/    6]    Overall Loss 0.018526    Objective Loss 0.018526    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.608613    
2023-01-14 17:03:20,249 - --- validate (epoch=94)-----------
2023-01-14 17:03:20,250 - 148 samples (240 per mini-batch)
2023-01-14 17:03:20,785 - Epoch: [94][    1/    1]    Loss 0.356054    Top1 89.864865    Top5 97.972973    
2023-01-14 17:03:20,826 - ==> Top1: 89.865    Top5: 97.973    Loss: 0.356

2023-01-14 17:03:20,837 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:03:20,838 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:03:20,884 - 

2023-01-14 17:03:20,885 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:03:23,485 - Epoch: [95][    6/    6]    Overall Loss 0.018336    Objective Loss 0.018336    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.432973    
2023-01-14 17:03:23,533 - --- validate (epoch=95)-----------
2023-01-14 17:03:23,534 - 148 samples (240 per mini-batch)
2023-01-14 17:03:24,108 - Epoch: [95][    1/    1]    Loss 0.333008    Top1 89.189189    Top5 98.648649    
2023-01-14 17:03:24,151 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.333

2023-01-14 17:03:24,161 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:03:24,161 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:03:24,203 - 

2023-01-14 17:03:24,204 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:03:26,997 - Epoch: [96][    6/    6]    Overall Loss 0.017937    Objective Loss 0.017937    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.465261    
2023-01-14 17:03:27,038 - --- validate (epoch=96)-----------
2023-01-14 17:03:27,039 - 148 samples (240 per mini-batch)
2023-01-14 17:03:27,628 - Epoch: [96][    1/    1]    Loss 0.351475    Top1 89.189189    Top5 99.324324    
2023-01-14 17:03:27,674 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.351

2023-01-14 17:03:27,681 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:03:27,681 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:03:27,731 - 

2023-01-14 17:03:27,732 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:03:30,695 - Epoch: [97][    6/    6]    Overall Loss 0.018232    Objective Loss 0.018232    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.492698    
2023-01-14 17:03:30,738 - --- validate (epoch=97)-----------
2023-01-14 17:03:30,738 - 148 samples (240 per mini-batch)
2023-01-14 17:03:31,198 - Epoch: [97][    1/    1]    Loss 0.342885    Top1 89.189189    Top5 97.972973    
2023-01-14 17:03:31,240 - ==> Top1: 89.189    Top5: 97.973    Loss: 0.343

2023-01-14 17:03:31,252 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:03:31,254 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:03:31,297 - 

2023-01-14 17:03:31,297 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:03:34,061 - Epoch: [98][    6/    6]    Overall Loss 0.017645    Objective Loss 0.017645    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.460276    
2023-01-14 17:03:34,113 - --- validate (epoch=98)-----------
2023-01-14 17:03:34,114 - 148 samples (240 per mini-batch)
2023-01-14 17:03:34,684 - Epoch: [98][    1/    1]    Loss 0.342219    Top1 89.189189    Top5 98.648649    
2023-01-14 17:03:34,742 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.342

2023-01-14 17:03:34,753 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:03:34,754 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:03:34,798 - 

2023-01-14 17:03:34,798 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:03:38,376 - Epoch: [99][    6/    6]    Overall Loss 0.018341    Objective Loss 0.018341    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.596089    
2023-01-14 17:03:38,419 - --- validate (epoch=99)-----------
2023-01-14 17:03:38,419 - 148 samples (240 per mini-batch)
2023-01-14 17:03:38,897 - Epoch: [99][    1/    1]    Loss 0.330437    Top1 87.837838    Top5 98.648649    
2023-01-14 17:03:38,943 - ==> Top1: 87.838    Top5: 98.649    Loss: 0.330

2023-01-14 17:03:38,953 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:03:38,954 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:03:38,991 - 

2023-01-14 17:03:38,992 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:03:41,347 - Epoch: [100][    6/    6]    Overall Loss 0.018281    Objective Loss 0.018281    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.392283    
2023-01-14 17:03:41,389 - --- validate (epoch=100)-----------
2023-01-14 17:03:41,390 - 148 samples (240 per mini-batch)
2023-01-14 17:03:41,909 - Epoch: [100][    1/    1]    Loss 0.316535    Top1 89.864865    Top5 97.972973    
2023-01-14 17:03:41,953 - ==> Top1: 89.865    Top5: 97.973    Loss: 0.317

2023-01-14 17:03:41,966 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:03:41,966 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:03:42,001 - 

2023-01-14 17:03:42,002 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:03:45,302 - Epoch: [101][    6/    6]    Overall Loss 0.018014    Objective Loss 0.018014    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.549742    
2023-01-14 17:03:45,343 - --- validate (epoch=101)-----------
2023-01-14 17:03:45,344 - 148 samples (240 per mini-batch)
2023-01-14 17:03:45,912 - Epoch: [101][    1/    1]    Loss 0.331002    Top1 88.513514    Top5 99.324324    
2023-01-14 17:03:45,951 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.331

2023-01-14 17:03:45,961 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:03:45,962 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:03:46,004 - 

2023-01-14 17:03:46,004 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:03:48,774 - Epoch: [102][    6/    6]    Overall Loss 0.017442    Objective Loss 0.017442    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.461429    
2023-01-14 17:03:48,820 - --- validate (epoch=102)-----------
2023-01-14 17:03:48,821 - 148 samples (240 per mini-batch)
2023-01-14 17:03:49,424 - Epoch: [102][    1/    1]    Loss 0.343919    Top1 89.189189    Top5 99.324324    
2023-01-14 17:03:49,487 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.344

2023-01-14 17:03:49,496 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:03:49,496 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:03:49,536 - 

2023-01-14 17:03:49,536 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:03:52,161 - Epoch: [103][    6/    6]    Overall Loss 0.017822    Objective Loss 0.017822    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.437227    
2023-01-14 17:03:52,204 - --- validate (epoch=103)-----------
2023-01-14 17:03:52,204 - 148 samples (240 per mini-batch)
2023-01-14 17:03:52,775 - Epoch: [103][    1/    1]    Loss 0.335619    Top1 89.189189    Top5 98.648649    
2023-01-14 17:03:52,812 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.336

2023-01-14 17:03:52,826 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:03:52,827 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:03:52,868 - 

2023-01-14 17:03:52,869 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:03:55,789 - Epoch: [104][    6/    6]    Overall Loss 0.017971    Objective Loss 0.017971    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.486516    
2023-01-14 17:03:55,832 - --- validate (epoch=104)-----------
2023-01-14 17:03:55,832 - 148 samples (240 per mini-batch)
2023-01-14 17:03:56,324 - Epoch: [104][    1/    1]    Loss 0.321993    Top1 89.189189    Top5 99.324324    
2023-01-14 17:03:56,371 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.322

2023-01-14 17:03:56,382 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:03:56,382 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:03:56,441 - 

2023-01-14 17:03:56,442 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:03:59,116 - Epoch: [105][    6/    6]    Overall Loss 0.018213    Objective Loss 0.018213    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.445504    
2023-01-14 17:03:59,160 - --- validate (epoch=105)-----------
2023-01-14 17:03:59,161 - 148 samples (240 per mini-batch)
2023-01-14 17:03:59,668 - Epoch: [105][    1/    1]    Loss 0.361711    Top1 87.162162    Top5 97.972973    
2023-01-14 17:03:59,705 - ==> Top1: 87.162    Top5: 97.973    Loss: 0.362

2023-01-14 17:03:59,715 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:03:59,715 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:03:59,760 - 

2023-01-14 17:03:59,761 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:04:02,444 - Epoch: [106][    6/    6]    Overall Loss 0.018169    Objective Loss 0.018169    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.446816    
2023-01-14 17:04:02,493 - --- validate (epoch=106)-----------
2023-01-14 17:04:02,493 - 148 samples (240 per mini-batch)
2023-01-14 17:04:03,015 - Epoch: [106][    1/    1]    Loss 0.340371    Top1 89.864865    Top5 98.648649    
2023-01-14 17:04:03,056 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.340

2023-01-14 17:04:03,067 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:04:03,068 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:04:03,118 - 

2023-01-14 17:04:03,120 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:04:05,635 - Epoch: [107][    6/    6]    Overall Loss 0.017083    Objective Loss 0.017083    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.418868    
2023-01-14 17:04:05,677 - --- validate (epoch=107)-----------
2023-01-14 17:04:05,678 - 148 samples (240 per mini-batch)
2023-01-14 17:04:06,198 - Epoch: [107][    1/    1]    Loss 0.323049    Top1 89.864865    Top5 98.648649    
2023-01-14 17:04:06,239 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.323

2023-01-14 17:04:06,246 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:04:06,247 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:04:06,287 - 

2023-01-14 17:04:06,288 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:04:09,031 - Epoch: [108][    6/    6]    Overall Loss 0.017912    Objective Loss 0.017912    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.456964    
2023-01-14 17:04:09,075 - --- validate (epoch=108)-----------
2023-01-14 17:04:09,076 - 148 samples (240 per mini-batch)
2023-01-14 17:04:09,555 - Epoch: [108][    1/    1]    Loss 0.324606    Top1 88.513514    Top5 99.324324    
2023-01-14 17:04:09,592 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.325

2023-01-14 17:04:09,606 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:04:09,606 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:04:09,656 - 

2023-01-14 17:04:09,657 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:04:12,723 - Epoch: [109][    6/    6]    Overall Loss 0.017444    Objective Loss 0.017444    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.510824    
2023-01-14 17:04:12,769 - --- validate (epoch=109)-----------
2023-01-14 17:04:12,769 - 148 samples (240 per mini-batch)
2023-01-14 17:04:13,239 - Epoch: [109][    1/    1]    Loss 0.339083    Top1 88.513514    Top5 98.648649    
2023-01-14 17:04:13,292 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.339

2023-01-14 17:04:13,302 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:04:13,302 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:04:13,338 - 

2023-01-14 17:04:13,339 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:04:16,449 - Epoch: [110][    6/    6]    Overall Loss 0.017678    Objective Loss 0.017678    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.518116    
2023-01-14 17:04:16,500 - --- validate (epoch=110)-----------
2023-01-14 17:04:16,500 - 148 samples (240 per mini-batch)
2023-01-14 17:04:17,084 - Epoch: [110][    1/    1]    Loss 0.333552    Top1 88.513514    Top5 97.972973    
2023-01-14 17:04:17,164 - ==> Top1: 88.514    Top5: 97.973    Loss: 0.334

2023-01-14 17:04:17,178 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:04:17,179 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:04:17,248 - 

2023-01-14 17:04:17,248 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:04:20,935 - Epoch: [111][    6/    6]    Overall Loss 0.017498    Objective Loss 0.017498    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.614204    
2023-01-14 17:04:20,978 - --- validate (epoch=111)-----------
2023-01-14 17:04:20,979 - 148 samples (240 per mini-batch)
2023-01-14 17:04:21,450 - Epoch: [111][    1/    1]    Loss 0.342402    Top1 88.513514    Top5 98.648649    
2023-01-14 17:04:21,490 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.342

2023-01-14 17:04:21,500 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:04:21,500 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:04:21,545 - 

2023-01-14 17:04:21,546 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:04:24,373 - Epoch: [112][    6/    6]    Overall Loss 0.016998    Objective Loss 0.016998    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.470982    
2023-01-14 17:04:24,415 - --- validate (epoch=112)-----------
2023-01-14 17:04:24,416 - 148 samples (240 per mini-batch)
2023-01-14 17:04:24,962 - Epoch: [112][    1/    1]    Loss 0.336449    Top1 89.864865    Top5 97.972973    
2023-01-14 17:04:25,004 - ==> Top1: 89.865    Top5: 97.973    Loss: 0.336

2023-01-14 17:04:25,014 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:04:25,014 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:04:25,059 - 

2023-01-14 17:04:25,060 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:04:27,433 - Epoch: [113][    6/    6]    Overall Loss 0.016336    Objective Loss 0.016336    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.395297    
2023-01-14 17:04:27,487 - --- validate (epoch=113)-----------
2023-01-14 17:04:27,488 - 148 samples (240 per mini-batch)
2023-01-14 17:04:27,980 - Epoch: [113][    1/    1]    Loss 0.328010    Top1 89.189189    Top5 98.648649    
2023-01-14 17:04:28,030 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.328

2023-01-14 17:04:28,039 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:04:28,040 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:04:28,083 - 

2023-01-14 17:04:28,083 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:04:30,558 - Epoch: [114][    6/    6]    Overall Loss 0.016938    Objective Loss 0.016938    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.412184    
2023-01-14 17:04:30,611 - --- validate (epoch=114)-----------
2023-01-14 17:04:30,613 - 148 samples (240 per mini-batch)
2023-01-14 17:04:31,146 - Epoch: [114][    1/    1]    Loss 0.335748    Top1 89.189189    Top5 98.648649    
2023-01-14 17:04:31,186 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.336

2023-01-14 17:04:31,199 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:04:31,199 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:04:31,240 - 

2023-01-14 17:04:31,241 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:04:33,838 - Epoch: [115][    6/    6]    Overall Loss 0.016890    Objective Loss 0.016890    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.432439    
2023-01-14 17:04:33,882 - --- validate (epoch=115)-----------
2023-01-14 17:04:33,882 - 148 samples (240 per mini-batch)
2023-01-14 17:04:34,492 - Epoch: [115][    1/    1]    Loss 0.322432    Top1 88.513514    Top5 99.324324    
2023-01-14 17:04:34,550 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.322

2023-01-14 17:04:34,562 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:04:34,562 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:04:34,609 - 

2023-01-14 17:04:34,609 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:04:37,453 - Epoch: [116][    6/    6]    Overall Loss 0.016938    Objective Loss 0.016938    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.473715    
2023-01-14 17:04:37,514 - --- validate (epoch=116)-----------
2023-01-14 17:04:37,515 - 148 samples (240 per mini-batch)
2023-01-14 17:04:38,032 - Epoch: [116][    1/    1]    Loss 0.345609    Top1 89.189189    Top5 99.324324    
2023-01-14 17:04:38,082 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.346

2023-01-14 17:04:38,093 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:04:38,094 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:04:38,137 - 

2023-01-14 17:04:38,138 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:04:40,989 - Epoch: [117][    6/    6]    Overall Loss 0.016988    Objective Loss 0.016988    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.474930    
2023-01-14 17:04:41,035 - --- validate (epoch=117)-----------
2023-01-14 17:04:41,035 - 148 samples (240 per mini-batch)
2023-01-14 17:04:41,552 - Epoch: [117][    1/    1]    Loss 0.325477    Top1 90.540541    Top5 98.648649    
2023-01-14 17:04:41,593 - ==> Top1: 90.541    Top5: 98.649    Loss: 0.325

2023-01-14 17:04:41,607 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:04:41,608 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:04:41,654 - 

2023-01-14 17:04:41,654 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:04:44,371 - Epoch: [118][    6/    6]    Overall Loss 0.016691    Objective Loss 0.016691    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.452433    
2023-01-14 17:04:44,415 - --- validate (epoch=118)-----------
2023-01-14 17:04:44,416 - 148 samples (240 per mini-batch)
2023-01-14 17:04:44,907 - Epoch: [118][    1/    1]    Loss 0.315562    Top1 90.540541    Top5 97.972973    
2023-01-14 17:04:44,941 - ==> Top1: 90.541    Top5: 97.973    Loss: 0.316

2023-01-14 17:04:44,956 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:04:44,956 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:04:45,001 - 

2023-01-14 17:04:45,001 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:04:47,903 - Epoch: [119][    6/    6]    Overall Loss 0.016675    Objective Loss 0.016675    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.483377    
2023-01-14 17:04:47,945 - --- validate (epoch=119)-----------
2023-01-14 17:04:47,946 - 148 samples (240 per mini-batch)
2023-01-14 17:04:48,429 - Epoch: [119][    1/    1]    Loss 0.356416    Top1 87.837838    Top5 98.648649    
2023-01-14 17:04:48,476 - ==> Top1: 87.838    Top5: 98.649    Loss: 0.356

2023-01-14 17:04:48,487 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:04:48,487 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:04:48,539 - 

2023-01-14 17:04:48,540 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:04:51,028 - Epoch: [120][    6/    6]    Overall Loss 0.016525    Objective Loss 0.016525    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.414426    
2023-01-14 17:04:51,072 - --- validate (epoch=120)-----------
2023-01-14 17:04:51,073 - 148 samples (240 per mini-batch)
2023-01-14 17:04:51,595 - Epoch: [120][    1/    1]    Loss 0.354245    Top1 88.513514    Top5 98.648649    
2023-01-14 17:04:51,635 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.354

2023-01-14 17:04:51,647 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:04:51,650 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:04:51,693 - 

2023-01-14 17:04:51,694 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:04:54,140 - Epoch: [121][    6/    6]    Overall Loss 0.016975    Objective Loss 0.016975    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.407080    
2023-01-14 17:04:54,189 - --- validate (epoch=121)-----------
2023-01-14 17:04:54,189 - 148 samples (240 per mini-batch)
2023-01-14 17:04:54,768 - Epoch: [121][    1/    1]    Loss 0.353443    Top1 88.513514    Top5 99.324324    
2023-01-14 17:04:54,805 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.353

2023-01-14 17:04:54,817 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:04:54,818 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:04:54,861 - 

2023-01-14 17:04:54,862 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:04:58,276 - Epoch: [122][    6/    6]    Overall Loss 0.016987    Objective Loss 0.016987    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.568810    
2023-01-14 17:04:58,327 - --- validate (epoch=122)-----------
2023-01-14 17:04:58,328 - 148 samples (240 per mini-batch)
2023-01-14 17:04:58,921 - Epoch: [122][    1/    1]    Loss 0.330771    Top1 89.189189    Top5 99.324324    
2023-01-14 17:04:58,964 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.331

2023-01-14 17:04:58,976 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:04:58,976 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:04:59,023 - 

2023-01-14 17:04:59,024 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:05:02,160 - Epoch: [123][    6/    6]    Overall Loss 0.016236    Objective Loss 0.016236    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.522256    
2023-01-14 17:05:02,206 - --- validate (epoch=123)-----------
2023-01-14 17:05:02,206 - 148 samples (240 per mini-batch)
2023-01-14 17:05:02,799 - Epoch: [123][    1/    1]    Loss 0.356634    Top1 89.864865    Top5 98.648649    
2023-01-14 17:05:02,835 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.357

2023-01-14 17:05:02,847 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 54]
2023-01-14 17:05:02,848 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:05:02,887 - 

2023-01-14 17:05:02,887 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:05:05,658 - Epoch: [124][    6/    6]    Overall Loss 0.016068    Objective Loss 0.016068    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.461549    
2023-01-14 17:05:05,701 - --- validate (epoch=124)-----------
2023-01-14 17:05:05,701 - 148 samples (240 per mini-batch)
2023-01-14 17:05:06,176 - Epoch: [124][    1/    1]    Loss 0.339852    Top1 90.540541    Top5 99.324324    
2023-01-14 17:05:06,222 - ==> Top1: 90.541    Top5: 99.324    Loss: 0.340

2023-01-14 17:05:06,231 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 124]
2023-01-14 17:05:06,231 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:05:06,279 - 

2023-01-14 17:05:06,280 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:05:09,557 - Epoch: [125][    6/    6]    Overall Loss 0.016467    Objective Loss 0.016467    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.545880    
2023-01-14 17:05:09,602 - --- validate (epoch=125)-----------
2023-01-14 17:05:09,603 - 148 samples (240 per mini-batch)
2023-01-14 17:05:10,168 - Epoch: [125][    1/    1]    Loss 0.349396    Top1 89.189189    Top5 98.648649    
2023-01-14 17:05:10,211 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.349

2023-01-14 17:05:10,222 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 124]
2023-01-14 17:05:10,223 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:05:10,264 - 

2023-01-14 17:05:10,265 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:05:13,176 - Epoch: [126][    6/    6]    Overall Loss 0.015755    Objective Loss 0.015755    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.485008    
2023-01-14 17:05:13,246 - --- validate (epoch=126)-----------
2023-01-14 17:05:13,246 - 148 samples (240 per mini-batch)
2023-01-14 17:05:13,854 - Epoch: [126][    1/    1]    Loss 0.324177    Top1 87.837838    Top5 98.648649    
2023-01-14 17:05:13,905 - ==> Top1: 87.838    Top5: 98.649    Loss: 0.324

2023-01-14 17:05:13,913 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 124]
2023-01-14 17:05:13,913 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:05:13,951 - 

2023-01-14 17:05:13,952 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:05:17,523 - Epoch: [127][    6/    6]    Overall Loss 0.015798    Objective Loss 0.015798    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.594898    
2023-01-14 17:05:17,568 - --- validate (epoch=127)-----------
2023-01-14 17:05:17,568 - 148 samples (240 per mini-batch)
2023-01-14 17:05:18,061 - Epoch: [127][    1/    1]    Loss 0.311758    Top1 89.864865    Top5 99.324324    
2023-01-14 17:05:18,112 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.312

2023-01-14 17:05:18,122 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 124]
2023-01-14 17:05:18,122 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:05:18,160 - 

2023-01-14 17:05:18,160 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:05:21,399 - Epoch: [128][    6/    6]    Overall Loss 0.015786    Objective Loss 0.015786    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.539590    
2023-01-14 17:05:21,449 - --- validate (epoch=128)-----------
2023-01-14 17:05:21,450 - 148 samples (240 per mini-batch)
2023-01-14 17:05:21,917 - Epoch: [128][    1/    1]    Loss 0.330711    Top1 88.513514    Top5 98.648649    
2023-01-14 17:05:21,958 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.331

2023-01-14 17:05:21,968 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 124]
2023-01-14 17:05:21,969 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:05:22,015 - 

2023-01-14 17:05:22,016 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:05:25,131 - Epoch: [129][    6/    6]    Overall Loss 0.015491    Objective Loss 0.015491    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.518799    
2023-01-14 17:05:25,174 - --- validate (epoch=129)-----------
2023-01-14 17:05:25,175 - 148 samples (240 per mini-batch)
2023-01-14 17:05:25,736 - Epoch: [129][    1/    1]    Loss 0.336497    Top1 89.864865    Top5 100.000000    
2023-01-14 17:05:25,776 - ==> Top1: 89.865    Top5: 100.000    Loss: 0.336

2023-01-14 17:05:25,791 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 124]
2023-01-14 17:05:25,791 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:05:25,834 - 

2023-01-14 17:05:25,834 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:05:28,302 - Epoch: [130][    6/    6]    Overall Loss 0.015971    Objective Loss 0.015971    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.410999    
2023-01-14 17:05:28,344 - --- validate (epoch=130)-----------
2023-01-14 17:05:28,345 - 148 samples (240 per mini-batch)
2023-01-14 17:05:28,916 - Epoch: [130][    1/    1]    Loss 0.338615    Top1 88.513514    Top5 99.324324    
2023-01-14 17:05:28,958 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.339

2023-01-14 17:05:28,969 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 124]
2023-01-14 17:05:28,969 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:05:29,010 - 

2023-01-14 17:05:29,011 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:05:31,798 - Epoch: [131][    6/    6]    Overall Loss 0.016151    Objective Loss 0.016151    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.464170    
2023-01-14 17:05:31,841 - --- validate (epoch=131)-----------
2023-01-14 17:05:31,841 - 148 samples (240 per mini-batch)
2023-01-14 17:05:32,415 - Epoch: [131][    1/    1]    Loss 0.340079    Top1 89.189189    Top5 98.648649    
2023-01-14 17:05:32,467 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.340

2023-01-14 17:05:32,482 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 124]
2023-01-14 17:05:32,483 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:05:32,530 - 

2023-01-14 17:05:32,531 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:05:35,466 - Epoch: [132][    6/    6]    Overall Loss 0.015679    Objective Loss 0.015679    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.488928    
2023-01-14 17:05:35,504 - --- validate (epoch=132)-----------
2023-01-14 17:05:35,505 - 148 samples (240 per mini-batch)
2023-01-14 17:05:36,104 - Epoch: [132][    1/    1]    Loss 0.357339    Top1 89.189189    Top5 99.324324    
2023-01-14 17:05:36,149 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.357

2023-01-14 17:05:36,164 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 124]
2023-01-14 17:05:36,164 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:05:36,221 - 

2023-01-14 17:05:36,221 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:05:38,926 - Epoch: [133][    6/    6]    Overall Loss 0.015568    Objective Loss 0.015568    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.450614    
2023-01-14 17:05:38,978 - --- validate (epoch=133)-----------
2023-01-14 17:05:38,980 - 148 samples (240 per mini-batch)
2023-01-14 17:05:39,485 - Epoch: [133][    1/    1]    Loss 0.337134    Top1 87.837838    Top5 98.648649    
2023-01-14 17:05:39,531 - ==> Top1: 87.838    Top5: 98.649    Loss: 0.337

2023-01-14 17:05:39,545 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 124]
2023-01-14 17:05:39,545 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:05:39,585 - 

2023-01-14 17:05:39,586 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:05:42,071 - Epoch: [134][    6/    6]    Overall Loss 0.015850    Objective Loss 0.015850    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.413833    
2023-01-14 17:05:42,115 - --- validate (epoch=134)-----------
2023-01-14 17:05:42,116 - 148 samples (240 per mini-batch)
2023-01-14 17:05:42,660 - Epoch: [134][    1/    1]    Loss 0.337115    Top1 89.864865    Top5 99.324324    
2023-01-14 17:05:42,698 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.337

2023-01-14 17:05:42,711 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 124]
2023-01-14 17:05:42,711 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:05:42,749 - 

2023-01-14 17:05:42,750 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:05:45,643 - Epoch: [135][    6/    6]    Overall Loss 0.016556    Objective Loss 0.016556    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.481911    
2023-01-14 17:05:45,683 - --- validate (epoch=135)-----------
2023-01-14 17:05:45,684 - 148 samples (240 per mini-batch)
2023-01-14 17:05:46,193 - Epoch: [135][    1/    1]    Loss 0.358692    Top1 89.189189    Top5 99.324324    
2023-01-14 17:05:46,234 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.359

2023-01-14 17:05:46,246 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 124]
2023-01-14 17:05:46,247 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:05:46,297 - 

2023-01-14 17:05:46,297 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:05:49,191 - Epoch: [136][    6/    6]    Overall Loss 0.015706    Objective Loss 0.015706    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.482104    
2023-01-14 17:05:49,235 - --- validate (epoch=136)-----------
2023-01-14 17:05:49,236 - 148 samples (240 per mini-batch)
2023-01-14 17:05:49,711 - Epoch: [136][    1/    1]    Loss 0.329594    Top1 90.540541    Top5 99.324324    
2023-01-14 17:05:49,753 - ==> Top1: 90.541    Top5: 99.324    Loss: 0.330

2023-01-14 17:05:49,764 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 136]
2023-01-14 17:05:49,765 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:05:49,817 - 

2023-01-14 17:05:49,819 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:05:53,162 - Epoch: [137][    6/    6]    Overall Loss 0.015910    Objective Loss 0.015910    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.556727    
2023-01-14 17:05:53,206 - --- validate (epoch=137)-----------
2023-01-14 17:05:53,207 - 148 samples (240 per mini-batch)
2023-01-14 17:05:53,728 - Epoch: [137][    1/    1]    Loss 0.353096    Top1 88.513514    Top5 99.324324    
2023-01-14 17:05:53,765 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.353

2023-01-14 17:05:53,776 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 136]
2023-01-14 17:05:53,776 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:05:53,814 - 

2023-01-14 17:05:53,814 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:05:56,149 - Epoch: [138][    6/    6]    Overall Loss 0.016008    Objective Loss 0.016008    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.388815    
2023-01-14 17:05:56,193 - --- validate (epoch=138)-----------
2023-01-14 17:05:56,194 - 148 samples (240 per mini-batch)
2023-01-14 17:05:56,727 - Epoch: [138][    1/    1]    Loss 0.322350    Top1 89.189189    Top5 98.648649    
2023-01-14 17:05:56,768 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.322

2023-01-14 17:05:56,776 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 136]
2023-01-14 17:05:56,777 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:05:56,825 - 

2023-01-14 17:05:56,825 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:05:59,745 - Epoch: [139][    6/    6]    Overall Loss 0.016045    Objective Loss 0.016045    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.486465    
2023-01-14 17:05:59,788 - --- validate (epoch=139)-----------
2023-01-14 17:05:59,789 - 148 samples (240 per mini-batch)
2023-01-14 17:06:00,269 - Epoch: [139][    1/    1]    Loss 0.336311    Top1 89.864865    Top5 97.972973    
2023-01-14 17:06:00,316 - ==> Top1: 89.865    Top5: 97.973    Loss: 0.336

2023-01-14 17:06:00,325 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 136]
2023-01-14 17:06:00,325 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:06:00,372 - 

2023-01-14 17:06:00,373 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:06:02,982 - Epoch: [140][    6/    6]    Overall Loss 0.015377    Objective Loss 0.015377    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.434541    
2023-01-14 17:06:03,025 - --- validate (epoch=140)-----------
2023-01-14 17:06:03,026 - 148 samples (240 per mini-batch)
2023-01-14 17:06:03,592 - Epoch: [140][    1/    1]    Loss 0.331146    Top1 88.513514    Top5 97.972973    
2023-01-14 17:06:03,637 - ==> Top1: 88.514    Top5: 97.973    Loss: 0.331

2023-01-14 17:06:03,655 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 136]
2023-01-14 17:06:03,655 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:06:03,724 - 

2023-01-14 17:06:03,724 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:06:06,341 - Epoch: [141][    6/    6]    Overall Loss 0.015753    Objective Loss 0.015753    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.435732    
2023-01-14 17:06:06,384 - --- validate (epoch=141)-----------
2023-01-14 17:06:06,384 - 148 samples (240 per mini-batch)
2023-01-14 17:06:06,947 - Epoch: [141][    1/    1]    Loss 0.338373    Top1 87.837838    Top5 99.324324    
2023-01-14 17:06:06,996 - ==> Top1: 87.838    Top5: 99.324    Loss: 0.338

2023-01-14 17:06:07,004 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 136]
2023-01-14 17:06:07,005 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:06:07,045 - 

2023-01-14 17:06:07,045 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:06:09,749 - Epoch: [142][    6/    6]    Overall Loss 0.015022    Objective Loss 0.015022    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.450327    
2023-01-14 17:06:09,806 - --- validate (epoch=142)-----------
2023-01-14 17:06:09,807 - 148 samples (240 per mini-batch)
2023-01-14 17:06:10,314 - Epoch: [142][    1/    1]    Loss 0.357425    Top1 88.513514    Top5 98.648649    
2023-01-14 17:06:10,356 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.357

2023-01-14 17:06:10,367 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 136]
2023-01-14 17:06:10,367 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:06:10,412 - 

2023-01-14 17:06:10,412 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:06:13,035 - Epoch: [143][    6/    6]    Overall Loss 0.015150    Objective Loss 0.015150    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.437013    
2023-01-14 17:06:13,076 - --- validate (epoch=143)-----------
2023-01-14 17:06:13,077 - 148 samples (240 per mini-batch)
2023-01-14 17:06:13,646 - Epoch: [143][    1/    1]    Loss 0.344476    Top1 89.189189    Top5 98.648649    
2023-01-14 17:06:13,714 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.344

2023-01-14 17:06:13,721 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 136]
2023-01-14 17:06:13,722 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:06:13,768 - 

2023-01-14 17:06:13,768 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:06:17,507 - Epoch: [144][    6/    6]    Overall Loss 0.015183    Objective Loss 0.015183    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.622721    
2023-01-14 17:06:17,552 - --- validate (epoch=144)-----------
2023-01-14 17:06:17,553 - 148 samples (240 per mini-batch)
2023-01-14 17:06:18,130 - Epoch: [144][    1/    1]    Loss 0.354209    Top1 88.513514    Top5 98.648649    
2023-01-14 17:06:18,183 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.354

2023-01-14 17:06:18,193 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 136]
2023-01-14 17:06:18,193 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:06:18,233 - 

2023-01-14 17:06:18,234 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:06:20,889 - Epoch: [145][    6/    6]    Overall Loss 0.014986    Objective Loss 0.014986    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.442302    
2023-01-14 17:06:20,929 - --- validate (epoch=145)-----------
2023-01-14 17:06:20,930 - 148 samples (240 per mini-batch)
2023-01-14 17:06:21,512 - Epoch: [145][    1/    1]    Loss 0.358448    Top1 87.837838    Top5 98.648649    
2023-01-14 17:06:21,566 - ==> Top1: 87.838    Top5: 98.649    Loss: 0.358

2023-01-14 17:06:21,577 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 136]
2023-01-14 17:06:21,577 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:06:21,614 - 

2023-01-14 17:06:21,615 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:06:24,437 - Epoch: [146][    6/    6]    Overall Loss 0.015730    Objective Loss 0.015730    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.470013    
2023-01-14 17:06:24,482 - --- validate (epoch=146)-----------
2023-01-14 17:06:24,482 - 148 samples (240 per mini-batch)
2023-01-14 17:06:25,031 - Epoch: [146][    1/    1]    Loss 0.350896    Top1 87.837838    Top5 99.324324    
2023-01-14 17:06:25,073 - ==> Top1: 87.838    Top5: 99.324    Loss: 0.351

2023-01-14 17:06:25,082 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 136]
2023-01-14 17:06:25,083 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:06:25,130 - 

2023-01-14 17:06:25,130 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:06:27,761 - Epoch: [147][    6/    6]    Overall Loss 0.015369    Objective Loss 0.015369    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.438203    
2023-01-14 17:06:27,810 - --- validate (epoch=147)-----------
2023-01-14 17:06:27,810 - 148 samples (240 per mini-batch)
2023-01-14 17:06:28,372 - Epoch: [147][    1/    1]    Loss 0.348215    Top1 89.189189    Top5 98.648649    
2023-01-14 17:06:28,413 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.348

2023-01-14 17:06:28,423 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 136]
2023-01-14 17:06:28,425 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:06:28,466 - 

2023-01-14 17:06:28,467 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:06:31,464 - Epoch: [148][    6/    6]    Overall Loss 0.014929    Objective Loss 0.014929    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.499276    
2023-01-14 17:06:31,521 - --- validate (epoch=148)-----------
2023-01-14 17:06:31,522 - 148 samples (240 per mini-batch)
2023-01-14 17:06:32,063 - Epoch: [148][    1/    1]    Loss 0.334665    Top1 89.189189    Top5 98.648649    
2023-01-14 17:06:32,104 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.335

2023-01-14 17:06:32,113 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 136]
2023-01-14 17:06:32,113 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:06:32,163 - 

2023-01-14 17:06:32,163 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:06:34,931 - Epoch: [149][    6/    6]    Overall Loss 0.015465    Objective Loss 0.015465    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.461013    
2023-01-14 17:06:34,973 - --- validate (epoch=149)-----------
2023-01-14 17:06:34,974 - 148 samples (240 per mini-batch)
2023-01-14 17:06:35,566 - Epoch: [149][    1/    1]    Loss 0.332000    Top1 88.513514    Top5 98.648649    
2023-01-14 17:06:35,610 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.332

2023-01-14 17:06:35,618 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 136]
2023-01-14 17:06:35,618 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:06:35,659 - 

2023-01-14 17:06:35,660 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:06:39,101 - Epoch: [150][    6/    6]    Overall Loss 0.015385    Objective Loss 0.015385    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.573269    
2023-01-14 17:06:39,144 - --- validate (epoch=150)-----------
2023-01-14 17:06:39,145 - 148 samples (240 per mini-batch)
2023-01-14 17:06:39,738 - Epoch: [150][    1/    1]    Loss 0.342168    Top1 89.189189    Top5 97.972973    
2023-01-14 17:06:39,781 - ==> Top1: 89.189    Top5: 97.973    Loss: 0.342

2023-01-14 17:06:39,791 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 136]
2023-01-14 17:06:39,791 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:06:39,834 - 

2023-01-14 17:06:39,834 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:06:42,295 - Epoch: [151][    6/    6]    Overall Loss 0.015565    Objective Loss 0.015565    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.409923    
2023-01-14 17:06:42,339 - --- validate (epoch=151)-----------
2023-01-14 17:06:42,340 - 148 samples (240 per mini-batch)
2023-01-14 17:06:42,948 - Epoch: [151][    1/    1]    Loss 0.332526    Top1 89.864865    Top5 98.648649    
2023-01-14 17:06:42,999 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.333

2023-01-14 17:06:43,008 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 136]
2023-01-14 17:06:43,009 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:06:43,054 - 

2023-01-14 17:06:43,055 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:06:46,015 - Epoch: [152][    6/    6]    Overall Loss 0.014917    Objective Loss 0.014917    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.493126    
2023-01-14 17:06:46,056 - --- validate (epoch=152)-----------
2023-01-14 17:06:46,056 - 148 samples (240 per mini-batch)
2023-01-14 17:06:46,628 - Epoch: [152][    1/    1]    Loss 0.338087    Top1 89.189189    Top5 97.972973    
2023-01-14 17:06:46,673 - ==> Top1: 89.189    Top5: 97.973    Loss: 0.338

2023-01-14 17:06:46,684 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 136]
2023-01-14 17:06:46,685 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:06:46,719 - 

2023-01-14 17:06:46,720 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:06:49,728 - Epoch: [153][    6/    6]    Overall Loss 0.014776    Objective Loss 0.014776    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.501254    
2023-01-14 17:06:49,767 - --- validate (epoch=153)-----------
2023-01-14 17:06:49,768 - 148 samples (240 per mini-batch)
2023-01-14 17:06:50,317 - Epoch: [153][    1/    1]    Loss 0.349634    Top1 89.189189    Top5 98.648649    
2023-01-14 17:06:50,357 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.350

2023-01-14 17:06:50,367 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 136]
2023-01-14 17:06:50,370 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:06:50,409 - 

2023-01-14 17:06:50,410 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:06:53,934 - Epoch: [154][    6/    6]    Overall Loss 0.015182    Objective Loss 0.015182    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.586658    
2023-01-14 17:06:53,982 - --- validate (epoch=154)-----------
2023-01-14 17:06:53,983 - 148 samples (240 per mini-batch)
2023-01-14 17:06:54,510 - Epoch: [154][    1/    1]    Loss 0.334166    Top1 88.513514    Top5 99.324324    
2023-01-14 17:06:54,552 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.334

2023-01-14 17:06:54,561 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 136]
2023-01-14 17:06:54,562 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:06:54,605 - 

2023-01-14 17:06:54,606 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:06:57,339 - Epoch: [155][    6/    6]    Overall Loss 0.014622    Objective Loss 0.014622    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.455105    
2023-01-14 17:06:57,379 - --- validate (epoch=155)-----------
2023-01-14 17:06:57,379 - 148 samples (240 per mini-batch)
2023-01-14 17:06:57,870 - Epoch: [155][    1/    1]    Loss 0.323757    Top1 89.864865    Top5 98.648649    
2023-01-14 17:06:57,911 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.324

2023-01-14 17:06:57,919 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 136]
2023-01-14 17:06:57,920 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:06:57,964 - 

2023-01-14 17:06:57,964 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:07:00,766 - Epoch: [156][    6/    6]    Overall Loss 0.014894    Objective Loss 0.014894    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.466862    
2023-01-14 17:07:00,810 - --- validate (epoch=156)-----------
2023-01-14 17:07:00,811 - 148 samples (240 per mini-batch)
2023-01-14 17:07:01,363 - Epoch: [156][    1/    1]    Loss 0.353885    Top1 87.837838    Top5 98.648649    
2023-01-14 17:07:01,415 - ==> Top1: 87.838    Top5: 98.649    Loss: 0.354

2023-01-14 17:07:01,428 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 136]
2023-01-14 17:07:01,428 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:07:01,473 - 

2023-01-14 17:07:01,474 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:07:04,221 - Epoch: [157][    6/    6]    Overall Loss 0.015270    Objective Loss 0.015270    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.457647    
2023-01-14 17:07:04,280 - --- validate (epoch=157)-----------
2023-01-14 17:07:04,280 - 148 samples (240 per mini-batch)
2023-01-14 17:07:04,861 - Epoch: [157][    1/    1]    Loss 0.323430    Top1 89.864865    Top5 98.648649    
2023-01-14 17:07:04,924 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.323

2023-01-14 17:07:04,935 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 136]
2023-01-14 17:07:04,938 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:07:04,979 - 

2023-01-14 17:07:04,979 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:07:07,305 - Epoch: [158][    6/    6]    Overall Loss 0.015454    Objective Loss 0.015454    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.387397    
2023-01-14 17:07:07,358 - --- validate (epoch=158)-----------
2023-01-14 17:07:07,359 - 148 samples (240 per mini-batch)
2023-01-14 17:07:07,906 - Epoch: [158][    1/    1]    Loss 0.345526    Top1 87.837838    Top5 98.648649    
2023-01-14 17:07:07,942 - ==> Top1: 87.838    Top5: 98.649    Loss: 0.346

2023-01-14 17:07:07,953 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 136]
2023-01-14 17:07:07,953 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:07:08,005 - 

2023-01-14 17:07:08,005 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:07:10,749 - Epoch: [159][    6/    6]    Overall Loss 0.015122    Objective Loss 0.015122    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.457107    
2023-01-14 17:07:10,795 - --- validate (epoch=159)-----------
2023-01-14 17:07:10,796 - 148 samples (240 per mini-batch)
2023-01-14 17:07:11,268 - Epoch: [159][    1/    1]    Loss 0.362402    Top1 87.837838    Top5 98.648649    
2023-01-14 17:07:11,305 - ==> Top1: 87.838    Top5: 98.649    Loss: 0.362

2023-01-14 17:07:11,314 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 136]
2023-01-14 17:07:11,314 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:07:11,363 - 

2023-01-14 17:07:11,364 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:07:15,021 - Epoch: [160][    6/    6]    Overall Loss 0.014790    Objective Loss 0.014790    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.608789    
2023-01-14 17:07:15,071 - --- validate (epoch=160)-----------
2023-01-14 17:07:15,072 - 148 samples (240 per mini-batch)
2023-01-14 17:07:15,607 - Epoch: [160][    1/    1]    Loss 0.332526    Top1 87.837838    Top5 99.324324    
2023-01-14 17:07:15,655 - ==> Top1: 87.838    Top5: 99.324    Loss: 0.333

2023-01-14 17:07:15,665 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 136]
2023-01-14 17:07:15,666 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:07:15,713 - 

2023-01-14 17:07:15,715 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:07:18,571 - Epoch: [161][    6/    6]    Overall Loss 0.014723    Objective Loss 0.014723    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.475648    
2023-01-14 17:07:18,641 - --- validate (epoch=161)-----------
2023-01-14 17:07:18,642 - 148 samples (240 per mini-batch)
2023-01-14 17:07:19,133 - Epoch: [161][    1/    1]    Loss 0.345417    Top1 87.837838    Top5 99.324324    
2023-01-14 17:07:19,180 - ==> Top1: 87.838    Top5: 99.324    Loss: 0.345

2023-01-14 17:07:19,187 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 136]
2023-01-14 17:07:19,188 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:07:19,248 - 

2023-01-14 17:07:19,249 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:07:22,189 - Epoch: [162][    6/    6]    Overall Loss 0.014561    Objective Loss 0.014561    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.489771    
2023-01-14 17:07:22,231 - --- validate (epoch=162)-----------
2023-01-14 17:07:22,232 - 148 samples (240 per mini-batch)
2023-01-14 17:07:22,801 - Epoch: [162][    1/    1]    Loss 0.353275    Top1 88.513514    Top5 99.324324    
2023-01-14 17:07:22,845 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.353

2023-01-14 17:07:22,856 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 136]
2023-01-14 17:07:22,857 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:07:22,941 - 

2023-01-14 17:07:22,942 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:07:25,443 - Epoch: [163][    6/    6]    Overall Loss 0.014656    Objective Loss 0.014656    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.416473    
2023-01-14 17:07:25,493 - --- validate (epoch=163)-----------
2023-01-14 17:07:25,493 - 148 samples (240 per mini-batch)
2023-01-14 17:07:25,997 - Epoch: [163][    1/    1]    Loss 0.371498    Top1 89.189189    Top5 97.972973    
2023-01-14 17:07:26,038 - ==> Top1: 89.189    Top5: 97.973    Loss: 0.371

2023-01-14 17:07:26,052 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 136]
2023-01-14 17:07:26,053 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:07:26,100 - 

2023-01-14 17:07:26,101 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:07:28,656 - Epoch: [164][    6/    6]    Overall Loss 0.015343    Objective Loss 0.015343    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.425458    
2023-01-14 17:07:28,704 - --- validate (epoch=164)-----------
2023-01-14 17:07:28,704 - 148 samples (240 per mini-batch)
2023-01-14 17:07:29,193 - Epoch: [164][    1/    1]    Loss 0.330373    Top1 88.513514    Top5 98.648649    
2023-01-14 17:07:29,233 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.330

2023-01-14 17:07:29,243 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 136]
2023-01-14 17:07:29,244 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:07:29,289 - 

2023-01-14 17:07:29,290 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:07:31,631 - Epoch: [165][    6/    6]    Overall Loss 0.014341    Objective Loss 0.014341    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.389897    
2023-01-14 17:07:31,687 - --- validate (epoch=165)-----------
2023-01-14 17:07:31,687 - 148 samples (240 per mini-batch)
2023-01-14 17:07:32,206 - Epoch: [165][    1/    1]    Loss 0.329361    Top1 89.189189    Top5 98.648649    
2023-01-14 17:07:32,251 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.329

2023-01-14 17:07:32,262 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 136]
2023-01-14 17:07:32,262 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:07:32,310 - 

2023-01-14 17:07:32,311 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:07:36,050 - Epoch: [166][    6/    6]    Overall Loss 0.014782    Objective Loss 0.014782    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.622991    
2023-01-14 17:07:36,096 - --- validate (epoch=166)-----------
2023-01-14 17:07:36,097 - 148 samples (240 per mini-batch)
2023-01-14 17:07:36,566 - Epoch: [166][    1/    1]    Loss 0.355535    Top1 88.513514    Top5 98.648649    
2023-01-14 17:07:36,608 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.356

2023-01-14 17:07:36,617 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 136]
2023-01-14 17:07:36,618 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:07:36,671 - 

2023-01-14 17:07:36,672 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:07:39,574 - Epoch: [167][    6/    6]    Overall Loss 0.014265    Objective Loss 0.014265    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.483316    
2023-01-14 17:07:39,618 - --- validate (epoch=167)-----------
2023-01-14 17:07:39,619 - 148 samples (240 per mini-batch)
2023-01-14 17:07:40,083 - Epoch: [167][    1/    1]    Loss 0.339034    Top1 90.540541    Top5 99.324324    
2023-01-14 17:07:40,129 - ==> Top1: 90.541    Top5: 99.324    Loss: 0.339

2023-01-14 17:07:40,139 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:07:40,140 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:07:40,180 - 

2023-01-14 17:07:40,181 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:07:43,939 - Epoch: [168][    6/    6]    Overall Loss 0.014884    Objective Loss 0.014884    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.626187    
2023-01-14 17:07:43,989 - --- validate (epoch=168)-----------
2023-01-14 17:07:43,990 - 148 samples (240 per mini-batch)
2023-01-14 17:07:44,573 - Epoch: [168][    1/    1]    Loss 0.356935    Top1 89.189189    Top5 98.648649    
2023-01-14 17:07:44,615 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.357

2023-01-14 17:07:44,627 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:07:44,629 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:07:44,678 - 

2023-01-14 17:07:44,678 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:07:47,073 - Epoch: [169][    6/    6]    Overall Loss 0.014905    Objective Loss 0.014905    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.398952    
2023-01-14 17:07:47,110 - --- validate (epoch=169)-----------
2023-01-14 17:07:47,110 - 148 samples (240 per mini-batch)
2023-01-14 17:07:47,610 - Epoch: [169][    1/    1]    Loss 0.349581    Top1 89.189189    Top5 98.648649    
2023-01-14 17:07:47,664 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.350

2023-01-14 17:07:47,674 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:07:47,675 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:07:47,727 - 

2023-01-14 17:07:47,728 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:07:50,290 - Epoch: [170][    6/    6]    Overall Loss 0.014568    Objective Loss 0.014568    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.426587    
2023-01-14 17:07:50,335 - --- validate (epoch=170)-----------
2023-01-14 17:07:50,336 - 148 samples (240 per mini-batch)
2023-01-14 17:07:50,940 - Epoch: [170][    1/    1]    Loss 0.328549    Top1 89.189189    Top5 99.324324    
2023-01-14 17:07:50,979 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.329

2023-01-14 17:07:50,992 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:07:50,992 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:07:51,047 - 

2023-01-14 17:07:51,048 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:07:54,296 - Epoch: [171][    6/    6]    Overall Loss 0.014880    Objective Loss 0.014880    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.541114    
2023-01-14 17:07:54,339 - --- validate (epoch=171)-----------
2023-01-14 17:07:54,339 - 148 samples (240 per mini-batch)
2023-01-14 17:07:54,819 - Epoch: [171][    1/    1]    Loss 0.336338    Top1 88.513514    Top5 98.648649    
2023-01-14 17:07:54,859 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.336

2023-01-14 17:07:54,867 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:07:54,868 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:07:54,911 - 

2023-01-14 17:07:54,912 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:07:58,160 - Epoch: [172][    6/    6]    Overall Loss 0.014682    Objective Loss 0.014682    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.541107    
2023-01-14 17:07:58,204 - --- validate (epoch=172)-----------
2023-01-14 17:07:58,205 - 148 samples (240 per mini-batch)
2023-01-14 17:07:58,683 - Epoch: [172][    1/    1]    Loss 0.329773    Top1 88.513514    Top5 99.324324    
2023-01-14 17:07:58,726 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.330

2023-01-14 17:07:58,735 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:07:58,736 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:07:58,777 - 

2023-01-14 17:07:58,779 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:08:01,652 - Epoch: [173][    6/    6]    Overall Loss 0.014747    Objective Loss 0.014747    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.478539    
2023-01-14 17:08:01,699 - --- validate (epoch=173)-----------
2023-01-14 17:08:01,699 - 148 samples (240 per mini-batch)
2023-01-14 17:08:02,192 - Epoch: [173][    1/    1]    Loss 0.317429    Top1 89.189189    Top5 99.324324    
2023-01-14 17:08:02,233 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.317

2023-01-14 17:08:02,245 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:08:02,246 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:08:02,295 - 

2023-01-14 17:08:02,295 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:08:04,781 - Epoch: [174][    6/    6]    Overall Loss 0.014457    Objective Loss 0.014457    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.414004    
2023-01-14 17:08:04,822 - --- validate (epoch=174)-----------
2023-01-14 17:08:04,823 - 148 samples (240 per mini-batch)
2023-01-14 17:08:05,368 - Epoch: [174][    1/    1]    Loss 0.344954    Top1 89.864865    Top5 98.648649    
2023-01-14 17:08:05,420 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.345

2023-01-14 17:08:05,430 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:08:05,431 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:08:05,485 - 

2023-01-14 17:08:05,485 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:08:08,438 - Epoch: [175][    6/    6]    Overall Loss 0.014400    Objective Loss 0.014400    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.491917    
2023-01-14 17:08:08,478 - --- validate (epoch=175)-----------
2023-01-14 17:08:08,479 - 148 samples (240 per mini-batch)
2023-01-14 17:08:09,041 - Epoch: [175][    1/    1]    Loss 0.325856    Top1 89.189189    Top5 99.324324    
2023-01-14 17:08:09,079 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.326

2023-01-14 17:08:09,090 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:08:09,090 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:08:09,132 - 

2023-01-14 17:08:09,133 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:08:11,656 - Epoch: [176][    6/    6]    Overall Loss 0.014759    Objective Loss 0.014759    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.420354    
2023-01-14 17:08:11,700 - --- validate (epoch=176)-----------
2023-01-14 17:08:11,701 - 148 samples (240 per mini-batch)
2023-01-14 17:08:12,244 - Epoch: [176][    1/    1]    Loss 0.345367    Top1 88.513514    Top5 98.648649    
2023-01-14 17:08:12,310 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.345

2023-01-14 17:08:12,321 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:08:12,321 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:08:12,374 - 

2023-01-14 17:08:12,374 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:08:16,086 - Epoch: [177][    6/    6]    Overall Loss 0.014905    Objective Loss 0.014905    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.618293    
2023-01-14 17:08:16,141 - --- validate (epoch=177)-----------
2023-01-14 17:08:16,142 - 148 samples (240 per mini-batch)
2023-01-14 17:08:16,739 - Epoch: [177][    1/    1]    Loss 0.343891    Top1 89.189189    Top5 99.324324    
2023-01-14 17:08:16,783 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.344

2023-01-14 17:08:16,791 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:08:16,792 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:08:16,831 - 

2023-01-14 17:08:16,832 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:08:20,050 - Epoch: [178][    6/    6]    Overall Loss 0.015031    Objective Loss 0.015031    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.536089    
2023-01-14 17:08:20,096 - --- validate (epoch=178)-----------
2023-01-14 17:08:20,097 - 148 samples (240 per mini-batch)
2023-01-14 17:08:20,618 - Epoch: [178][    1/    1]    Loss 0.361442    Top1 87.837838    Top5 97.972973    
2023-01-14 17:08:20,657 - ==> Top1: 87.838    Top5: 97.973    Loss: 0.361

2023-01-14 17:08:20,669 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:08:20,671 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:08:20,714 - 

2023-01-14 17:08:20,715 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:08:23,570 - Epoch: [179][    6/    6]    Overall Loss 0.015088    Objective Loss 0.015088    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.475625    
2023-01-14 17:08:23,619 - --- validate (epoch=179)-----------
2023-01-14 17:08:23,619 - 148 samples (240 per mini-batch)
2023-01-14 17:08:24,129 - Epoch: [179][    1/    1]    Loss 0.359343    Top1 89.189189    Top5 98.648649    
2023-01-14 17:08:24,172 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.359

2023-01-14 17:08:24,181 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:08:24,182 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:08:24,230 - 

2023-01-14 17:08:24,231 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:08:27,136 - Epoch: [180][    6/    6]    Overall Loss 0.014819    Objective Loss 0.014819    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.483441    
2023-01-14 17:08:27,187 - --- validate (epoch=180)-----------
2023-01-14 17:08:27,188 - 148 samples (240 per mini-batch)
2023-01-14 17:08:27,778 - Epoch: [180][    1/    1]    Loss 0.363157    Top1 88.513514    Top5 97.972973    
2023-01-14 17:08:27,821 - ==> Top1: 88.514    Top5: 97.973    Loss: 0.363

2023-01-14 17:08:27,830 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:08:27,830 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:08:27,872 - 

2023-01-14 17:08:27,872 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:08:30,522 - Epoch: [181][    6/    6]    Overall Loss 0.015104    Objective Loss 0.015104    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.441320    
2023-01-14 17:08:30,566 - --- validate (epoch=181)-----------
2023-01-14 17:08:30,567 - 148 samples (240 per mini-batch)
2023-01-14 17:08:31,148 - Epoch: [181][    1/    1]    Loss 0.322687    Top1 89.864865    Top5 98.648649    
2023-01-14 17:08:31,189 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.323

2023-01-14 17:08:31,199 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:08:31,199 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:08:31,239 - 

2023-01-14 17:08:31,240 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:08:34,504 - Epoch: [182][    6/    6]    Overall Loss 0.014510    Objective Loss 0.014510    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.543790    
2023-01-14 17:08:34,550 - --- validate (epoch=182)-----------
2023-01-14 17:08:34,551 - 148 samples (240 per mini-batch)
2023-01-14 17:08:35,029 - Epoch: [182][    1/    1]    Loss 0.337670    Top1 88.513514    Top5 99.324324    
2023-01-14 17:08:35,083 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.338

2023-01-14 17:08:35,093 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:08:35,094 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:08:35,137 - 

2023-01-14 17:08:35,137 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:08:37,390 - Epoch: [183][    6/    6]    Overall Loss 0.014887    Objective Loss 0.014887    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.375188    
2023-01-14 17:08:37,433 - --- validate (epoch=183)-----------
2023-01-14 17:08:37,434 - 148 samples (240 per mini-batch)
2023-01-14 17:08:38,024 - Epoch: [183][    1/    1]    Loss 0.340904    Top1 89.189189    Top5 99.324324    
2023-01-14 17:08:38,069 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.341

2023-01-14 17:08:38,083 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:08:38,084 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:08:38,128 - 

2023-01-14 17:08:38,129 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:08:40,913 - Epoch: [184][    6/    6]    Overall Loss 0.014633    Objective Loss 0.014633    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.463854    
2023-01-14 17:08:40,953 - --- validate (epoch=184)-----------
2023-01-14 17:08:40,954 - 148 samples (240 per mini-batch)
2023-01-14 17:08:41,400 - Epoch: [184][    1/    1]    Loss 0.332051    Top1 88.513514    Top5 98.648649    
2023-01-14 17:08:41,442 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.332

2023-01-14 17:08:41,451 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:08:41,452 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:08:41,488 - 

2023-01-14 17:08:41,489 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:08:43,828 - Epoch: [185][    6/    6]    Overall Loss 0.014635    Objective Loss 0.014635    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.389473    
2023-01-14 17:08:43,871 - --- validate (epoch=185)-----------
2023-01-14 17:08:43,871 - 148 samples (240 per mini-batch)
2023-01-14 17:08:44,402 - Epoch: [185][    1/    1]    Loss 0.335485    Top1 87.837838    Top5 99.324324    
2023-01-14 17:08:44,444 - ==> Top1: 87.838    Top5: 99.324    Loss: 0.335

2023-01-14 17:08:44,456 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:08:44,457 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:08:44,511 - 

2023-01-14 17:08:44,511 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:08:47,359 - Epoch: [186][    6/    6]    Overall Loss 0.014421    Objective Loss 0.014421    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.474441    
2023-01-14 17:08:47,402 - --- validate (epoch=186)-----------
2023-01-14 17:08:47,402 - 148 samples (240 per mini-batch)
2023-01-14 17:08:47,919 - Epoch: [186][    1/    1]    Loss 0.317189    Top1 88.513514    Top5 99.324324    
2023-01-14 17:08:47,957 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.317

2023-01-14 17:08:47,965 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:08:47,966 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:08:48,011 - 

2023-01-14 17:08:48,011 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:08:50,850 - Epoch: [187][    6/    6]    Overall Loss 0.014350    Objective Loss 0.014350    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.472926    
2023-01-14 17:08:50,895 - --- validate (epoch=187)-----------
2023-01-14 17:08:50,896 - 148 samples (240 per mini-batch)
2023-01-14 17:08:51,438 - Epoch: [187][    1/    1]    Loss 0.341764    Top1 89.189189    Top5 99.324324    
2023-01-14 17:08:51,479 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.342

2023-01-14 17:08:51,489 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:08:51,489 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:08:51,534 - 

2023-01-14 17:08:51,535 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:08:54,294 - Epoch: [188][    6/    6]    Overall Loss 0.013970    Objective Loss 0.013970    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.459464    
2023-01-14 17:08:54,348 - --- validate (epoch=188)-----------
2023-01-14 17:08:54,349 - 148 samples (240 per mini-batch)
2023-01-14 17:08:54,927 - Epoch: [188][    1/    1]    Loss 0.346813    Top1 87.837838    Top5 98.648649    
2023-01-14 17:08:54,972 - ==> Top1: 87.838    Top5: 98.649    Loss: 0.347

2023-01-14 17:08:54,982 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:08:54,983 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:08:55,032 - 

2023-01-14 17:08:55,032 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:08:58,159 - Epoch: [189][    6/    6]    Overall Loss 0.014238    Objective Loss 0.014238    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.520797    
2023-01-14 17:08:58,199 - --- validate (epoch=189)-----------
2023-01-14 17:08:58,200 - 148 samples (240 per mini-batch)
2023-01-14 17:08:58,670 - Epoch: [189][    1/    1]    Loss 0.318312    Top1 89.864865    Top5 98.648649    
2023-01-14 17:08:58,718 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.318

2023-01-14 17:08:58,727 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:08:58,728 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:08:58,774 - 

2023-01-14 17:08:58,774 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:09:01,827 - Epoch: [190][    6/    6]    Overall Loss 0.014652    Objective Loss 0.014652    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.508435    
2023-01-14 17:09:01,874 - --- validate (epoch=190)-----------
2023-01-14 17:09:01,875 - 148 samples (240 per mini-batch)
2023-01-14 17:09:02,350 - Epoch: [190][    1/    1]    Loss 0.335608    Top1 89.864865    Top5 98.648649    
2023-01-14 17:09:02,395 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.336

2023-01-14 17:09:02,403 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:09:02,403 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:09:02,438 - 

2023-01-14 17:09:02,438 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:09:06,190 - Epoch: [191][    6/    6]    Overall Loss 0.014081    Objective Loss 0.014081    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.624935    
2023-01-14 17:09:06,234 - --- validate (epoch=191)-----------
2023-01-14 17:09:06,235 - 148 samples (240 per mini-batch)
2023-01-14 17:09:06,703 - Epoch: [191][    1/    1]    Loss 0.326938    Top1 87.837838    Top5 99.324324    
2023-01-14 17:09:06,741 - ==> Top1: 87.838    Top5: 99.324    Loss: 0.327

2023-01-14 17:09:06,752 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:09:06,753 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:09:06,808 - 

2023-01-14 17:09:06,808 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:09:10,081 - Epoch: [192][    6/    6]    Overall Loss 0.014684    Objective Loss 0.014684    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.545279    
2023-01-14 17:09:10,132 - --- validate (epoch=192)-----------
2023-01-14 17:09:10,132 - 148 samples (240 per mini-batch)
2023-01-14 17:09:10,703 - Epoch: [192][    1/    1]    Loss 0.356731    Top1 88.513514    Top5 99.324324    
2023-01-14 17:09:10,740 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.357

2023-01-14 17:09:10,749 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:09:10,750 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:09:10,790 - 

2023-01-14 17:09:10,791 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:09:13,388 - Epoch: [193][    6/    6]    Overall Loss 0.014840    Objective Loss 0.014840    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.432565    
2023-01-14 17:09:13,447 - --- validate (epoch=193)-----------
2023-01-14 17:09:13,447 - 148 samples (240 per mini-batch)
2023-01-14 17:09:14,054 - Epoch: [193][    1/    1]    Loss 0.315987    Top1 89.864865    Top5 99.324324    
2023-01-14 17:09:14,110 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.316

2023-01-14 17:09:14,119 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:09:14,121 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:09:14,156 - 

2023-01-14 17:09:14,156 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:09:17,247 - Epoch: [194][    6/    6]    Overall Loss 0.014240    Objective Loss 0.014240    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.514695    
2023-01-14 17:09:17,319 - --- validate (epoch=194)-----------
2023-01-14 17:09:17,320 - 148 samples (240 per mini-batch)
2023-01-14 17:09:17,912 - Epoch: [194][    1/    1]    Loss 0.326552    Top1 89.864865    Top5 99.324324    
2023-01-14 17:09:17,971 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.327

2023-01-14 17:09:17,981 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:09:17,981 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:09:18,028 - 

2023-01-14 17:09:18,029 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:09:21,434 - Epoch: [195][    6/    6]    Overall Loss 0.014123    Objective Loss 0.014123    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.567261    
2023-01-14 17:09:21,474 - --- validate (epoch=195)-----------
2023-01-14 17:09:21,475 - 148 samples (240 per mini-batch)
2023-01-14 17:09:21,948 - Epoch: [195][    1/    1]    Loss 0.350468    Top1 89.864865    Top5 99.324324    
2023-01-14 17:09:21,997 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.350

2023-01-14 17:09:22,007 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:09:22,008 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:09:22,048 - 

2023-01-14 17:09:22,049 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:09:24,999 - Epoch: [196][    6/    6]    Overall Loss 0.014386    Objective Loss 0.014386    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.491394    
2023-01-14 17:09:25,054 - --- validate (epoch=196)-----------
2023-01-14 17:09:25,056 - 148 samples (240 per mini-batch)
2023-01-14 17:09:25,611 - Epoch: [196][    1/    1]    Loss 0.351926    Top1 87.837838    Top5 98.648649    
2023-01-14 17:09:25,647 - ==> Top1: 87.838    Top5: 98.649    Loss: 0.352

2023-01-14 17:09:25,660 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:09:25,661 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:09:25,700 - 

2023-01-14 17:09:25,700 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:09:28,072 - Epoch: [197][    6/    6]    Overall Loss 0.014489    Objective Loss 0.014489    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.395124    
2023-01-14 17:09:28,122 - --- validate (epoch=197)-----------
2023-01-14 17:09:28,123 - 148 samples (240 per mini-batch)
2023-01-14 17:09:28,638 - Epoch: [197][    1/    1]    Loss 0.342705    Top1 89.189189    Top5 98.648649    
2023-01-14 17:09:28,685 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.343

2023-01-14 17:09:28,696 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:09:28,697 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:09:28,748 - 

2023-01-14 17:09:28,748 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:09:31,407 - Epoch: [198][    6/    6]    Overall Loss 0.014307    Objective Loss 0.014307    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.442880    
2023-01-14 17:09:31,454 - --- validate (epoch=198)-----------
2023-01-14 17:09:31,455 - 148 samples (240 per mini-batch)
2023-01-14 17:09:31,982 - Epoch: [198][    1/    1]    Loss 0.341640    Top1 89.189189    Top5 98.648649    
2023-01-14 17:09:32,031 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.342

2023-01-14 17:09:32,042 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:09:32,042 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:09:32,085 - 

2023-01-14 17:09:32,086 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:09:34,973 - Epoch: [199][    6/    6]    Overall Loss 0.014827    Objective Loss 0.014827    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.480948    
2023-01-14 17:09:35,022 - --- validate (epoch=199)-----------
2023-01-14 17:09:35,023 - 148 samples (240 per mini-batch)
2023-01-14 17:09:35,522 - Epoch: [199][    1/    1]    Loss 0.342725    Top1 87.837838    Top5 98.648649    
2023-01-14 17:09:35,563 - ==> Top1: 87.838    Top5: 98.649    Loss: 0.343

2023-01-14 17:09:35,573 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:09:35,573 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:09:35,618 - 

2023-01-14 17:09:35,618 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:09:41,257 - Epoch: [200][    6/    6]    Overall Loss 0.014709    Objective Loss 0.014709    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.939634    
2023-01-14 17:09:41,337 - --- validate (epoch=200)-----------
2023-01-14 17:09:41,337 - 148 samples (240 per mini-batch)
2023-01-14 17:09:41,868 - Epoch: [200][    1/    1]    Loss 0.343985    Top1 89.189189    Top5 99.324324    
2023-01-14 17:09:41,909 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.344

2023-01-14 17:09:41,920 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:09:41,921 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:09:41,965 - 

2023-01-14 17:09:41,965 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:09:44,672 - Epoch: [201][    6/    6]    Overall Loss 0.014494    Objective Loss 0.014494    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.450780    
2023-01-14 17:09:44,716 - --- validate (epoch=201)-----------
2023-01-14 17:09:44,717 - 148 samples (240 per mini-batch)
2023-01-14 17:09:45,219 - Epoch: [201][    1/    1]    Loss 0.343545    Top1 87.162162    Top5 99.324324    
2023-01-14 17:09:45,260 - ==> Top1: 87.162    Top5: 99.324    Loss: 0.344

2023-01-14 17:09:45,274 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:09:45,275 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:09:45,324 - 

2023-01-14 17:09:45,325 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:09:48,231 - Epoch: [202][    6/    6]    Overall Loss 0.014858    Objective Loss 0.014858    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.484092    
2023-01-14 17:09:48,272 - --- validate (epoch=202)-----------
2023-01-14 17:09:48,273 - 148 samples (240 per mini-batch)
2023-01-14 17:09:48,738 - Epoch: [202][    1/    1]    Loss 0.352703    Top1 89.189189    Top5 99.324324    
2023-01-14 17:09:48,777 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.353

2023-01-14 17:09:48,787 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:09:48,788 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:09:48,824 - 

2023-01-14 17:09:48,825 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:09:51,752 - Epoch: [203][    6/    6]    Overall Loss 0.014351    Objective Loss 0.014351    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.487370    
2023-01-14 17:09:51,798 - --- validate (epoch=203)-----------
2023-01-14 17:09:51,799 - 148 samples (240 per mini-batch)
2023-01-14 17:09:52,391 - Epoch: [203][    1/    1]    Loss 0.344289    Top1 88.513514    Top5 98.648649    
2023-01-14 17:09:52,446 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.344

2023-01-14 17:09:52,456 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:09:52,456 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:09:52,498 - 

2023-01-14 17:09:52,498 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:09:55,702 - Epoch: [204][    6/    6]    Overall Loss 0.014310    Objective Loss 0.014310    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.533660    
2023-01-14 17:09:55,745 - --- validate (epoch=204)-----------
2023-01-14 17:09:55,746 - 148 samples (240 per mini-batch)
2023-01-14 17:09:56,267 - Epoch: [204][    1/    1]    Loss 0.326918    Top1 89.864865    Top5 99.324324    
2023-01-14 17:09:56,306 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.327

2023-01-14 17:09:56,316 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:09:56,316 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:09:56,355 - 

2023-01-14 17:09:56,356 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:09:59,195 - Epoch: [205][    6/    6]    Overall Loss 0.014410    Objective Loss 0.014410    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.472739    
2023-01-14 17:09:59,236 - --- validate (epoch=205)-----------
2023-01-14 17:09:59,237 - 148 samples (240 per mini-batch)
2023-01-14 17:09:59,787 - Epoch: [205][    1/    1]    Loss 0.364211    Top1 88.513514    Top5 98.648649    
2023-01-14 17:09:59,827 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.364

2023-01-14 17:09:59,837 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:09:59,838 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:09:59,891 - 

2023-01-14 17:09:59,891 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:10:02,634 - Epoch: [206][    6/    6]    Overall Loss 0.014448    Objective Loss 0.014448    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.456752    
2023-01-14 17:10:02,674 - --- validate (epoch=206)-----------
2023-01-14 17:10:02,675 - 148 samples (240 per mini-batch)
2023-01-14 17:10:03,150 - Epoch: [206][    1/    1]    Loss 0.332640    Top1 88.513514    Top5 99.324324    
2023-01-14 17:10:03,200 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.333

2023-01-14 17:10:03,211 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:10:03,211 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:10:03,259 - 

2023-01-14 17:10:03,259 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:10:05,709 - Epoch: [207][    6/    6]    Overall Loss 0.014535    Objective Loss 0.014535    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.408032    
2023-01-14 17:10:05,765 - --- validate (epoch=207)-----------
2023-01-14 17:10:05,766 - 148 samples (240 per mini-batch)
2023-01-14 17:10:06,313 - Epoch: [207][    1/    1]    Loss 0.337539    Top1 88.513514    Top5 99.324324    
2023-01-14 17:10:06,362 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.338

2023-01-14 17:10:06,372 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:10:06,373 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:10:06,414 - 

2023-01-14 17:10:06,415 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:10:09,257 - Epoch: [208][    6/    6]    Overall Loss 0.014189    Objective Loss 0.014189    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.473468    
2023-01-14 17:10:09,294 - --- validate (epoch=208)-----------
2023-01-14 17:10:09,295 - 148 samples (240 per mini-batch)
2023-01-14 17:10:09,845 - Epoch: [208][    1/    1]    Loss 0.327831    Top1 89.189189    Top5 98.648649    
2023-01-14 17:10:09,885 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.328

2023-01-14 17:10:09,894 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:10:09,895 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:10:09,938 - 

2023-01-14 17:10:09,938 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:10:12,726 - Epoch: [209][    6/    6]    Overall Loss 0.014292    Objective Loss 0.014292    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.464397    
2023-01-14 17:10:12,782 - --- validate (epoch=209)-----------
2023-01-14 17:10:12,783 - 148 samples (240 per mini-batch)
2023-01-14 17:10:13,341 - Epoch: [209][    1/    1]    Loss 0.339375    Top1 89.864865    Top5 99.324324    
2023-01-14 17:10:13,391 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.339

2023-01-14 17:10:13,401 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:10:13,404 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:10:13,458 - 

2023-01-14 17:10:13,459 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:10:16,371 - Epoch: [210][    6/    6]    Overall Loss 0.014227    Objective Loss 0.014227    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.484981    
2023-01-14 17:10:16,425 - --- validate (epoch=210)-----------
2023-01-14 17:10:16,425 - 148 samples (240 per mini-batch)
2023-01-14 17:10:17,025 - Epoch: [210][    1/    1]    Loss 0.340101    Top1 89.189189    Top5 99.324324    
2023-01-14 17:10:17,076 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.340

2023-01-14 17:10:17,084 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:10:17,084 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:10:17,121 - 

2023-01-14 17:10:17,121 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:10:20,359 - Epoch: [211][    6/    6]    Overall Loss 0.014142    Objective Loss 0.014142    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.539441    
2023-01-14 17:10:20,413 - --- validate (epoch=211)-----------
2023-01-14 17:10:20,414 - 148 samples (240 per mini-batch)
2023-01-14 17:10:21,024 - Epoch: [211][    1/    1]    Loss 0.338022    Top1 90.540541    Top5 98.648649    
2023-01-14 17:10:21,077 - ==> Top1: 90.541    Top5: 98.649    Loss: 0.338

2023-01-14 17:10:21,086 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:10:21,087 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:10:21,135 - 

2023-01-14 17:10:21,135 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:10:23,659 - Epoch: [212][    6/    6]    Overall Loss 0.014518    Objective Loss 0.014518    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.420462    
2023-01-14 17:10:23,711 - --- validate (epoch=212)-----------
2023-01-14 17:10:23,712 - 148 samples (240 per mini-batch)
2023-01-14 17:10:24,248 - Epoch: [212][    1/    1]    Loss 0.364738    Top1 87.837838    Top5 98.648649    
2023-01-14 17:10:24,298 - ==> Top1: 87.838    Top5: 98.649    Loss: 0.365

2023-01-14 17:10:24,309 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:10:24,309 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:10:24,361 - 

2023-01-14 17:10:24,362 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:10:27,315 - Epoch: [213][    6/    6]    Overall Loss 0.014088    Objective Loss 0.014088    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.491917    
2023-01-14 17:10:27,366 - --- validate (epoch=213)-----------
2023-01-14 17:10:27,366 - 148 samples (240 per mini-batch)
2023-01-14 17:10:27,922 - Epoch: [213][    1/    1]    Loss 0.334981    Top1 89.864865    Top5 98.648649    
2023-01-14 17:10:27,965 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.335

2023-01-14 17:10:27,974 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:10:27,975 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:10:28,018 - 

2023-01-14 17:10:28,019 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:10:31,328 - Epoch: [214][    6/    6]    Overall Loss 0.014413    Objective Loss 0.014413    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.551261    
2023-01-14 17:10:31,381 - --- validate (epoch=214)-----------
2023-01-14 17:10:31,381 - 148 samples (240 per mini-batch)
2023-01-14 17:10:31,938 - Epoch: [214][    1/    1]    Loss 0.345252    Top1 89.864865    Top5 100.000000    
2023-01-14 17:10:32,005 - ==> Top1: 89.865    Top5: 100.000    Loss: 0.345

2023-01-14 17:10:32,019 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:10:32,019 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:10:32,082 - 

2023-01-14 17:10:32,083 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:10:34,799 - Epoch: [215][    6/    6]    Overall Loss 0.014540    Objective Loss 0.014540    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.452358    
2023-01-14 17:10:34,840 - --- validate (epoch=215)-----------
2023-01-14 17:10:34,841 - 148 samples (240 per mini-batch)
2023-01-14 17:10:35,307 - Epoch: [215][    1/    1]    Loss 0.327637    Top1 87.837838    Top5 98.648649    
2023-01-14 17:10:35,353 - ==> Top1: 87.838    Top5: 98.649    Loss: 0.328

2023-01-14 17:10:35,365 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:10:35,365 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:10:35,405 - 

2023-01-14 17:10:35,407 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:10:38,476 - Epoch: [216][    6/    6]    Overall Loss 0.013650    Objective Loss 0.013650    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.511230    
2023-01-14 17:10:38,526 - --- validate (epoch=216)-----------
2023-01-14 17:10:38,527 - 148 samples (240 per mini-batch)
2023-01-14 17:10:39,135 - Epoch: [216][    1/    1]    Loss 0.342247    Top1 88.513514    Top5 98.648649    
2023-01-14 17:10:39,184 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.342

2023-01-14 17:10:39,193 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:10:39,194 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:10:39,237 - 

2023-01-14 17:10:39,237 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:10:42,168 - Epoch: [217][    6/    6]    Overall Loss 0.014132    Objective Loss 0.014132    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.488195    
2023-01-14 17:10:42,210 - --- validate (epoch=217)-----------
2023-01-14 17:10:42,211 - 148 samples (240 per mini-batch)
2023-01-14 17:10:42,803 - Epoch: [217][    1/    1]    Loss 0.341443    Top1 89.864865    Top5 99.324324    
2023-01-14 17:10:42,850 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.341

2023-01-14 17:10:42,857 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:10:42,857 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:10:42,893 - 

2023-01-14 17:10:42,894 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:10:45,775 - Epoch: [218][    6/    6]    Overall Loss 0.014381    Objective Loss 0.014381    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.480056    
2023-01-14 17:10:45,820 - --- validate (epoch=218)-----------
2023-01-14 17:10:45,820 - 148 samples (240 per mini-batch)
2023-01-14 17:10:46,351 - Epoch: [218][    1/    1]    Loss 0.347080    Top1 88.513514    Top5 99.324324    
2023-01-14 17:10:46,408 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.347

2023-01-14 17:10:46,420 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:10:46,420 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:10:46,460 - 

2023-01-14 17:10:46,461 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:10:49,189 - Epoch: [219][    6/    6]    Overall Loss 0.013466    Objective Loss 0.013466    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.454350    
2023-01-14 17:10:49,227 - --- validate (epoch=219)-----------
2023-01-14 17:10:49,227 - 148 samples (240 per mini-batch)
2023-01-14 17:10:49,711 - Epoch: [219][    1/    1]    Loss 0.329890    Top1 88.513514    Top5 99.324324    
2023-01-14 17:10:49,752 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.330

2023-01-14 17:10:49,762 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:10:49,762 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:10:49,812 - 

2023-01-14 17:10:49,812 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:10:52,690 - Epoch: [220][    6/    6]    Overall Loss 0.013782    Objective Loss 0.013782    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.479340    
2023-01-14 17:10:52,735 - --- validate (epoch=220)-----------
2023-01-14 17:10:52,736 - 148 samples (240 per mini-batch)
2023-01-14 17:10:53,222 - Epoch: [220][    1/    1]    Loss 0.332527    Top1 88.513514    Top5 97.972973    
2023-01-14 17:10:53,267 - ==> Top1: 88.514    Top5: 97.973    Loss: 0.333

2023-01-14 17:10:53,277 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:10:53,278 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:10:53,328 - 

2023-01-14 17:10:53,329 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:10:55,968 - Epoch: [221][    6/    6]    Overall Loss 0.014138    Objective Loss 0.014138    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.439239    
2023-01-14 17:10:56,010 - --- validate (epoch=221)-----------
2023-01-14 17:10:56,011 - 148 samples (240 per mini-batch)
2023-01-14 17:10:56,560 - Epoch: [221][    1/    1]    Loss 0.340003    Top1 89.189189    Top5 99.324324    
2023-01-14 17:10:56,606 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.340

2023-01-14 17:10:56,617 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:10:56,617 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:10:56,660 - 

2023-01-14 17:10:56,660 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:10:59,566 - Epoch: [222][    6/    6]    Overall Loss 0.013490    Objective Loss 0.013490    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.484153    
2023-01-14 17:10:59,611 - --- validate (epoch=222)-----------
2023-01-14 17:10:59,612 - 148 samples (240 per mini-batch)
2023-01-14 17:11:00,102 - Epoch: [222][    1/    1]    Loss 0.328681    Top1 89.864865    Top5 99.324324    
2023-01-14 17:11:00,141 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.329

2023-01-14 17:11:00,156 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:11:00,157 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:11:00,203 - 

2023-01-14 17:11:00,203 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:11:02,519 - Epoch: [223][    6/    6]    Overall Loss 0.014019    Objective Loss 0.014019    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.385665    
2023-01-14 17:11:02,562 - --- validate (epoch=223)-----------
2023-01-14 17:11:02,562 - 148 samples (240 per mini-batch)
2023-01-14 17:11:03,104 - Epoch: [223][    1/    1]    Loss 0.316970    Top1 88.513514    Top5 99.324324    
2023-01-14 17:11:03,144 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.317

2023-01-14 17:11:03,155 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:11:03,155 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:11:03,198 - 

2023-01-14 17:11:03,198 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:11:06,473 - Epoch: [224][    6/    6]    Overall Loss 0.014505    Objective Loss 0.014505    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.545517    
2023-01-14 17:11:06,518 - --- validate (epoch=224)-----------
2023-01-14 17:11:06,518 - 148 samples (240 per mini-batch)
2023-01-14 17:11:07,105 - Epoch: [224][    1/    1]    Loss 0.347117    Top1 89.189189    Top5 99.324324    
2023-01-14 17:11:07,152 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.347

2023-01-14 17:11:07,163 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:11:07,163 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:11:07,204 - 

2023-01-14 17:11:07,205 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:11:09,695 - Epoch: [225][    6/    6]    Overall Loss 0.014616    Objective Loss 0.014616    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.414839    
2023-01-14 17:11:09,738 - --- validate (epoch=225)-----------
2023-01-14 17:11:09,739 - 148 samples (240 per mini-batch)
2023-01-14 17:11:10,297 - Epoch: [225][    1/    1]    Loss 0.327598    Top1 89.189189    Top5 99.324324    
2023-01-14 17:11:10,372 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.328

2023-01-14 17:11:10,383 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:11:10,384 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:11:10,434 - 

2023-01-14 17:11:10,435 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:11:13,318 - Epoch: [226][    6/    6]    Overall Loss 0.013672    Objective Loss 0.013672    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.480261    
2023-01-14 17:11:13,386 - --- validate (epoch=226)-----------
2023-01-14 17:11:13,386 - 148 samples (240 per mini-batch)
2023-01-14 17:11:13,984 - Epoch: [226][    1/    1]    Loss 0.341440    Top1 89.864865    Top5 99.324324    
2023-01-14 17:11:14,035 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.341

2023-01-14 17:11:14,043 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:11:14,043 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:11:14,083 - 

2023-01-14 17:11:14,084 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:11:16,709 - Epoch: [227][    6/    6]    Overall Loss 0.014394    Objective Loss 0.014394    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.437137    
2023-01-14 17:11:16,758 - --- validate (epoch=227)-----------
2023-01-14 17:11:16,758 - 148 samples (240 per mini-batch)
2023-01-14 17:11:17,340 - Epoch: [227][    1/    1]    Loss 0.323314    Top1 89.189189    Top5 98.648649    
2023-01-14 17:11:17,418 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.323

2023-01-14 17:11:17,433 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:11:17,433 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:11:17,486 - 

2023-01-14 17:11:17,487 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:11:20,853 - Epoch: [228][    6/    6]    Overall Loss 0.013830    Objective Loss 0.013830    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.560539    
2023-01-14 17:11:20,894 - --- validate (epoch=228)-----------
2023-01-14 17:11:20,895 - 148 samples (240 per mini-batch)
2023-01-14 17:11:21,368 - Epoch: [228][    1/    1]    Loss 0.355560    Top1 89.189189    Top5 99.324324    
2023-01-14 17:11:21,412 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.356

2023-01-14 17:11:21,420 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:11:21,421 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:11:21,461 - 

2023-01-14 17:11:21,462 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:11:23,954 - Epoch: [229][    6/    6]    Overall Loss 0.014205    Objective Loss 0.014205    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.415150    
2023-01-14 17:11:24,001 - --- validate (epoch=229)-----------
2023-01-14 17:11:24,001 - 148 samples (240 per mini-batch)
2023-01-14 17:11:24,538 - Epoch: [229][    1/    1]    Loss 0.362386    Top1 88.513514    Top5 99.324324    
2023-01-14 17:11:24,580 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.362

2023-01-14 17:11:24,590 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:11:24,591 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:11:24,631 - 

2023-01-14 17:11:24,632 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:11:27,562 - Epoch: [230][    6/    6]    Overall Loss 0.014111    Objective Loss 0.014111    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.487837    
2023-01-14 17:11:27,624 - --- validate (epoch=230)-----------
2023-01-14 17:11:27,624 - 148 samples (240 per mini-batch)
2023-01-14 17:11:28,208 - Epoch: [230][    1/    1]    Loss 0.330514    Top1 87.837838    Top5 99.324324    
2023-01-14 17:11:28,252 - ==> Top1: 87.838    Top5: 99.324    Loss: 0.331

2023-01-14 17:11:28,261 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:11:28,262 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:11:28,309 - 

2023-01-14 17:11:28,310 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:11:31,409 - Epoch: [231][    6/    6]    Overall Loss 0.013662    Objective Loss 0.013662    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.516258    
2023-01-14 17:11:31,460 - --- validate (epoch=231)-----------
2023-01-14 17:11:31,461 - 148 samples (240 per mini-batch)
2023-01-14 17:11:32,058 - Epoch: [231][    1/    1]    Loss 0.344048    Top1 88.513514    Top5 98.648649    
2023-01-14 17:11:32,097 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.344

2023-01-14 17:11:32,110 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:11:32,111 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:11:32,152 - 

2023-01-14 17:11:32,153 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:11:35,017 - Epoch: [232][    6/    6]    Overall Loss 0.013795    Objective Loss 0.013795    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.477158    
2023-01-14 17:11:35,054 - --- validate (epoch=232)-----------
2023-01-14 17:11:35,055 - 148 samples (240 per mini-batch)
2023-01-14 17:11:35,595 - Epoch: [232][    1/    1]    Loss 0.355098    Top1 89.189189    Top5 98.648649    
2023-01-14 17:11:35,636 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.355

2023-01-14 17:11:35,646 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:11:35,647 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:11:35,699 - 

2023-01-14 17:11:35,700 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:11:38,544 - Epoch: [233][    6/    6]    Overall Loss 0.014534    Objective Loss 0.014534    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.473734    
2023-01-14 17:11:38,587 - --- validate (epoch=233)-----------
2023-01-14 17:11:38,588 - 148 samples (240 per mini-batch)
2023-01-14 17:11:39,114 - Epoch: [233][    1/    1]    Loss 0.315048    Top1 89.864865    Top5 98.648649    
2023-01-14 17:11:39,166 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.315

2023-01-14 17:11:39,180 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:11:39,181 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:11:39,220 - 

2023-01-14 17:11:39,221 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:11:41,705 - Epoch: [234][    6/    6]    Overall Loss 0.013975    Objective Loss 0.013975    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.413638    
2023-01-14 17:11:41,748 - --- validate (epoch=234)-----------
2023-01-14 17:11:41,748 - 148 samples (240 per mini-batch)
2023-01-14 17:11:42,291 - Epoch: [234][    1/    1]    Loss 0.358494    Top1 87.837838    Top5 98.648649    
2023-01-14 17:11:42,330 - ==> Top1: 87.838    Top5: 98.649    Loss: 0.358

2023-01-14 17:11:42,342 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:11:42,345 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:11:42,391 - 

2023-01-14 17:11:42,392 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:11:44,770 - Epoch: [235][    6/    6]    Overall Loss 0.014154    Objective Loss 0.014154    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.395931    
2023-01-14 17:11:44,832 - --- validate (epoch=235)-----------
2023-01-14 17:11:44,833 - 148 samples (240 per mini-batch)
2023-01-14 17:11:45,317 - Epoch: [235][    1/    1]    Loss 0.346401    Top1 89.864865    Top5 99.324324    
2023-01-14 17:11:45,366 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.346

2023-01-14 17:11:45,376 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:11:45,376 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:11:45,417 - 

2023-01-14 17:11:45,418 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:11:47,593 - Epoch: [236][    6/    6]    Overall Loss 0.013625    Objective Loss 0.013625    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.362247    
2023-01-14 17:11:47,637 - --- validate (epoch=236)-----------
2023-01-14 17:11:47,638 - 148 samples (240 per mini-batch)
2023-01-14 17:11:48,158 - Epoch: [236][    1/    1]    Loss 0.337295    Top1 89.189189    Top5 98.648649    
2023-01-14 17:11:48,200 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.337

2023-01-14 17:11:48,211 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:11:48,212 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:11:48,251 - 

2023-01-14 17:11:48,252 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:11:50,724 - Epoch: [237][    6/    6]    Overall Loss 0.013863    Objective Loss 0.013863    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.411454    
2023-01-14 17:11:50,776 - --- validate (epoch=237)-----------
2023-01-14 17:11:50,777 - 148 samples (240 per mini-batch)
2023-01-14 17:11:51,330 - Epoch: [237][    1/    1]    Loss 0.345464    Top1 88.513514    Top5 99.324324    
2023-01-14 17:11:51,378 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.345

2023-01-14 17:11:51,391 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:11:51,394 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:11:51,442 - 

2023-01-14 17:11:51,443 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:11:54,137 - Epoch: [238][    6/    6]    Overall Loss 0.013752    Objective Loss 0.013752    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.448760    
2023-01-14 17:11:54,179 - --- validate (epoch=238)-----------
2023-01-14 17:11:54,179 - 148 samples (240 per mini-batch)
2023-01-14 17:11:54,692 - Epoch: [238][    1/    1]    Loss 0.338581    Top1 88.513514    Top5 99.324324    
2023-01-14 17:11:54,729 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.339

2023-01-14 17:11:54,739 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 167]
2023-01-14 17:11:54,739 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:11:54,784 - 

2023-01-14 17:11:54,784 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:11:57,582 - Epoch: [239][    6/    6]    Overall Loss 0.012983    Objective Loss 0.012983    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.465998    
2023-01-14 17:11:57,638 - --- validate (epoch=239)-----------
2023-01-14 17:11:57,639 - 148 samples (240 per mini-batch)
2023-01-14 17:11:58,192 - Epoch: [239][    1/    1]    Loss 0.344351    Top1 90.540541    Top5 99.324324    
2023-01-14 17:11:58,233 - ==> Top1: 90.541    Top5: 99.324    Loss: 0.344

2023-01-14 17:11:58,243 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:11:58,243 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:11:58,297 - 

2023-01-14 17:11:58,298 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:12:00,982 - Epoch: [240][    6/    6]    Overall Loss 0.014177    Objective Loss 0.014177    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.447009    
2023-01-14 17:12:01,031 - --- validate (epoch=240)-----------
2023-01-14 17:12:01,031 - 148 samples (240 per mini-batch)
2023-01-14 17:12:01,555 - Epoch: [240][    1/    1]    Loss 0.336056    Top1 88.513514    Top5 98.648649    
2023-01-14 17:12:01,597 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.336

2023-01-14 17:12:01,607 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:12:01,607 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:12:01,659 - 

2023-01-14 17:12:01,659 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:12:04,295 - Epoch: [241][    6/    6]    Overall Loss 0.013644    Objective Loss 0.013644    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.439010    
2023-01-14 17:12:04,339 - --- validate (epoch=241)-----------
2023-01-14 17:12:04,340 - 148 samples (240 per mini-batch)
2023-01-14 17:12:04,892 - Epoch: [241][    1/    1]    Loss 0.331045    Top1 89.864865    Top5 98.648649    
2023-01-14 17:12:04,931 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.331

2023-01-14 17:12:04,944 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:12:04,946 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:12:04,989 - 

2023-01-14 17:12:04,990 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:12:07,528 - Epoch: [242][    6/    6]    Overall Loss 0.014138    Objective Loss 0.014138    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.422893    
2023-01-14 17:12:07,571 - --- validate (epoch=242)-----------
2023-01-14 17:12:07,572 - 148 samples (240 per mini-batch)
2023-01-14 17:12:08,088 - Epoch: [242][    1/    1]    Loss 0.327671    Top1 89.189189    Top5 98.648649    
2023-01-14 17:12:08,134 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.328

2023-01-14 17:12:08,145 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:12:08,146 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:12:08,193 - 

2023-01-14 17:12:08,194 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:12:10,998 - Epoch: [243][    6/    6]    Overall Loss 0.013729    Objective Loss 0.013729    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.467175    
2023-01-14 17:12:11,052 - --- validate (epoch=243)-----------
2023-01-14 17:12:11,053 - 148 samples (240 per mini-batch)
2023-01-14 17:12:11,600 - Epoch: [243][    1/    1]    Loss 0.334932    Top1 89.864865    Top5 99.324324    
2023-01-14 17:12:11,640 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.335

2023-01-14 17:12:11,650 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:12:11,651 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:12:11,687 - 

2023-01-14 17:12:11,688 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:12:14,338 - Epoch: [244][    6/    6]    Overall Loss 0.014459    Objective Loss 0.014459    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.441437    
2023-01-14 17:12:14,393 - --- validate (epoch=244)-----------
2023-01-14 17:12:14,394 - 148 samples (240 per mini-batch)
2023-01-14 17:12:14,951 - Epoch: [244][    1/    1]    Loss 0.350136    Top1 88.513514    Top5 98.648649    
2023-01-14 17:12:15,001 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.350

2023-01-14 17:12:15,008 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:12:15,008 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:12:15,050 - 

2023-01-14 17:12:15,051 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:12:17,991 - Epoch: [245][    6/    6]    Overall Loss 0.013501    Objective Loss 0.013501    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.489712    
2023-01-14 17:12:18,056 - --- validate (epoch=245)-----------
2023-01-14 17:12:18,057 - 148 samples (240 per mini-batch)
2023-01-14 17:12:18,629 - Epoch: [245][    1/    1]    Loss 0.356502    Top1 87.837838    Top5 98.648649    
2023-01-14 17:12:18,677 - ==> Top1: 87.838    Top5: 98.649    Loss: 0.357

2023-01-14 17:12:18,686 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:12:18,686 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:12:18,727 - 

2023-01-14 17:12:18,728 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:12:21,347 - Epoch: [246][    6/    6]    Overall Loss 0.014126    Objective Loss 0.014126    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.436077    
2023-01-14 17:12:21,391 - --- validate (epoch=246)-----------
2023-01-14 17:12:21,391 - 148 samples (240 per mini-batch)
2023-01-14 17:12:21,963 - Epoch: [246][    1/    1]    Loss 0.349925    Top1 89.189189    Top5 99.324324    
2023-01-14 17:12:21,995 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.350

2023-01-14 17:12:22,010 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:12:22,011 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:12:22,053 - 

2023-01-14 17:12:22,054 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:12:25,242 - Epoch: [247][    6/    6]    Overall Loss 0.013584    Objective Loss 0.013584    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.531232    
2023-01-14 17:12:25,286 - --- validate (epoch=247)-----------
2023-01-14 17:12:25,286 - 148 samples (240 per mini-batch)
2023-01-14 17:12:25,841 - Epoch: [247][    1/    1]    Loss 0.346601    Top1 87.837838    Top5 98.648649    
2023-01-14 17:12:25,881 - ==> Top1: 87.838    Top5: 98.649    Loss: 0.347

2023-01-14 17:12:25,890 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:12:25,890 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:12:25,933 - 

2023-01-14 17:12:25,933 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:12:28,709 - Epoch: [248][    6/    6]    Overall Loss 0.013916    Objective Loss 0.013916    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.462310    
2023-01-14 17:12:28,761 - --- validate (epoch=248)-----------
2023-01-14 17:12:28,762 - 148 samples (240 per mini-batch)
2023-01-14 17:12:29,356 - Epoch: [248][    1/    1]    Loss 0.350921    Top1 88.513514    Top5 97.972973    
2023-01-14 17:12:29,405 - ==> Top1: 88.514    Top5: 97.973    Loss: 0.351

2023-01-14 17:12:29,415 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:12:29,415 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:12:29,463 - 

2023-01-14 17:12:29,464 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:12:32,253 - Epoch: [249][    6/    6]    Overall Loss 0.013707    Objective Loss 0.013707    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.464704    
2023-01-14 17:12:32,296 - --- validate (epoch=249)-----------
2023-01-14 17:12:32,296 - 148 samples (240 per mini-batch)
2023-01-14 17:12:32,878 - Epoch: [249][    1/    1]    Loss 0.331098    Top1 89.189189    Top5 98.648649    
2023-01-14 17:12:32,922 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.331

2023-01-14 17:12:32,933 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:12:32,933 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:12:32,982 - 

2023-01-14 17:12:32,983 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:12:35,658 - Epoch: [250][    6/    6]    Overall Loss 0.013709    Objective Loss 0.013709    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.445616    
2023-01-14 17:12:35,693 - --- validate (epoch=250)-----------
2023-01-14 17:12:35,694 - 148 samples (240 per mini-batch)
2023-01-14 17:12:36,237 - Epoch: [250][    1/    1]    Loss 0.335057    Top1 89.864865    Top5 98.648649    
2023-01-14 17:12:36,278 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.335

2023-01-14 17:12:36,290 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:12:36,291 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:12:36,332 - 

2023-01-14 17:12:36,334 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:12:39,037 - Epoch: [251][    6/    6]    Overall Loss 0.014406    Objective Loss 0.014406    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.450272    
2023-01-14 17:12:39,082 - --- validate (epoch=251)-----------
2023-01-14 17:12:39,083 - 148 samples (240 per mini-batch)
2023-01-14 17:12:39,593 - Epoch: [251][    1/    1]    Loss 0.361907    Top1 89.189189    Top5 98.648649    
2023-01-14 17:12:39,642 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.362

2023-01-14 17:12:39,653 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:12:39,653 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:12:39,686 - 

2023-01-14 17:12:39,686 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:12:42,442 - Epoch: [252][    6/    6]    Overall Loss 0.013969    Objective Loss 0.013969    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.458965    
2023-01-14 17:12:42,494 - --- validate (epoch=252)-----------
2023-01-14 17:12:42,495 - 148 samples (240 per mini-batch)
2023-01-14 17:12:43,075 - Epoch: [252][    1/    1]    Loss 0.358911    Top1 89.189189    Top5 99.324324    
2023-01-14 17:12:43,119 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.359

2023-01-14 17:12:43,131 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:12:43,131 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:12:43,183 - 

2023-01-14 17:12:43,184 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:12:46,118 - Epoch: [253][    6/    6]    Overall Loss 0.013721    Objective Loss 0.013721    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.488754    
2023-01-14 17:12:46,172 - --- validate (epoch=253)-----------
2023-01-14 17:12:46,172 - 148 samples (240 per mini-batch)
2023-01-14 17:12:46,772 - Epoch: [253][    1/    1]    Loss 0.338072    Top1 89.189189    Top5 97.972973    
2023-01-14 17:12:46,812 - ==> Top1: 89.189    Top5: 97.973    Loss: 0.338

2023-01-14 17:12:46,822 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:12:46,822 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:12:46,860 - 

2023-01-14 17:12:46,860 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:12:49,650 - Epoch: [254][    6/    6]    Overall Loss 0.014143    Objective Loss 0.014143    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.464306    
2023-01-14 17:12:49,695 - --- validate (epoch=254)-----------
2023-01-14 17:12:49,696 - 148 samples (240 per mini-batch)
2023-01-14 17:12:50,165 - Epoch: [254][    1/    1]    Loss 0.364086    Top1 88.513514    Top5 99.324324    
2023-01-14 17:12:50,208 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.364

2023-01-14 17:12:50,219 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:12:50,219 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:12:50,266 - 

2023-01-14 17:12:50,266 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:12:52,900 - Epoch: [255][    6/    6]    Overall Loss 0.013831    Objective Loss 0.013831    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.438808    
2023-01-14 17:12:52,945 - --- validate (epoch=255)-----------
2023-01-14 17:12:52,946 - 148 samples (240 per mini-batch)
2023-01-14 17:12:53,491 - Epoch: [255][    1/    1]    Loss 0.340194    Top1 89.189189    Top5 98.648649    
2023-01-14 17:12:53,534 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.340

2023-01-14 17:12:53,549 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:12:53,549 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:12:53,595 - 

2023-01-14 17:12:53,596 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:12:56,491 - Epoch: [256][    6/    6]    Overall Loss 0.014290    Objective Loss 0.014290    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.482152    
2023-01-14 17:12:56,534 - --- validate (epoch=256)-----------
2023-01-14 17:12:56,535 - 148 samples (240 per mini-batch)
2023-01-14 17:12:57,026 - Epoch: [256][    1/    1]    Loss 0.332174    Top1 90.540541    Top5 98.648649    
2023-01-14 17:12:57,065 - ==> Top1: 90.541    Top5: 98.649    Loss: 0.332

2023-01-14 17:12:57,074 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:12:57,075 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:12:57,115 - 

2023-01-14 17:12:57,115 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:12:59,558 - Epoch: [257][    6/    6]    Overall Loss 0.014049    Objective Loss 0.014049    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.406819    
2023-01-14 17:12:59,602 - --- validate (epoch=257)-----------
2023-01-14 17:12:59,603 - 148 samples (240 per mini-batch)
2023-01-14 17:13:00,185 - Epoch: [257][    1/    1]    Loss 0.339825    Top1 87.837838    Top5 99.324324    
2023-01-14 17:13:00,225 - ==> Top1: 87.838    Top5: 99.324    Loss: 0.340

2023-01-14 17:13:00,235 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:13:00,235 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:13:00,287 - 

2023-01-14 17:13:00,287 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:13:03,396 - Epoch: [258][    6/    6]    Overall Loss 0.014047    Objective Loss 0.014047    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.517830    
2023-01-14 17:13:03,442 - --- validate (epoch=258)-----------
2023-01-14 17:13:03,443 - 148 samples (240 per mini-batch)
2023-01-14 17:13:04,043 - Epoch: [258][    1/    1]    Loss 0.334210    Top1 89.189189    Top5 98.648649    
2023-01-14 17:13:04,082 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.334

2023-01-14 17:13:04,097 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:13:04,097 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:13:04,139 - 

2023-01-14 17:13:04,139 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:13:06,471 - Epoch: [259][    6/    6]    Overall Loss 0.013588    Objective Loss 0.013588    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.388423    
2023-01-14 17:13:06,523 - --- validate (epoch=259)-----------
2023-01-14 17:13:06,523 - 148 samples (240 per mini-batch)
2023-01-14 17:13:07,065 - Epoch: [259][    1/    1]    Loss 0.343638    Top1 89.864865    Top5 99.324324    
2023-01-14 17:13:07,105 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.344

2023-01-14 17:13:07,118 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:13:07,120 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:13:07,167 - 

2023-01-14 17:13:07,167 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:13:10,596 - Epoch: [260][    6/    6]    Overall Loss 0.014103    Objective Loss 0.014103    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.571272    
2023-01-14 17:13:10,651 - --- validate (epoch=260)-----------
2023-01-14 17:13:10,651 - 148 samples (240 per mini-batch)
2023-01-14 17:13:11,238 - Epoch: [260][    1/    1]    Loss 0.352833    Top1 89.189189    Top5 98.648649    
2023-01-14 17:13:11,289 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.353

2023-01-14 17:13:11,300 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:13:11,301 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:13:11,354 - 

2023-01-14 17:13:11,355 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:13:13,900 - Epoch: [261][    6/    6]    Overall Loss 0.014142    Objective Loss 0.014142    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.423864    
2023-01-14 17:13:13,961 - --- validate (epoch=261)-----------
2023-01-14 17:13:13,962 - 148 samples (240 per mini-batch)
2023-01-14 17:13:14,572 - Epoch: [261][    1/    1]    Loss 0.333599    Top1 88.513514    Top5 99.324324    
2023-01-14 17:13:14,625 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.334

2023-01-14 17:13:14,638 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:13:14,640 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:13:14,686 - 

2023-01-14 17:13:14,687 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:13:17,620 - Epoch: [262][    6/    6]    Overall Loss 0.013636    Objective Loss 0.013636    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.488481    
2023-01-14 17:13:17,683 - --- validate (epoch=262)-----------
2023-01-14 17:13:17,684 - 148 samples (240 per mini-batch)
2023-01-14 17:13:18,279 - Epoch: [262][    1/    1]    Loss 0.368026    Top1 88.513514    Top5 98.648649    
2023-01-14 17:13:18,325 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.368

2023-01-14 17:13:18,333 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:13:18,333 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:13:18,371 - 

2023-01-14 17:13:18,371 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:13:21,313 - Epoch: [263][    6/    6]    Overall Loss 0.013509    Objective Loss 0.013509    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.490070    
2023-01-14 17:13:21,357 - --- validate (epoch=263)-----------
2023-01-14 17:13:21,357 - 148 samples (240 per mini-batch)
2023-01-14 17:13:21,827 - Epoch: [263][    1/    1]    Loss 0.331412    Top1 88.513514    Top5 97.972973    
2023-01-14 17:13:21,867 - ==> Top1: 88.514    Top5: 97.973    Loss: 0.331

2023-01-14 17:13:21,881 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:13:21,882 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:13:21,933 - 

2023-01-14 17:13:21,933 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:13:24,736 - Epoch: [264][    6/    6]    Overall Loss 0.013615    Objective Loss 0.013615    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.466967    
2023-01-14 17:13:24,782 - --- validate (epoch=264)-----------
2023-01-14 17:13:24,783 - 148 samples (240 per mini-batch)
2023-01-14 17:13:25,326 - Epoch: [264][    1/    1]    Loss 0.333805    Top1 88.513514    Top5 98.648649    
2023-01-14 17:13:25,371 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.334

2023-01-14 17:13:25,386 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:13:25,387 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:13:25,431 - 

2023-01-14 17:13:25,433 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:13:28,693 - Epoch: [265][    6/    6]    Overall Loss 0.013767    Objective Loss 0.013767    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.543024    
2023-01-14 17:13:28,738 - --- validate (epoch=265)-----------
2023-01-14 17:13:28,739 - 148 samples (240 per mini-batch)
2023-01-14 17:13:29,337 - Epoch: [265][    1/    1]    Loss 0.332760    Top1 88.513514    Top5 98.648649    
2023-01-14 17:13:29,377 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.333

2023-01-14 17:13:29,385 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:13:29,386 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:13:29,427 - 

2023-01-14 17:13:29,428 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:13:31,821 - Epoch: [266][    6/    6]    Overall Loss 0.013805    Objective Loss 0.013805    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.398439    
2023-01-14 17:13:31,863 - --- validate (epoch=266)-----------
2023-01-14 17:13:31,864 - 148 samples (240 per mini-batch)
2023-01-14 17:13:32,375 - Epoch: [266][    1/    1]    Loss 0.315204    Top1 89.864865    Top5 99.324324    
2023-01-14 17:13:32,421 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.315

2023-01-14 17:13:32,434 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:13:32,434 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:13:32,476 - 

2023-01-14 17:13:32,476 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:13:35,122 - Epoch: [267][    6/    6]    Overall Loss 0.013664    Objective Loss 0.013664    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.440683    
2023-01-14 17:13:35,166 - --- validate (epoch=267)-----------
2023-01-14 17:13:35,167 - 148 samples (240 per mini-batch)
2023-01-14 17:13:35,713 - Epoch: [267][    1/    1]    Loss 0.351468    Top1 88.513514    Top5 98.648649    
2023-01-14 17:13:35,767 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.351

2023-01-14 17:13:35,777 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:13:35,777 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:13:35,816 - 

2023-01-14 17:13:35,817 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:13:38,301 - Epoch: [268][    6/    6]    Overall Loss 0.013251    Objective Loss 0.013251    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.413624    
2023-01-14 17:13:38,353 - --- validate (epoch=268)-----------
2023-01-14 17:13:38,353 - 148 samples (240 per mini-batch)
2023-01-14 17:13:38,892 - Epoch: [268][    1/    1]    Loss 0.344997    Top1 88.513514    Top5 99.324324    
2023-01-14 17:13:38,935 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.345

2023-01-14 17:13:38,946 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:13:38,947 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:13:38,990 - 

2023-01-14 17:13:38,990 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:13:41,805 - Epoch: [269][    6/    6]    Overall Loss 0.012939    Objective Loss 0.012939    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.468948    
2023-01-14 17:13:41,849 - --- validate (epoch=269)-----------
2023-01-14 17:13:41,850 - 148 samples (240 per mini-batch)
2023-01-14 17:13:42,403 - Epoch: [269][    1/    1]    Loss 0.352296    Top1 87.837838    Top5 97.972973    
2023-01-14 17:13:42,448 - ==> Top1: 87.838    Top5: 97.973    Loss: 0.352

2023-01-14 17:13:42,461 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:13:42,462 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:13:42,501 - 

2023-01-14 17:13:42,502 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:13:45,419 - Epoch: [270][    6/    6]    Overall Loss 0.013842    Objective Loss 0.013842    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.485741    
2023-01-14 17:13:45,468 - --- validate (epoch=270)-----------
2023-01-14 17:13:45,469 - 148 samples (240 per mini-batch)
2023-01-14 17:13:45,941 - Epoch: [270][    1/    1]    Loss 0.370374    Top1 89.189189    Top5 99.324324    
2023-01-14 17:13:45,984 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.370

2023-01-14 17:13:45,994 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:13:45,994 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:13:46,039 - 

2023-01-14 17:13:46,040 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:13:48,941 - Epoch: [271][    6/    6]    Overall Loss 0.013774    Objective Loss 0.013774    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.483236    
2023-01-14 17:13:48,983 - --- validate (epoch=271)-----------
2023-01-14 17:13:48,984 - 148 samples (240 per mini-batch)
2023-01-14 17:13:49,594 - Epoch: [271][    1/    1]    Loss 0.346247    Top1 89.864865    Top5 99.324324    
2023-01-14 17:13:49,636 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.346

2023-01-14 17:13:49,647 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:13:49,647 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:13:49,695 - 

2023-01-14 17:13:49,696 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:13:52,801 - Epoch: [272][    6/    6]    Overall Loss 0.013752    Objective Loss 0.013752    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.517352    
2023-01-14 17:13:52,868 - --- validate (epoch=272)-----------
2023-01-14 17:13:52,869 - 148 samples (240 per mini-batch)
2023-01-14 17:13:53,438 - Epoch: [272][    1/    1]    Loss 0.339634    Top1 89.189189    Top5 98.648649    
2023-01-14 17:13:53,489 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.340

2023-01-14 17:13:53,502 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:13:53,504 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:13:53,543 - 

2023-01-14 17:13:53,543 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:13:55,751 - Epoch: [273][    6/    6]    Overall Loss 0.013670    Objective Loss 0.013670    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.367688    
2023-01-14 17:13:55,799 - --- validate (epoch=273)-----------
2023-01-14 17:13:55,799 - 148 samples (240 per mini-batch)
2023-01-14 17:13:56,320 - Epoch: [273][    1/    1]    Loss 0.352300    Top1 89.189189    Top5 98.648649    
2023-01-14 17:13:56,374 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.352

2023-01-14 17:13:56,387 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:13:56,387 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:13:56,428 - 

2023-01-14 17:13:56,429 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:13:59,928 - Epoch: [274][    6/    6]    Overall Loss 0.013314    Objective Loss 0.013314    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.582846    
2023-01-14 17:13:59,977 - --- validate (epoch=274)-----------
2023-01-14 17:13:59,978 - 148 samples (240 per mini-batch)
2023-01-14 17:14:00,507 - Epoch: [274][    1/    1]    Loss 0.342394    Top1 88.513514    Top5 99.324324    
2023-01-14 17:14:00,555 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.342

2023-01-14 17:14:00,565 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:14:00,565 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:14:00,605 - 

2023-01-14 17:14:00,605 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:14:03,258 - Epoch: [275][    6/    6]    Overall Loss 0.013456    Objective Loss 0.013456    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.441839    
2023-01-14 17:14:03,307 - --- validate (epoch=275)-----------
2023-01-14 17:14:03,308 - 148 samples (240 per mini-batch)
2023-01-14 17:14:03,854 - Epoch: [275][    1/    1]    Loss 0.326595    Top1 89.864865    Top5 98.648649    
2023-01-14 17:14:03,900 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.327

2023-01-14 17:14:03,907 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:14:03,907 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:14:03,950 - 

2023-01-14 17:14:03,951 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:14:06,505 - Epoch: [276][    6/    6]    Overall Loss 0.013457    Objective Loss 0.013457    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.425374    
2023-01-14 17:14:06,547 - --- validate (epoch=276)-----------
2023-01-14 17:14:06,548 - 148 samples (240 per mini-batch)
2023-01-14 17:14:07,038 - Epoch: [276][    1/    1]    Loss 0.341185    Top1 87.837838    Top5 98.648649    
2023-01-14 17:14:07,081 - ==> Top1: 87.838    Top5: 98.649    Loss: 0.341

2023-01-14 17:14:07,094 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:14:07,095 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:14:07,160 - 

2023-01-14 17:14:07,161 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:14:10,537 - Epoch: [277][    6/    6]    Overall Loss 0.013619    Objective Loss 0.013619    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.562521    
2023-01-14 17:14:10,582 - --- validate (epoch=277)-----------
2023-01-14 17:14:10,583 - 148 samples (240 per mini-batch)
2023-01-14 17:14:11,057 - Epoch: [277][    1/    1]    Loss 0.358118    Top1 87.837838    Top5 98.648649    
2023-01-14 17:14:11,103 - ==> Top1: 87.838    Top5: 98.649    Loss: 0.358

2023-01-14 17:14:11,112 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:14:11,112 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:14:11,154 - 

2023-01-14 17:14:11,155 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:14:14,114 - Epoch: [278][    6/    6]    Overall Loss 0.013825    Objective Loss 0.013825    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.492823    
2023-01-14 17:14:14,163 - --- validate (epoch=278)-----------
2023-01-14 17:14:14,164 - 148 samples (240 per mini-batch)
2023-01-14 17:14:14,728 - Epoch: [278][    1/    1]    Loss 0.354602    Top1 89.189189    Top5 99.324324    
2023-01-14 17:14:14,783 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.355

2023-01-14 17:14:14,794 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:14:14,795 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:14:14,836 - 

2023-01-14 17:14:14,837 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:14:17,527 - Epoch: [279][    6/    6]    Overall Loss 0.013435    Objective Loss 0.013435    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.447887    
2023-01-14 17:14:17,581 - --- validate (epoch=279)-----------
2023-01-14 17:14:17,582 - 148 samples (240 per mini-batch)
2023-01-14 17:14:18,086 - Epoch: [279][    1/    1]    Loss 0.348743    Top1 89.189189    Top5 98.648649    
2023-01-14 17:14:18,122 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.349

2023-01-14 17:14:18,129 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:14:18,129 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:14:18,157 - 

2023-01-14 17:14:18,158 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:14:21,269 - Epoch: [280][    6/    6]    Overall Loss 0.013288    Objective Loss 0.013288    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.518342    
2023-01-14 17:14:21,323 - --- validate (epoch=280)-----------
2023-01-14 17:14:21,324 - 148 samples (240 per mini-batch)
2023-01-14 17:14:21,780 - Epoch: [280][    1/    1]    Loss 0.334969    Top1 89.864865    Top5 97.972973    
2023-01-14 17:14:21,815 - ==> Top1: 89.865    Top5: 97.973    Loss: 0.335

2023-01-14 17:14:21,827 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:14:21,827 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:14:21,861 - 

2023-01-14 17:14:21,861 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:14:25,151 - Epoch: [281][    6/    6]    Overall Loss 0.013274    Objective Loss 0.013274    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.548127    
2023-01-14 17:14:25,200 - --- validate (epoch=281)-----------
2023-01-14 17:14:25,201 - 148 samples (240 per mini-batch)
2023-01-14 17:14:25,765 - Epoch: [281][    1/    1]    Loss 0.328504    Top1 89.864865    Top5 98.648649    
2023-01-14 17:14:25,805 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.329

2023-01-14 17:14:25,815 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:14:25,816 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:14:25,859 - 

2023-01-14 17:14:25,860 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:14:28,613 - Epoch: [282][    6/    6]    Overall Loss 0.013190    Objective Loss 0.013190    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.458662    
2023-01-14 17:14:28,655 - --- validate (epoch=282)-----------
2023-01-14 17:14:28,655 - 148 samples (240 per mini-batch)
2023-01-14 17:14:29,138 - Epoch: [282][    1/    1]    Loss 0.355090    Top1 88.513514    Top5 98.648649    
2023-01-14 17:14:29,179 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.355

2023-01-14 17:14:29,188 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:14:29,188 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:14:29,228 - 

2023-01-14 17:14:29,229 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:14:31,727 - Epoch: [283][    6/    6]    Overall Loss 0.013242    Objective Loss 0.013242    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.416162    
2023-01-14 17:14:31,790 - --- validate (epoch=283)-----------
2023-01-14 17:14:31,790 - 148 samples (240 per mini-batch)
2023-01-14 17:14:32,321 - Epoch: [283][    1/    1]    Loss 0.327170    Top1 89.864865    Top5 99.324324    
2023-01-14 17:14:32,361 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.327

2023-01-14 17:14:32,370 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:14:32,371 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:14:32,435 - 

2023-01-14 17:14:32,436 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:14:35,267 - Epoch: [284][    6/    6]    Overall Loss 0.013720    Objective Loss 0.013720    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.471458    
2023-01-14 17:14:35,316 - --- validate (epoch=284)-----------
2023-01-14 17:14:35,317 - 148 samples (240 per mini-batch)
2023-01-14 17:14:35,838 - Epoch: [284][    1/    1]    Loss 0.322763    Top1 89.189189    Top5 99.324324    
2023-01-14 17:14:35,876 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.323

2023-01-14 17:14:35,887 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:14:35,887 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:14:35,929 - 

2023-01-14 17:14:35,930 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:14:39,256 - Epoch: [285][    6/    6]    Overall Loss 0.013499    Objective Loss 0.013499    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.553657    
2023-01-14 17:14:39,302 - --- validate (epoch=285)-----------
2023-01-14 17:14:39,302 - 148 samples (240 per mini-batch)
2023-01-14 17:14:39,848 - Epoch: [285][    1/    1]    Loss 0.352839    Top1 87.837838    Top5 99.324324    
2023-01-14 17:14:39,885 - ==> Top1: 87.838    Top5: 99.324    Loss: 0.353

2023-01-14 17:14:39,895 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:14:39,895 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:14:39,933 - 

2023-01-14 17:14:39,934 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:14:42,567 - Epoch: [286][    6/    6]    Overall Loss 0.013688    Objective Loss 0.013688    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.438716    
2023-01-14 17:14:42,607 - --- validate (epoch=286)-----------
2023-01-14 17:14:42,607 - 148 samples (240 per mini-batch)
2023-01-14 17:14:43,186 - Epoch: [286][    1/    1]    Loss 0.348104    Top1 88.513514    Top5 98.648649    
2023-01-14 17:14:43,234 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.348

2023-01-14 17:14:43,245 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:14:43,246 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:14:43,298 - 

2023-01-14 17:14:43,299 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:14:46,130 - Epoch: [287][    6/    6]    Overall Loss 0.013705    Objective Loss 0.013705    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.471385    
2023-01-14 17:14:46,166 - --- validate (epoch=287)-----------
2023-01-14 17:14:46,166 - 148 samples (240 per mini-batch)
2023-01-14 17:14:46,717 - Epoch: [287][    1/    1]    Loss 0.337394    Top1 88.513514    Top5 99.324324    
2023-01-14 17:14:46,752 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.337

2023-01-14 17:14:46,763 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:14:46,763 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:14:46,801 - 

2023-01-14 17:14:46,801 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:14:49,560 - Epoch: [288][    6/    6]    Overall Loss 0.013108    Objective Loss 0.013108    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.459540    
2023-01-14 17:14:49,607 - --- validate (epoch=288)-----------
2023-01-14 17:14:49,608 - 148 samples (240 per mini-batch)
2023-01-14 17:14:50,083 - Epoch: [288][    1/    1]    Loss 0.340255    Top1 89.189189    Top5 98.648649    
2023-01-14 17:14:50,123 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.340

2023-01-14 17:14:50,133 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:14:50,133 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:14:50,175 - 

2023-01-14 17:14:50,176 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:14:53,643 - Epoch: [289][    6/    6]    Overall Loss 0.012948    Objective Loss 0.012948    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.577555    
2023-01-14 17:14:53,690 - --- validate (epoch=289)-----------
2023-01-14 17:14:53,691 - 148 samples (240 per mini-batch)
2023-01-14 17:14:54,252 - Epoch: [289][    1/    1]    Loss 0.336847    Top1 89.189189    Top5 98.648649    
2023-01-14 17:14:54,291 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.337

2023-01-14 17:14:54,301 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:14:54,301 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:14:54,334 - 

2023-01-14 17:14:54,335 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:14:57,094 - Epoch: [290][    6/    6]    Overall Loss 0.013323    Objective Loss 0.013323    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.459609    
2023-01-14 17:14:57,136 - --- validate (epoch=290)-----------
2023-01-14 17:14:57,137 - 148 samples (240 per mini-batch)
2023-01-14 17:14:57,614 - Epoch: [290][    1/    1]    Loss 0.361972    Top1 89.189189    Top5 98.648649    
2023-01-14 17:14:57,650 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.362

2023-01-14 17:14:57,661 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:14:57,661 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:14:57,700 - 

2023-01-14 17:14:57,701 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:15:00,521 - Epoch: [291][    6/    6]    Overall Loss 0.013038    Objective Loss 0.013038    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.469830    
2023-01-14 17:15:00,578 - --- validate (epoch=291)-----------
2023-01-14 17:15:00,579 - 148 samples (240 per mini-batch)
2023-01-14 17:15:01,115 - Epoch: [291][    1/    1]    Loss 0.320935    Top1 89.864865    Top5 98.648649    
2023-01-14 17:15:01,155 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.321

2023-01-14 17:15:01,165 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:15:01,166 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:15:01,199 - 

2023-01-14 17:15:01,200 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:15:04,299 - Epoch: [292][    6/    6]    Overall Loss 0.013106    Objective Loss 0.013106    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.516176    
2023-01-14 17:15:04,340 - --- validate (epoch=292)-----------
2023-01-14 17:15:04,341 - 148 samples (240 per mini-batch)
2023-01-14 17:15:04,822 - Epoch: [292][    1/    1]    Loss 0.338539    Top1 89.189189    Top5 98.648649    
2023-01-14 17:15:04,861 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.339

2023-01-14 17:15:04,869 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:15:04,869 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:15:04,905 - 

2023-01-14 17:15:04,906 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:15:07,505 - Epoch: [293][    6/    6]    Overall Loss 0.012977    Objective Loss 0.012977    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.432999    
2023-01-14 17:15:07,548 - --- validate (epoch=293)-----------
2023-01-14 17:15:07,548 - 148 samples (240 per mini-batch)
2023-01-14 17:15:08,008 - Epoch: [293][    1/    1]    Loss 0.342686    Top1 89.864865    Top5 98.648649    
2023-01-14 17:15:08,044 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.343

2023-01-14 17:15:08,053 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:15:08,054 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:15:08,088 - 

2023-01-14 17:15:08,088 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:15:11,343 - Epoch: [294][    6/    6]    Overall Loss 0.013384    Objective Loss 0.013384    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.542257    
2023-01-14 17:15:11,384 - --- validate (epoch=294)-----------
2023-01-14 17:15:11,385 - 148 samples (240 per mini-batch)
2023-01-14 17:15:11,886 - Epoch: [294][    1/    1]    Loss 0.338915    Top1 89.189189    Top5 98.648649    
2023-01-14 17:15:11,929 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.339

2023-01-14 17:15:11,939 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:15:11,940 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:15:11,973 - 

2023-01-14 17:15:11,973 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:15:15,160 - Epoch: [295][    6/    6]    Overall Loss 0.013467    Objective Loss 0.013467    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.530937    
2023-01-14 17:15:15,215 - --- validate (epoch=295)-----------
2023-01-14 17:15:15,216 - 148 samples (240 per mini-batch)
2023-01-14 17:15:15,710 - Epoch: [295][    1/    1]    Loss 0.356470    Top1 87.837838    Top5 99.324324    
2023-01-14 17:15:15,763 - ==> Top1: 87.838    Top5: 99.324    Loss: 0.356

2023-01-14 17:15:15,773 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:15:15,773 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:15:15,808 - 

2023-01-14 17:15:15,809 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:15:19,365 - Epoch: [296][    6/    6]    Overall Loss 0.013329    Objective Loss 0.013329    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.592360    
2023-01-14 17:15:19,412 - --- validate (epoch=296)-----------
2023-01-14 17:15:19,413 - 148 samples (240 per mini-batch)
2023-01-14 17:15:19,892 - Epoch: [296][    1/    1]    Loss 0.347603    Top1 88.513514    Top5 99.324324    
2023-01-14 17:15:19,928 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.348

2023-01-14 17:15:19,937 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:15:19,938 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:15:19,970 - 

2023-01-14 17:15:19,971 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:15:22,372 - Epoch: [297][    6/    6]    Overall Loss 0.013755    Objective Loss 0.013755    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.399895    
2023-01-14 17:15:22,414 - --- validate (epoch=297)-----------
2023-01-14 17:15:22,414 - 148 samples (240 per mini-batch)
2023-01-14 17:15:22,903 - Epoch: [297][    1/    1]    Loss 0.352638    Top1 88.513514    Top5 99.324324    
2023-01-14 17:15:22,936 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.353

2023-01-14 17:15:22,947 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:15:22,948 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:15:22,975 - 

2023-01-14 17:15:22,976 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:15:25,520 - Epoch: [298][    6/    6]    Overall Loss 0.013545    Objective Loss 0.013545    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.423225    
2023-01-14 17:15:25,559 - --- validate (epoch=298)-----------
2023-01-14 17:15:25,560 - 148 samples (240 per mini-batch)
2023-01-14 17:15:26,083 - Epoch: [298][    1/    1]    Loss 0.361117    Top1 89.189189    Top5 99.324324    
2023-01-14 17:15:26,117 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.361

2023-01-14 17:15:26,129 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:15:26,129 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:15:26,167 - 

2023-01-14 17:15:26,168 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:15:28,818 - Epoch: [299][    6/    6]    Overall Loss 0.013226    Objective Loss 0.013226    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.441543    
2023-01-14 17:15:28,859 - --- validate (epoch=299)-----------
2023-01-14 17:15:28,859 - 148 samples (240 per mini-batch)
2023-01-14 17:15:29,417 - Epoch: [299][    1/    1]    Loss 0.336983    Top1 89.864865    Top5 99.324324    
2023-01-14 17:15:29,455 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.337

2023-01-14 17:15:29,464 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:15:29,464 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:15:29,498 - 

2023-01-14 17:15:29,498 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:15:32,569 - Epoch: [300][    6/    6]    Overall Loss 0.013280    Objective Loss 0.013280    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.511561    
2023-01-14 17:15:32,611 - --- validate (epoch=300)-----------
2023-01-14 17:15:32,611 - 148 samples (240 per mini-batch)
2023-01-14 17:15:33,115 - Epoch: [300][    1/    1]    Loss 0.354972    Top1 89.189189    Top5 99.324324    
2023-01-14 17:15:33,150 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.355

2023-01-14 17:15:33,160 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:15:33,160 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:15:33,192 - 

2023-01-14 17:15:33,193 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:15:36,103 - Epoch: [301][    6/    6]    Overall Loss 0.013254    Objective Loss 0.013254    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.484883    
2023-01-14 17:15:36,143 - --- validate (epoch=301)-----------
2023-01-14 17:15:36,144 - 148 samples (240 per mini-batch)
2023-01-14 17:15:36,631 - Epoch: [301][    1/    1]    Loss 0.338629    Top1 90.540541    Top5 98.648649    
2023-01-14 17:15:36,671 - ==> Top1: 90.541    Top5: 98.649    Loss: 0.339

2023-01-14 17:15:36,682 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:15:36,682 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:15:36,727 - 

2023-01-14 17:15:36,728 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:15:39,105 - Epoch: [302][    6/    6]    Overall Loss 0.013006    Objective Loss 0.013006    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.395780    
2023-01-14 17:15:39,149 - --- validate (epoch=302)-----------
2023-01-14 17:15:39,149 - 148 samples (240 per mini-batch)
2023-01-14 17:15:39,649 - Epoch: [302][    1/    1]    Loss 0.318080    Top1 89.864865    Top5 99.324324    
2023-01-14 17:15:39,686 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.318

2023-01-14 17:15:39,697 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:15:39,698 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:15:39,735 - 

2023-01-14 17:15:39,735 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:15:43,164 - Epoch: [303][    6/    6]    Overall Loss 0.013226    Objective Loss 0.013226    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.571157    
2023-01-14 17:15:43,209 - --- validate (epoch=303)-----------
2023-01-14 17:15:43,209 - 148 samples (240 per mini-batch)
2023-01-14 17:15:43,671 - Epoch: [303][    1/    1]    Loss 0.360411    Top1 88.513514    Top5 99.324324    
2023-01-14 17:15:43,716 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.360

2023-01-14 17:15:43,727 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:15:43,728 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:15:43,769 - 

2023-01-14 17:15:43,770 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:15:46,574 - Epoch: [304][    6/    6]    Overall Loss 0.013382    Objective Loss 0.013382    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.466868    
2023-01-14 17:15:46,616 - --- validate (epoch=304)-----------
2023-01-14 17:15:46,617 - 148 samples (240 per mini-batch)
2023-01-14 17:15:47,162 - Epoch: [304][    1/    1]    Loss 0.330606    Top1 89.189189    Top5 99.324324    
2023-01-14 17:15:47,200 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.331

2023-01-14 17:15:47,209 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:15:47,209 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:15:47,243 - 

2023-01-14 17:15:47,244 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:15:50,083 - Epoch: [305][    6/    6]    Overall Loss 0.012937    Objective Loss 0.012937    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.472989    
2023-01-14 17:15:50,125 - --- validate (epoch=305)-----------
2023-01-14 17:15:50,126 - 148 samples (240 per mini-batch)
2023-01-14 17:15:50,680 - Epoch: [305][    1/    1]    Loss 0.356520    Top1 89.189189    Top5 98.648649    
2023-01-14 17:15:50,722 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.357

2023-01-14 17:15:50,733 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:15:50,734 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:15:50,773 - 

2023-01-14 17:15:50,773 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:15:53,203 - Epoch: [306][    6/    6]    Overall Loss 0.013229    Objective Loss 0.013229    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.404733    
2023-01-14 17:15:53,245 - --- validate (epoch=306)-----------
2023-01-14 17:15:53,246 - 148 samples (240 per mini-batch)
2023-01-14 17:15:53,836 - Epoch: [306][    1/    1]    Loss 0.341283    Top1 89.189189    Top5 99.324324    
2023-01-14 17:15:53,869 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.341

2023-01-14 17:15:53,880 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:15:53,880 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:15:53,911 - 

2023-01-14 17:15:53,911 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:15:56,958 - Epoch: [307][    6/    6]    Overall Loss 0.013483    Objective Loss 0.013483    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.507579    
2023-01-14 17:15:56,996 - --- validate (epoch=307)-----------
2023-01-14 17:15:56,997 - 148 samples (240 per mini-batch)
2023-01-14 17:15:57,556 - Epoch: [307][    1/    1]    Loss 0.339554    Top1 89.189189    Top5 99.324324    
2023-01-14 17:15:57,589 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.340

2023-01-14 17:15:57,599 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:15:57,599 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:15:57,625 - 

2023-01-14 17:15:57,625 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:16:00,295 - Epoch: [308][    6/    6]    Overall Loss 0.013348    Objective Loss 0.013348    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.444602    
2023-01-14 17:16:00,337 - --- validate (epoch=308)-----------
2023-01-14 17:16:00,338 - 148 samples (240 per mini-batch)
2023-01-14 17:16:00,902 - Epoch: [308][    1/    1]    Loss 0.330601    Top1 89.189189    Top5 99.324324    
2023-01-14 17:16:00,947 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.331

2023-01-14 17:16:00,953 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:16:00,953 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:16:00,984 - 

2023-01-14 17:16:00,984 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:16:03,365 - Epoch: [309][    6/    6]    Overall Loss 0.013251    Objective Loss 0.013251    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.396656    
2023-01-14 17:16:03,404 - --- validate (epoch=309)-----------
2023-01-14 17:16:03,405 - 148 samples (240 per mini-batch)
2023-01-14 17:16:03,927 - Epoch: [309][    1/    1]    Loss 0.367774    Top1 88.513514    Top5 98.648649    
2023-01-14 17:16:03,962 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.368

2023-01-14 17:16:03,972 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:16:03,973 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:16:04,005 - 

2023-01-14 17:16:04,005 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:16:06,197 - Epoch: [310][    6/    6]    Overall Loss 0.013086    Objective Loss 0.013086    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.365004    
2023-01-14 17:16:06,247 - --- validate (epoch=310)-----------
2023-01-14 17:16:06,247 - 148 samples (240 per mini-batch)
2023-01-14 17:16:06,768 - Epoch: [310][    1/    1]    Loss 0.328444    Top1 90.540541    Top5 98.648649    
2023-01-14 17:16:06,842 - ==> Top1: 90.541    Top5: 98.649    Loss: 0.328

2023-01-14 17:16:06,853 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:16:06,854 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:16:06,886 - 

2023-01-14 17:16:06,888 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:16:09,442 - Epoch: [311][    6/    6]    Overall Loss 0.012978    Objective Loss 0.012978    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.425448    
2023-01-14 17:16:09,490 - --- validate (epoch=311)-----------
2023-01-14 17:16:09,491 - 148 samples (240 per mini-batch)
2023-01-14 17:16:09,967 - Epoch: [311][    1/    1]    Loss 0.345499    Top1 88.513514    Top5 98.648649    
2023-01-14 17:16:10,007 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.345

2023-01-14 17:16:10,017 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:16:10,017 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:16:10,050 - 

2023-01-14 17:16:10,050 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:16:12,753 - Epoch: [312][    6/    6]    Overall Loss 0.013180    Objective Loss 0.013180    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.450167    
2023-01-14 17:16:12,795 - --- validate (epoch=312)-----------
2023-01-14 17:16:12,795 - 148 samples (240 per mini-batch)
2023-01-14 17:16:13,306 - Epoch: [312][    1/    1]    Loss 0.332675    Top1 89.864865    Top5 98.648649    
2023-01-14 17:16:13,345 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.333

2023-01-14 17:16:13,353 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:16:13,354 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:16:13,382 - 

2023-01-14 17:16:13,383 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:16:16,616 - Epoch: [313][    6/    6]    Overall Loss 0.013418    Objective Loss 0.013418    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.538405    
2023-01-14 17:16:16,661 - --- validate (epoch=313)-----------
2023-01-14 17:16:16,662 - 148 samples (240 per mini-batch)
2023-01-14 17:16:17,412 - Epoch: [313][    1/    1]    Loss 0.344175    Top1 89.864865    Top5 99.324324    
2023-01-14 17:16:17,476 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.344

2023-01-14 17:16:17,488 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:16:17,489 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:16:17,526 - 

2023-01-14 17:16:17,527 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:16:21,110 - Epoch: [314][    6/    6]    Overall Loss 0.013075    Objective Loss 0.013075    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.596986    
2023-01-14 17:16:21,150 - --- validate (epoch=314)-----------
2023-01-14 17:16:21,151 - 148 samples (240 per mini-batch)
2023-01-14 17:16:21,685 - Epoch: [314][    1/    1]    Loss 0.327601    Top1 89.189189    Top5 98.648649    
2023-01-14 17:16:21,723 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.328

2023-01-14 17:16:21,731 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:16:21,732 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:16:21,768 - 

2023-01-14 17:16:21,768 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:16:24,110 - Epoch: [315][    6/    6]    Overall Loss 0.013398    Objective Loss 0.013398    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.390137    
2023-01-14 17:16:24,147 - --- validate (epoch=315)-----------
2023-01-14 17:16:24,147 - 148 samples (240 per mini-batch)
2023-01-14 17:16:24,690 - Epoch: [315][    1/    1]    Loss 0.330123    Top1 88.513514    Top5 99.324324    
2023-01-14 17:16:24,731 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.330

2023-01-14 17:16:24,739 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:16:24,739 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:16:24,770 - 

2023-01-14 17:16:24,770 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:16:27,490 - Epoch: [316][    6/    6]    Overall Loss 0.013463    Objective Loss 0.013463    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.453020    
2023-01-14 17:16:27,538 - --- validate (epoch=316)-----------
2023-01-14 17:16:27,539 - 148 samples (240 per mini-batch)
2023-01-14 17:16:28,052 - Epoch: [316][    1/    1]    Loss 0.336033    Top1 89.864865    Top5 99.324324    
2023-01-14 17:16:28,087 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.336

2023-01-14 17:16:28,099 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:16:28,099 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:16:28,136 - 

2023-01-14 17:16:28,137 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:16:31,577 - Epoch: [317][    6/    6]    Overall Loss 0.013395    Objective Loss 0.013395    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.573082    
2023-01-14 17:16:31,618 - --- validate (epoch=317)-----------
2023-01-14 17:16:31,619 - 148 samples (240 per mini-batch)
2023-01-14 17:16:32,079 - Epoch: [317][    1/    1]    Loss 0.334603    Top1 89.864865    Top5 98.648649    
2023-01-14 17:16:32,120 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.335

2023-01-14 17:16:32,131 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:16:32,132 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:16:32,175 - 

2023-01-14 17:16:32,176 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:16:34,684 - Epoch: [318][    6/    6]    Overall Loss 0.012681    Objective Loss 0.012681    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.417433    
2023-01-14 17:16:34,724 - --- validate (epoch=318)-----------
2023-01-14 17:16:34,725 - 148 samples (240 per mini-batch)
2023-01-14 17:16:35,255 - Epoch: [318][    1/    1]    Loss 0.339017    Top1 89.189189    Top5 98.648649    
2023-01-14 17:16:35,301 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.339

2023-01-14 17:16:35,313 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:16:35,313 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:16:35,353 - 

2023-01-14 17:16:35,354 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:16:37,877 - Epoch: [319][    6/    6]    Overall Loss 0.013278    Objective Loss 0.013278    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.420348    
2023-01-14 17:16:37,916 - --- validate (epoch=319)-----------
2023-01-14 17:16:37,916 - 148 samples (240 per mini-batch)
2023-01-14 17:16:38,434 - Epoch: [319][    1/    1]    Loss 0.337287    Top1 87.837838    Top5 99.324324    
2023-01-14 17:16:38,472 - ==> Top1: 87.838    Top5: 99.324    Loss: 0.337

2023-01-14 17:16:38,483 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:16:38,484 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:16:38,521 - 

2023-01-14 17:16:38,521 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:16:41,852 - Epoch: [320][    6/    6]    Overall Loss 0.013091    Objective Loss 0.013091    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.554816    
2023-01-14 17:16:41,918 - --- validate (epoch=320)-----------
2023-01-14 17:16:41,918 - 148 samples (240 per mini-batch)
2023-01-14 17:16:42,452 - Epoch: [320][    1/    1]    Loss 0.355306    Top1 88.513514    Top5 99.324324    
2023-01-14 17:16:42,504 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.355

2023-01-14 17:16:42,518 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:16:42,518 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:16:42,552 - 

2023-01-14 17:16:42,553 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:16:45,628 - Epoch: [321][    6/    6]    Overall Loss 0.013202    Objective Loss 0.013202    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.512259    
2023-01-14 17:16:45,678 - --- validate (epoch=321)-----------
2023-01-14 17:16:45,679 - 148 samples (240 per mini-batch)
2023-01-14 17:16:46,299 - Epoch: [321][    1/    1]    Loss 0.326121    Top1 89.864865    Top5 98.648649    
2023-01-14 17:16:46,347 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.326

2023-01-14 17:16:46,355 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:16:46,356 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:16:46,398 - 

2023-01-14 17:16:46,399 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:16:48,988 - Epoch: [322][    6/    6]    Overall Loss 0.012674    Objective Loss 0.012674    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.431261    
2023-01-14 17:16:49,028 - --- validate (epoch=322)-----------
2023-01-14 17:16:49,029 - 148 samples (240 per mini-batch)
2023-01-14 17:16:49,505 - Epoch: [322][    1/    1]    Loss 0.347028    Top1 88.513514    Top5 98.648649    
2023-01-14 17:16:49,550 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.347

2023-01-14 17:16:49,562 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:16:49,563 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:16:49,595 - 

2023-01-14 17:16:49,596 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:16:52,351 - Epoch: [323][    6/    6]    Overall Loss 0.013592    Objective Loss 0.013592    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.458965    
2023-01-14 17:16:52,394 - --- validate (epoch=323)-----------
2023-01-14 17:16:52,395 - 148 samples (240 per mini-batch)
2023-01-14 17:16:53,007 - Epoch: [323][    1/    1]    Loss 0.340839    Top1 89.189189    Top5 99.324324    
2023-01-14 17:16:53,044 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.341

2023-01-14 17:16:53,052 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:16:53,053 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:16:53,082 - 

2023-01-14 17:16:53,082 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:16:55,566 - Epoch: [324][    6/    6]    Overall Loss 0.013161    Objective Loss 0.013161    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.413663    
2023-01-14 17:16:55,606 - --- validate (epoch=324)-----------
2023-01-14 17:16:55,606 - 148 samples (240 per mini-batch)
2023-01-14 17:16:56,174 - Epoch: [324][    1/    1]    Loss 0.358665    Top1 88.513514    Top5 99.324324    
2023-01-14 17:16:56,219 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.359

2023-01-14 17:16:56,230 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:16:56,230 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:16:56,268 - 

2023-01-14 17:16:56,269 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:16:59,085 - Epoch: [325][    6/    6]    Overall Loss 0.012867    Objective Loss 0.012867    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.469126    
2023-01-14 17:16:59,126 - --- validate (epoch=325)-----------
2023-01-14 17:16:59,126 - 148 samples (240 per mini-batch)
2023-01-14 17:16:59,694 - Epoch: [325][    1/    1]    Loss 0.370472    Top1 89.864865    Top5 98.648649    
2023-01-14 17:16:59,735 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.370

2023-01-14 17:16:59,744 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 239]
2023-01-14 17:16:59,745 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:16:59,789 - 

2023-01-14 17:16:59,789 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:17:02,627 - Epoch: [326][    6/    6]    Overall Loss 0.012974    Objective Loss 0.012974    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.472548    
2023-01-14 17:17:02,684 - --- validate (epoch=326)-----------
2023-01-14 17:17:02,684 - 148 samples (240 per mini-batch)
2023-01-14 17:17:03,209 - Epoch: [326][    1/    1]    Loss 0.340952    Top1 90.540541    Top5 99.324324    
2023-01-14 17:17:03,252 - ==> Top1: 90.541    Top5: 99.324    Loss: 0.341

2023-01-14 17:17:03,261 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 326]
2023-01-14 17:17:03,261 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:17:03,303 - 

2023-01-14 17:17:03,303 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:17:06,133 - Epoch: [327][    6/    6]    Overall Loss 0.012565    Objective Loss 0.012565    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.471348    
2023-01-14 17:17:06,173 - --- validate (epoch=327)-----------
2023-01-14 17:17:06,174 - 148 samples (240 per mini-batch)
2023-01-14 17:17:06,729 - Epoch: [327][    1/    1]    Loss 0.331516    Top1 89.189189    Top5 98.648649    
2023-01-14 17:17:06,766 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.332

2023-01-14 17:17:06,778 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 326]
2023-01-14 17:17:06,778 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:17:06,824 - 

2023-01-14 17:17:06,825 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:17:09,349 - Epoch: [328][    6/    6]    Overall Loss 0.013132    Objective Loss 0.013132    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.420514    
2023-01-14 17:17:09,391 - --- validate (epoch=328)-----------
2023-01-14 17:17:09,393 - 148 samples (240 per mini-batch)
2023-01-14 17:17:09,920 - Epoch: [328][    1/    1]    Loss 0.337277    Top1 89.189189    Top5 98.648649    
2023-01-14 17:17:09,954 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.337

2023-01-14 17:17:09,965 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 326]
2023-01-14 17:17:09,965 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:17:09,994 - 

2023-01-14 17:17:09,994 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:17:12,810 - Epoch: [329][    6/    6]    Overall Loss 0.012905    Objective Loss 0.012905    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.469042    
2023-01-14 17:17:12,848 - --- validate (epoch=329)-----------
2023-01-14 17:17:12,849 - 148 samples (240 per mini-batch)
2023-01-14 17:17:13,445 - Epoch: [329][    1/    1]    Loss 0.337481    Top1 88.513514    Top5 98.648649    
2023-01-14 17:17:13,500 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.337

2023-01-14 17:17:13,516 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 326]
2023-01-14 17:17:13,517 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:17:13,565 - 

2023-01-14 17:17:13,566 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:17:16,459 - Epoch: [330][    6/    6]    Overall Loss 0.012389    Objective Loss 0.012389    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.481975    
2023-01-14 17:17:16,508 - --- validate (epoch=330)-----------
2023-01-14 17:17:16,509 - 148 samples (240 per mini-batch)
2023-01-14 17:17:16,971 - Epoch: [330][    1/    1]    Loss 0.337841    Top1 89.189189    Top5 99.324324    
2023-01-14 17:17:17,016 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.338

2023-01-14 17:17:17,024 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 326]
2023-01-14 17:17:17,025 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:17:17,059 - 

2023-01-14 17:17:17,060 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:17:19,979 - Epoch: [331][    6/    6]    Overall Loss 0.012546    Objective Loss 0.012546    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.486241    
2023-01-14 17:17:20,017 - --- validate (epoch=331)-----------
2023-01-14 17:17:20,018 - 148 samples (240 per mini-batch)
2023-01-14 17:17:20,625 - Epoch: [331][    1/    1]    Loss 0.351218    Top1 90.540541    Top5 98.648649    
2023-01-14 17:17:20,662 - ==> Top1: 90.541    Top5: 98.649    Loss: 0.351

2023-01-14 17:17:20,675 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 326]
2023-01-14 17:17:20,676 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:17:20,708 - 

2023-01-14 17:17:20,709 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:17:23,145 - Epoch: [332][    6/    6]    Overall Loss 0.012902    Objective Loss 0.012902    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.405801    
2023-01-14 17:17:23,185 - --- validate (epoch=332)-----------
2023-01-14 17:17:23,186 - 148 samples (240 per mini-batch)
2023-01-14 17:17:23,670 - Epoch: [332][    1/    1]    Loss 0.342839    Top1 88.513514    Top5 99.324324    
2023-01-14 17:17:23,711 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.343

2023-01-14 17:17:23,720 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 326]
2023-01-14 17:17:23,721 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:17:23,754 - 

2023-01-14 17:17:23,755 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:17:26,853 - Epoch: [333][    6/    6]    Overall Loss 0.013184    Objective Loss 0.013184    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.516180    
2023-01-14 17:17:26,894 - --- validate (epoch=333)-----------
2023-01-14 17:17:26,894 - 148 samples (240 per mini-batch)
2023-01-14 17:17:27,491 - Epoch: [333][    1/    1]    Loss 0.345687    Top1 88.513514    Top5 99.324324    
2023-01-14 17:17:27,530 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.346

2023-01-14 17:17:27,540 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 326]
2023-01-14 17:17:27,540 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:17:27,570 - 

2023-01-14 17:17:27,571 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:17:30,454 - Epoch: [334][    6/    6]    Overall Loss 0.012964    Objective Loss 0.012964    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.480231    
2023-01-14 17:17:30,515 - --- validate (epoch=334)-----------
2023-01-14 17:17:30,516 - 148 samples (240 per mini-batch)
2023-01-14 17:17:31,040 - Epoch: [334][    1/    1]    Loss 0.345701    Top1 90.540541    Top5 99.324324    
2023-01-14 17:17:31,082 - ==> Top1: 90.541    Top5: 99.324    Loss: 0.346

2023-01-14 17:17:31,090 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 334]
2023-01-14 17:17:31,091 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:17:31,126 - 

2023-01-14 17:17:31,126 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:17:33,703 - Epoch: [335][    6/    6]    Overall Loss 0.013232    Objective Loss 0.013232    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.429245    
2023-01-14 17:17:33,752 - --- validate (epoch=335)-----------
2023-01-14 17:17:33,754 - 148 samples (240 per mini-batch)
2023-01-14 17:17:34,233 - Epoch: [335][    1/    1]    Loss 0.342028    Top1 90.540541    Top5 99.324324    
2023-01-14 17:17:34,284 - ==> Top1: 90.541    Top5: 99.324    Loss: 0.342

2023-01-14 17:17:34,292 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:17:34,292 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:17:34,338 - 

2023-01-14 17:17:34,338 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:17:37,039 - Epoch: [336][    6/    6]    Overall Loss 0.012894    Objective Loss 0.012894    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.449908    
2023-01-14 17:17:37,082 - --- validate (epoch=336)-----------
2023-01-14 17:17:37,083 - 148 samples (240 per mini-batch)
2023-01-14 17:17:37,586 - Epoch: [336][    1/    1]    Loss 0.351087    Top1 89.189189    Top5 99.324324    
2023-01-14 17:17:37,623 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.351

2023-01-14 17:17:37,633 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:17:37,633 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:17:37,663 - 

2023-01-14 17:17:37,664 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:17:40,358 - Epoch: [337][    6/    6]    Overall Loss 0.012826    Objective Loss 0.012826    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.448487    
2023-01-14 17:17:40,398 - --- validate (epoch=337)-----------
2023-01-14 17:17:40,398 - 148 samples (240 per mini-batch)
2023-01-14 17:17:41,103 - Epoch: [337][    1/    1]    Loss 0.321793    Top1 89.189189    Top5 98.648649    
2023-01-14 17:17:41,153 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.322

2023-01-14 17:17:41,161 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:17:41,162 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:17:41,203 - 

2023-01-14 17:17:41,204 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:17:45,066 - Epoch: [338][    6/    6]    Overall Loss 0.012474    Objective Loss 0.012474    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.643380    
2023-01-14 17:17:45,122 - --- validate (epoch=338)-----------
2023-01-14 17:17:45,122 - 148 samples (240 per mini-batch)
2023-01-14 17:17:45,750 - Epoch: [338][    1/    1]    Loss 0.363893    Top1 87.837838    Top5 98.648649    
2023-01-14 17:17:45,794 - ==> Top1: 87.838    Top5: 98.649    Loss: 0.364

2023-01-14 17:17:45,804 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:17:45,804 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:17:45,836 - 

2023-01-14 17:17:45,836 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:17:49,067 - Epoch: [339][    6/    6]    Overall Loss 0.012543    Objective Loss 0.012543    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.538305    
2023-01-14 17:17:49,108 - --- validate (epoch=339)-----------
2023-01-14 17:17:49,109 - 148 samples (240 per mini-batch)
2023-01-14 17:17:49,629 - Epoch: [339][    1/    1]    Loss 0.351064    Top1 89.189189    Top5 98.648649    
2023-01-14 17:17:49,671 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.351

2023-01-14 17:17:49,680 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:17:49,680 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:17:49,713 - 

2023-01-14 17:17:49,714 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:17:52,633 - Epoch: [340][    6/    6]    Overall Loss 0.012999    Objective Loss 0.012999    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.486169    
2023-01-14 17:17:52,679 - --- validate (epoch=340)-----------
2023-01-14 17:17:52,680 - 148 samples (240 per mini-batch)
2023-01-14 17:17:53,149 - Epoch: [340][    1/    1]    Loss 0.350037    Top1 87.837838    Top5 98.648649    
2023-01-14 17:17:53,188 - ==> Top1: 87.838    Top5: 98.649    Loss: 0.350

2023-01-14 17:17:53,196 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:17:53,197 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:17:53,228 - 

2023-01-14 17:17:53,228 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:17:55,672 - Epoch: [341][    6/    6]    Overall Loss 0.012725    Objective Loss 0.012725    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.407126    
2023-01-14 17:17:55,717 - --- validate (epoch=341)-----------
2023-01-14 17:17:55,718 - 148 samples (240 per mini-batch)
2023-01-14 17:17:56,314 - Epoch: [341][    1/    1]    Loss 0.346230    Top1 89.864865    Top5 98.648649    
2023-01-14 17:17:56,349 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.346

2023-01-14 17:17:56,361 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:17:56,362 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:17:56,390 - 

2023-01-14 17:17:56,391 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:17:59,090 - Epoch: [342][    6/    6]    Overall Loss 0.012997    Objective Loss 0.012997    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.449736    
2023-01-14 17:17:59,128 - --- validate (epoch=342)-----------
2023-01-14 17:17:59,128 - 148 samples (240 per mini-batch)
2023-01-14 17:17:59,670 - Epoch: [342][    1/    1]    Loss 0.341091    Top1 89.864865    Top5 98.648649    
2023-01-14 17:17:59,707 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.341

2023-01-14 17:17:59,719 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:17:59,720 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:17:59,753 - 

2023-01-14 17:17:59,754 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:18:02,532 - Epoch: [343][    6/    6]    Overall Loss 0.012425    Objective Loss 0.012425    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.462839    
2023-01-14 17:18:02,575 - --- validate (epoch=343)-----------
2023-01-14 17:18:02,575 - 148 samples (240 per mini-batch)
2023-01-14 17:18:03,036 - Epoch: [343][    1/    1]    Loss 0.353177    Top1 89.864865    Top5 99.324324    
2023-01-14 17:18:03,070 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.353

2023-01-14 17:18:03,082 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:18:03,083 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:18:03,116 - 

2023-01-14 17:18:03,117 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:18:05,777 - Epoch: [344][    6/    6]    Overall Loss 0.012436    Objective Loss 0.012436    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.443136    
2023-01-14 17:18:05,811 - --- validate (epoch=344)-----------
2023-01-14 17:18:05,812 - 148 samples (240 per mini-batch)
2023-01-14 17:18:06,362 - Epoch: [344][    1/    1]    Loss 0.341114    Top1 89.864865    Top5 98.648649    
2023-01-14 17:18:06,399 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.341

2023-01-14 17:18:06,411 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:18:06,411 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:18:06,446 - 

2023-01-14 17:18:06,447 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:18:08,917 - Epoch: [345][    6/    6]    Overall Loss 0.012791    Objective Loss 0.012791    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.411491    
2023-01-14 17:18:08,957 - --- validate (epoch=345)-----------
2023-01-14 17:18:08,957 - 148 samples (240 per mini-batch)
2023-01-14 17:18:09,401 - Epoch: [345][    1/    1]    Loss 0.343663    Top1 89.189189    Top5 98.648649    
2023-01-14 17:18:09,441 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.344

2023-01-14 17:18:09,453 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:18:09,454 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:18:09,494 - 

2023-01-14 17:18:09,494 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:18:12,066 - Epoch: [346][    6/    6]    Overall Loss 0.013039    Objective Loss 0.013039    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.428341    
2023-01-14 17:18:12,106 - --- validate (epoch=346)-----------
2023-01-14 17:18:12,106 - 148 samples (240 per mini-batch)
2023-01-14 17:18:12,577 - Epoch: [346][    1/    1]    Loss 0.373677    Top1 89.864865    Top5 99.324324    
2023-01-14 17:18:12,616 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.374

2023-01-14 17:18:12,625 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:18:12,626 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:18:12,657 - 

2023-01-14 17:18:12,657 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:18:15,483 - Epoch: [347][    6/    6]    Overall Loss 0.013152    Objective Loss 0.013152    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.470631    
2023-01-14 17:18:15,549 - --- validate (epoch=347)-----------
2023-01-14 17:18:15,550 - 148 samples (240 per mini-batch)
2023-01-14 17:18:16,091 - Epoch: [347][    1/    1]    Loss 0.337295    Top1 89.864865    Top5 98.648649    
2023-01-14 17:18:16,130 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.337

2023-01-14 17:18:16,137 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:18:16,138 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:18:16,169 - 

2023-01-14 17:18:16,169 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:18:19,183 - Epoch: [348][    6/    6]    Overall Loss 0.012458    Objective Loss 0.012458    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.501928    
2023-01-14 17:18:19,220 - --- validate (epoch=348)-----------
2023-01-14 17:18:19,221 - 148 samples (240 per mini-batch)
2023-01-14 17:18:19,766 - Epoch: [348][    1/    1]    Loss 0.328923    Top1 88.513514    Top5 99.324324    
2023-01-14 17:18:19,800 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.329

2023-01-14 17:18:19,813 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:18:19,814 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:18:19,856 - 

2023-01-14 17:18:19,856 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:18:22,598 - Epoch: [349][    6/    6]    Overall Loss 0.013037    Objective Loss 0.013037    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.456657    
2023-01-14 17:18:22,634 - --- validate (epoch=349)-----------
2023-01-14 17:18:22,635 - 148 samples (240 per mini-batch)
2023-01-14 17:18:23,133 - Epoch: [349][    1/    1]    Loss 0.324790    Top1 89.189189    Top5 98.648649    
2023-01-14 17:18:23,168 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.325

2023-01-14 17:18:23,182 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:18:23,182 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:18:23,215 - 

2023-01-14 17:18:23,215 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:18:26,143 - Epoch: [350][    6/    6]    Overall Loss 0.013429    Objective Loss 0.013429    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.487615    
2023-01-14 17:18:26,179 - --- validate (epoch=350)-----------
2023-01-14 17:18:26,180 - 148 samples (240 per mini-batch)
2023-01-14 17:18:26,777 - Epoch: [350][    1/    1]    Loss 0.355602    Top1 89.189189    Top5 99.324324    
2023-01-14 17:18:26,825 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.356

2023-01-14 17:18:26,836 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:18:26,836 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:18:26,868 - 

2023-01-14 17:18:26,869 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:18:29,682 - Epoch: [351][    6/    6]    Overall Loss 0.012573    Objective Loss 0.012573    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.468732    
2023-01-14 17:18:29,722 - --- validate (epoch=351)-----------
2023-01-14 17:18:29,723 - 148 samples (240 per mini-batch)
2023-01-14 17:18:30,297 - Epoch: [351][    1/    1]    Loss 0.356817    Top1 89.189189    Top5 99.324324    
2023-01-14 17:18:30,335 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.357

2023-01-14 17:18:30,345 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:18:30,345 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:18:30,378 - 

2023-01-14 17:18:30,379 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:18:32,987 - Epoch: [352][    6/    6]    Overall Loss 0.012836    Objective Loss 0.012836    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.434435    
2023-01-14 17:18:33,026 - --- validate (epoch=352)-----------
2023-01-14 17:18:33,027 - 148 samples (240 per mini-batch)
2023-01-14 17:18:33,523 - Epoch: [352][    1/    1]    Loss 0.352567    Top1 89.189189    Top5 98.648649    
2023-01-14 17:18:33,562 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.353

2023-01-14 17:18:33,571 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:18:33,572 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:18:33,615 - 

2023-01-14 17:18:33,616 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:18:36,396 - Epoch: [353][    6/    6]    Overall Loss 0.012766    Objective Loss 0.012766    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.463075    
2023-01-14 17:18:36,439 - --- validate (epoch=353)-----------
2023-01-14 17:18:36,440 - 148 samples (240 per mini-batch)
2023-01-14 17:18:37,014 - Epoch: [353][    1/    1]    Loss 0.348847    Top1 89.189189    Top5 98.648649    
2023-01-14 17:18:37,054 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.349

2023-01-14 17:18:37,064 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:18:37,065 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:18:37,098 - 

2023-01-14 17:18:37,098 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:18:39,571 - Epoch: [354][    6/    6]    Overall Loss 0.012913    Objective Loss 0.012913    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.411918    
2023-01-14 17:18:39,613 - --- validate (epoch=354)-----------
2023-01-14 17:18:39,615 - 148 samples (240 per mini-batch)
2023-01-14 17:18:40,176 - Epoch: [354][    1/    1]    Loss 0.346417    Top1 89.864865    Top5 99.324324    
2023-01-14 17:18:40,215 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.346

2023-01-14 17:18:40,225 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:18:40,225 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:18:40,258 - 

2023-01-14 17:18:40,259 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:18:43,889 - Epoch: [355][    6/    6]    Overall Loss 0.012485    Objective Loss 0.012485    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.604762    
2023-01-14 17:18:43,927 - --- validate (epoch=355)-----------
2023-01-14 17:18:43,928 - 148 samples (240 per mini-batch)
2023-01-14 17:18:44,406 - Epoch: [355][    1/    1]    Loss 0.356321    Top1 88.513514    Top5 98.648649    
2023-01-14 17:18:44,448 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.356

2023-01-14 17:18:44,460 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:18:44,460 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:18:44,497 - 

2023-01-14 17:18:44,498 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:18:47,197 - Epoch: [356][    6/    6]    Overall Loss 0.012899    Objective Loss 0.012899    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.449585    
2023-01-14 17:18:47,242 - --- validate (epoch=356)-----------
2023-01-14 17:18:47,243 - 148 samples (240 per mini-batch)
2023-01-14 17:18:47,762 - Epoch: [356][    1/    1]    Loss 0.347930    Top1 89.189189    Top5 99.324324    
2023-01-14 17:18:47,801 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.348

2023-01-14 17:18:47,812 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:18:47,812 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:18:47,849 - 

2023-01-14 17:18:47,849 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:18:50,930 - Epoch: [357][    6/    6]    Overall Loss 0.012672    Objective Loss 0.012672    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.513162    
2023-01-14 17:18:50,972 - --- validate (epoch=357)-----------
2023-01-14 17:18:50,972 - 148 samples (240 per mini-batch)
2023-01-14 17:18:51,447 - Epoch: [357][    1/    1]    Loss 0.344400    Top1 88.513514    Top5 99.324324    
2023-01-14 17:18:51,482 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.344

2023-01-14 17:18:51,494 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:18:51,495 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:18:51,535 - 

2023-01-14 17:18:51,535 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:18:54,069 - Epoch: [358][    6/    6]    Overall Loss 0.012966    Objective Loss 0.012966    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.421970    
2023-01-14 17:18:54,109 - --- validate (epoch=358)-----------
2023-01-14 17:18:54,110 - 148 samples (240 per mini-batch)
2023-01-14 17:18:54,624 - Epoch: [358][    1/    1]    Loss 0.352996    Top1 89.189189    Top5 98.648649    
2023-01-14 17:18:54,681 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.353

2023-01-14 17:18:54,689 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:18:54,690 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:18:54,719 - 

2023-01-14 17:18:54,720 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:18:57,461 - Epoch: [359][    6/    6]    Overall Loss 0.012639    Objective Loss 0.012639    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.456686    
2023-01-14 17:18:57,500 - --- validate (epoch=359)-----------
2023-01-14 17:18:57,501 - 148 samples (240 per mini-batch)
2023-01-14 17:18:57,977 - Epoch: [359][    1/    1]    Loss 0.360640    Top1 89.189189    Top5 98.648649    
2023-01-14 17:18:58,015 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.361

2023-01-14 17:18:58,025 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:18:58,025 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:18:58,066 - 

2023-01-14 17:18:58,066 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:19:01,321 - Epoch: [360][    6/    6]    Overall Loss 0.012071    Objective Loss 0.012071    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.542229    
2023-01-14 17:19:01,362 - --- validate (epoch=360)-----------
2023-01-14 17:19:01,362 - 148 samples (240 per mini-batch)
2023-01-14 17:19:01,833 - Epoch: [360][    1/    1]    Loss 0.336560    Top1 89.864865    Top5 98.648649    
2023-01-14 17:19:01,871 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.337

2023-01-14 17:19:01,882 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:19:01,882 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:19:01,920 - 

2023-01-14 17:19:01,920 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:19:04,409 - Epoch: [361][    6/    6]    Overall Loss 0.012988    Objective Loss 0.012988    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.414540    
2023-01-14 17:19:04,448 - --- validate (epoch=361)-----------
2023-01-14 17:19:04,449 - 148 samples (240 per mini-batch)
2023-01-14 17:19:04,996 - Epoch: [361][    1/    1]    Loss 0.359021    Top1 90.540541    Top5 98.648649    
2023-01-14 17:19:05,037 - ==> Top1: 90.541    Top5: 98.649    Loss: 0.359

2023-01-14 17:19:05,046 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:19:05,046 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:19:05,083 - 

2023-01-14 17:19:05,084 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:19:07,979 - Epoch: [362][    6/    6]    Overall Loss 0.012967    Objective Loss 0.012967    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.482169    
2023-01-14 17:19:08,021 - --- validate (epoch=362)-----------
2023-01-14 17:19:08,021 - 148 samples (240 per mini-batch)
2023-01-14 17:19:08,533 - Epoch: [362][    1/    1]    Loss 0.364373    Top1 88.513514    Top5 99.324324    
2023-01-14 17:19:08,567 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.364

2023-01-14 17:19:08,581 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:19:08,582 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:19:08,614 - 

2023-01-14 17:19:08,614 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:19:11,177 - Epoch: [363][    6/    6]    Overall Loss 0.012423    Objective Loss 0.012423    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.426789    
2023-01-14 17:19:11,218 - --- validate (epoch=363)-----------
2023-01-14 17:19:11,219 - 148 samples (240 per mini-batch)
2023-01-14 17:19:11,719 - Epoch: [363][    1/    1]    Loss 0.346198    Top1 89.189189    Top5 98.648649    
2023-01-14 17:19:11,764 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.346

2023-01-14 17:19:11,773 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:19:11,774 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:19:11,805 - 

2023-01-14 17:19:11,806 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:19:15,057 - Epoch: [364][    6/    6]    Overall Loss 0.012705    Objective Loss 0.012705    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.541576    
2023-01-14 17:19:15,097 - --- validate (epoch=364)-----------
2023-01-14 17:19:15,097 - 148 samples (240 per mini-batch)
2023-01-14 17:19:15,711 - Epoch: [364][    1/    1]    Loss 0.367944    Top1 89.864865    Top5 99.324324    
2023-01-14 17:19:15,745 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.368

2023-01-14 17:19:15,755 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:19:15,755 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:19:15,782 - 

2023-01-14 17:19:15,783 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:19:18,632 - Epoch: [365][    6/    6]    Overall Loss 0.012234    Objective Loss 0.012234    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.474674    
2023-01-14 17:19:18,677 - --- validate (epoch=365)-----------
2023-01-14 17:19:18,678 - 148 samples (240 per mini-batch)
2023-01-14 17:19:19,231 - Epoch: [365][    1/    1]    Loss 0.326097    Top1 88.513514    Top5 99.324324    
2023-01-14 17:19:19,269 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.326

2023-01-14 17:19:19,280 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:19:19,281 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:19:19,319 - 

2023-01-14 17:19:19,319 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:19:21,840 - Epoch: [366][    6/    6]    Overall Loss 0.012205    Objective Loss 0.012205    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.419945    
2023-01-14 17:19:21,874 - --- validate (epoch=366)-----------
2023-01-14 17:19:21,875 - 148 samples (240 per mini-batch)
2023-01-14 17:19:22,420 - Epoch: [366][    1/    1]    Loss 0.357862    Top1 89.189189    Top5 99.324324    
2023-01-14 17:19:22,462 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.358

2023-01-14 17:19:22,470 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:19:22,471 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:19:22,504 - 

2023-01-14 17:19:22,504 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:19:25,428 - Epoch: [367][    6/    6]    Overall Loss 0.012194    Objective Loss 0.012194    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.487054    
2023-01-14 17:19:25,472 - --- validate (epoch=367)-----------
2023-01-14 17:19:25,473 - 148 samples (240 per mini-batch)
2023-01-14 17:19:25,951 - Epoch: [367][    1/    1]    Loss 0.329853    Top1 89.864865    Top5 99.324324    
2023-01-14 17:19:25,987 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.330

2023-01-14 17:19:25,997 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:19:25,997 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:19:26,028 - 

2023-01-14 17:19:26,029 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:19:28,799 - Epoch: [368][    6/    6]    Overall Loss 0.012167    Objective Loss 0.012167    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.461434    
2023-01-14 17:19:28,845 - --- validate (epoch=368)-----------
2023-01-14 17:19:28,846 - 148 samples (240 per mini-batch)
2023-01-14 17:19:29,304 - Epoch: [368][    1/    1]    Loss 0.340866    Top1 88.513514    Top5 98.648649    
2023-01-14 17:19:29,340 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.341

2023-01-14 17:19:29,350 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:19:29,351 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:19:29,384 - 

2023-01-14 17:19:29,384 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:19:32,382 - Epoch: [369][    6/    6]    Overall Loss 0.012504    Objective Loss 0.012504    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.499310    
2023-01-14 17:19:32,425 - --- validate (epoch=369)-----------
2023-01-14 17:19:32,426 - 148 samples (240 per mini-batch)
2023-01-14 17:19:32,980 - Epoch: [369][    1/    1]    Loss 0.358915    Top1 89.864865    Top5 99.324324    
2023-01-14 17:19:33,022 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.359

2023-01-14 17:19:33,031 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:19:33,031 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:19:33,071 - 

2023-01-14 17:19:33,071 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:19:36,049 - Epoch: [370][    6/    6]    Overall Loss 0.012294    Objective Loss 0.012294    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.496152    
2023-01-14 17:19:36,092 - --- validate (epoch=370)-----------
2023-01-14 17:19:36,093 - 148 samples (240 per mini-batch)
2023-01-14 17:19:36,648 - Epoch: [370][    1/    1]    Loss 0.345821    Top1 89.189189    Top5 99.324324    
2023-01-14 17:19:36,690 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.346

2023-01-14 17:19:36,700 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:19:36,701 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:19:36,735 - 

2023-01-14 17:19:36,736 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:19:39,882 - Epoch: [371][    6/    6]    Overall Loss 0.012726    Objective Loss 0.012726    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.524008    
2023-01-14 17:19:39,923 - --- validate (epoch=371)-----------
2023-01-14 17:19:39,923 - 148 samples (240 per mini-batch)
2023-01-14 17:19:40,490 - Epoch: [371][    1/    1]    Loss 0.343890    Top1 89.864865    Top5 98.648649    
2023-01-14 17:19:40,531 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.344

2023-01-14 17:19:40,540 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:19:40,540 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:19:40,574 - 

2023-01-14 17:19:40,574 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:19:43,370 - Epoch: [372][    6/    6]    Overall Loss 0.012885    Objective Loss 0.012885    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.465661    
2023-01-14 17:19:43,418 - --- validate (epoch=372)-----------
2023-01-14 17:19:43,418 - 148 samples (240 per mini-batch)
2023-01-14 17:19:43,993 - Epoch: [372][    1/    1]    Loss 0.368187    Top1 89.189189    Top5 98.648649    
2023-01-14 17:19:44,031 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.368

2023-01-14 17:19:44,040 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:19:44,041 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:19:44,073 - 

2023-01-14 17:19:44,073 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:19:47,058 - Epoch: [373][    6/    6]    Overall Loss 0.012323    Objective Loss 0.012323    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.497240    
2023-01-14 17:19:47,116 - --- validate (epoch=373)-----------
2023-01-14 17:19:47,117 - 148 samples (240 per mini-batch)
2023-01-14 17:19:47,694 - Epoch: [373][    1/    1]    Loss 0.364490    Top1 88.513514    Top5 98.648649    
2023-01-14 17:19:47,732 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.364

2023-01-14 17:19:47,741 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:19:47,742 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:19:47,774 - 

2023-01-14 17:19:47,774 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:19:50,547 - Epoch: [374][    6/    6]    Overall Loss 0.012255    Objective Loss 0.012255    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.461997    
2023-01-14 17:19:50,588 - --- validate (epoch=374)-----------
2023-01-14 17:19:50,589 - 148 samples (240 per mini-batch)
2023-01-14 17:19:51,072 - Epoch: [374][    1/    1]    Loss 0.368673    Top1 89.864865    Top5 98.648649    
2023-01-14 17:19:51,108 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.369

2023-01-14 17:19:51,118 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:19:51,118 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:19:51,152 - 

2023-01-14 17:19:51,152 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:19:53,383 - Epoch: [375][    6/    6]    Overall Loss 0.012729    Objective Loss 0.012729    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.371596    
2023-01-14 17:19:53,424 - --- validate (epoch=375)-----------
2023-01-14 17:19:53,425 - 148 samples (240 per mini-batch)
2023-01-14 17:19:53,925 - Epoch: [375][    1/    1]    Loss 0.357376    Top1 90.540541    Top5 98.648649    
2023-01-14 17:19:53,968 - ==> Top1: 90.541    Top5: 98.649    Loss: 0.357

2023-01-14 17:19:53,978 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:19:53,978 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:19:54,017 - 

2023-01-14 17:19:54,018 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:19:56,950 - Epoch: [376][    6/    6]    Overall Loss 0.012717    Objective Loss 0.012717    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.488335    
2023-01-14 17:19:56,989 - --- validate (epoch=376)-----------
2023-01-14 17:19:56,990 - 148 samples (240 per mini-batch)
2023-01-14 17:19:57,563 - Epoch: [376][    1/    1]    Loss 0.347303    Top1 89.189189    Top5 98.648649    
2023-01-14 17:19:57,601 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.347

2023-01-14 17:19:57,608 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:19:57,608 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:19:57,635 - 

2023-01-14 17:19:57,636 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:19:59,884 - Epoch: [377][    6/    6]    Overall Loss 0.013013    Objective Loss 0.013013    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.374577    
2023-01-14 17:19:59,923 - --- validate (epoch=377)-----------
2023-01-14 17:19:59,924 - 148 samples (240 per mini-batch)
2023-01-14 17:20:00,445 - Epoch: [377][    1/    1]    Loss 0.337644    Top1 89.189189    Top5 99.324324    
2023-01-14 17:20:00,483 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.338

2023-01-14 17:20:00,495 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:20:00,495 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:20:00,534 - 

2023-01-14 17:20:00,535 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:20:03,283 - Epoch: [378][    6/    6]    Overall Loss 0.012506    Objective Loss 0.012506    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.457922    
2023-01-14 17:20:03,326 - --- validate (epoch=378)-----------
2023-01-14 17:20:03,327 - 148 samples (240 per mini-batch)
2023-01-14 17:20:03,808 - Epoch: [378][    1/    1]    Loss 0.341155    Top1 89.864865    Top5 99.324324    
2023-01-14 17:20:03,851 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.341

2023-01-14 17:20:03,861 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:20:03,862 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:20:03,893 - 

2023-01-14 17:20:03,893 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:20:06,528 - Epoch: [379][    6/    6]    Overall Loss 0.012375    Objective Loss 0.012375    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.438953    
2023-01-14 17:20:06,569 - --- validate (epoch=379)-----------
2023-01-14 17:20:06,570 - 148 samples (240 per mini-batch)
2023-01-14 17:20:07,131 - Epoch: [379][    1/    1]    Loss 0.345808    Top1 88.513514    Top5 98.648649    
2023-01-14 17:20:07,171 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.346

2023-01-14 17:20:07,180 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:20:07,180 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:20:07,214 - 

2023-01-14 17:20:07,214 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:20:09,769 - Epoch: [380][    6/    6]    Overall Loss 0.012662    Objective Loss 0.012662    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.425614    
2023-01-14 17:20:09,816 - --- validate (epoch=380)-----------
2023-01-14 17:20:09,816 - 148 samples (240 per mini-batch)
2023-01-14 17:20:10,336 - Epoch: [380][    1/    1]    Loss 0.358046    Top1 89.864865    Top5 98.648649    
2023-01-14 17:20:10,373 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.358

2023-01-14 17:20:10,386 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:20:10,386 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:20:10,433 - 

2023-01-14 17:20:10,434 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:20:12,939 - Epoch: [381][    6/    6]    Overall Loss 0.012125    Objective Loss 0.012125    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.417321    
2023-01-14 17:20:12,982 - --- validate (epoch=381)-----------
2023-01-14 17:20:12,982 - 148 samples (240 per mini-batch)
2023-01-14 17:20:13,506 - Epoch: [381][    1/    1]    Loss 0.355677    Top1 89.189189    Top5 99.324324    
2023-01-14 17:20:13,560 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.356

2023-01-14 17:20:13,569 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:20:13,569 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:20:13,604 - 

2023-01-14 17:20:13,605 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:20:16,851 - Epoch: [382][    6/    6]    Overall Loss 0.012233    Objective Loss 0.012233    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.540457    
2023-01-14 17:20:16,897 - --- validate (epoch=382)-----------
2023-01-14 17:20:16,898 - 148 samples (240 per mini-batch)
2023-01-14 17:20:17,380 - Epoch: [382][    1/    1]    Loss 0.332648    Top1 89.864865    Top5 99.324324    
2023-01-14 17:20:17,425 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.333

2023-01-14 17:20:17,432 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:20:17,432 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:20:17,464 - 

2023-01-14 17:20:17,465 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:20:20,264 - Epoch: [383][    6/    6]    Overall Loss 0.012104    Objective Loss 0.012104    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.466211    
2023-01-14 17:20:20,302 - --- validate (epoch=383)-----------
2023-01-14 17:20:20,303 - 148 samples (240 per mini-batch)
2023-01-14 17:20:20,872 - Epoch: [383][    1/    1]    Loss 0.350226    Top1 89.189189    Top5 98.648649    
2023-01-14 17:20:20,913 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.350

2023-01-14 17:20:20,921 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:20:20,921 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:20:20,956 - 

2023-01-14 17:20:20,957 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:20:24,064 - Epoch: [384][    6/    6]    Overall Loss 0.012318    Objective Loss 0.012318    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.517555    
2023-01-14 17:20:24,107 - --- validate (epoch=384)-----------
2023-01-14 17:20:24,107 - 148 samples (240 per mini-batch)
2023-01-14 17:20:24,578 - Epoch: [384][    1/    1]    Loss 0.352048    Top1 89.189189    Top5 98.648649    
2023-01-14 17:20:24,617 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.352

2023-01-14 17:20:24,625 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:20:24,626 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:20:24,660 - 

2023-01-14 17:20:24,661 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:20:27,615 - Epoch: [385][    6/    6]    Overall Loss 0.012275    Objective Loss 0.012275    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.491597    
2023-01-14 17:20:27,661 - --- validate (epoch=385)-----------
2023-01-14 17:20:27,661 - 148 samples (240 per mini-batch)
2023-01-14 17:20:28,235 - Epoch: [385][    1/    1]    Loss 0.327809    Top1 89.864865    Top5 98.648649    
2023-01-14 17:20:28,275 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.328

2023-01-14 17:20:28,285 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:20:28,285 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:20:28,322 - 

2023-01-14 17:20:28,323 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:20:31,372 - Epoch: [386][    6/    6]    Overall Loss 0.012607    Objective Loss 0.012607    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.507898    
2023-01-14 17:20:31,414 - --- validate (epoch=386)-----------
2023-01-14 17:20:31,415 - 148 samples (240 per mini-batch)
2023-01-14 17:20:31,936 - Epoch: [386][    1/    1]    Loss 0.338166    Top1 89.864865    Top5 98.648649    
2023-01-14 17:20:31,972 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.338

2023-01-14 17:20:31,982 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:20:31,983 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:20:32,015 - 

2023-01-14 17:20:32,015 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:20:35,610 - Epoch: [387][    6/    6]    Overall Loss 0.012300    Objective Loss 0.012300    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.598879    
2023-01-14 17:20:35,650 - --- validate (epoch=387)-----------
2023-01-14 17:20:35,651 - 148 samples (240 per mini-batch)
2023-01-14 17:20:36,125 - Epoch: [387][    1/    1]    Loss 0.350691    Top1 89.189189    Top5 99.324324    
2023-01-14 17:20:36,166 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.351

2023-01-14 17:20:36,175 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:20:36,175 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:20:36,208 - 

2023-01-14 17:20:36,209 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:20:38,967 - Epoch: [388][    6/    6]    Overall Loss 0.012370    Objective Loss 0.012370    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.459570    
2023-01-14 17:20:39,006 - --- validate (epoch=388)-----------
2023-01-14 17:20:39,007 - 148 samples (240 per mini-batch)
2023-01-14 17:20:39,486 - Epoch: [388][    1/    1]    Loss 0.345978    Top1 89.864865    Top5 98.648649    
2023-01-14 17:20:39,527 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.346

2023-01-14 17:20:39,536 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:20:39,537 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:20:39,575 - 

2023-01-14 17:20:39,575 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:20:42,312 - Epoch: [389][    6/    6]    Overall Loss 0.012301    Objective Loss 0.012301    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.455934    
2023-01-14 17:20:42,370 - --- validate (epoch=389)-----------
2023-01-14 17:20:42,370 - 148 samples (240 per mini-batch)
2023-01-14 17:20:42,955 - Epoch: [389][    1/    1]    Loss 0.338487    Top1 89.864865    Top5 98.648649    
2023-01-14 17:20:42,996 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.338

2023-01-14 17:20:43,007 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:20:43,008 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:20:43,044 - 

2023-01-14 17:20:43,045 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:20:45,433 - Epoch: [390][    6/    6]    Overall Loss 0.012174    Objective Loss 0.012174    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.397854    
2023-01-14 17:20:45,482 - --- validate (epoch=390)-----------
2023-01-14 17:20:45,483 - 148 samples (240 per mini-batch)
2023-01-14 17:20:46,007 - Epoch: [390][    1/    1]    Loss 0.343425    Top1 89.189189    Top5 98.648649    
2023-01-14 17:20:46,051 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.343

2023-01-14 17:20:46,061 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:20:46,061 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:20:46,091 - 

2023-01-14 17:20:46,092 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:20:49,180 - Epoch: [391][    6/    6]    Overall Loss 0.012530    Objective Loss 0.012530    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.514452    
2023-01-14 17:20:49,229 - --- validate (epoch=391)-----------
2023-01-14 17:20:49,229 - 148 samples (240 per mini-batch)
2023-01-14 17:20:49,705 - Epoch: [391][    1/    1]    Loss 0.325934    Top1 89.864865    Top5 98.648649    
2023-01-14 17:20:49,745 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.326

2023-01-14 17:20:49,755 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:20:49,756 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:20:49,790 - 

2023-01-14 17:20:49,791 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:20:52,595 - Epoch: [392][    6/    6]    Overall Loss 0.012550    Objective Loss 0.012550    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.467023    
2023-01-14 17:20:52,638 - --- validate (epoch=392)-----------
2023-01-14 17:20:52,638 - 148 samples (240 per mini-batch)
2023-01-14 17:20:53,197 - Epoch: [392][    1/    1]    Loss 0.349023    Top1 87.837838    Top5 99.324324    
2023-01-14 17:20:53,237 - ==> Top1: 87.838    Top5: 99.324    Loss: 0.349

2023-01-14 17:20:53,246 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:20:53,247 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:20:53,283 - 

2023-01-14 17:20:53,283 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:20:55,779 - Epoch: [393][    6/    6]    Overall Loss 0.012201    Objective Loss 0.012201    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.415691    
2023-01-14 17:20:55,816 - --- validate (epoch=393)-----------
2023-01-14 17:20:55,817 - 148 samples (240 per mini-batch)
2023-01-14 17:20:56,380 - Epoch: [393][    1/    1]    Loss 0.361242    Top1 89.864865    Top5 98.648649    
2023-01-14 17:20:56,427 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.361

2023-01-14 17:20:56,436 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:20:56,437 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:20:56,471 - 

2023-01-14 17:20:56,471 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:20:59,564 - Epoch: [394][    6/    6]    Overall Loss 0.012150    Objective Loss 0.012150    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.514961    
2023-01-14 17:20:59,601 - --- validate (epoch=394)-----------
2023-01-14 17:20:59,602 - 148 samples (240 per mini-batch)
2023-01-14 17:21:00,084 - Epoch: [394][    1/    1]    Loss 0.337767    Top1 89.864865    Top5 98.648649    
2023-01-14 17:21:00,120 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.338

2023-01-14 17:21:00,130 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:21:00,131 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:21:00,166 - 

2023-01-14 17:21:00,166 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:21:03,327 - Epoch: [395][    6/    6]    Overall Loss 0.012076    Objective Loss 0.012076    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.526515    
2023-01-14 17:21:03,375 - --- validate (epoch=395)-----------
2023-01-14 17:21:03,376 - 148 samples (240 per mini-batch)
2023-01-14 17:21:03,924 - Epoch: [395][    1/    1]    Loss 0.328399    Top1 89.864865    Top5 100.000000    
2023-01-14 17:21:03,964 - ==> Top1: 89.865    Top5: 100.000    Loss: 0.328

2023-01-14 17:21:03,976 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:21:03,977 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:21:04,009 - 

2023-01-14 17:21:04,010 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:21:06,837 - Epoch: [396][    6/    6]    Overall Loss 0.012410    Objective Loss 0.012410    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.470804    
2023-01-14 17:21:06,872 - --- validate (epoch=396)-----------
2023-01-14 17:21:06,873 - 148 samples (240 per mini-batch)
2023-01-14 17:21:07,435 - Epoch: [396][    1/    1]    Loss 0.333821    Top1 89.864865    Top5 98.648649    
2023-01-14 17:21:07,480 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.334

2023-01-14 17:21:07,492 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:21:07,492 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:21:07,525 - 

2023-01-14 17:21:07,525 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:21:10,071 - Epoch: [397][    6/    6]    Overall Loss 0.013207    Objective Loss 0.013207    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.424133    
2023-01-14 17:21:10,115 - --- validate (epoch=397)-----------
2023-01-14 17:21:10,116 - 148 samples (240 per mini-batch)
2023-01-14 17:21:10,633 - Epoch: [397][    1/    1]    Loss 0.329666    Top1 89.864865    Top5 99.324324    
2023-01-14 17:21:10,668 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.330

2023-01-14 17:21:10,678 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:21:10,679 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:21:10,710 - 

2023-01-14 17:21:10,710 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:21:13,971 - Epoch: [398][    6/    6]    Overall Loss 0.012802    Objective Loss 0.012802    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.543116    
2023-01-14 17:21:14,034 - --- validate (epoch=398)-----------
2023-01-14 17:21:14,035 - 148 samples (240 per mini-batch)
2023-01-14 17:21:14,638 - Epoch: [398][    1/    1]    Loss 0.361891    Top1 89.864865    Top5 98.648649    
2023-01-14 17:21:14,686 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.362

2023-01-14 17:21:14,694 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:21:14,694 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:21:14,726 - 

2023-01-14 17:21:14,727 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:21:17,413 - Epoch: [399][    6/    6]    Overall Loss 0.012593    Objective Loss 0.012593    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.447426    
2023-01-14 17:21:17,468 - --- validate (epoch=399)-----------
2023-01-14 17:21:17,468 - 148 samples (240 per mini-batch)
2023-01-14 17:21:17,995 - Epoch: [399][    1/    1]    Loss 0.342037    Top1 89.864865    Top5 98.648649    
2023-01-14 17:21:18,034 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.342

2023-01-14 17:21:18,042 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:21:18,043 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:21:18,072 - 

2023-01-14 17:21:18,073 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:21:21,161 - Epoch: [400][    6/    6]    Overall Loss 0.011818    Objective Loss 0.011818    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.514446    
2023-01-14 17:21:21,220 - --- validate (epoch=400)-----------
2023-01-14 17:21:21,220 - 148 samples (240 per mini-batch)
2023-01-14 17:21:21,694 - Epoch: [400][    1/    1]    Loss 0.346931    Top1 89.189189    Top5 98.648649    
2023-01-14 17:21:21,732 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.347

2023-01-14 17:21:21,742 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:21:21,743 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:21:21,777 - 

2023-01-14 17:21:21,777 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:21:23,950 - Epoch: [401][    6/    6]    Overall Loss 0.012537    Objective Loss 0.012537    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.361946    
2023-01-14 17:21:23,991 - --- validate (epoch=401)-----------
2023-01-14 17:21:23,992 - 148 samples (240 per mini-batch)
2023-01-14 17:21:24,513 - Epoch: [401][    1/    1]    Loss 0.360658    Top1 89.189189    Top5 98.648649    
2023-01-14 17:21:24,548 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.361

2023-01-14 17:21:24,559 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:21:24,560 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:21:24,592 - 

2023-01-14 17:21:24,592 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:21:27,862 - Epoch: [402][    6/    6]    Overall Loss 0.011831    Objective Loss 0.011831    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.544818    
2023-01-14 17:21:27,910 - --- validate (epoch=402)-----------
2023-01-14 17:21:27,911 - 148 samples (240 per mini-batch)
2023-01-14 17:21:28,383 - Epoch: [402][    1/    1]    Loss 0.330927    Top1 89.864865    Top5 99.324324    
2023-01-14 17:21:28,417 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.331

2023-01-14 17:21:28,432 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:21:28,432 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:21:28,524 - 

2023-01-14 17:21:28,524 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:21:32,217 - Epoch: [403][    6/    6]    Overall Loss 0.011977    Objective Loss 0.011977    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.615312    
2023-01-14 17:21:32,256 - --- validate (epoch=403)-----------
2023-01-14 17:21:32,257 - 148 samples (240 per mini-batch)
2023-01-14 17:21:32,742 - Epoch: [403][    1/    1]    Loss 0.330018    Top1 90.540541    Top5 98.648649    
2023-01-14 17:21:32,780 - ==> Top1: 90.541    Top5: 98.649    Loss: 0.330

2023-01-14 17:21:32,790 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:21:32,791 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:21:32,825 - 

2023-01-14 17:21:32,825 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:21:35,653 - Epoch: [404][    6/    6]    Overall Loss 0.012298    Objective Loss 0.012298    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.471110    
2023-01-14 17:21:35,697 - --- validate (epoch=404)-----------
2023-01-14 17:21:35,698 - 148 samples (240 per mini-batch)
2023-01-14 17:21:36,240 - Epoch: [404][    1/    1]    Loss 0.355478    Top1 89.864865    Top5 99.324324    
2023-01-14 17:21:36,275 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.355

2023-01-14 17:21:36,283 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:21:36,283 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:21:36,320 - 

2023-01-14 17:21:36,320 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:21:39,430 - Epoch: [405][    6/    6]    Overall Loss 0.012088    Objective Loss 0.012088    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.517894    
2023-01-14 17:21:39,469 - --- validate (epoch=405)-----------
2023-01-14 17:21:39,470 - 148 samples (240 per mini-batch)
2023-01-14 17:21:40,077 - Epoch: [405][    1/    1]    Loss 0.348832    Top1 89.864865    Top5 99.324324    
2023-01-14 17:21:40,122 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.349

2023-01-14 17:21:40,133 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:21:40,134 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:21:40,163 - 

2023-01-14 17:21:40,164 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:21:42,717 - Epoch: [406][    6/    6]    Overall Loss 0.012093    Objective Loss 0.012093    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.425273    
2023-01-14 17:21:42,761 - --- validate (epoch=406)-----------
2023-01-14 17:21:42,761 - 148 samples (240 per mini-batch)
2023-01-14 17:21:43,285 - Epoch: [406][    1/    1]    Loss 0.313940    Top1 90.540541    Top5 98.648649    
2023-01-14 17:21:43,327 - ==> Top1: 90.541    Top5: 98.649    Loss: 0.314

2023-01-14 17:21:43,336 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:21:43,336 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:21:43,368 - 

2023-01-14 17:21:43,368 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:21:46,102 - Epoch: [407][    6/    6]    Overall Loss 0.012063    Objective Loss 0.012063    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.455358    
2023-01-14 17:21:46,150 - --- validate (epoch=407)-----------
2023-01-14 17:21:46,150 - 148 samples (240 per mini-batch)
2023-01-14 17:21:46,642 - Epoch: [407][    1/    1]    Loss 0.359656    Top1 89.189189    Top5 98.648649    
2023-01-14 17:21:46,678 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.360

2023-01-14 17:21:46,691 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:21:46,691 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:21:46,736 - 

2023-01-14 17:21:46,737 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:21:49,638 - Epoch: [408][    6/    6]    Overall Loss 0.011866    Objective Loss 0.011866    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.483250    
2023-01-14 17:21:49,671 - --- validate (epoch=408)-----------
2023-01-14 17:21:49,671 - 148 samples (240 per mini-batch)
2023-01-14 17:21:50,163 - Epoch: [408][    1/    1]    Loss 0.359140    Top1 88.513514    Top5 99.324324    
2023-01-14 17:21:50,199 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.359

2023-01-14 17:21:50,212 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:21:50,212 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:21:50,251 - 

2023-01-14 17:21:50,251 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:21:53,066 - Epoch: [409][    6/    6]    Overall Loss 0.011997    Objective Loss 0.011997    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.468654    
2023-01-14 17:21:53,109 - --- validate (epoch=409)-----------
2023-01-14 17:21:53,110 - 148 samples (240 per mini-batch)
2023-01-14 17:21:53,668 - Epoch: [409][    1/    1]    Loss 0.366713    Top1 88.513514    Top5 98.648649    
2023-01-14 17:21:53,703 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.367

2023-01-14 17:21:53,713 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:21:53,714 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:21:53,747 - 

2023-01-14 17:21:53,748 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:21:56,348 - Epoch: [410][    6/    6]    Overall Loss 0.012635    Objective Loss 0.012635    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.433132    
2023-01-14 17:21:56,388 - --- validate (epoch=410)-----------
2023-01-14 17:21:56,389 - 148 samples (240 per mini-batch)
2023-01-14 17:21:56,869 - Epoch: [410][    1/    1]    Loss 0.339601    Top1 89.864865    Top5 99.324324    
2023-01-14 17:21:56,909 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.340

2023-01-14 17:21:56,919 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:21:56,919 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:21:56,954 - 

2023-01-14 17:21:56,954 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:21:59,704 - Epoch: [411][    6/    6]    Overall Loss 0.012119    Objective Loss 0.012119    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.458055    
2023-01-14 17:21:59,742 - --- validate (epoch=411)-----------
2023-01-14 17:21:59,742 - 148 samples (240 per mini-batch)
2023-01-14 17:22:00,222 - Epoch: [411][    1/    1]    Loss 0.339353    Top1 89.864865    Top5 98.648649    
2023-01-14 17:22:00,265 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.339

2023-01-14 17:22:00,275 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:22:00,275 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:22:00,325 - 

2023-01-14 17:22:00,325 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:22:02,839 - Epoch: [412][    6/    6]    Overall Loss 0.012352    Objective Loss 0.012352    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.418781    
2023-01-14 17:22:02,880 - --- validate (epoch=412)-----------
2023-01-14 17:22:02,880 - 148 samples (240 per mini-batch)
2023-01-14 17:22:03,396 - Epoch: [412][    1/    1]    Loss 0.350694    Top1 89.864865    Top5 99.324324    
2023-01-14 17:22:03,431 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.351

2023-01-14 17:22:03,442 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:22:03,442 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:22:03,481 - 

2023-01-14 17:22:03,482 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:22:06,353 - Epoch: [413][    6/    6]    Overall Loss 0.011973    Objective Loss 0.011973    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.478339    
2023-01-14 17:22:06,393 - --- validate (epoch=413)-----------
2023-01-14 17:22:06,394 - 148 samples (240 per mini-batch)
2023-01-14 17:22:06,917 - Epoch: [413][    1/    1]    Loss 0.347760    Top1 89.864865    Top5 99.324324    
2023-01-14 17:22:06,955 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.348

2023-01-14 17:22:06,964 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:22:06,965 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:22:06,998 - 

2023-01-14 17:22:06,999 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:22:10,098 - Epoch: [414][    6/    6]    Overall Loss 0.012215    Objective Loss 0.012215    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.516359    
2023-01-14 17:22:10,140 - --- validate (epoch=414)-----------
2023-01-14 17:22:10,141 - 148 samples (240 per mini-batch)
2023-01-14 17:22:10,743 - Epoch: [414][    1/    1]    Loss 0.342335    Top1 89.189189    Top5 98.648649    
2023-01-14 17:22:10,783 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.342

2023-01-14 17:22:10,793 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:22:10,793 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:22:10,824 - 

2023-01-14 17:22:10,825 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:22:13,697 - Epoch: [415][    6/    6]    Overall Loss 0.012298    Objective Loss 0.012298    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.478425    
2023-01-14 17:22:13,739 - --- validate (epoch=415)-----------
2023-01-14 17:22:13,740 - 148 samples (240 per mini-batch)
2023-01-14 17:22:14,295 - Epoch: [415][    1/    1]    Loss 0.330149    Top1 89.864865    Top5 100.000000    
2023-01-14 17:22:14,343 - ==> Top1: 89.865    Top5: 100.000    Loss: 0.330

2023-01-14 17:22:14,353 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:22:14,353 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:22:14,388 - 

2023-01-14 17:22:14,389 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:22:16,972 - Epoch: [416][    6/    6]    Overall Loss 0.012753    Objective Loss 0.012753    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.430225    
2023-01-14 17:22:17,008 - --- validate (epoch=416)-----------
2023-01-14 17:22:17,009 - 148 samples (240 per mini-batch)
2023-01-14 17:22:17,492 - Epoch: [416][    1/    1]    Loss 0.361054    Top1 89.864865    Top5 99.324324    
2023-01-14 17:22:17,537 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.361

2023-01-14 17:22:17,545 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:22:17,545 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:22:17,575 - 

2023-01-14 17:22:17,576 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:22:20,751 - Epoch: [417][    6/    6]    Overall Loss 0.012315    Objective Loss 0.012315    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.529059    
2023-01-14 17:22:20,798 - --- validate (epoch=417)-----------
2023-01-14 17:22:20,799 - 148 samples (240 per mini-batch)
2023-01-14 17:22:21,334 - Epoch: [417][    1/    1]    Loss 0.346780    Top1 89.864865    Top5 98.648649    
2023-01-14 17:22:21,382 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.347

2023-01-14 17:22:21,392 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:22:21,392 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:22:21,441 - 

2023-01-14 17:22:21,442 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:22:25,173 - Epoch: [418][    6/    6]    Overall Loss 0.012042    Objective Loss 0.012042    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.621625    
2023-01-14 17:22:25,230 - --- validate (epoch=418)-----------
2023-01-14 17:22:25,231 - 148 samples (240 per mini-batch)
2023-01-14 17:22:25,834 - Epoch: [418][    1/    1]    Loss 0.318333    Top1 89.189189    Top5 98.648649    
2023-01-14 17:22:25,887 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.318

2023-01-14 17:22:25,898 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:22:25,898 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:22:25,945 - 

2023-01-14 17:22:25,945 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:22:29,455 - Epoch: [419][    6/    6]    Overall Loss 0.011872    Objective Loss 0.011872    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.584451    
2023-01-14 17:22:29,498 - --- validate (epoch=419)-----------
2023-01-14 17:22:29,499 - 148 samples (240 per mini-batch)
2023-01-14 17:22:30,028 - Epoch: [419][    1/    1]    Loss 0.344377    Top1 89.189189    Top5 98.648649    
2023-01-14 17:22:30,068 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.344

2023-01-14 17:22:30,084 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:22:30,084 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:22:30,125 - 

2023-01-14 17:22:30,125 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:22:32,887 - Epoch: [420][    6/    6]    Overall Loss 0.011887    Objective Loss 0.011887    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.459967    
2023-01-14 17:22:32,938 - --- validate (epoch=420)-----------
2023-01-14 17:22:32,939 - 148 samples (240 per mini-batch)
2023-01-14 17:22:33,520 - Epoch: [420][    1/    1]    Loss 0.352531    Top1 87.837838    Top5 99.324324    
2023-01-14 17:22:33,561 - ==> Top1: 87.838    Top5: 99.324    Loss: 0.353

2023-01-14 17:22:33,570 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:22:33,571 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:22:33,619 - 

2023-01-14 17:22:33,620 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:22:36,354 - Epoch: [421][    6/    6]    Overall Loss 0.012030    Objective Loss 0.012030    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.455320    
2023-01-14 17:22:36,415 - --- validate (epoch=421)-----------
2023-01-14 17:22:36,416 - 148 samples (240 per mini-batch)
2023-01-14 17:22:36,904 - Epoch: [421][    1/    1]    Loss 0.353856    Top1 89.189189    Top5 99.324324    
2023-01-14 17:22:36,947 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.354

2023-01-14 17:22:36,960 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:22:36,962 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:22:37,005 - 

2023-01-14 17:22:37,006 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:22:39,567 - Epoch: [422][    6/    6]    Overall Loss 0.011841    Objective Loss 0.011841    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.426521    
2023-01-14 17:22:39,611 - --- validate (epoch=422)-----------
2023-01-14 17:22:39,612 - 148 samples (240 per mini-batch)
2023-01-14 17:22:40,091 - Epoch: [422][    1/    1]    Loss 0.327001    Top1 89.864865    Top5 98.648649    
2023-01-14 17:22:40,139 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.327

2023-01-14 17:22:40,150 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:22:40,150 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:22:40,194 - 

2023-01-14 17:22:40,195 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:22:43,266 - Epoch: [423][    6/    6]    Overall Loss 0.012108    Objective Loss 0.012108    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.511699    
2023-01-14 17:22:43,324 - --- validate (epoch=423)-----------
2023-01-14 17:22:43,325 - 148 samples (240 per mini-batch)
2023-01-14 17:22:43,915 - Epoch: [423][    1/    1]    Loss 0.336255    Top1 89.864865    Top5 98.648649    
2023-01-14 17:22:43,968 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.336

2023-01-14 17:22:43,978 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:22:43,978 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:22:44,011 - 

2023-01-14 17:22:44,011 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:22:46,797 - Epoch: [424][    6/    6]    Overall Loss 0.011888    Objective Loss 0.011888    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.464069    
2023-01-14 17:22:46,845 - --- validate (epoch=424)-----------
2023-01-14 17:22:46,845 - 148 samples (240 per mini-batch)
2023-01-14 17:22:47,430 - Epoch: [424][    1/    1]    Loss 0.394542    Top1 88.513514    Top5 98.648649    
2023-01-14 17:22:47,482 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.395

2023-01-14 17:22:47,492 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:22:47,493 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:22:47,531 - 

2023-01-14 17:22:47,532 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:22:50,089 - Epoch: [425][    6/    6]    Overall Loss 0.012134    Objective Loss 0.012134    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.425966    
2023-01-14 17:22:50,141 - --- validate (epoch=425)-----------
2023-01-14 17:22:50,142 - 148 samples (240 per mini-batch)
2023-01-14 17:22:50,646 - Epoch: [425][    1/    1]    Loss 0.318366    Top1 89.864865    Top5 99.324324    
2023-01-14 17:22:50,690 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.318

2023-01-14 17:22:50,699 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:22:50,699 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:22:50,741 - 

2023-01-14 17:22:50,742 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:22:53,643 - Epoch: [426][    6/    6]    Overall Loss 0.011938    Objective Loss 0.011938    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.483257    
2023-01-14 17:22:53,687 - --- validate (epoch=426)-----------
2023-01-14 17:22:53,688 - 148 samples (240 per mini-batch)
2023-01-14 17:22:54,163 - Epoch: [426][    1/    1]    Loss 0.354850    Top1 88.513514    Top5 99.324324    
2023-01-14 17:22:54,207 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.355

2023-01-14 17:22:54,219 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:22:54,222 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:22:54,263 - 

2023-01-14 17:22:54,264 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:22:57,342 - Epoch: [427][    6/    6]    Overall Loss 0.012206    Objective Loss 0.012206    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.512880    
2023-01-14 17:22:57,385 - --- validate (epoch=427)-----------
2023-01-14 17:22:57,386 - 148 samples (240 per mini-batch)
2023-01-14 17:22:57,854 - Epoch: [427][    1/    1]    Loss 0.355148    Top1 89.189189    Top5 99.324324    
2023-01-14 17:22:57,900 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.355

2023-01-14 17:22:57,910 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:22:57,910 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:22:57,945 - 

2023-01-14 17:22:57,946 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:23:00,430 - Epoch: [428][    6/    6]    Overall Loss 0.012178    Objective Loss 0.012178    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.413341    
2023-01-14 17:23:00,474 - --- validate (epoch=428)-----------
2023-01-14 17:23:00,474 - 148 samples (240 per mini-batch)
2023-01-14 17:23:01,016 - Epoch: [428][    1/    1]    Loss 0.364754    Top1 88.513514    Top5 98.648649    
2023-01-14 17:23:01,062 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.365

2023-01-14 17:23:01,073 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:23:01,073 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:23:01,114 - 

2023-01-14 17:23:01,115 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:23:03,806 - Epoch: [429][    6/    6]    Overall Loss 0.012295    Objective Loss 0.012295    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.448240    
2023-01-14 17:23:03,849 - --- validate (epoch=429)-----------
2023-01-14 17:23:03,849 - 148 samples (240 per mini-batch)
2023-01-14 17:23:04,371 - Epoch: [429][    1/    1]    Loss 0.341652    Top1 89.189189    Top5 98.648649    
2023-01-14 17:23:04,418 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.342

2023-01-14 17:23:04,428 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:23:04,429 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:23:04,479 - 

2023-01-14 17:23:04,479 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:23:06,927 - Epoch: [430][    6/    6]    Overall Loss 0.012509    Objective Loss 0.012509    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.407616    
2023-01-14 17:23:06,969 - --- validate (epoch=430)-----------
2023-01-14 17:23:06,970 - 148 samples (240 per mini-batch)
2023-01-14 17:23:07,541 - Epoch: [430][    1/    1]    Loss 0.355296    Top1 89.189189    Top5 99.324324    
2023-01-14 17:23:07,581 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.355

2023-01-14 17:23:07,594 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:23:07,595 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:23:07,636 - 

2023-01-14 17:23:07,637 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:23:10,734 - Epoch: [431][    6/    6]    Overall Loss 0.012399    Objective Loss 0.012399    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.516006    
2023-01-14 17:23:10,775 - --- validate (epoch=431)-----------
2023-01-14 17:23:10,775 - 148 samples (240 per mini-batch)
2023-01-14 17:23:11,374 - Epoch: [431][    1/    1]    Loss 0.358694    Top1 87.837838    Top5 99.324324    
2023-01-14 17:23:11,422 - ==> Top1: 87.838    Top5: 99.324    Loss: 0.359

2023-01-14 17:23:11,432 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:23:11,432 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:23:11,484 - 

2023-01-14 17:23:11,484 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:23:14,426 - Epoch: [432][    6/    6]    Overall Loss 0.011963    Objective Loss 0.011963    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.490091    
2023-01-14 17:23:14,489 - --- validate (epoch=432)-----------
2023-01-14 17:23:14,490 - 148 samples (240 per mini-batch)
2023-01-14 17:23:15,088 - Epoch: [432][    1/    1]    Loss 0.356696    Top1 89.189189    Top5 98.648649    
2023-01-14 17:23:15,142 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.357

2023-01-14 17:23:15,152 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:23:15,152 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:23:15,196 - 

2023-01-14 17:23:15,197 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:23:18,951 - Epoch: [433][    6/    6]    Overall Loss 0.011877    Objective Loss 0.011877    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.625343    
2023-01-14 17:23:19,001 - --- validate (epoch=433)-----------
2023-01-14 17:23:19,001 - 148 samples (240 per mini-batch)
2023-01-14 17:23:19,592 - Epoch: [433][    1/    1]    Loss 0.346037    Top1 89.864865    Top5 100.000000    
2023-01-14 17:23:19,634 - ==> Top1: 89.865    Top5: 100.000    Loss: 0.346

2023-01-14 17:23:19,648 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:23:19,649 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:23:19,701 - 

2023-01-14 17:23:19,702 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:23:22,372 - Epoch: [434][    6/    6]    Overall Loss 0.012155    Objective Loss 0.012155    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.444760    
2023-01-14 17:23:22,425 - --- validate (epoch=434)-----------
2023-01-14 17:23:22,426 - 148 samples (240 per mini-batch)
2023-01-14 17:23:22,981 - Epoch: [434][    1/    1]    Loss 0.356066    Top1 89.189189    Top5 99.324324    
2023-01-14 17:23:23,021 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.356

2023-01-14 17:23:23,030 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:23:23,031 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:23:23,070 - 

2023-01-14 17:23:23,072 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:23:26,565 - Epoch: [435][    6/    6]    Overall Loss 0.011973    Objective Loss 0.011973    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.581542    
2023-01-14 17:23:26,613 - --- validate (epoch=435)-----------
2023-01-14 17:23:26,615 - 148 samples (240 per mini-batch)
2023-01-14 17:23:27,160 - Epoch: [435][    1/    1]    Loss 0.354659    Top1 88.513514    Top5 98.648649    
2023-01-14 17:23:27,206 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.355

2023-01-14 17:23:27,215 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:23:27,216 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:23:27,262 - 

2023-01-14 17:23:27,262 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:23:30,529 - Epoch: [436][    6/    6]    Overall Loss 0.012402    Objective Loss 0.012402    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.544263    
2023-01-14 17:23:30,575 - --- validate (epoch=436)-----------
2023-01-14 17:23:30,576 - 148 samples (240 per mini-batch)
2023-01-14 17:23:31,149 - Epoch: [436][    1/    1]    Loss 0.362458    Top1 89.864865    Top5 99.324324    
2023-01-14 17:23:31,194 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.362

2023-01-14 17:23:31,204 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 335]
2023-01-14 17:23:31,204 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:23:31,242 - 

2023-01-14 17:23:31,243 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:23:34,359 - Epoch: [437][    6/    6]    Overall Loss 0.011952    Objective Loss 0.011952    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.519189    
2023-01-14 17:23:34,407 - --- validate (epoch=437)-----------
2023-01-14 17:23:34,407 - 148 samples (240 per mini-batch)
2023-01-14 17:23:34,881 - Epoch: [437][    1/    1]    Loss 0.343488    Top1 90.540541    Top5 99.324324    
2023-01-14 17:23:34,926 - ==> Top1: 90.541    Top5: 99.324    Loss: 0.343

2023-01-14 17:23:34,938 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 437]
2023-01-14 17:23:34,938 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:23:34,984 - 

2023-01-14 17:23:34,984 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:23:37,884 - Epoch: [438][    6/    6]    Overall Loss 0.012148    Objective Loss 0.012148    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.483048    
2023-01-14 17:23:37,927 - --- validate (epoch=438)-----------
2023-01-14 17:23:37,928 - 148 samples (240 per mini-batch)
2023-01-14 17:23:38,401 - Epoch: [438][    1/    1]    Loss 0.360409    Top1 89.189189    Top5 98.648649    
2023-01-14 17:23:38,442 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.360

2023-01-14 17:23:38,453 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 437]
2023-01-14 17:23:38,453 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:23:38,495 - 

2023-01-14 17:23:38,496 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:23:41,896 - Epoch: [439][    6/    6]    Overall Loss 0.012295    Objective Loss 0.012295    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.566430    
2023-01-14 17:23:41,941 - --- validate (epoch=439)-----------
2023-01-14 17:23:41,942 - 148 samples (240 per mini-batch)
2023-01-14 17:23:42,416 - Epoch: [439][    1/    1]    Loss 0.362147    Top1 89.189189    Top5 98.648649    
2023-01-14 17:23:42,457 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.362

2023-01-14 17:23:42,466 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 437]
2023-01-14 17:23:42,467 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:23:42,504 - 

2023-01-14 17:23:42,504 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:23:45,766 - Epoch: [440][    6/    6]    Overall Loss 0.011908    Objective Loss 0.011908    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.543410    
2023-01-14 17:23:45,810 - --- validate (epoch=440)-----------
2023-01-14 17:23:45,811 - 148 samples (240 per mini-batch)
2023-01-14 17:23:46,391 - Epoch: [440][    1/    1]    Loss 0.338545    Top1 89.189189    Top5 98.648649    
2023-01-14 17:23:46,435 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.339

2023-01-14 17:23:46,446 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 437]
2023-01-14 17:23:46,447 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:23:46,497 - 

2023-01-14 17:23:46,497 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:23:49,543 - Epoch: [441][    6/    6]    Overall Loss 0.011599    Objective Loss 0.011599    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.507428    
2023-01-14 17:23:49,584 - --- validate (epoch=441)-----------
2023-01-14 17:23:49,585 - 148 samples (240 per mini-batch)
2023-01-14 17:23:50,112 - Epoch: [441][    1/    1]    Loss 0.361931    Top1 89.864865    Top5 98.648649    
2023-01-14 17:23:50,157 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.362

2023-01-14 17:23:50,166 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 437]
2023-01-14 17:23:50,167 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:23:50,216 - 

2023-01-14 17:23:50,216 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:23:53,351 - Epoch: [442][    6/    6]    Overall Loss 0.011811    Objective Loss 0.011811    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.522230    
2023-01-14 17:23:53,396 - --- validate (epoch=442)-----------
2023-01-14 17:23:53,397 - 148 samples (240 per mini-batch)
2023-01-14 17:23:53,957 - Epoch: [442][    1/    1]    Loss 0.354758    Top1 90.540541    Top5 99.324324    
2023-01-14 17:23:54,002 - ==> Top1: 90.541    Top5: 99.324    Loss: 0.355

2023-01-14 17:23:54,012 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 442]
2023-01-14 17:23:54,012 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:23:54,053 - 

2023-01-14 17:23:54,053 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:23:56,866 - Epoch: [443][    6/    6]    Overall Loss 0.011793    Objective Loss 0.011793    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.468567    
2023-01-14 17:23:56,914 - --- validate (epoch=443)-----------
2023-01-14 17:23:56,915 - 148 samples (240 per mini-batch)
2023-01-14 17:23:57,470 - Epoch: [443][    1/    1]    Loss 0.343457    Top1 89.864865    Top5 98.648649    
2023-01-14 17:23:57,513 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.343

2023-01-14 17:23:57,525 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 442]
2023-01-14 17:23:57,527 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:23:57,569 - 

2023-01-14 17:23:57,570 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:24:00,069 - Epoch: [444][    6/    6]    Overall Loss 0.011800    Objective Loss 0.011800    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.415975    
2023-01-14 17:24:00,112 - --- validate (epoch=444)-----------
2023-01-14 17:24:00,113 - 148 samples (240 per mini-batch)
2023-01-14 17:24:00,655 - Epoch: [444][    1/    1]    Loss 0.369689    Top1 89.189189    Top5 99.324324    
2023-01-14 17:24:00,700 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.370

2023-01-14 17:24:00,711 - ==> Best [Top1: 90.541   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 442]
2023-01-14 17:24:00,712 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:24:00,757 - 

2023-01-14 17:24:00,757 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:24:04,166 - Epoch: [445][    6/    6]    Overall Loss 0.011954    Objective Loss 0.011954    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.567661    
2023-01-14 17:24:04,211 - --- validate (epoch=445)-----------
2023-01-14 17:24:04,212 - 148 samples (240 per mini-batch)
2023-01-14 17:24:04,687 - Epoch: [445][    1/    1]    Loss 0.338302    Top1 90.540541    Top5 100.000000    
2023-01-14 17:24:04,731 - ==> Top1: 90.541    Top5: 100.000    Loss: 0.338

2023-01-14 17:24:04,741 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 445]
2023-01-14 17:24:04,742 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:24:04,782 - 

2023-01-14 17:24:04,782 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:24:07,999 - Epoch: [446][    6/    6]    Overall Loss 0.011742    Objective Loss 0.011742    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.536004    
2023-01-14 17:24:08,043 - --- validate (epoch=446)-----------
2023-01-14 17:24:08,043 - 148 samples (240 per mini-batch)
2023-01-14 17:24:08,535 - Epoch: [446][    1/    1]    Loss 0.339600    Top1 89.189189    Top5 99.324324    
2023-01-14 17:24:08,580 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.340

2023-01-14 17:24:08,592 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 445]
2023-01-14 17:24:08,592 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:24:08,632 - 

2023-01-14 17:24:08,633 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:24:11,340 - Epoch: [447][    6/    6]    Overall Loss 0.011687    Objective Loss 0.011687    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.451027    
2023-01-14 17:24:11,385 - --- validate (epoch=447)-----------
2023-01-14 17:24:11,386 - 148 samples (240 per mini-batch)
2023-01-14 17:24:11,885 - Epoch: [447][    1/    1]    Loss 0.366292    Top1 89.189189    Top5 98.648649    
2023-01-14 17:24:11,927 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.366

2023-01-14 17:24:11,940 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 445]
2023-01-14 17:24:11,940 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:24:11,988 - 

2023-01-14 17:24:11,989 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:24:15,055 - Epoch: [448][    6/    6]    Overall Loss 0.011716    Objective Loss 0.011716    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.510823    
2023-01-14 17:24:15,110 - --- validate (epoch=448)-----------
2023-01-14 17:24:15,111 - 148 samples (240 per mini-batch)
2023-01-14 17:24:15,706 - Epoch: [448][    1/    1]    Loss 0.367125    Top1 88.513514    Top5 99.324324    
2023-01-14 17:24:15,753 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.367

2023-01-14 17:24:15,764 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 445]
2023-01-14 17:24:15,765 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:24:15,805 - 

2023-01-14 17:24:15,806 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:24:19,213 - Epoch: [449][    6/    6]    Overall Loss 0.012438    Objective Loss 0.012438    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.567548    
2023-01-14 17:24:19,262 - --- validate (epoch=449)-----------
2023-01-14 17:24:19,262 - 148 samples (240 per mini-batch)
2023-01-14 17:24:19,765 - Epoch: [449][    1/    1]    Loss 0.356287    Top1 89.864865    Top5 98.648649    
2023-01-14 17:24:19,811 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.356

2023-01-14 17:24:19,821 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 445]
2023-01-14 17:24:19,822 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:24:19,858 - 

2023-01-14 17:24:19,858 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:24:22,538 - Epoch: [450][    6/    6]    Overall Loss 0.011828    Objective Loss 0.011828    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.446499    
2023-01-14 17:24:22,584 - --- validate (epoch=450)-----------
2023-01-14 17:24:22,585 - 148 samples (240 per mini-batch)
2023-01-14 17:24:23,118 - Epoch: [450][    1/    1]    Loss 0.333454    Top1 89.864865    Top5 99.324324    
2023-01-14 17:24:23,159 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.333

2023-01-14 17:24:23,170 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 445]
2023-01-14 17:24:23,171 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:24:23,218 - 

2023-01-14 17:24:23,218 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:24:25,866 - Epoch: [451][    6/    6]    Overall Loss 0.012401    Objective Loss 0.012401    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.441006    
2023-01-14 17:24:25,912 - --- validate (epoch=451)-----------
2023-01-14 17:24:25,912 - 148 samples (240 per mini-batch)
2023-01-14 17:24:26,459 - Epoch: [451][    1/    1]    Loss 0.374575    Top1 88.513514    Top5 99.324324    
2023-01-14 17:24:26,513 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.375

2023-01-14 17:24:26,527 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 445]
2023-01-14 17:24:26,528 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:24:26,572 - 

2023-01-14 17:24:26,573 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:24:29,265 - Epoch: [452][    6/    6]    Overall Loss 0.012130    Objective Loss 0.012130    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.448164    
2023-01-14 17:24:29,311 - --- validate (epoch=452)-----------
2023-01-14 17:24:29,312 - 148 samples (240 per mini-batch)
2023-01-14 17:24:29,817 - Epoch: [452][    1/    1]    Loss 0.358281    Top1 89.189189    Top5 99.324324    
2023-01-14 17:24:29,861 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.358

2023-01-14 17:24:29,870 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 445]
2023-01-14 17:24:29,872 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:24:29,914 - 

2023-01-14 17:24:29,915 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:24:32,527 - Epoch: [453][    6/    6]    Overall Loss 0.011736    Objective Loss 0.011736    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.434953    
2023-01-14 17:24:32,573 - --- validate (epoch=453)-----------
2023-01-14 17:24:32,574 - 148 samples (240 per mini-batch)
2023-01-14 17:24:33,159 - Epoch: [453][    1/    1]    Loss 0.352678    Top1 89.864865    Top5 99.324324    
2023-01-14 17:24:33,206 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.353

2023-01-14 17:24:33,215 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 445]
2023-01-14 17:24:33,216 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:24:33,260 - 

2023-01-14 17:24:33,261 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:24:36,500 - Epoch: [454][    6/    6]    Overall Loss 0.011615    Objective Loss 0.011615    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.539615    
2023-01-14 17:24:36,545 - --- validate (epoch=454)-----------
2023-01-14 17:24:36,546 - 148 samples (240 per mini-batch)
2023-01-14 17:24:37,022 - Epoch: [454][    1/    1]    Loss 0.365609    Top1 88.513514    Top5 98.648649    
2023-01-14 17:24:37,070 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.366

2023-01-14 17:24:37,078 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 445]
2023-01-14 17:24:37,079 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:24:37,121 - 

2023-01-14 17:24:37,121 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:24:40,012 - Epoch: [455][    6/    6]    Overall Loss 0.012310    Objective Loss 0.012310    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.481547    
2023-01-14 17:24:40,059 - --- validate (epoch=455)-----------
2023-01-14 17:24:40,060 - 148 samples (240 per mini-batch)
2023-01-14 17:24:40,548 - Epoch: [455][    1/    1]    Loss 0.359881    Top1 90.540541    Top5 98.648649    
2023-01-14 17:24:40,599 - ==> Top1: 90.541    Top5: 98.649    Loss: 0.360

2023-01-14 17:24:40,609 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 445]
2023-01-14 17:24:40,609 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:24:40,644 - 

2023-01-14 17:24:40,645 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:24:43,182 - Epoch: [456][    6/    6]    Overall Loss 0.011648    Objective Loss 0.011648    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.422653    
2023-01-14 17:24:43,235 - --- validate (epoch=456)-----------
2023-01-14 17:24:43,235 - 148 samples (240 per mini-batch)
2023-01-14 17:24:43,855 - Epoch: [456][    1/    1]    Loss 0.347394    Top1 89.864865    Top5 99.324324    
2023-01-14 17:24:43,896 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.347

2023-01-14 17:24:43,907 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 445]
2023-01-14 17:24:43,908 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:24:43,954 - 

2023-01-14 17:24:43,954 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:24:46,732 - Epoch: [457][    6/    6]    Overall Loss 0.011925    Objective Loss 0.011925    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.462785    
2023-01-14 17:24:46,789 - --- validate (epoch=457)-----------
2023-01-14 17:24:46,790 - 148 samples (240 per mini-batch)
2023-01-14 17:24:47,375 - Epoch: [457][    1/    1]    Loss 0.344938    Top1 89.864865    Top5 98.648649    
2023-01-14 17:24:47,434 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.345

2023-01-14 17:24:47,445 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 445]
2023-01-14 17:24:47,445 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:24:47,492 - 

2023-01-14 17:24:47,492 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:24:50,121 - Epoch: [458][    6/    6]    Overall Loss 0.011641    Objective Loss 0.011641    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.437925    
2023-01-14 17:24:50,162 - --- validate (epoch=458)-----------
2023-01-14 17:24:50,164 - 148 samples (240 per mini-batch)
2023-01-14 17:24:50,728 - Epoch: [458][    1/    1]    Loss 0.339809    Top1 89.864865    Top5 98.648649    
2023-01-14 17:24:50,772 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.340

2023-01-14 17:24:50,784 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 445]
2023-01-14 17:24:50,785 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:24:50,824 - 

2023-01-14 17:24:50,824 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:24:53,338 - Epoch: [459][    6/    6]    Overall Loss 0.011681    Objective Loss 0.011681    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.418821    
2023-01-14 17:24:53,386 - --- validate (epoch=459)-----------
2023-01-14 17:24:53,387 - 148 samples (240 per mini-batch)
2023-01-14 17:24:53,932 - Epoch: [459][    1/    1]    Loss 0.356882    Top1 89.189189    Top5 98.648649    
2023-01-14 17:24:53,976 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.357

2023-01-14 17:24:53,987 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 445]
2023-01-14 17:24:53,987 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:24:54,026 - 

2023-01-14 17:24:54,027 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:24:56,908 - Epoch: [460][    6/    6]    Overall Loss 0.011806    Objective Loss 0.011806    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.479852    
2023-01-14 17:24:56,950 - --- validate (epoch=460)-----------
2023-01-14 17:24:56,951 - 148 samples (240 per mini-batch)
2023-01-14 17:24:57,450 - Epoch: [460][    1/    1]    Loss 0.366470    Top1 89.864865    Top5 98.648649    
2023-01-14 17:24:57,500 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.366

2023-01-14 17:24:57,516 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 445]
2023-01-14 17:24:57,519 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:24:57,556 - 

2023-01-14 17:24:57,556 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:25:00,581 - Epoch: [461][    6/    6]    Overall Loss 0.011978    Objective Loss 0.011978    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.503876    
2023-01-14 17:25:00,629 - --- validate (epoch=461)-----------
2023-01-14 17:25:00,630 - 148 samples (240 per mini-batch)
2023-01-14 17:25:01,138 - Epoch: [461][    1/    1]    Loss 0.350958    Top1 89.864865    Top5 99.324324    
2023-01-14 17:25:01,185 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.351

2023-01-14 17:25:01,196 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 445]
2023-01-14 17:25:01,197 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:25:01,240 - 

2023-01-14 17:25:01,240 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:25:04,813 - Epoch: [462][    6/    6]    Overall Loss 0.011480    Objective Loss 0.011480    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.595220    
2023-01-14 17:25:04,856 - --- validate (epoch=462)-----------
2023-01-14 17:25:04,857 - 148 samples (240 per mini-batch)
2023-01-14 17:25:05,328 - Epoch: [462][    1/    1]    Loss 0.354698    Top1 89.189189    Top5 99.324324    
2023-01-14 17:25:05,386 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.355

2023-01-14 17:25:05,397 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 445]
2023-01-14 17:25:05,398 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:25:05,439 - 

2023-01-14 17:25:05,440 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:25:08,931 - Epoch: [463][    6/    6]    Overall Loss 0.012068    Objective Loss 0.012068    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.581626    
2023-01-14 17:25:08,980 - --- validate (epoch=463)-----------
2023-01-14 17:25:08,981 - 148 samples (240 per mini-batch)
2023-01-14 17:25:09,508 - Epoch: [463][    1/    1]    Loss 0.365287    Top1 89.189189    Top5 99.324324    
2023-01-14 17:25:09,556 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.365

2023-01-14 17:25:09,567 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 445]
2023-01-14 17:25:09,567 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:25:09,615 - 

2023-01-14 17:25:09,615 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:25:11,913 - Epoch: [464][    6/    6]    Overall Loss 0.011560    Objective Loss 0.011560    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.382674    
2023-01-14 17:25:11,954 - --- validate (epoch=464)-----------
2023-01-14 17:25:11,955 - 148 samples (240 per mini-batch)
2023-01-14 17:25:12,515 - Epoch: [464][    1/    1]    Loss 0.352009    Top1 88.513514    Top5 99.324324    
2023-01-14 17:25:12,567 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.352

2023-01-14 17:25:12,575 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 445]
2023-01-14 17:25:12,576 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:25:12,609 - 

2023-01-14 17:25:12,609 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:25:15,715 - Epoch: [465][    6/    6]    Overall Loss 0.011861    Objective Loss 0.011861    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.517142    
2023-01-14 17:25:15,778 - --- validate (epoch=465)-----------
2023-01-14 17:25:15,779 - 148 samples (240 per mini-batch)
2023-01-14 17:25:16,356 - Epoch: [465][    1/    1]    Loss 0.381510    Top1 88.513514    Top5 98.648649    
2023-01-14 17:25:16,427 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.382

2023-01-14 17:25:16,436 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 445]
2023-01-14 17:25:16,436 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:25:16,488 - 

2023-01-14 17:25:16,488 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:25:19,721 - Epoch: [466][    6/    6]    Overall Loss 0.011456    Objective Loss 0.011456    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.538566    
2023-01-14 17:25:19,780 - --- validate (epoch=466)-----------
2023-01-14 17:25:19,781 - 148 samples (240 per mini-batch)
2023-01-14 17:25:20,384 - Epoch: [466][    1/    1]    Loss 0.374011    Top1 89.864865    Top5 99.324324    
2023-01-14 17:25:20,434 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.374

2023-01-14 17:25:20,444 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 445]
2023-01-14 17:25:20,445 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:25:20,492 - 

2023-01-14 17:25:20,493 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:25:23,447 - Epoch: [467][    6/    6]    Overall Loss 0.011609    Objective Loss 0.011609    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.492198    
2023-01-14 17:25:23,494 - --- validate (epoch=467)-----------
2023-01-14 17:25:23,494 - 148 samples (240 per mini-batch)
2023-01-14 17:25:24,061 - Epoch: [467][    1/    1]    Loss 0.366589    Top1 88.513514    Top5 100.000000    
2023-01-14 17:25:24,105 - ==> Top1: 88.514    Top5: 100.000    Loss: 0.367

2023-01-14 17:25:24,114 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 445]
2023-01-14 17:25:24,115 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:25:24,163 - 

2023-01-14 17:25:24,163 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:25:26,758 - Epoch: [468][    6/    6]    Overall Loss 0.011722    Objective Loss 0.011722    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.431955    
2023-01-14 17:25:26,806 - --- validate (epoch=468)-----------
2023-01-14 17:25:26,806 - 148 samples (240 per mini-batch)
2023-01-14 17:25:27,272 - Epoch: [468][    1/    1]    Loss 0.357415    Top1 88.513514    Top5 100.000000    
2023-01-14 17:25:27,327 - ==> Top1: 88.514    Top5: 100.000    Loss: 0.357

2023-01-14 17:25:27,342 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 445]
2023-01-14 17:25:27,342 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:25:27,394 - 

2023-01-14 17:25:27,394 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:25:30,407 - Epoch: [469][    6/    6]    Overall Loss 0.011687    Objective Loss 0.011687    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.501789    
2023-01-14 17:25:30,452 - --- validate (epoch=469)-----------
2023-01-14 17:25:30,453 - 148 samples (240 per mini-batch)
2023-01-14 17:25:30,942 - Epoch: [469][    1/    1]    Loss 0.376141    Top1 89.189189    Top5 98.648649    
2023-01-14 17:25:30,987 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.376

2023-01-14 17:25:30,997 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 445]
2023-01-14 17:25:30,998 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:25:31,035 - 

2023-01-14 17:25:31,035 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:25:33,933 - Epoch: [470][    6/    6]    Overall Loss 0.011626    Objective Loss 0.011626    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.482761    
2023-01-14 17:25:33,978 - --- validate (epoch=470)-----------
2023-01-14 17:25:33,979 - 148 samples (240 per mini-batch)
2023-01-14 17:25:34,474 - Epoch: [470][    1/    1]    Loss 0.358446    Top1 89.189189    Top5 99.324324    
2023-01-14 17:25:34,514 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.358

2023-01-14 17:25:34,525 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 445]
2023-01-14 17:25:34,526 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:25:34,565 - 

2023-01-14 17:25:34,566 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:25:37,586 - Epoch: [471][    6/    6]    Overall Loss 0.011728    Objective Loss 0.011728    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.503085    
2023-01-14 17:25:37,631 - --- validate (epoch=471)-----------
2023-01-14 17:25:37,632 - 148 samples (240 per mini-batch)
2023-01-14 17:25:38,152 - Epoch: [471][    1/    1]    Loss 0.360239    Top1 88.513514    Top5 98.648649    
2023-01-14 17:25:38,199 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.360

2023-01-14 17:25:38,211 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 445]
2023-01-14 17:25:38,213 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:25:38,262 - 

2023-01-14 17:25:38,263 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:25:40,775 - Epoch: [472][    6/    6]    Overall Loss 0.011614    Objective Loss 0.011614    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.418442    
2023-01-14 17:25:40,821 - --- validate (epoch=472)-----------
2023-01-14 17:25:40,822 - 148 samples (240 per mini-batch)
2023-01-14 17:25:41,337 - Epoch: [472][    1/    1]    Loss 0.378727    Top1 89.189189    Top5 100.000000    
2023-01-14 17:25:41,381 - ==> Top1: 89.189    Top5: 100.000    Loss: 0.379

2023-01-14 17:25:41,395 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 445]
2023-01-14 17:25:41,396 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:25:41,453 - 

2023-01-14 17:25:41,453 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:25:43,956 - Epoch: [473][    6/    6]    Overall Loss 0.011666    Objective Loss 0.011666    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.416881    
2023-01-14 17:25:44,002 - --- validate (epoch=473)-----------
2023-01-14 17:25:44,003 - 148 samples (240 per mini-batch)
2023-01-14 17:25:44,522 - Epoch: [473][    1/    1]    Loss 0.349248    Top1 90.540541    Top5 99.324324    
2023-01-14 17:25:44,566 - ==> Top1: 90.541    Top5: 99.324    Loss: 0.349

2023-01-14 17:25:44,576 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 445]
2023-01-14 17:25:44,577 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:25:44,614 - 

2023-01-14 17:25:44,614 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:25:47,053 - Epoch: [474][    6/    6]    Overall Loss 0.011654    Objective Loss 0.011654    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.406237    
2023-01-14 17:25:47,100 - --- validate (epoch=474)-----------
2023-01-14 17:25:47,101 - 148 samples (240 per mini-batch)
2023-01-14 17:25:47,692 - Epoch: [474][    1/    1]    Loss 0.373516    Top1 88.513514    Top5 98.648649    
2023-01-14 17:25:47,758 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.374

2023-01-14 17:25:47,767 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 445]
2023-01-14 17:25:47,767 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:25:47,803 - 

2023-01-14 17:25:47,805 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:25:50,713 - Epoch: [475][    6/    6]    Overall Loss 0.011997    Objective Loss 0.011997    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.484193    
2023-01-14 17:25:50,758 - --- validate (epoch=475)-----------
2023-01-14 17:25:50,758 - 148 samples (240 per mini-batch)
2023-01-14 17:25:51,348 - Epoch: [475][    1/    1]    Loss 0.328725    Top1 89.864865    Top5 98.648649    
2023-01-14 17:25:51,398 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.329

2023-01-14 17:25:51,412 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 445]
2023-01-14 17:25:51,413 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:25:51,455 - 

2023-01-14 17:25:51,455 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:25:54,232 - Epoch: [476][    6/    6]    Overall Loss 0.011602    Objective Loss 0.011602    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.462467    
2023-01-14 17:25:54,280 - --- validate (epoch=476)-----------
2023-01-14 17:25:54,281 - 148 samples (240 per mini-batch)
2023-01-14 17:25:54,884 - Epoch: [476][    1/    1]    Loss 0.347686    Top1 89.189189    Top5 100.000000    
2023-01-14 17:25:54,926 - ==> Top1: 89.189    Top5: 100.000    Loss: 0.348

2023-01-14 17:25:54,941 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 445]
2023-01-14 17:25:54,942 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:25:54,987 - 

2023-01-14 17:25:54,987 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:25:57,493 - Epoch: [477][    6/    6]    Overall Loss 0.011624    Objective Loss 0.011624    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.417507    
2023-01-14 17:25:57,538 - --- validate (epoch=477)-----------
2023-01-14 17:25:57,539 - 148 samples (240 per mini-batch)
2023-01-14 17:25:58,082 - Epoch: [477][    1/    1]    Loss 0.347719    Top1 90.540541    Top5 100.000000    
2023-01-14 17:25:58,128 - ==> Top1: 90.541    Top5: 100.000    Loss: 0.348

2023-01-14 17:25:58,136 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80607 on epoch: 477]
2023-01-14 17:25:58,136 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:25:58,171 - 

2023-01-14 17:25:58,171 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:26:01,581 - Epoch: [478][    6/    6]    Overall Loss 0.011567    Objective Loss 0.011567    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.568051    
2023-01-14 17:26:01,625 - --- validate (epoch=478)-----------
2023-01-14 17:26:01,626 - 148 samples (240 per mini-batch)
2023-01-14 17:26:02,110 - Epoch: [478][    1/    1]    Loss 0.337136    Top1 89.189189    Top5 100.000000    
2023-01-14 17:26:02,152 - ==> Top1: 89.189    Top5: 100.000    Loss: 0.337

2023-01-14 17:26:02,162 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80607 on epoch: 477]
2023-01-14 17:26:02,162 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:26:02,215 - 

2023-01-14 17:26:02,216 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:26:04,759 - Epoch: [479][    6/    6]    Overall Loss 0.011743    Objective Loss 0.011743    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.423592    
2023-01-14 17:26:04,802 - --- validate (epoch=479)-----------
2023-01-14 17:26:04,803 - 148 samples (240 per mini-batch)
2023-01-14 17:26:05,297 - Epoch: [479][    1/    1]    Loss 0.347779    Top1 90.540541    Top5 98.648649    
2023-01-14 17:26:05,349 - ==> Top1: 90.541    Top5: 98.649    Loss: 0.348

2023-01-14 17:26:05,365 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80607 on epoch: 477]
2023-01-14 17:26:05,366 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:26:05,415 - 

2023-01-14 17:26:05,415 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:26:08,104 - Epoch: [480][    6/    6]    Overall Loss 0.011853    Objective Loss 0.011853    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.447868    
2023-01-14 17:26:08,146 - --- validate (epoch=480)-----------
2023-01-14 17:26:08,147 - 148 samples (240 per mini-batch)
2023-01-14 17:26:08,642 - Epoch: [480][    1/    1]    Loss 0.337614    Top1 89.864865    Top5 99.324324    
2023-01-14 17:26:08,685 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.338

2023-01-14 17:26:08,699 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80607 on epoch: 477]
2023-01-14 17:26:08,700 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:26:08,750 - 

2023-01-14 17:26:08,751 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:26:12,315 - Epoch: [481][    6/    6]    Overall Loss 0.011867    Objective Loss 0.011867    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.593673    
2023-01-14 17:26:12,370 - --- validate (epoch=481)-----------
2023-01-14 17:26:12,371 - 148 samples (240 per mini-batch)
2023-01-14 17:26:12,980 - Epoch: [481][    1/    1]    Loss 0.363683    Top1 89.189189    Top5 98.648649    
2023-01-14 17:26:13,026 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.364

2023-01-14 17:26:13,033 - ==> Best [Top1: 90.541   Top5: 100.000   Sparsity:0.00   Params: 80607 on epoch: 477]
2023-01-14 17:26:13,034 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:26:13,070 - 

2023-01-14 17:26:13,070 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:26:16,185 - Epoch: [482][    6/    6]    Overall Loss 0.011724    Objective Loss 0.011724    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.518581    
2023-01-14 17:26:16,244 - --- validate (epoch=482)-----------
2023-01-14 17:26:16,245 - 148 samples (240 per mini-batch)
2023-01-14 17:26:16,834 - Epoch: [482][    1/    1]    Loss 0.354757    Top1 91.216216    Top5 98.648649    
2023-01-14 17:26:16,880 - ==> Top1: 91.216    Top5: 98.649    Loss: 0.355

2023-01-14 17:26:16,890 - ==> Best [Top1: 91.216   Top5: 98.649   Sparsity:0.00   Params: 80608 on epoch: 482]
2023-01-14 17:26:16,891 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:26:16,934 - 

2023-01-14 17:26:16,935 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:26:19,656 - Epoch: [483][    6/    6]    Overall Loss 0.011811    Objective Loss 0.011811    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.453298    
2023-01-14 17:26:19,698 - --- validate (epoch=483)-----------
2023-01-14 17:26:19,698 - 148 samples (240 per mini-batch)
2023-01-14 17:26:20,201 - Epoch: [483][    1/    1]    Loss 0.376213    Top1 88.513514    Top5 100.000000    
2023-01-14 17:26:20,246 - ==> Top1: 88.514    Top5: 100.000    Loss: 0.376

2023-01-14 17:26:20,261 - ==> Best [Top1: 91.216   Top5: 98.649   Sparsity:0.00   Params: 80608 on epoch: 482]
2023-01-14 17:26:20,261 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:26:20,309 - 

2023-01-14 17:26:20,310 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:26:23,194 - Epoch: [484][    6/    6]    Overall Loss 0.011366    Objective Loss 0.011366    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.480528    
2023-01-14 17:26:23,239 - --- validate (epoch=484)-----------
2023-01-14 17:26:23,240 - 148 samples (240 per mini-batch)
2023-01-14 17:26:23,728 - Epoch: [484][    1/    1]    Loss 0.388599    Top1 87.837838    Top5 99.324324    
2023-01-14 17:26:23,768 - ==> Top1: 87.838    Top5: 99.324    Loss: 0.389

2023-01-14 17:26:23,781 - ==> Best [Top1: 91.216   Top5: 98.649   Sparsity:0.00   Params: 80608 on epoch: 482]
2023-01-14 17:26:23,781 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:26:23,826 - 

2023-01-14 17:26:23,826 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:26:26,559 - Epoch: [485][    6/    6]    Overall Loss 0.011742    Objective Loss 0.011742    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.455267    
2023-01-14 17:26:26,615 - --- validate (epoch=485)-----------
2023-01-14 17:26:26,616 - 148 samples (240 per mini-batch)
2023-01-14 17:26:27,215 - Epoch: [485][    1/    1]    Loss 0.340238    Top1 91.216216    Top5 99.324324    
2023-01-14 17:26:27,260 - ==> Top1: 91.216    Top5: 99.324    Loss: 0.340

2023-01-14 17:26:27,273 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 485]
2023-01-14 17:26:27,275 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:26:27,320 - 

2023-01-14 17:26:27,321 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:26:30,479 - Epoch: [486][    6/    6]    Overall Loss 0.011257    Objective Loss 0.011257    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.526100    
2023-01-14 17:26:30,537 - --- validate (epoch=486)-----------
2023-01-14 17:26:30,538 - 148 samples (240 per mini-batch)
2023-01-14 17:26:31,083 - Epoch: [486][    1/    1]    Loss 0.385509    Top1 89.189189    Top5 99.324324    
2023-01-14 17:26:31,125 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.386

2023-01-14 17:26:31,136 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 485]
2023-01-14 17:26:31,138 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:26:31,180 - 

2023-01-14 17:26:31,181 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:26:34,041 - Epoch: [487][    6/    6]    Overall Loss 0.012290    Objective Loss 0.012290    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.476361    
2023-01-14 17:26:34,087 - --- validate (epoch=487)-----------
2023-01-14 17:26:34,088 - 148 samples (240 per mini-batch)
2023-01-14 17:26:34,605 - Epoch: [487][    1/    1]    Loss 0.377039    Top1 89.189189    Top5 99.324324    
2023-01-14 17:26:34,646 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.377

2023-01-14 17:26:34,657 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 485]
2023-01-14 17:26:34,658 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:26:34,706 - 

2023-01-14 17:26:34,707 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:26:37,448 - Epoch: [488][    6/    6]    Overall Loss 0.012100    Objective Loss 0.012100    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.456649    
2023-01-14 17:26:37,495 - --- validate (epoch=488)-----------
2023-01-14 17:26:37,496 - 148 samples (240 per mini-batch)
2023-01-14 17:26:38,105 - Epoch: [488][    1/    1]    Loss 0.356403    Top1 89.864865    Top5 98.648649    
2023-01-14 17:26:38,157 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.356

2023-01-14 17:26:38,169 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 485]
2023-01-14 17:26:38,171 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:26:38,205 - 

2023-01-14 17:26:38,206 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:26:41,333 - Epoch: [489][    6/    6]    Overall Loss 0.011630    Objective Loss 0.011630    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.520857    
2023-01-14 17:26:41,385 - --- validate (epoch=489)-----------
2023-01-14 17:26:41,385 - 148 samples (240 per mini-batch)
2023-01-14 17:26:41,954 - Epoch: [489][    1/    1]    Loss 0.358741    Top1 90.540541    Top5 98.648649    
2023-01-14 17:26:41,993 - ==> Top1: 90.541    Top5: 98.649    Loss: 0.359

2023-01-14 17:26:42,006 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 485]
2023-01-14 17:26:42,006 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:26:42,042 - 

2023-01-14 17:26:42,043 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:26:44,649 - Epoch: [490][    6/    6]    Overall Loss 0.011779    Objective Loss 0.011779    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.433939    
2023-01-14 17:26:44,709 - --- validate (epoch=490)-----------
2023-01-14 17:26:44,710 - 148 samples (240 per mini-batch)
2023-01-14 17:26:45,171 - Epoch: [490][    1/    1]    Loss 0.350703    Top1 89.864865    Top5 99.324324    
2023-01-14 17:26:45,212 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.351

2023-01-14 17:26:45,226 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 485]
2023-01-14 17:26:45,227 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:26:45,267 - 

2023-01-14 17:26:45,267 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:26:47,925 - Epoch: [491][    6/    6]    Overall Loss 0.011511    Objective Loss 0.011511    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.442643    
2023-01-14 17:26:47,968 - --- validate (epoch=491)-----------
2023-01-14 17:26:47,969 - 148 samples (240 per mini-batch)
2023-01-14 17:26:48,502 - Epoch: [491][    1/    1]    Loss 0.327565    Top1 90.540541    Top5 99.324324    
2023-01-14 17:26:48,549 - ==> Top1: 90.541    Top5: 99.324    Loss: 0.328

2023-01-14 17:26:48,558 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 485]
2023-01-14 17:26:48,559 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:26:48,602 - 

2023-01-14 17:26:48,603 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:26:51,099 - Epoch: [492][    6/    6]    Overall Loss 0.011335    Objective Loss 0.011335    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.415684    
2023-01-14 17:26:51,141 - --- validate (epoch=492)-----------
2023-01-14 17:26:51,142 - 148 samples (240 per mini-batch)
2023-01-14 17:26:51,692 - Epoch: [492][    1/    1]    Loss 0.336547    Top1 89.864865    Top5 100.000000    
2023-01-14 17:26:51,734 - ==> Top1: 89.865    Top5: 100.000    Loss: 0.337

2023-01-14 17:26:51,748 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 485]
2023-01-14 17:26:51,749 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:26:51,797 - 

2023-01-14 17:26:51,798 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:26:54,426 - Epoch: [493][    6/    6]    Overall Loss 0.011443    Objective Loss 0.011443    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.437667    
2023-01-14 17:26:54,483 - --- validate (epoch=493)-----------
2023-01-14 17:26:54,483 - 148 samples (240 per mini-batch)
2023-01-14 17:26:55,035 - Epoch: [493][    1/    1]    Loss 0.331312    Top1 89.189189    Top5 99.324324    
2023-01-14 17:26:55,104 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.331

2023-01-14 17:26:55,112 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 485]
2023-01-14 17:26:55,112 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:26:55,151 - 

2023-01-14 17:26:55,152 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:26:58,529 - Epoch: [494][    6/    6]    Overall Loss 0.011037    Objective Loss 0.011037    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.562599    
2023-01-14 17:26:58,583 - --- validate (epoch=494)-----------
2023-01-14 17:26:58,584 - 148 samples (240 per mini-batch)
2023-01-14 17:26:59,215 - Epoch: [494][    1/    1]    Loss 0.340621    Top1 90.540541    Top5 99.324324    
2023-01-14 17:26:59,268 - ==> Top1: 90.541    Top5: 99.324    Loss: 0.341

2023-01-14 17:26:59,280 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 485]
2023-01-14 17:26:59,281 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:26:59,331 - 

2023-01-14 17:26:59,332 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:27:02,681 - Epoch: [495][    6/    6]    Overall Loss 0.012022    Objective Loss 0.012022    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.557932    
2023-01-14 17:27:02,748 - --- validate (epoch=495)-----------
2023-01-14 17:27:02,749 - 148 samples (240 per mini-batch)
2023-01-14 17:27:03,253 - Epoch: [495][    1/    1]    Loss 0.355754    Top1 89.864865    Top5 99.324324    
2023-01-14 17:27:03,296 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.356

2023-01-14 17:27:03,308 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 485]
2023-01-14 17:27:03,308 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:27:03,353 - 

2023-01-14 17:27:03,354 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:27:06,281 - Epoch: [496][    6/    6]    Overall Loss 0.011422    Objective Loss 0.011422    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.487611    
2023-01-14 17:27:06,330 - --- validate (epoch=496)-----------
2023-01-14 17:27:06,330 - 148 samples (240 per mini-batch)
2023-01-14 17:27:06,913 - Epoch: [496][    1/    1]    Loss 0.368254    Top1 91.216216    Top5 98.648649    
2023-01-14 17:27:06,958 - ==> Top1: 91.216    Top5: 98.649    Loss: 0.368

2023-01-14 17:27:06,972 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 485]
2023-01-14 17:27:06,973 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:27:07,017 - 

2023-01-14 17:27:07,019 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:27:10,100 - Epoch: [497][    6/    6]    Overall Loss 0.011427    Objective Loss 0.011427    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.513012    
2023-01-14 17:27:10,141 - --- validate (epoch=497)-----------
2023-01-14 17:27:10,141 - 148 samples (240 per mini-batch)
2023-01-14 17:27:10,617 - Epoch: [497][    1/    1]    Loss 0.329921    Top1 89.864865    Top5 99.324324    
2023-01-14 17:27:10,656 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.330

2023-01-14 17:27:10,666 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 485]
2023-01-14 17:27:10,669 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:27:10,724 - 

2023-01-14 17:27:10,725 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:27:13,227 - Epoch: [498][    6/    6]    Overall Loss 0.011512    Objective Loss 0.011512    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.416790    
2023-01-14 17:27:13,273 - --- validate (epoch=498)-----------
2023-01-14 17:27:13,274 - 148 samples (240 per mini-batch)
2023-01-14 17:27:13,796 - Epoch: [498][    1/    1]    Loss 0.362330    Top1 89.189189    Top5 98.648649    
2023-01-14 17:27:13,856 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.362

2023-01-14 17:27:13,866 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 485]
2023-01-14 17:27:13,866 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:27:13,909 - 

2023-01-14 17:27:13,910 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:27:17,010 - Epoch: [499][    6/    6]    Overall Loss 0.011549    Objective Loss 0.011549    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.516373    
2023-01-14 17:27:17,067 - --- validate (epoch=499)-----------
2023-01-14 17:27:17,068 - 148 samples (240 per mini-batch)
2023-01-14 17:27:17,640 - Epoch: [499][    1/    1]    Loss 0.371720    Top1 89.189189    Top5 98.648649    
2023-01-14 17:27:17,708 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.372

2023-01-14 17:27:17,721 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 485]
2023-01-14 17:27:17,722 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:27:17,765 - 

2023-01-14 17:27:17,765 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:27:20,707 - Epoch: [500][    6/    6]    Overall Loss 0.011487    Objective Loss 0.011487    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.490144    
2023-01-14 17:27:20,752 - --- validate (epoch=500)-----------
2023-01-14 17:27:20,752 - 148 samples (240 per mini-batch)
2023-01-14 17:27:21,318 - Epoch: [500][    1/    1]    Loss 0.362810    Top1 89.864865    Top5 98.648649    
2023-01-14 17:27:21,367 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.363

2023-01-14 17:27:21,384 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 485]
2023-01-14 17:27:21,384 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:27:21,438 - 

2023-01-14 17:27:21,439 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:27:24,513 - Epoch: [501][    6/    6]    Overall Loss 0.011518    Objective Loss 0.011518    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.512147    
2023-01-14 17:27:24,558 - --- validate (epoch=501)-----------
2023-01-14 17:27:24,558 - 148 samples (240 per mini-batch)
2023-01-14 17:27:25,153 - Epoch: [501][    1/    1]    Loss 0.348438    Top1 91.216216    Top5 98.648649    
2023-01-14 17:27:25,195 - ==> Top1: 91.216    Top5: 98.649    Loss: 0.348

2023-01-14 17:27:25,206 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 485]
2023-01-14 17:27:25,207 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:27:25,252 - 

2023-01-14 17:27:25,253 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:27:27,785 - Epoch: [502][    6/    6]    Overall Loss 0.011562    Objective Loss 0.011562    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.421738    
2023-01-14 17:27:27,828 - --- validate (epoch=502)-----------
2023-01-14 17:27:27,829 - 148 samples (240 per mini-batch)
2023-01-14 17:27:28,363 - Epoch: [502][    1/    1]    Loss 0.340868    Top1 90.540541    Top5 99.324324    
2023-01-14 17:27:28,403 - ==> Top1: 90.541    Top5: 99.324    Loss: 0.341

2023-01-14 17:27:28,420 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 485]
2023-01-14 17:27:28,420 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:27:28,463 - 

2023-01-14 17:27:28,464 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:27:31,225 - Epoch: [503][    6/    6]    Overall Loss 0.011313    Objective Loss 0.011313    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.459950    
2023-01-14 17:27:31,265 - --- validate (epoch=503)-----------
2023-01-14 17:27:31,265 - 148 samples (240 per mini-batch)
2023-01-14 17:27:31,853 - Epoch: [503][    1/    1]    Loss 0.364562    Top1 89.864865    Top5 98.648649    
2023-01-14 17:27:31,895 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.365

2023-01-14 17:27:31,907 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 485]
2023-01-14 17:27:31,909 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:27:31,958 - 

2023-01-14 17:27:31,959 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:27:34,787 - Epoch: [504][    6/    6]    Overall Loss 0.011114    Objective Loss 0.011114    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.471108    
2023-01-14 17:27:34,845 - --- validate (epoch=504)-----------
2023-01-14 17:27:34,846 - 148 samples (240 per mini-batch)
2023-01-14 17:27:35,389 - Epoch: [504][    1/    1]    Loss 0.361219    Top1 89.864865    Top5 98.648649    
2023-01-14 17:27:35,436 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.361

2023-01-14 17:27:35,448 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 485]
2023-01-14 17:27:35,448 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:27:35,489 - 

2023-01-14 17:27:35,490 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:27:38,589 - Epoch: [505][    6/    6]    Overall Loss 0.011319    Objective Loss 0.011319    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.516269    
2023-01-14 17:27:38,634 - --- validate (epoch=505)-----------
2023-01-14 17:27:38,635 - 148 samples (240 per mini-batch)
2023-01-14 17:27:39,219 - Epoch: [505][    1/    1]    Loss 0.345365    Top1 89.864865    Top5 99.324324    
2023-01-14 17:27:39,282 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.345

2023-01-14 17:27:39,295 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 485]
2023-01-14 17:27:39,295 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:27:39,340 - 

2023-01-14 17:27:39,341 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:27:42,312 - Epoch: [506][    6/    6]    Overall Loss 0.011622    Objective Loss 0.011622    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.494812    
2023-01-14 17:27:42,358 - --- validate (epoch=506)-----------
2023-01-14 17:27:42,359 - 148 samples (240 per mini-batch)
2023-01-14 17:27:42,920 - Epoch: [506][    1/    1]    Loss 0.349446    Top1 89.189189    Top5 98.648649    
2023-01-14 17:27:42,957 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.349

2023-01-14 17:27:42,966 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 485]
2023-01-14 17:27:42,967 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:27:43,010 - 

2023-01-14 17:27:43,011 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:27:45,729 - Epoch: [507][    6/    6]    Overall Loss 0.011438    Objective Loss 0.011438    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.452713    
2023-01-14 17:27:45,772 - --- validate (epoch=507)-----------
2023-01-14 17:27:45,773 - 148 samples (240 per mini-batch)
2023-01-14 17:27:46,287 - Epoch: [507][    1/    1]    Loss 0.350298    Top1 89.864865    Top5 99.324324    
2023-01-14 17:27:46,345 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.350

2023-01-14 17:27:46,355 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 485]
2023-01-14 17:27:46,355 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:27:46,402 - 

2023-01-14 17:27:46,403 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:27:49,097 - Epoch: [508][    6/    6]    Overall Loss 0.011706    Objective Loss 0.011706    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.448483    
2023-01-14 17:27:49,142 - --- validate (epoch=508)-----------
2023-01-14 17:27:49,142 - 148 samples (240 per mini-batch)
2023-01-14 17:27:49,640 - Epoch: [508][    1/    1]    Loss 0.368876    Top1 89.189189    Top5 98.648649    
2023-01-14 17:27:49,685 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.369

2023-01-14 17:27:49,694 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 485]
2023-01-14 17:27:49,694 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:27:49,736 - 

2023-01-14 17:27:49,737 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:27:52,247 - Epoch: [509][    6/    6]    Overall Loss 0.011590    Objective Loss 0.011590    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.418029    
2023-01-14 17:27:52,293 - --- validate (epoch=509)-----------
2023-01-14 17:27:52,293 - 148 samples (240 per mini-batch)
2023-01-14 17:27:52,825 - Epoch: [509][    1/    1]    Loss 0.333283    Top1 89.864865    Top5 98.648649    
2023-01-14 17:27:52,873 - ==> Top1: 89.865    Top5: 98.649    Loss: 0.333

2023-01-14 17:27:52,885 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 485]
2023-01-14 17:27:52,886 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:27:52,935 - 

2023-01-14 17:27:52,935 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:27:55,466 - Epoch: [510][    6/    6]    Overall Loss 0.011866    Objective Loss 0.011866    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.421498    
2023-01-14 17:27:55,519 - --- validate (epoch=510)-----------
2023-01-14 17:27:55,520 - 148 samples (240 per mini-batch)
2023-01-14 17:27:56,002 - Epoch: [510][    1/    1]    Loss 0.352008    Top1 89.189189    Top5 98.648649    
2023-01-14 17:27:56,042 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.352

2023-01-14 17:27:56,052 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 485]
2023-01-14 17:27:56,053 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:27:56,097 - 

2023-01-14 17:27:56,098 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:27:58,848 - Epoch: [511][    6/    6]    Overall Loss 0.012222    Objective Loss 0.012222    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.458108    
2023-01-14 17:27:58,891 - --- validate (epoch=511)-----------
2023-01-14 17:27:58,892 - 148 samples (240 per mini-batch)
2023-01-14 17:27:59,369 - Epoch: [511][    1/    1]    Loss 0.370713    Top1 88.513514    Top5 100.000000    
2023-01-14 17:27:59,418 - ==> Top1: 88.514    Top5: 100.000    Loss: 0.371

2023-01-14 17:27:59,430 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 485]
2023-01-14 17:27:59,430 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:27:59,476 - 

2023-01-14 17:27:59,477 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:28:02,117 - Epoch: [512][    6/    6]    Overall Loss 0.012344    Objective Loss 0.012344    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.439719    
2023-01-14 17:28:02,176 - --- validate (epoch=512)-----------
2023-01-14 17:28:02,177 - 148 samples (240 per mini-batch)
2023-01-14 17:28:02,713 - Epoch: [512][    1/    1]    Loss 0.351006    Top1 90.540541    Top5 99.324324    
2023-01-14 17:28:02,757 - ==> Top1: 90.541    Top5: 99.324    Loss: 0.351

2023-01-14 17:28:02,766 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 485]
2023-01-14 17:28:02,766 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:28:02,801 - 

2023-01-14 17:28:02,802 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:28:05,140 - Epoch: [513][    6/    6]    Overall Loss 0.011522    Objective Loss 0.011522    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.389387    
2023-01-14 17:28:05,186 - --- validate (epoch=513)-----------
2023-01-14 17:28:05,187 - 148 samples (240 per mini-batch)
2023-01-14 17:28:05,724 - Epoch: [513][    1/    1]    Loss 0.374766    Top1 90.540541    Top5 100.000000    
2023-01-14 17:28:05,766 - ==> Top1: 90.541    Top5: 100.000    Loss: 0.375

2023-01-14 17:28:05,779 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 485]
2023-01-14 17:28:05,779 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:28:05,817 - 

2023-01-14 17:28:05,818 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:28:09,408 - Epoch: [514][    6/    6]    Overall Loss 0.011903    Objective Loss 0.011903    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.598084    
2023-01-14 17:28:09,454 - --- validate (epoch=514)-----------
2023-01-14 17:28:09,455 - 148 samples (240 per mini-batch)
2023-01-14 17:28:10,039 - Epoch: [514][    1/    1]    Loss 0.325697    Top1 91.216216    Top5 99.324324    
2023-01-14 17:28:10,078 - ==> Top1: 91.216    Top5: 99.324    Loss: 0.326

2023-01-14 17:28:10,094 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 514]
2023-01-14 17:28:10,094 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:28:10,138 - 

2023-01-14 17:28:10,139 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:28:12,808 - Epoch: [515][    6/    6]    Overall Loss 0.011212    Objective Loss 0.011212    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.444410    
2023-01-14 17:28:12,863 - --- validate (epoch=515)-----------
2023-01-14 17:28:12,864 - 148 samples (240 per mini-batch)
2023-01-14 17:28:13,429 - Epoch: [515][    1/    1]    Loss 0.358826    Top1 89.864865    Top5 99.324324    
2023-01-14 17:28:13,505 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.359

2023-01-14 17:28:13,518 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 514]
2023-01-14 17:28:13,518 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:28:13,568 - 

2023-01-14 17:28:13,569 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:28:17,090 - Epoch: [516][    6/    6]    Overall Loss 0.011537    Objective Loss 0.011537    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.586400    
2023-01-14 17:28:17,144 - --- validate (epoch=516)-----------
2023-01-14 17:28:17,144 - 148 samples (240 per mini-batch)
2023-01-14 17:28:17,756 - Epoch: [516][    1/    1]    Loss 0.322131    Top1 89.189189    Top5 99.324324    
2023-01-14 17:28:17,800 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.322

2023-01-14 17:28:17,813 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 514]
2023-01-14 17:28:17,814 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:28:17,854 - 

2023-01-14 17:28:17,855 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:28:20,534 - Epoch: [517][    6/    6]    Overall Loss 0.011567    Objective Loss 0.011567    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.446120    
2023-01-14 17:28:20,574 - --- validate (epoch=517)-----------
2023-01-14 17:28:20,574 - 148 samples (240 per mini-batch)
2023-01-14 17:28:21,120 - Epoch: [517][    1/    1]    Loss 0.329559    Top1 89.864865    Top5 99.324324    
2023-01-14 17:28:21,166 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.330

2023-01-14 17:28:21,178 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 514]
2023-01-14 17:28:21,178 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:28:21,228 - 

2023-01-14 17:28:21,229 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:28:23,762 - Epoch: [518][    6/    6]    Overall Loss 0.011213    Objective Loss 0.011213    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.421897    
2023-01-14 17:28:23,813 - --- validate (epoch=518)-----------
2023-01-14 17:28:23,814 - 148 samples (240 per mini-batch)
2023-01-14 17:28:24,325 - Epoch: [518][    1/    1]    Loss 0.359744    Top1 89.189189    Top5 99.324324    
2023-01-14 17:28:24,378 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.360

2023-01-14 17:28:24,390 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 514]
2023-01-14 17:28:24,390 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:28:24,432 - 

2023-01-14 17:28:24,433 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:28:27,506 - Epoch: [519][    6/    6]    Overall Loss 0.011699    Objective Loss 0.011699    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.511916    
2023-01-14 17:28:27,561 - --- validate (epoch=519)-----------
2023-01-14 17:28:27,562 - 148 samples (240 per mini-batch)
2023-01-14 17:28:28,147 - Epoch: [519][    1/    1]    Loss 0.368449    Top1 88.513514    Top5 98.648649    
2023-01-14 17:28:28,185 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.368

2023-01-14 17:28:28,198 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 514]
2023-01-14 17:28:28,200 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:28:28,238 - 

2023-01-14 17:28:28,238 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:28:31,017 - Epoch: [520][    6/    6]    Overall Loss 0.011579    Objective Loss 0.011579    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.462897    
2023-01-14 17:28:31,066 - --- validate (epoch=520)-----------
2023-01-14 17:28:31,066 - 148 samples (240 per mini-batch)
2023-01-14 17:28:31,531 - Epoch: [520][    1/    1]    Loss 0.364360    Top1 88.513514    Top5 98.648649    
2023-01-14 17:28:31,570 - ==> Top1: 88.514    Top5: 98.649    Loss: 0.364

2023-01-14 17:28:31,582 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 514]
2023-01-14 17:28:31,584 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:28:31,623 - 

2023-01-14 17:28:31,623 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:28:34,536 - Epoch: [521][    6/    6]    Overall Loss 0.011091    Objective Loss 0.011091    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.485160    
2023-01-14 17:28:34,584 - --- validate (epoch=521)-----------
2023-01-14 17:28:34,585 - 148 samples (240 per mini-batch)
2023-01-14 17:28:35,187 - Epoch: [521][    1/    1]    Loss 0.359645    Top1 89.864865    Top5 99.324324    
2023-01-14 17:28:35,234 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.360

2023-01-14 17:28:35,245 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 514]
2023-01-14 17:28:35,246 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:28:35,286 - 

2023-01-14 17:28:35,286 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:28:38,075 - Epoch: [522][    6/    6]    Overall Loss 0.011188    Objective Loss 0.011188    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.464461    
2023-01-14 17:28:38,122 - --- validate (epoch=522)-----------
2023-01-14 17:28:38,123 - 148 samples (240 per mini-batch)
2023-01-14 17:28:38,698 - Epoch: [522][    1/    1]    Loss 0.350934    Top1 89.189189    Top5 99.324324    
2023-01-14 17:28:38,752 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.351

2023-01-14 17:28:38,762 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 514]
2023-01-14 17:28:38,763 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:28:38,803 - 

2023-01-14 17:28:38,804 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:28:41,782 - Epoch: [523][    6/    6]    Overall Loss 0.011218    Objective Loss 0.011218    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.495943    
2023-01-14 17:28:41,825 - --- validate (epoch=523)-----------
2023-01-14 17:28:41,825 - 148 samples (240 per mini-batch)
2023-01-14 17:28:42,391 - Epoch: [523][    1/    1]    Loss 0.346680    Top1 89.189189    Top5 100.000000    
2023-01-14 17:28:42,446 - ==> Top1: 89.189    Top5: 100.000    Loss: 0.347

2023-01-14 17:28:42,587 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 514]
2023-01-14 17:28:42,588 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:28:42,637 - 

2023-01-14 17:28:42,637 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:28:45,243 - Epoch: [524][    6/    6]    Overall Loss 0.011337    Objective Loss 0.011337    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.434067    
2023-01-14 17:28:45,287 - --- validate (epoch=524)-----------
2023-01-14 17:28:45,288 - 148 samples (240 per mini-batch)
2023-01-14 17:28:45,762 - Epoch: [524][    1/    1]    Loss 0.355420    Top1 89.864865    Top5 100.000000    
2023-01-14 17:28:45,803 - ==> Top1: 89.865    Top5: 100.000    Loss: 0.355

2023-01-14 17:28:45,812 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 514]
2023-01-14 17:28:45,812 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:28:45,849 - 

2023-01-14 17:28:45,849 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:28:48,354 - Epoch: [525][    6/    6]    Overall Loss 0.011146    Objective Loss 0.011146    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.417168    
2023-01-14 17:28:48,395 - --- validate (epoch=525)-----------
2023-01-14 17:28:48,396 - 148 samples (240 per mini-batch)
2023-01-14 17:28:48,939 - Epoch: [525][    1/    1]    Loss 0.363671    Top1 89.189189    Top5 99.324324    
2023-01-14 17:28:48,983 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.364

2023-01-14 17:28:48,995 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 514]
2023-01-14 17:28:48,995 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:28:49,035 - 

2023-01-14 17:28:49,035 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:28:51,519 - Epoch: [526][    6/    6]    Overall Loss 0.011045    Objective Loss 0.011045    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.413758    
2023-01-14 17:28:51,564 - --- validate (epoch=526)-----------
2023-01-14 17:28:51,565 - 148 samples (240 per mini-batch)
2023-01-14 17:28:52,109 - Epoch: [526][    1/    1]    Loss 0.345391    Top1 89.864865    Top5 99.324324    
2023-01-14 17:28:52,158 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.345

2023-01-14 17:28:52,168 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 514]
2023-01-14 17:28:52,169 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:28:52,211 - 

2023-01-14 17:28:52,211 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:28:54,566 - Epoch: [527][    6/    6]    Overall Loss 0.010855    Objective Loss 0.010855    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.392265    
2023-01-14 17:28:54,611 - --- validate (epoch=527)-----------
2023-01-14 17:28:54,612 - 148 samples (240 per mini-batch)
2023-01-14 17:28:55,130 - Epoch: [527][    1/    1]    Loss 0.359181    Top1 90.540541    Top5 100.000000    
2023-01-14 17:28:55,178 - ==> Top1: 90.541    Top5: 100.000    Loss: 0.359

2023-01-14 17:28:55,191 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 514]
2023-01-14 17:28:55,191 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:28:55,236 - 

2023-01-14 17:28:55,236 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:28:57,794 - Epoch: [528][    6/    6]    Overall Loss 0.010975    Objective Loss 0.010975    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.426011    
2023-01-14 17:28:57,853 - --- validate (epoch=528)-----------
2023-01-14 17:28:57,854 - 148 samples (240 per mini-batch)
2023-01-14 17:28:58,451 - Epoch: [528][    1/    1]    Loss 0.343428    Top1 89.189189    Top5 99.324324    
2023-01-14 17:28:58,492 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.343

2023-01-14 17:28:58,504 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 514]
2023-01-14 17:28:58,506 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:28:58,557 - 

2023-01-14 17:28:58,557 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:29:02,055 - Epoch: [529][    6/    6]    Overall Loss 0.011176    Objective Loss 0.011176    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.582797    
2023-01-14 17:29:02,111 - --- validate (epoch=529)-----------
2023-01-14 17:29:02,112 - 148 samples (240 per mini-batch)
2023-01-14 17:29:02,666 - Epoch: [529][    1/    1]    Loss 0.380184    Top1 89.189189    Top5 99.324324    
2023-01-14 17:29:02,713 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.380

2023-01-14 17:29:02,723 - ==> Best [Top1: 91.216   Top5: 99.324   Sparsity:0.00   Params: 80608 on epoch: 514]
2023-01-14 17:29:02,723 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:29:02,763 - 

2023-01-14 17:29:02,764 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:29:05,474 - Epoch: [530][    6/    6]    Overall Loss 0.011408    Objective Loss 0.011408    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.451285    
2023-01-14 17:29:05,524 - --- validate (epoch=530)-----------
2023-01-14 17:29:05,524 - 148 samples (240 per mini-batch)
2023-01-14 17:29:06,022 - Epoch: [530][    1/    1]    Loss 0.343869    Top1 91.216216    Top5 100.000000    
2023-01-14 17:29:06,060 - ==> Top1: 91.216    Top5: 100.000    Loss: 0.344

2023-01-14 17:29:06,073 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 530]
2023-01-14 17:29:06,073 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:29:06,122 - 

2023-01-14 17:29:06,122 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:29:09,099 - Epoch: [531][    6/    6]    Overall Loss 0.011544    Objective Loss 0.011544    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.495989    
2023-01-14 17:29:09,155 - --- validate (epoch=531)-----------
2023-01-14 17:29:09,156 - 148 samples (240 per mini-batch)
2023-01-14 17:29:09,707 - Epoch: [531][    1/    1]    Loss 0.359590    Top1 89.864865    Top5 99.324324    
2023-01-14 17:29:09,749 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.360

2023-01-14 17:29:09,760 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 530]
2023-01-14 17:29:09,761 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:29:09,805 - 

2023-01-14 17:29:09,806 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:29:12,706 - Epoch: [532][    6/    6]    Overall Loss 0.011624    Objective Loss 0.011624    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.483065    
2023-01-14 17:29:12,754 - --- validate (epoch=532)-----------
2023-01-14 17:29:12,755 - 148 samples (240 per mini-batch)
2023-01-14 17:29:13,238 - Epoch: [532][    1/    1]    Loss 0.377706    Top1 89.864865    Top5 97.972973    
2023-01-14 17:29:13,287 - ==> Top1: 89.865    Top5: 97.973    Loss: 0.378

2023-01-14 17:29:13,299 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 530]
2023-01-14 17:29:13,299 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:29:13,346 - 

2023-01-14 17:29:13,346 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:29:16,232 - Epoch: [533][    6/    6]    Overall Loss 0.011338    Objective Loss 0.011338    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.480478    
2023-01-14 17:29:16,279 - --- validate (epoch=533)-----------
2023-01-14 17:29:16,279 - 148 samples (240 per mini-batch)
2023-01-14 17:29:16,880 - Epoch: [533][    1/    1]    Loss 0.350766    Top1 89.189189    Top5 100.000000    
2023-01-14 17:29:16,928 - ==> Top1: 89.189    Top5: 100.000    Loss: 0.351

2023-01-14 17:29:16,941 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 530]
2023-01-14 17:29:16,942 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:29:16,984 - 

2023-01-14 17:29:16,984 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:29:19,357 - Epoch: [534][    6/    6]    Overall Loss 0.011929    Objective Loss 0.011929    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.395204    
2023-01-14 17:29:19,402 - --- validate (epoch=534)-----------
2023-01-14 17:29:19,403 - 148 samples (240 per mini-batch)
2023-01-14 17:29:19,926 - Epoch: [534][    1/    1]    Loss 0.356874    Top1 89.864865    Top5 99.324324    
2023-01-14 17:29:19,975 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.357

2023-01-14 17:29:19,986 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 530]
2023-01-14 17:29:19,986 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:29:20,032 - 

2023-01-14 17:29:20,033 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:29:22,917 - Epoch: [535][    6/    6]    Overall Loss 0.011257    Objective Loss 0.011257    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.480500    
2023-01-14 17:29:22,972 - --- validate (epoch=535)-----------
2023-01-14 17:29:22,973 - 148 samples (240 per mini-batch)
2023-01-14 17:29:23,577 - Epoch: [535][    1/    1]    Loss 0.371771    Top1 89.864865    Top5 99.324324    
2023-01-14 17:29:23,638 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.372

2023-01-14 17:29:23,648 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 530]
2023-01-14 17:29:23,649 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:29:23,697 - 

2023-01-14 17:29:23,698 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:29:27,754 - Epoch: [536][    6/    6]    Overall Loss 0.011254    Objective Loss 0.011254    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.675690    
2023-01-14 17:29:27,809 - --- validate (epoch=536)-----------
2023-01-14 17:29:27,809 - 148 samples (240 per mini-batch)
2023-01-14 17:29:28,305 - Epoch: [536][    1/    1]    Loss 0.342891    Top1 88.513514    Top5 99.324324    
2023-01-14 17:29:28,350 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.343

2023-01-14 17:29:28,360 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 530]
2023-01-14 17:29:28,360 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:29:28,403 - 

2023-01-14 17:29:28,404 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:29:31,352 - Epoch: [537][    6/    6]    Overall Loss 0.011459    Objective Loss 0.011459    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.491139    
2023-01-14 17:29:31,395 - --- validate (epoch=537)-----------
2023-01-14 17:29:31,396 - 148 samples (240 per mini-batch)
2023-01-14 17:29:31,976 - Epoch: [537][    1/    1]    Loss 0.366738    Top1 89.189189    Top5 100.000000    
2023-01-14 17:29:32,022 - ==> Top1: 89.189    Top5: 100.000    Loss: 0.367

2023-01-14 17:29:32,028 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 530]
2023-01-14 17:29:32,029 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:29:32,065 - 

2023-01-14 17:29:32,066 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:29:34,938 - Epoch: [538][    6/    6]    Overall Loss 0.011102    Objective Loss 0.011102    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.478385    
2023-01-14 17:29:34,985 - --- validate (epoch=538)-----------
2023-01-14 17:29:34,986 - 148 samples (240 per mini-batch)
2023-01-14 17:29:35,500 - Epoch: [538][    1/    1]    Loss 0.375164    Top1 89.864865    Top5 99.324324    
2023-01-14 17:29:35,544 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.375

2023-01-14 17:29:35,556 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 530]
2023-01-14 17:29:35,556 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:29:35,598 - 

2023-01-14 17:29:35,599 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:29:38,428 - Epoch: [539][    6/    6]    Overall Loss 0.011076    Objective Loss 0.011076    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.471198    
2023-01-14 17:29:38,471 - --- validate (epoch=539)-----------
2023-01-14 17:29:38,472 - 148 samples (240 per mini-batch)
2023-01-14 17:29:39,009 - Epoch: [539][    1/    1]    Loss 0.358523    Top1 89.864865    Top5 99.324324    
2023-01-14 17:29:39,049 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.359

2023-01-14 17:29:39,059 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 530]
2023-01-14 17:29:39,059 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:29:39,097 - 

2023-01-14 17:29:39,098 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:29:41,795 - Epoch: [540][    6/    6]    Overall Loss 0.011158    Objective Loss 0.011158    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.448531    
2023-01-14 17:29:41,839 - --- validate (epoch=540)-----------
2023-01-14 17:29:41,840 - 148 samples (240 per mini-batch)
2023-01-14 17:29:42,368 - Epoch: [540][    1/    1]    Loss 0.352365    Top1 89.189189    Top5 98.648649    
2023-01-14 17:29:42,410 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.352

2023-01-14 17:29:42,422 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 530]
2023-01-14 17:29:42,422 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:29:42,465 - 

2023-01-14 17:29:42,466 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:29:45,537 - Epoch: [541][    6/    6]    Overall Loss 0.011376    Objective Loss 0.011376    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.511602    
2023-01-14 17:29:45,584 - --- validate (epoch=541)-----------
2023-01-14 17:29:45,584 - 148 samples (240 per mini-batch)
2023-01-14 17:29:46,061 - Epoch: [541][    1/    1]    Loss 0.366733    Top1 89.864865    Top5 99.324324    
2023-01-14 17:29:46,112 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.367

2023-01-14 17:29:46,124 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 530]
2023-01-14 17:29:46,124 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:29:46,169 - 

2023-01-14 17:29:46,170 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:29:49,221 - Epoch: [542][    6/    6]    Overall Loss 0.011521    Objective Loss 0.011521    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.508287    
2023-01-14 17:29:49,265 - --- validate (epoch=542)-----------
2023-01-14 17:29:49,265 - 148 samples (240 per mini-batch)
2023-01-14 17:29:49,871 - Epoch: [542][    1/    1]    Loss 0.332621    Top1 90.540541    Top5 99.324324    
2023-01-14 17:29:49,919 - ==> Top1: 90.541    Top5: 99.324    Loss: 0.333

2023-01-14 17:29:49,934 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 530]
2023-01-14 17:29:49,934 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:29:49,981 - 

2023-01-14 17:29:49,982 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:29:52,466 - Epoch: [543][    6/    6]    Overall Loss 0.011475    Objective Loss 0.011475    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.413831    
2023-01-14 17:29:52,513 - --- validate (epoch=543)-----------
2023-01-14 17:29:52,513 - 148 samples (240 per mini-batch)
2023-01-14 17:29:53,067 - Epoch: [543][    1/    1]    Loss 0.332863    Top1 88.513514    Top5 99.324324    
2023-01-14 17:29:53,107 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.333

2023-01-14 17:29:53,117 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 530]
2023-01-14 17:29:53,118 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:29:53,157 - 

2023-01-14 17:29:53,158 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:29:55,862 - Epoch: [544][    6/    6]    Overall Loss 0.011213    Objective Loss 0.011213    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.449924    
2023-01-14 17:29:55,910 - --- validate (epoch=544)-----------
2023-01-14 17:29:55,911 - 148 samples (240 per mini-batch)
2023-01-14 17:29:56,439 - Epoch: [544][    1/    1]    Loss 0.337813    Top1 89.864865    Top5 99.324324    
2023-01-14 17:29:56,488 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.338

2023-01-14 17:29:56,497 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 530]
2023-01-14 17:29:56,497 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:29:56,543 - 

2023-01-14 17:29:56,544 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:29:59,171 - Epoch: [545][    6/    6]    Overall Loss 0.011366    Objective Loss 0.011366    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.437487    
2023-01-14 17:29:59,242 - --- validate (epoch=545)-----------
2023-01-14 17:29:59,242 - 148 samples (240 per mini-batch)
2023-01-14 17:29:59,780 - Epoch: [545][    1/    1]    Loss 0.363365    Top1 89.864865    Top5 99.324324    
2023-01-14 17:29:59,814 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.363

2023-01-14 17:29:59,829 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 530]
2023-01-14 17:29:59,829 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:29:59,880 - 

2023-01-14 17:29:59,880 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:30:02,519 - Epoch: [546][    6/    6]    Overall Loss 0.011460    Objective Loss 0.011460    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.439559    
2023-01-14 17:30:02,568 - --- validate (epoch=546)-----------
2023-01-14 17:30:02,569 - 148 samples (240 per mini-batch)
2023-01-14 17:30:03,126 - Epoch: [546][    1/    1]    Loss 0.361547    Top1 89.189189    Top5 99.324324    
2023-01-14 17:30:03,163 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.362

2023-01-14 17:30:03,176 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 530]
2023-01-14 17:30:03,176 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:30:03,216 - 

2023-01-14 17:30:03,217 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:30:05,564 - Epoch: [547][    6/    6]    Overall Loss 0.010913    Objective Loss 0.010913    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.390864    
2023-01-14 17:30:05,614 - --- validate (epoch=547)-----------
2023-01-14 17:30:05,615 - 148 samples (240 per mini-batch)
2023-01-14 17:30:06,140 - Epoch: [547][    1/    1]    Loss 0.368745    Top1 89.864865    Top5 99.324324    
2023-01-14 17:30:06,182 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.369

2023-01-14 17:30:06,191 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 530]
2023-01-14 17:30:06,191 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:30:06,225 - 

2023-01-14 17:30:06,225 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:30:09,103 - Epoch: [548][    6/    6]    Overall Loss 0.011303    Objective Loss 0.011303    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.479462    
2023-01-14 17:30:09,151 - --- validate (epoch=548)-----------
2023-01-14 17:30:09,152 - 148 samples (240 per mini-batch)
2023-01-14 17:30:09,672 - Epoch: [548][    1/    1]    Loss 0.355580    Top1 90.540541    Top5 98.648649    
2023-01-14 17:30:09,717 - ==> Top1: 90.541    Top5: 98.649    Loss: 0.356

2023-01-14 17:30:09,730 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 530]
2023-01-14 17:30:09,733 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:30:09,775 - 

2023-01-14 17:30:09,775 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:30:12,714 - Epoch: [549][    6/    6]    Overall Loss 0.011030    Objective Loss 0.011030    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.489563    
2023-01-14 17:30:12,762 - --- validate (epoch=549)-----------
2023-01-14 17:30:12,762 - 148 samples (240 per mini-batch)
2023-01-14 17:30:13,339 - Epoch: [549][    1/    1]    Loss 0.345768    Top1 89.189189    Top5 99.324324    
2023-01-14 17:30:13,394 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.346

2023-01-14 17:30:13,404 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 530]
2023-01-14 17:30:13,405 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:30:13,493 - 

2023-01-14 17:30:13,494 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:30:16,694 - Epoch: [550][    6/    6]    Overall Loss 0.010717    Objective Loss 0.010717    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.532782    
2023-01-14 17:30:16,752 - --- validate (epoch=550)-----------
2023-01-14 17:30:16,753 - 148 samples (240 per mini-batch)
2023-01-14 17:30:17,353 - Epoch: [550][    1/    1]    Loss 0.337353    Top1 89.189189    Top5 99.324324    
2023-01-14 17:30:17,424 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.337

2023-01-14 17:30:17,437 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 530]
2023-01-14 17:30:17,438 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:30:17,486 - 

2023-01-14 17:30:17,487 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:30:20,401 - Epoch: [551][    6/    6]    Overall Loss 0.010955    Objective Loss 0.010955    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.485465    
2023-01-14 17:30:20,450 - --- validate (epoch=551)-----------
2023-01-14 17:30:20,450 - 148 samples (240 per mini-batch)
2023-01-14 17:30:21,031 - Epoch: [551][    1/    1]    Loss 0.313593    Top1 91.216216    Top5 100.000000    
2023-01-14 17:30:21,073 - ==> Top1: 91.216    Top5: 100.000    Loss: 0.314

2023-01-14 17:30:21,086 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 551]
2023-01-14 17:30:21,086 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:30:21,137 - 

2023-01-14 17:30:21,138 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:30:24,005 - Epoch: [552][    6/    6]    Overall Loss 0.010832    Objective Loss 0.010832    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.477586    
2023-01-14 17:30:24,050 - --- validate (epoch=552)-----------
2023-01-14 17:30:24,050 - 148 samples (240 per mini-batch)
2023-01-14 17:30:24,566 - Epoch: [552][    1/    1]    Loss 0.365475    Top1 89.189189    Top5 99.324324    
2023-01-14 17:30:24,610 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.365

2023-01-14 17:30:24,625 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 551]
2023-01-14 17:30:24,626 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:30:24,676 - 

2023-01-14 17:30:24,677 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:30:27,743 - Epoch: [553][    6/    6]    Overall Loss 0.010992    Objective Loss 0.010992    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.510555    
2023-01-14 17:30:27,789 - --- validate (epoch=553)-----------
2023-01-14 17:30:27,789 - 148 samples (240 per mini-batch)
2023-01-14 17:30:28,266 - Epoch: [553][    1/    1]    Loss 0.366449    Top1 88.513514    Top5 99.324324    
2023-01-14 17:30:28,311 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.366

2023-01-14 17:30:28,325 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 551]
2023-01-14 17:30:28,326 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:30:28,373 - 

2023-01-14 17:30:28,373 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:30:31,505 - Epoch: [554][    6/    6]    Overall Loss 0.010848    Objective Loss 0.010848    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.521495    
2023-01-14 17:30:31,552 - --- validate (epoch=554)-----------
2023-01-14 17:30:31,552 - 148 samples (240 per mini-batch)
2023-01-14 17:30:32,095 - Epoch: [554][    1/    1]    Loss 0.353282    Top1 90.540541    Top5 99.324324    
2023-01-14 17:30:32,140 - ==> Top1: 90.541    Top5: 99.324    Loss: 0.353

2023-01-14 17:30:32,153 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 551]
2023-01-14 17:30:32,153 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:30:32,211 - 

2023-01-14 17:30:32,211 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:30:35,239 - Epoch: [555][    6/    6]    Overall Loss 0.010933    Objective Loss 0.010933    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.504444    
2023-01-14 17:30:35,319 - --- validate (epoch=555)-----------
2023-01-14 17:30:35,319 - 148 samples (240 per mini-batch)
2023-01-14 17:30:35,946 - Epoch: [555][    1/    1]    Loss 0.357636    Top1 88.513514    Top5 100.000000    
2023-01-14 17:30:35,989 - ==> Top1: 88.514    Top5: 100.000    Loss: 0.358

2023-01-14 17:30:35,998 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 551]
2023-01-14 17:30:35,999 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:30:36,035 - 

2023-01-14 17:30:36,035 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:30:38,970 - Epoch: [556][    6/    6]    Overall Loss 0.011628    Objective Loss 0.011628    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.488881    
2023-01-14 17:30:39,016 - --- validate (epoch=556)-----------
2023-01-14 17:30:39,016 - 148 samples (240 per mini-batch)
2023-01-14 17:30:39,618 - Epoch: [556][    1/    1]    Loss 0.344563    Top1 89.864865    Top5 100.000000    
2023-01-14 17:30:39,666 - ==> Top1: 89.865    Top5: 100.000    Loss: 0.345

2023-01-14 17:30:39,676 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 551]
2023-01-14 17:30:39,677 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:30:39,713 - 

2023-01-14 17:30:39,714 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:30:42,449 - Epoch: [557][    6/    6]    Overall Loss 0.010931    Objective Loss 0.010931    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.455567    
2023-01-14 17:30:42,498 - --- validate (epoch=557)-----------
2023-01-14 17:30:42,499 - 148 samples (240 per mini-batch)
2023-01-14 17:30:43,000 - Epoch: [557][    1/    1]    Loss 0.345854    Top1 89.189189    Top5 98.648649    
2023-01-14 17:30:43,048 - ==> Top1: 89.189    Top5: 98.649    Loss: 0.346

2023-01-14 17:30:43,058 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 551]
2023-01-14 17:30:43,059 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:30:43,102 - 

2023-01-14 17:30:43,103 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:30:45,624 - Epoch: [558][    6/    6]    Overall Loss 0.011126    Objective Loss 0.011126    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.419838    
2023-01-14 17:30:45,667 - --- validate (epoch=558)-----------
2023-01-14 17:30:45,669 - 148 samples (240 per mini-batch)
2023-01-14 17:30:46,183 - Epoch: [558][    1/    1]    Loss 0.369764    Top1 89.864865    Top5 100.000000    
2023-01-14 17:30:46,227 - ==> Top1: 89.865    Top5: 100.000    Loss: 0.370

2023-01-14 17:30:46,239 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 551]
2023-01-14 17:30:46,239 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:30:46,276 - 

2023-01-14 17:30:46,276 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:30:49,367 - Epoch: [559][    6/    6]    Overall Loss 0.011296    Objective Loss 0.011296    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.514903    
2023-01-14 17:30:49,412 - --- validate (epoch=559)-----------
2023-01-14 17:30:49,413 - 148 samples (240 per mini-batch)
2023-01-14 17:30:50,007 - Epoch: [559][    1/    1]    Loss 0.355180    Top1 90.540541    Top5 100.000000    
2023-01-14 17:30:50,058 - ==> Top1: 90.541    Top5: 100.000    Loss: 0.355

2023-01-14 17:30:50,078 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 551]
2023-01-14 17:30:50,078 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:30:50,123 - 

2023-01-14 17:30:50,123 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:30:53,085 - Epoch: [560][    6/    6]    Overall Loss 0.011374    Objective Loss 0.011374    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.493359    
2023-01-14 17:30:53,136 - --- validate (epoch=560)-----------
2023-01-14 17:30:53,137 - 148 samples (240 per mini-batch)
2023-01-14 17:30:53,702 - Epoch: [560][    1/    1]    Loss 0.369143    Top1 89.864865    Top5 100.000000    
2023-01-14 17:30:53,754 - ==> Top1: 89.865    Top5: 100.000    Loss: 0.369

2023-01-14 17:30:53,769 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 551]
2023-01-14 17:30:53,770 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:30:53,814 - 

2023-01-14 17:30:53,816 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:30:57,391 - Epoch: [561][    6/    6]    Overall Loss 0.010855    Objective Loss 0.010855    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.595590    
2023-01-14 17:30:57,440 - --- validate (epoch=561)-----------
2023-01-14 17:30:57,441 - 148 samples (240 per mini-batch)
2023-01-14 17:30:58,047 - Epoch: [561][    1/    1]    Loss 0.340045    Top1 91.216216    Top5 98.648649    
2023-01-14 17:30:58,089 - ==> Top1: 91.216    Top5: 98.649    Loss: 0.340

2023-01-14 17:30:58,101 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 551]
2023-01-14 17:30:58,101 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:30:58,140 - 

2023-01-14 17:30:58,140 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:31:01,745 - Epoch: [562][    6/    6]    Overall Loss 0.011148    Objective Loss 0.011148    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.600565    
2023-01-14 17:31:01,792 - --- validate (epoch=562)-----------
2023-01-14 17:31:01,793 - 148 samples (240 per mini-batch)
2023-01-14 17:31:02,260 - Epoch: [562][    1/    1]    Loss 0.362197    Top1 89.189189    Top5 100.000000    
2023-01-14 17:31:02,307 - ==> Top1: 89.189    Top5: 100.000    Loss: 0.362

2023-01-14 17:31:02,320 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 551]
2023-01-14 17:31:02,320 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:31:02,370 - 

2023-01-14 17:31:02,370 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:31:05,935 - Epoch: [563][    6/    6]    Overall Loss 0.010928    Objective Loss 0.010928    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.593862    
2023-01-14 17:31:05,979 - --- validate (epoch=563)-----------
2023-01-14 17:31:05,979 - 148 samples (240 per mini-batch)
2023-01-14 17:31:06,577 - Epoch: [563][    1/    1]    Loss 0.352605    Top1 89.189189    Top5 100.000000    
2023-01-14 17:31:06,629 - ==> Top1: 89.189    Top5: 100.000    Loss: 0.353

2023-01-14 17:31:06,636 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 551]
2023-01-14 17:31:06,637 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:31:06,687 - 

2023-01-14 17:31:06,687 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:31:09,609 - Epoch: [564][    6/    6]    Overall Loss 0.010731    Objective Loss 0.010731    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.486795    
2023-01-14 17:31:09,659 - --- validate (epoch=564)-----------
2023-01-14 17:31:09,659 - 148 samples (240 per mini-batch)
2023-01-14 17:31:10,265 - Epoch: [564][    1/    1]    Loss 0.360361    Top1 89.189189    Top5 99.324324    
2023-01-14 17:31:10,308 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.360

2023-01-14 17:31:10,319 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 551]
2023-01-14 17:31:10,320 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:31:10,372 - 

2023-01-14 17:31:10,373 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:31:12,703 - Epoch: [565][    6/    6]    Overall Loss 0.011071    Objective Loss 0.011071    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.387990    
2023-01-14 17:31:12,778 - --- validate (epoch=565)-----------
2023-01-14 17:31:12,778 - 148 samples (240 per mini-batch)
2023-01-14 17:31:13,306 - Epoch: [565][    1/    1]    Loss 0.355791    Top1 89.864865    Top5 99.324324    
2023-01-14 17:31:13,355 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.356

2023-01-14 17:31:13,364 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 551]
2023-01-14 17:31:13,365 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:31:13,406 - 

2023-01-14 17:31:13,407 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:31:17,646 - Epoch: [566][    6/    6]    Overall Loss 0.010902    Objective Loss 0.010902    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.706101    
2023-01-14 17:31:17,728 - --- validate (epoch=566)-----------
2023-01-14 17:31:17,728 - 148 samples (240 per mini-batch)
2023-01-14 17:31:18,323 - Epoch: [566][    1/    1]    Loss 0.361058    Top1 89.864865    Top5 99.324324    
2023-01-14 17:31:18,392 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.361

2023-01-14 17:31:18,406 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 551]
2023-01-14 17:31:18,406 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:31:18,470 - 

2023-01-14 17:31:18,471 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:31:22,002 - Epoch: [567][    6/    6]    Overall Loss 0.011058    Objective Loss 0.011058    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.588073    
2023-01-14 17:31:22,051 - --- validate (epoch=567)-----------
2023-01-14 17:31:22,052 - 148 samples (240 per mini-batch)
2023-01-14 17:31:22,638 - Epoch: [567][    1/    1]    Loss 0.361102    Top1 89.864865    Top5 100.000000    
2023-01-14 17:31:22,681 - ==> Top1: 89.865    Top5: 100.000    Loss: 0.361

2023-01-14 17:31:22,694 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 551]
2023-01-14 17:31:22,694 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:31:22,750 - 

2023-01-14 17:31:22,751 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:31:25,750 - Epoch: [568][    6/    6]    Overall Loss 0.011322    Objective Loss 0.011322    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.499529    
2023-01-14 17:31:25,792 - --- validate (epoch=568)-----------
2023-01-14 17:31:25,793 - 148 samples (240 per mini-batch)
2023-01-14 17:31:26,349 - Epoch: [568][    1/    1]    Loss 0.351519    Top1 89.189189    Top5 99.324324    
2023-01-14 17:31:26,392 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.352

2023-01-14 17:31:26,408 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 551]
2023-01-14 17:31:26,408 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:31:26,460 - 

2023-01-14 17:31:26,460 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:31:29,520 - Epoch: [569][    6/    6]    Overall Loss 0.010748    Objective Loss 0.010748    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.509778    
2023-01-14 17:31:29,563 - --- validate (epoch=569)-----------
2023-01-14 17:31:29,564 - 148 samples (240 per mini-batch)
2023-01-14 17:31:30,049 - Epoch: [569][    1/    1]    Loss 0.355361    Top1 89.189189    Top5 99.324324    
2023-01-14 17:31:30,098 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.355

2023-01-14 17:31:30,110 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 551]
2023-01-14 17:31:30,110 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:31:30,160 - 

2023-01-14 17:31:30,160 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:31:33,062 - Epoch: [570][    6/    6]    Overall Loss 0.010851    Objective Loss 0.010851    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.483416    
2023-01-14 17:31:33,104 - --- validate (epoch=570)-----------
2023-01-14 17:31:33,105 - 148 samples (240 per mini-batch)
2023-01-14 17:31:33,703 - Epoch: [570][    1/    1]    Loss 0.380587    Top1 89.864865    Top5 99.324324    
2023-01-14 17:31:33,755 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.381

2023-01-14 17:31:33,770 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 551]
2023-01-14 17:31:33,771 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:31:33,816 - 

2023-01-14 17:31:33,816 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:31:37,065 - Epoch: [571][    6/    6]    Overall Loss 0.010808    Objective Loss 0.010808    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.541151    
2023-01-14 17:31:37,107 - --- validate (epoch=571)-----------
2023-01-14 17:31:37,108 - 148 samples (240 per mini-batch)
2023-01-14 17:31:37,594 - Epoch: [571][    1/    1]    Loss 0.360957    Top1 90.540541    Top5 99.324324    
2023-01-14 17:31:37,636 - ==> Top1: 90.541    Top5: 99.324    Loss: 0.361

2023-01-14 17:31:37,648 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 551]
2023-01-14 17:31:37,648 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:31:37,693 - 

2023-01-14 17:31:37,695 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:31:40,760 - Epoch: [572][    6/    6]    Overall Loss 0.011033    Objective Loss 0.011033    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.510489    
2023-01-14 17:31:40,818 - --- validate (epoch=572)-----------
2023-01-14 17:31:40,818 - 148 samples (240 per mini-batch)
2023-01-14 17:31:41,279 - Epoch: [572][    1/    1]    Loss 0.359936    Top1 89.864865    Top5 99.324324    
2023-01-14 17:31:41,326 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.360

2023-01-14 17:31:41,340 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 551]
2023-01-14 17:31:41,341 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:31:41,385 - 

2023-01-14 17:31:41,385 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:31:44,491 - Epoch: [573][    6/    6]    Overall Loss 0.010315    Objective Loss 0.010315    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.517467    
2023-01-14 17:31:44,536 - --- validate (epoch=573)-----------
2023-01-14 17:31:44,537 - 148 samples (240 per mini-batch)
2023-01-14 17:31:45,105 - Epoch: [573][    1/    1]    Loss 0.359045    Top1 89.864865    Top5 99.324324    
2023-01-14 17:31:45,152 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.359

2023-01-14 17:31:45,163 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 551]
2023-01-14 17:31:45,163 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:31:45,205 - 

2023-01-14 17:31:45,206 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:31:48,158 - Epoch: [574][    6/    6]    Overall Loss 0.010963    Objective Loss 0.010963    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.491625    
2023-01-14 17:31:48,202 - --- validate (epoch=574)-----------
2023-01-14 17:31:48,203 - 148 samples (240 per mini-batch)
2023-01-14 17:31:48,775 - Epoch: [574][    1/    1]    Loss 0.366744    Top1 89.864865    Top5 99.324324    
2023-01-14 17:31:48,821 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.367

2023-01-14 17:31:48,834 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 551]
2023-01-14 17:31:48,835 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:31:48,879 - 

2023-01-14 17:31:48,880 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:31:51,981 - Epoch: [575][    6/    6]    Overall Loss 0.010765    Objective Loss 0.010765    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.516542    
2023-01-14 17:31:52,029 - --- validate (epoch=575)-----------
2023-01-14 17:31:52,030 - 148 samples (240 per mini-batch)
2023-01-14 17:31:52,616 - Epoch: [575][    1/    1]    Loss 0.359610    Top1 89.189189    Top5 99.324324    
2023-01-14 17:31:52,660 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.360

2023-01-14 17:31:52,674 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 551]
2023-01-14 17:31:52,675 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:31:52,731 - 

2023-01-14 17:31:52,731 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:31:55,424 - Epoch: [576][    6/    6]    Overall Loss 0.011213    Objective Loss 0.011213    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.448530    
2023-01-14 17:31:55,471 - --- validate (epoch=576)-----------
2023-01-14 17:31:55,472 - 148 samples (240 per mini-batch)
2023-01-14 17:31:56,009 - Epoch: [576][    1/    1]    Loss 0.322830    Top1 90.540541    Top5 100.000000    
2023-01-14 17:31:56,049 - ==> Top1: 90.541    Top5: 100.000    Loss: 0.323

2023-01-14 17:31:56,066 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 551]
2023-01-14 17:31:56,066 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:31:56,110 - 

2023-01-14 17:31:56,110 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:31:59,189 - Epoch: [577][    6/    6]    Overall Loss 0.011570    Objective Loss 0.011570    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.512851    
2023-01-14 17:31:59,241 - --- validate (epoch=577)-----------
2023-01-14 17:31:59,242 - 148 samples (240 per mini-batch)
2023-01-14 17:31:59,824 - Epoch: [577][    1/    1]    Loss 0.359012    Top1 89.864865    Top5 100.000000    
2023-01-14 17:31:59,864 - ==> Top1: 89.865    Top5: 100.000    Loss: 0.359

2023-01-14 17:31:59,876 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 551]
2023-01-14 17:31:59,876 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:31:59,921 - 

2023-01-14 17:31:59,921 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:32:02,959 - Epoch: [578][    6/    6]    Overall Loss 0.011136    Objective Loss 0.011136    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.506059    
2023-01-14 17:32:03,029 - --- validate (epoch=578)-----------
2023-01-14 17:32:03,029 - 148 samples (240 per mini-batch)
2023-01-14 17:32:03,548 - Epoch: [578][    1/    1]    Loss 0.398331    Top1 89.189189    Top5 99.324324    
2023-01-14 17:32:03,597 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.398

2023-01-14 17:32:03,612 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 551]
2023-01-14 17:32:03,613 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:32:03,663 - 

2023-01-14 17:32:03,664 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:32:06,632 - Epoch: [579][    6/    6]    Overall Loss 0.010903    Objective Loss 0.010903    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.494209    
2023-01-14 17:32:06,678 - --- validate (epoch=579)-----------
2023-01-14 17:32:06,678 - 148 samples (240 per mini-batch)
2023-01-14 17:32:07,227 - Epoch: [579][    1/    1]    Loss 0.354484    Top1 89.189189    Top5 100.000000    
2023-01-14 17:32:07,280 - ==> Top1: 89.189    Top5: 100.000    Loss: 0.354

2023-01-14 17:32:07,295 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 551]
2023-01-14 17:32:07,296 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:32:07,695 - 

2023-01-14 17:32:07,696 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:32:10,935 - Epoch: [580][    6/    6]    Overall Loss 0.010995    Objective Loss 0.010995    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.539535    
2023-01-14 17:32:10,979 - --- validate (epoch=580)-----------
2023-01-14 17:32:10,980 - 148 samples (240 per mini-batch)
2023-01-14 17:32:11,563 - Epoch: [580][    1/    1]    Loss 0.328544    Top1 90.540541    Top5 100.000000    
2023-01-14 17:32:11,609 - ==> Top1: 90.541    Top5: 100.000    Loss: 0.329

2023-01-14 17:32:11,624 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 551]
2023-01-14 17:32:11,624 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:32:11,672 - 

2023-01-14 17:32:11,673 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:32:14,392 - Epoch: [581][    6/    6]    Overall Loss 0.011147    Objective Loss 0.011147    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.452915    
2023-01-14 17:32:14,454 - --- validate (epoch=581)-----------
2023-01-14 17:32:14,455 - 148 samples (240 per mini-batch)
2023-01-14 17:32:15,060 - Epoch: [581][    1/    1]    Loss 0.363890    Top1 89.864865    Top5 100.000000    
2023-01-14 17:32:15,107 - ==> Top1: 89.865    Top5: 100.000    Loss: 0.364

2023-01-14 17:32:15,117 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 551]
2023-01-14 17:32:15,117 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:32:15,154 - 

2023-01-14 17:32:15,154 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:32:17,915 - Epoch: [582][    6/    6]    Overall Loss 0.010902    Objective Loss 0.010902    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.459851    
2023-01-14 17:32:17,972 - --- validate (epoch=582)-----------
2023-01-14 17:32:17,972 - 148 samples (240 per mini-batch)
2023-01-14 17:32:18,590 - Epoch: [582][    1/    1]    Loss 0.355043    Top1 89.189189    Top5 99.324324    
2023-01-14 17:32:18,636 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.355

2023-01-14 17:32:18,644 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 551]
2023-01-14 17:32:18,644 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:32:18,674 - 

2023-01-14 17:32:18,675 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:32:21,422 - Epoch: [583][    6/    6]    Overall Loss 0.011283    Objective Loss 0.011283    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.457161    
2023-01-14 17:32:21,481 - --- validate (epoch=583)-----------
2023-01-14 17:32:21,481 - 148 samples (240 per mini-batch)
2023-01-14 17:32:21,982 - Epoch: [583][    1/    1]    Loss 0.364440    Top1 91.216216    Top5 100.000000    
2023-01-14 17:32:22,023 - ==> Top1: 91.216    Top5: 100.000    Loss: 0.364

2023-01-14 17:32:22,035 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 583]
2023-01-14 17:32:22,036 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:32:22,082 - 

2023-01-14 17:32:22,083 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:32:24,734 - Epoch: [584][    6/    6]    Overall Loss 0.011025    Objective Loss 0.011025    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.441619    
2023-01-14 17:32:24,781 - --- validate (epoch=584)-----------
2023-01-14 17:32:24,782 - 148 samples (240 per mini-batch)
2023-01-14 17:32:25,328 - Epoch: [584][    1/    1]    Loss 0.377188    Top1 89.189189    Top5 99.324324    
2023-01-14 17:32:25,370 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.377

2023-01-14 17:32:25,382 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 583]
2023-01-14 17:32:25,382 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:32:25,423 - 

2023-01-14 17:32:25,424 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:32:28,001 - Epoch: [585][    6/    6]    Overall Loss 0.010950    Objective Loss 0.010950    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.429329    
2023-01-14 17:32:28,045 - --- validate (epoch=585)-----------
2023-01-14 17:32:28,046 - 148 samples (240 per mini-batch)
2023-01-14 17:32:28,642 - Epoch: [585][    1/    1]    Loss 0.333813    Top1 90.540541    Top5 99.324324    
2023-01-14 17:32:28,685 - ==> Top1: 90.541    Top5: 99.324    Loss: 0.334

2023-01-14 17:32:28,696 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 583]
2023-01-14 17:32:28,696 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:32:28,746 - 

2023-01-14 17:32:28,746 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:32:31,616 - Epoch: [586][    6/    6]    Overall Loss 0.010795    Objective Loss 0.010795    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.478044    
2023-01-14 17:32:31,660 - --- validate (epoch=586)-----------
2023-01-14 17:32:31,661 - 148 samples (240 per mini-batch)
2023-01-14 17:32:32,198 - Epoch: [586][    1/    1]    Loss 0.352296    Top1 89.189189    Top5 99.324324    
2023-01-14 17:32:32,248 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.352

2023-01-14 17:32:32,266 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 583]
2023-01-14 17:32:32,266 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:32:32,317 - 

2023-01-14 17:32:32,318 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:32:34,983 - Epoch: [587][    6/    6]    Overall Loss 0.011209    Objective Loss 0.011209    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.443840    
2023-01-14 17:32:35,032 - --- validate (epoch=587)-----------
2023-01-14 17:32:35,032 - 148 samples (240 per mini-batch)
2023-01-14 17:32:35,551 - Epoch: [587][    1/    1]    Loss 0.375301    Top1 89.189189    Top5 99.324324    
2023-01-14 17:32:35,589 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.375

2023-01-14 17:32:35,602 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 583]
2023-01-14 17:32:35,603 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:32:35,689 - 

2023-01-14 17:32:35,690 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:32:38,817 - Epoch: [588][    6/    6]    Overall Loss 0.010594    Objective Loss 0.010594    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.520658    
2023-01-14 17:32:38,885 - --- validate (epoch=588)-----------
2023-01-14 17:32:38,885 - 148 samples (240 per mini-batch)
2023-01-14 17:32:39,542 - Epoch: [588][    1/    1]    Loss 0.361905    Top1 89.189189    Top5 99.324324    
2023-01-14 17:32:39,582 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.362

2023-01-14 17:32:39,592 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 583]
2023-01-14 17:32:39,592 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:32:39,640 - 

2023-01-14 17:32:39,641 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:32:42,672 - Epoch: [589][    6/    6]    Overall Loss 0.010622    Objective Loss 0.010622    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.504991    
2023-01-14 17:32:42,725 - --- validate (epoch=589)-----------
2023-01-14 17:32:42,726 - 148 samples (240 per mini-batch)
2023-01-14 17:32:43,247 - Epoch: [589][    1/    1]    Loss 0.342067    Top1 90.540541    Top5 99.324324    
2023-01-14 17:32:43,288 - ==> Top1: 90.541    Top5: 99.324    Loss: 0.342

2023-01-14 17:32:43,299 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 583]
2023-01-14 17:32:43,301 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:32:43,347 - 

2023-01-14 17:32:43,348 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:32:46,062 - Epoch: [590][    6/    6]    Overall Loss 0.010163    Objective Loss 0.010163    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.451923    
2023-01-14 17:32:46,118 - --- validate (epoch=590)-----------
2023-01-14 17:32:46,118 - 148 samples (240 per mini-batch)
2023-01-14 17:32:46,605 - Epoch: [590][    1/    1]    Loss 0.351084    Top1 89.864865    Top5 100.000000    
2023-01-14 17:32:46,645 - ==> Top1: 89.865    Top5: 100.000    Loss: 0.351

2023-01-14 17:32:46,657 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 583]
2023-01-14 17:32:46,657 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:32:46,705 - 

2023-01-14 17:32:46,705 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:32:49,237 - Epoch: [591][    6/    6]    Overall Loss 0.010632    Objective Loss 0.010632    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.421689    
2023-01-14 17:32:49,282 - --- validate (epoch=591)-----------
2023-01-14 17:32:49,283 - 148 samples (240 per mini-batch)
2023-01-14 17:32:49,793 - Epoch: [591][    1/    1]    Loss 0.353386    Top1 89.189189    Top5 99.324324    
2023-01-14 17:32:49,833 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.353

2023-01-14 17:32:49,848 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 583]
2023-01-14 17:32:49,849 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:32:49,900 - 

2023-01-14 17:32:49,901 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:32:52,614 - Epoch: [592][    6/    6]    Overall Loss 0.010666    Objective Loss 0.010666    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.452021    
2023-01-14 17:32:52,673 - --- validate (epoch=592)-----------
2023-01-14 17:32:52,674 - 148 samples (240 per mini-batch)
2023-01-14 17:32:53,276 - Epoch: [592][    1/    1]    Loss 0.352824    Top1 89.189189    Top5 99.324324    
2023-01-14 17:32:53,326 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.353

2023-01-14 17:32:53,336 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 583]
2023-01-14 17:32:53,337 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:32:53,379 - 

2023-01-14 17:32:53,380 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:32:56,561 - Epoch: [593][    6/    6]    Overall Loss 0.011201    Objective Loss 0.011201    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.529862    
2023-01-14 17:32:56,607 - --- validate (epoch=593)-----------
2023-01-14 17:32:56,608 - 148 samples (240 per mini-batch)
2023-01-14 17:32:57,146 - Epoch: [593][    1/    1]    Loss 0.339879    Top1 90.540541    Top5 99.324324    
2023-01-14 17:32:57,188 - ==> Top1: 90.541    Top5: 99.324    Loss: 0.340

2023-01-14 17:32:57,205 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 583]
2023-01-14 17:32:57,205 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:32:57,251 - 

2023-01-14 17:32:57,252 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:33:00,216 - Epoch: [594][    6/    6]    Overall Loss 0.010838    Objective Loss 0.010838    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.493779    
2023-01-14 17:33:00,262 - --- validate (epoch=594)-----------
2023-01-14 17:33:00,263 - 148 samples (240 per mini-batch)
2023-01-14 17:33:00,819 - Epoch: [594][    1/    1]    Loss 0.358183    Top1 88.513514    Top5 99.324324    
2023-01-14 17:33:00,864 - ==> Top1: 88.514    Top5: 99.324    Loss: 0.358

2023-01-14 17:33:00,877 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 583]
2023-01-14 17:33:00,878 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:33:00,920 - 

2023-01-14 17:33:00,921 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:33:03,802 - Epoch: [595][    6/    6]    Overall Loss 0.011062    Objective Loss 0.011062    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.479810    
2023-01-14 17:33:03,861 - --- validate (epoch=595)-----------
2023-01-14 17:33:03,862 - 148 samples (240 per mini-batch)
2023-01-14 17:33:04,355 - Epoch: [595][    1/    1]    Loss 0.379186    Top1 89.189189    Top5 100.000000    
2023-01-14 17:33:04,402 - ==> Top1: 89.189    Top5: 100.000    Loss: 0.379

2023-01-14 17:33:04,411 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 583]
2023-01-14 17:33:04,412 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:33:04,447 - 

2023-01-14 17:33:04,447 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:33:07,224 - Epoch: [596][    6/    6]    Overall Loss 0.010531    Objective Loss 0.010531    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.462615    
2023-01-14 17:33:07,268 - --- validate (epoch=596)-----------
2023-01-14 17:33:07,269 - 148 samples (240 per mini-batch)
2023-01-14 17:33:07,848 - Epoch: [596][    1/    1]    Loss 0.350256    Top1 89.189189    Top5 99.324324    
2023-01-14 17:33:07,890 - ==> Top1: 89.189    Top5: 99.324    Loss: 0.350

2023-01-14 17:33:07,901 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 583]
2023-01-14 17:33:07,903 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:33:07,944 - 

2023-01-14 17:33:07,945 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:33:10,544 - Epoch: [597][    6/    6]    Overall Loss 0.010799    Objective Loss 0.010799    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.432928    
2023-01-14 17:33:10,591 - --- validate (epoch=597)-----------
2023-01-14 17:33:10,592 - 148 samples (240 per mini-batch)
2023-01-14 17:33:11,061 - Epoch: [597][    1/    1]    Loss 0.333028    Top1 89.864865    Top5 99.324324    
2023-01-14 17:33:11,101 - ==> Top1: 89.865    Top5: 99.324    Loss: 0.333

2023-01-14 17:33:11,115 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 583]
2023-01-14 17:33:11,116 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:33:11,158 - 

2023-01-14 17:33:11,159 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:33:13,832 - Epoch: [598][    6/    6]    Overall Loss 0.010613    Objective Loss 0.010613    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.445359    
2023-01-14 17:33:13,885 - --- validate (epoch=598)-----------
2023-01-14 17:33:13,886 - 148 samples (240 per mini-batch)
2023-01-14 17:33:14,404 - Epoch: [598][    1/    1]    Loss 0.359394    Top1 89.864865    Top5 100.000000    
2023-01-14 17:33:14,472 - ==> Top1: 89.865    Top5: 100.000    Loss: 0.359

2023-01-14 17:33:14,481 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 583]
2023-01-14 17:33:14,481 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:33:14,525 - 

2023-01-14 17:33:14,526 - Training epoch: 1338 samples (240 per mini-batch)
2023-01-14 17:33:17,359 - Epoch: [599][    6/    6]    Overall Loss 0.010866    Objective Loss 0.010866    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.471978    
2023-01-14 17:33:17,406 - --- validate (epoch=599)-----------
2023-01-14 17:33:17,407 - 148 samples (240 per mini-batch)
2023-01-14 17:33:17,918 - Epoch: [599][    1/    1]    Loss 0.342860    Top1 89.864865    Top5 100.000000    
2023-01-14 17:33:17,970 - ==> Top1: 89.865    Top5: 100.000    Loss: 0.343

2023-01-14 17:33:17,979 - ==> Best [Top1: 91.216   Top5: 100.000   Sparsity:0.00   Params: 80608 on epoch: 583]
2023-01-14 17:33:17,979 - Saving checkpoint to: logs/2023.01.14-165720/qat_checkpoint.pth.tar
2023-01-14 17:33:18,020 - --- test ---------------------
2023-01-14 17:33:18,020 - 114 samples (240 per mini-batch)
2023-01-14 17:33:19,233 - Test: [    1/    1]    Loss 0.311681    Top1 90.350877    Top5 99.122807    
2023-01-14 17:33:19,276 - ==> Top1: 90.351    Top5: 99.123    Loss: 0.312

2023-01-14 17:33:19,279 - 
2023-01-14 17:33:19,279 - Log file for this run: /home/hehung/AI/ai8x-training/logs/2023.01.14-165720/2023.01.14-165720.log
