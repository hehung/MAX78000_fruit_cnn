2023-01-14 20:50:44,181 - Log file for this run: /home/hehung/AI/ai8x-training/logs/2023.01.14-205044/2023.01.14-205044.log
2023-01-14 20:51:01,979 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2023-01-14 20:51:01,990 - Optimizer Args: {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.001, 'amsgrad': False}
2023-01-14 20:51:02,097 - Dataset sizes:
	training=912
	validation=101
	test=80
2023-01-14 20:51:02,097 - Reading compression schedule from: policies/schedule-fruit.yaml
2023-01-14 20:51:02,110 - 

2023-01-14 20:51:02,111 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:51:10,335 - Epoch: [0][    4/    4]    Overall Loss 1.787003    Objective Loss 1.787003    Top1 31.018519    Top5 86.574074    LR 0.001000    Time 2.055273    
2023-01-14 20:51:10,392 - --- validate (epoch=0)-----------
2023-01-14 20:51:10,393 - 101 samples (240 per mini-batch)
2023-01-14 20:51:12,031 - Epoch: [0][    1/    1]    Loss 1.621121    Top1 29.702970    Top5 94.059406    
2023-01-14 20:51:12,077 - ==> Top1: 29.703    Top5: 94.059    Loss: 1.621

2023-01-14 20:51:12,099 - ==> Best [Top1: 29.703   Top5: 94.059   Sparsity:0.00   Params: 80096 on epoch: 0]
2023-01-14 20:51:12,102 - Saving checkpoint to: logs/2023.01.14-205044/checkpoint.pth.tar
2023-01-14 20:51:12,166 - 

2023-01-14 20:51:12,167 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:51:15,548 - Epoch: [1][    4/    4]    Overall Loss 1.568725    Objective Loss 1.568725    Top1 37.500000    Top5 93.055556    LR 0.001000    Time 0.844995    
2023-01-14 20:51:15,592 - --- validate (epoch=1)-----------
2023-01-14 20:51:15,593 - 101 samples (240 per mini-batch)
2023-01-14 20:51:17,767 - Epoch: [1][    1/    1]    Loss 1.461130    Top1 55.445545    Top5 94.059406    
2023-01-14 20:51:17,849 - ==> Top1: 55.446    Top5: 94.059    Loss: 1.461

2023-01-14 20:51:17,862 - ==> Best [Top1: 55.446   Top5: 94.059   Sparsity:0.00   Params: 80096 on epoch: 1]
2023-01-14 20:51:17,862 - Saving checkpoint to: logs/2023.01.14-205044/checkpoint.pth.tar
2023-01-14 20:51:17,991 - 

2023-01-14 20:51:17,992 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:51:19,779 - Epoch: [2][    4/    4]    Overall Loss 1.423562    Objective Loss 1.423562    Top1 57.407407    Top5 91.898148    LR 0.001000    Time 0.446387    
2023-01-14 20:51:19,853 - --- validate (epoch=2)-----------
2023-01-14 20:51:19,854 - 101 samples (240 per mini-batch)
2023-01-14 20:51:21,303 - Epoch: [2][    1/    1]    Loss 1.330740    Top1 56.435644    Top5 94.059406    
2023-01-14 20:51:21,343 - ==> Top1: 56.436    Top5: 94.059    Loss: 1.331

2023-01-14 20:51:21,354 - ==> Best [Top1: 56.436   Top5: 94.059   Sparsity:0.00   Params: 80096 on epoch: 2]
2023-01-14 20:51:21,354 - Saving checkpoint to: logs/2023.01.14-205044/checkpoint.pth.tar
2023-01-14 20:51:21,404 - 

2023-01-14 20:51:21,404 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:51:23,065 - Epoch: [3][    4/    4]    Overall Loss 1.286803    Objective Loss 1.286803    Top1 66.666667    Top5 92.824074    LR 0.001000    Time 0.414937    
2023-01-14 20:51:23,112 - --- validate (epoch=3)-----------
2023-01-14 20:51:23,113 - 101 samples (240 per mini-batch)
2023-01-14 20:51:24,260 - Epoch: [3][    1/    1]    Loss 1.225755    Top1 71.287129    Top5 94.059406    
2023-01-14 20:51:24,305 - ==> Top1: 71.287    Top5: 94.059    Loss: 1.226

2023-01-14 20:51:24,317 - ==> Best [Top1: 71.287   Top5: 94.059   Sparsity:0.00   Params: 80096 on epoch: 3]
2023-01-14 20:51:24,317 - Saving checkpoint to: logs/2023.01.14-205044/checkpoint.pth.tar
2023-01-14 20:51:24,382 - 

2023-01-14 20:51:24,383 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:51:26,014 - Epoch: [4][    4/    4]    Overall Loss 1.171524    Objective Loss 1.171524    Top1 70.370370    Top5 93.981481    LR 0.001000    Time 0.407535    
2023-01-14 20:51:26,057 - --- validate (epoch=4)-----------
2023-01-14 20:51:26,057 - 101 samples (240 per mini-batch)
2023-01-14 20:51:27,199 - Epoch: [4][    1/    1]    Loss 1.087198    Top1 76.237624    Top5 96.039604    
2023-01-14 20:51:27,240 - ==> Top1: 76.238    Top5: 96.040    Loss: 1.087

2023-01-14 20:51:27,252 - ==> Best [Top1: 76.238   Top5: 96.040   Sparsity:0.00   Params: 80096 on epoch: 4]
2023-01-14 20:51:27,252 - Saving checkpoint to: logs/2023.01.14-205044/checkpoint.pth.tar
2023-01-14 20:51:27,302 - 

2023-01-14 20:51:27,303 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:51:29,607 - Epoch: [5][    4/    4]    Overall Loss 1.067663    Objective Loss 1.067663    Top1 77.083333    Top5 96.064815    LR 0.001000    Time 0.575762    
2023-01-14 20:51:29,652 - --- validate (epoch=5)-----------
2023-01-14 20:51:29,653 - 101 samples (240 per mini-batch)
2023-01-14 20:51:30,683 - Epoch: [5][    1/    1]    Loss 1.000136    Top1 82.178218    Top5 98.019802    
2023-01-14 20:51:30,722 - ==> Top1: 82.178    Top5: 98.020    Loss: 1.000

2023-01-14 20:51:30,730 - ==> Best [Top1: 82.178   Top5: 98.020   Sparsity:0.00   Params: 80096 on epoch: 5]
2023-01-14 20:51:30,730 - Saving checkpoint to: logs/2023.01.14-205044/checkpoint.pth.tar
2023-01-14 20:51:30,854 - 

2023-01-14 20:51:30,854 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:51:32,790 - Epoch: [6][    4/    4]    Overall Loss 0.965747    Objective Loss 0.965747    Top1 80.787037    Top5 96.064815    LR 0.001000    Time 0.483684    
2023-01-14 20:51:32,847 - --- validate (epoch=6)-----------
2023-01-14 20:51:32,848 - 101 samples (240 per mini-batch)
2023-01-14 20:51:34,004 - Epoch: [6][    1/    1]    Loss 0.888338    Top1 80.198020    Top5 98.019802    
2023-01-14 20:51:34,052 - ==> Top1: 80.198    Top5: 98.020    Loss: 0.888

2023-01-14 20:51:34,061 - ==> Best [Top1: 82.178   Top5: 98.020   Sparsity:0.00   Params: 80096 on epoch: 5]
2023-01-14 20:51:34,061 - Saving checkpoint to: logs/2023.01.14-205044/checkpoint.pth.tar
2023-01-14 20:51:34,125 - 

2023-01-14 20:51:34,126 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:51:35,905 - Epoch: [7][    4/    4]    Overall Loss 0.864887    Objective Loss 0.864887    Top1 82.638889    Top5 97.916667    LR 0.001000    Time 0.444448    
2023-01-14 20:51:35,953 - --- validate (epoch=7)-----------
2023-01-14 20:51:35,953 - 101 samples (240 per mini-batch)
2023-01-14 20:51:37,024 - Epoch: [7][    1/    1]    Loss 0.797416    Top1 83.168317    Top5 98.019802    
2023-01-14 20:51:37,074 - ==> Top1: 83.168    Top5: 98.020    Loss: 0.797

2023-01-14 20:51:37,087 - ==> Best [Top1: 83.168   Top5: 98.020   Sparsity:0.00   Params: 80096 on epoch: 7]
2023-01-14 20:51:37,088 - Saving checkpoint to: logs/2023.01.14-205044/checkpoint.pth.tar
2023-01-14 20:51:37,153 - 

2023-01-14 20:51:37,154 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:51:39,380 - Epoch: [8][    4/    4]    Overall Loss 0.784054    Objective Loss 0.784054    Top1 83.796296    Top5 97.685185    LR 0.001000    Time 0.556096    
2023-01-14 20:51:39,425 - --- validate (epoch=8)-----------
2023-01-14 20:51:39,425 - 101 samples (240 per mini-batch)
2023-01-14 20:51:40,496 - Epoch: [8][    1/    1]    Loss 0.752191    Top1 85.148515    Top5 98.019802    
2023-01-14 20:51:40,538 - ==> Top1: 85.149    Top5: 98.020    Loss: 0.752

2023-01-14 20:51:40,555 - ==> Best [Top1: 85.149   Top5: 98.020   Sparsity:0.00   Params: 80096 on epoch: 8]
2023-01-14 20:51:40,556 - Saving checkpoint to: logs/2023.01.14-205044/checkpoint.pth.tar
2023-01-14 20:51:40,621 - 

2023-01-14 20:51:40,622 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:51:42,397 - Epoch: [9][    4/    4]    Overall Loss 0.716868    Objective Loss 0.716868    Top1 86.111111    Top5 99.537037    LR 0.001000    Time 0.443207    
2023-01-14 20:51:42,442 - --- validate (epoch=9)-----------
2023-01-14 20:51:42,443 - 101 samples (240 per mini-batch)
2023-01-14 20:51:43,615 - Epoch: [9][    1/    1]    Loss 0.672065    Top1 86.138614    Top5 100.000000    
2023-01-14 20:51:43,668 - ==> Top1: 86.139    Top5: 100.000    Loss: 0.672

2023-01-14 20:51:43,679 - ==> Best [Top1: 86.139   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 9]
2023-01-14 20:51:43,680 - Saving checkpoint to: logs/2023.01.14-205044/checkpoint.pth.tar
2023-01-14 20:51:43,840 - 

2023-01-14 20:51:43,840 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:51:46,154 - Epoch: [10][    4/    4]    Overall Loss 0.442883    Objective Loss 0.442883    Top1 87.500000    Top5 99.074074    LR 0.001000    Time 0.577913    
2023-01-14 20:51:46,199 - --- validate (epoch=10)-----------
2023-01-14 20:51:46,200 - 101 samples (240 per mini-batch)
2023-01-14 20:51:47,491 - Epoch: [10][    1/    1]    Loss 0.453125    Top1 86.138614    Top5 99.009901    
2023-01-14 20:51:47,531 - ==> Top1: 86.139    Top5: 99.010    Loss: 0.453

2023-01-14 20:51:47,540 - ==> Best [Top1: 86.139   Top5: 99.010   Sparsity:0.00   Params: 80096 on epoch: 10]
2023-01-14 20:51:47,540 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:51:47,588 - 

2023-01-14 20:51:47,588 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:51:49,470 - Epoch: [11][    4/    4]    Overall Loss 0.372154    Objective Loss 0.372154    Top1 85.185185    Top5 99.074074    LR 0.001000    Time 0.469832    
2023-01-14 20:51:49,513 - --- validate (epoch=11)-----------
2023-01-14 20:51:49,514 - 101 samples (240 per mini-batch)
2023-01-14 20:51:50,684 - Epoch: [11][    1/    1]    Loss 0.366310    Top1 89.108911    Top5 100.000000    
2023-01-14 20:51:50,727 - ==> Top1: 89.109    Top5: 100.000    Loss: 0.366

2023-01-14 20:51:50,735 - ==> Best [Top1: 89.109   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 11]
2023-01-14 20:51:50,735 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:51:50,783 - 

2023-01-14 20:51:50,784 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:51:52,662 - Epoch: [12][    4/    4]    Overall Loss 0.304816    Objective Loss 0.304816    Top1 89.814815    Top5 99.537037    LR 0.001000    Time 0.469343    
2023-01-14 20:51:52,722 - --- validate (epoch=12)-----------
2023-01-14 20:51:52,722 - 101 samples (240 per mini-batch)
2023-01-14 20:51:54,039 - Epoch: [12][    1/    1]    Loss 0.319524    Top1 90.099010    Top5 100.000000    
2023-01-14 20:51:54,088 - ==> Top1: 90.099    Top5: 100.000    Loss: 0.320

2023-01-14 20:51:54,097 - ==> Best [Top1: 90.099   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 12]
2023-01-14 20:51:54,098 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:51:54,153 - 

2023-01-14 20:51:54,154 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:51:56,413 - Epoch: [13][    4/    4]    Overall Loss 0.280900    Objective Loss 0.280900    Top1 88.888889    Top5 100.000000    LR 0.001000    Time 0.564491    
2023-01-14 20:51:56,473 - --- validate (epoch=13)-----------
2023-01-14 20:51:56,474 - 101 samples (240 per mini-batch)
2023-01-14 20:51:57,656 - Epoch: [13][    1/    1]    Loss 0.219266    Top1 92.079208    Top5 100.000000    
2023-01-14 20:51:57,700 - ==> Top1: 92.079    Top5: 100.000    Loss: 0.219

2023-01-14 20:51:57,710 - ==> Best [Top1: 92.079   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 13]
2023-01-14 20:51:57,711 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:51:57,758 - 

2023-01-14 20:51:57,758 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:51:59,680 - Epoch: [14][    4/    4]    Overall Loss 0.236427    Objective Loss 0.236427    Top1 91.203704    Top5 99.768519    LR 0.001000    Time 0.480099    
2023-01-14 20:51:59,726 - --- validate (epoch=14)-----------
2023-01-14 20:51:59,727 - 101 samples (240 per mini-batch)
2023-01-14 20:52:00,831 - Epoch: [14][    1/    1]    Loss 0.251750    Top1 93.069307    Top5 100.000000    
2023-01-14 20:52:00,871 - ==> Top1: 93.069    Top5: 100.000    Loss: 0.252

2023-01-14 20:52:00,888 - ==> Best [Top1: 93.069   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 14]
2023-01-14 20:52:00,888 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:52:00,953 - 

2023-01-14 20:52:00,954 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:52:02,957 - Epoch: [15][    4/    4]    Overall Loss 0.226978    Objective Loss 0.226978    Top1 92.129630    Top5 100.000000    LR 0.001000    Time 0.500421    
2023-01-14 20:52:03,028 - --- validate (epoch=15)-----------
2023-01-14 20:52:03,028 - 101 samples (240 per mini-batch)
2023-01-14 20:52:04,321 - Epoch: [15][    1/    1]    Loss 0.223209    Top1 90.099010    Top5 100.000000    
2023-01-14 20:52:04,373 - ==> Top1: 90.099    Top5: 100.000    Loss: 0.223

2023-01-14 20:52:04,387 - ==> Best [Top1: 93.069   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 14]
2023-01-14 20:52:04,388 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:52:04,455 - 

2023-01-14 20:52:04,456 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:52:06,934 - Epoch: [16][    4/    4]    Overall Loss 0.198954    Objective Loss 0.198954    Top1 93.750000    Top5 100.000000    LR 0.001000    Time 0.618993    
2023-01-14 20:52:06,977 - --- validate (epoch=16)-----------
2023-01-14 20:52:06,977 - 101 samples (240 per mini-batch)
2023-01-14 20:52:08,100 - Epoch: [16][    1/    1]    Loss 0.223295    Top1 93.069307    Top5 100.000000    
2023-01-14 20:52:08,145 - ==> Top1: 93.069    Top5: 100.000    Loss: 0.223

2023-01-14 20:52:08,155 - ==> Best [Top1: 93.069   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 16]
2023-01-14 20:52:08,155 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:52:08,215 - 

2023-01-14 20:52:08,215 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:52:10,071 - Epoch: [17][    4/    4]    Overall Loss 0.186135    Objective Loss 0.186135    Top1 91.435185    Top5 100.000000    LR 0.001000    Time 0.463608    
2023-01-14 20:52:10,116 - --- validate (epoch=17)-----------
2023-01-14 20:52:10,117 - 101 samples (240 per mini-batch)
2023-01-14 20:52:11,247 - Epoch: [17][    1/    1]    Loss 0.228618    Top1 93.069307    Top5 100.000000    
2023-01-14 20:52:11,280 - ==> Top1: 93.069    Top5: 100.000    Loss: 0.229

2023-01-14 20:52:11,294 - ==> Best [Top1: 93.069   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 17]
2023-01-14 20:52:11,295 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:52:11,349 - 

2023-01-14 20:52:11,349 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:52:13,140 - Epoch: [18][    4/    4]    Overall Loss 0.186136    Objective Loss 0.186136    Top1 95.138889    Top5 100.000000    LR 0.001000    Time 0.447224    
2023-01-14 20:52:13,214 - --- validate (epoch=18)-----------
2023-01-14 20:52:13,215 - 101 samples (240 per mini-batch)
2023-01-14 20:52:14,459 - Epoch: [18][    1/    1]    Loss 0.202316    Top1 93.069307    Top5 99.009901    
2023-01-14 20:52:14,530 - ==> Top1: 93.069    Top5: 99.010    Loss: 0.202

2023-01-14 20:52:14,540 - ==> Best [Top1: 93.069   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 17]
2023-01-14 20:52:14,541 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:52:14,585 - 

2023-01-14 20:52:14,586 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:52:16,656 - Epoch: [19][    4/    4]    Overall Loss 0.169638    Objective Loss 0.169638    Top1 94.675926    Top5 100.000000    LR 0.001000    Time 0.516895    
2023-01-14 20:52:16,715 - --- validate (epoch=19)-----------
2023-01-14 20:52:16,716 - 101 samples (240 per mini-batch)
2023-01-14 20:52:17,811 - Epoch: [19][    1/    1]    Loss 0.180549    Top1 93.069307    Top5 100.000000    
2023-01-14 20:52:17,860 - ==> Top1: 93.069    Top5: 100.000    Loss: 0.181

2023-01-14 20:52:17,871 - ==> Best [Top1: 93.069   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 19]
2023-01-14 20:52:17,872 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:52:17,930 - 

2023-01-14 20:52:17,930 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:52:19,941 - Epoch: [20][    4/    4]    Overall Loss 0.156909    Objective Loss 0.156909    Top1 94.444444    Top5 100.000000    LR 0.001000    Time 0.502408    
2023-01-14 20:52:19,984 - --- validate (epoch=20)-----------
2023-01-14 20:52:19,985 - 101 samples (240 per mini-batch)
2023-01-14 20:52:21,106 - Epoch: [20][    1/    1]    Loss 0.244787    Top1 93.069307    Top5 100.000000    
2023-01-14 20:52:21,147 - ==> Top1: 93.069    Top5: 100.000    Loss: 0.245

2023-01-14 20:52:21,159 - ==> Best [Top1: 93.069   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 20]
2023-01-14 20:52:21,159 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:52:21,207 - 

2023-01-14 20:52:21,208 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:52:23,167 - Epoch: [21][    4/    4]    Overall Loss 0.133603    Objective Loss 0.133603    Top1 96.064815    Top5 100.000000    LR 0.001000    Time 0.489382    
2023-01-14 20:52:23,252 - --- validate (epoch=21)-----------
2023-01-14 20:52:23,253 - 101 samples (240 per mini-batch)
2023-01-14 20:52:24,505 - Epoch: [21][    1/    1]    Loss 0.159959    Top1 97.029703    Top5 99.009901    
2023-01-14 20:52:24,561 - ==> Top1: 97.030    Top5: 99.010    Loss: 0.160

2023-01-14 20:52:24,572 - ==> Best [Top1: 97.030   Top5: 99.010   Sparsity:0.00   Params: 80096 on epoch: 21]
2023-01-14 20:52:24,573 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:52:24,636 - 

2023-01-14 20:52:24,637 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:52:26,704 - Epoch: [22][    4/    4]    Overall Loss 0.126834    Objective Loss 0.126834    Top1 95.833333    Top5 100.000000    LR 0.001000    Time 0.515898    
2023-01-14 20:52:26,754 - --- validate (epoch=22)-----------
2023-01-14 20:52:26,755 - 101 samples (240 per mini-batch)
2023-01-14 20:52:27,854 - Epoch: [22][    1/    1]    Loss 0.200698    Top1 93.069307    Top5 100.000000    
2023-01-14 20:52:27,904 - ==> Top1: 93.069    Top5: 100.000    Loss: 0.201

2023-01-14 20:52:27,933 - ==> Best [Top1: 97.030   Top5: 99.010   Sparsity:0.00   Params: 80096 on epoch: 21]
2023-01-14 20:52:27,934 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:52:28,034 - 

2023-01-14 20:52:28,035 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:52:30,194 - Epoch: [23][    4/    4]    Overall Loss 0.113589    Objective Loss 0.113589    Top1 96.990741    Top5 100.000000    LR 0.001000    Time 0.539443    
2023-01-14 20:52:30,251 - --- validate (epoch=23)-----------
2023-01-14 20:52:30,252 - 101 samples (240 per mini-batch)
2023-01-14 20:52:31,389 - Epoch: [23][    1/    1]    Loss 0.155920    Top1 95.049505    Top5 99.009901    
2023-01-14 20:52:31,434 - ==> Top1: 95.050    Top5: 99.010    Loss: 0.156

2023-01-14 20:52:31,443 - ==> Best [Top1: 97.030   Top5: 99.010   Sparsity:0.00   Params: 80096 on epoch: 21]
2023-01-14 20:52:31,443 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:52:31,491 - 

2023-01-14 20:52:31,491 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:52:33,676 - Epoch: [24][    4/    4]    Overall Loss 0.105910    Objective Loss 0.105910    Top1 96.990741    Top5 100.000000    LR 0.001000    Time 0.545814    
2023-01-14 20:52:33,716 - --- validate (epoch=24)-----------
2023-01-14 20:52:33,716 - 101 samples (240 per mini-batch)
2023-01-14 20:52:34,844 - Epoch: [24][    1/    1]    Loss 0.157095    Top1 94.059406    Top5 99.009901    
2023-01-14 20:52:34,882 - ==> Top1: 94.059    Top5: 99.010    Loss: 0.157

2023-01-14 20:52:34,896 - ==> Best [Top1: 97.030   Top5: 99.010   Sparsity:0.00   Params: 80096 on epoch: 21]
2023-01-14 20:52:34,898 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:52:34,966 - 

2023-01-14 20:52:34,966 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:52:37,565 - Epoch: [25][    4/    4]    Overall Loss 0.098237    Objective Loss 0.098237    Top1 97.222222    Top5 100.000000    LR 0.001000    Time 0.649557    
2023-01-14 20:52:37,615 - --- validate (epoch=25)-----------
2023-01-14 20:52:37,615 - 101 samples (240 per mini-batch)
2023-01-14 20:52:38,729 - Epoch: [25][    1/    1]    Loss 0.119580    Top1 96.039604    Top5 99.009901    
2023-01-14 20:52:38,775 - ==> Top1: 96.040    Top5: 99.010    Loss: 0.120

2023-01-14 20:52:38,786 - ==> Best [Top1: 97.030   Top5: 99.010   Sparsity:0.00   Params: 80096 on epoch: 21]
2023-01-14 20:52:38,786 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:52:38,849 - 

2023-01-14 20:52:38,849 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:52:41,038 - Epoch: [26][    4/    4]    Overall Loss 0.087677    Objective Loss 0.087677    Top1 96.990741    Top5 100.000000    LR 0.001000    Time 0.546827    
2023-01-14 20:52:41,096 - --- validate (epoch=26)-----------
2023-01-14 20:52:41,097 - 101 samples (240 per mini-batch)
2023-01-14 20:52:42,267 - Epoch: [26][    1/    1]    Loss 0.175898    Top1 94.059406    Top5 100.000000    
2023-01-14 20:52:42,306 - ==> Top1: 94.059    Top5: 100.000    Loss: 0.176

2023-01-14 20:52:42,317 - ==> Best [Top1: 97.030   Top5: 99.010   Sparsity:0.00   Params: 80096 on epoch: 21]
2023-01-14 20:52:42,318 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:52:42,369 - 

2023-01-14 20:52:42,369 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:52:44,594 - Epoch: [27][    4/    4]    Overall Loss 0.089791    Objective Loss 0.089791    Top1 98.379630    Top5 100.000000    LR 0.001000    Time 0.555746    
2023-01-14 20:52:44,635 - --- validate (epoch=27)-----------
2023-01-14 20:52:44,635 - 101 samples (240 per mini-batch)
2023-01-14 20:52:45,879 - Epoch: [27][    1/    1]    Loss 0.139245    Top1 95.049505    Top5 100.000000    
2023-01-14 20:52:45,919 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.139

2023-01-14 20:52:45,930 - ==> Best [Top1: 97.030   Top5: 99.010   Sparsity:0.00   Params: 80096 on epoch: 21]
2023-01-14 20:52:45,931 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:52:45,980 - 

2023-01-14 20:52:45,980 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:52:47,829 - Epoch: [28][    4/    4]    Overall Loss 0.077177    Objective Loss 0.077177    Top1 98.148148    Top5 100.000000    LR 0.001000    Time 0.461737    
2023-01-14 20:52:47,892 - --- validate (epoch=28)-----------
2023-01-14 20:52:47,893 - 101 samples (240 per mini-batch)
2023-01-14 20:52:49,115 - Epoch: [28][    1/    1]    Loss 0.162850    Top1 94.059406    Top5 99.009901    
2023-01-14 20:52:49,156 - ==> Top1: 94.059    Top5: 99.010    Loss: 0.163

2023-01-14 20:52:49,165 - ==> Best [Top1: 97.030   Top5: 99.010   Sparsity:0.00   Params: 80096 on epoch: 21]
2023-01-14 20:52:49,166 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:52:49,212 - 

2023-01-14 20:52:49,213 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:52:51,753 - Epoch: [29][    4/    4]    Overall Loss 0.091292    Objective Loss 0.091292    Top1 97.222222    Top5 100.000000    LR 0.001000    Time 0.634819    
2023-01-14 20:52:51,804 - --- validate (epoch=29)-----------
2023-01-14 20:52:51,805 - 101 samples (240 per mini-batch)
2023-01-14 20:52:52,975 - Epoch: [29][    1/    1]    Loss 0.123165    Top1 96.039604    Top5 100.000000    
2023-01-14 20:52:53,077 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.123

2023-01-14 20:52:53,088 - ==> Best [Top1: 97.030   Top5: 99.010   Sparsity:0.00   Params: 80096 on epoch: 21]
2023-01-14 20:52:53,088 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:52:53,143 - 

2023-01-14 20:52:53,144 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:52:55,508 - Epoch: [30][    4/    4]    Overall Loss 0.067065    Objective Loss 0.067065    Top1 98.842593    Top5 100.000000    LR 0.001000    Time 0.590782    
2023-01-14 20:52:55,576 - --- validate (epoch=30)-----------
2023-01-14 20:52:55,577 - 101 samples (240 per mini-batch)
2023-01-14 20:52:56,783 - Epoch: [30][    1/    1]    Loss 0.131447    Top1 95.049505    Top5 100.000000    
2023-01-14 20:52:56,849 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.131

2023-01-14 20:52:56,860 - ==> Best [Top1: 97.030   Top5: 99.010   Sparsity:0.00   Params: 80096 on epoch: 21]
2023-01-14 20:52:56,860 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:52:56,906 - 

2023-01-14 20:52:56,907 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:52:58,794 - Epoch: [31][    4/    4]    Overall Loss 0.062490    Objective Loss 0.062490    Top1 98.842593    Top5 100.000000    LR 0.001000    Time 0.471369    
2023-01-14 20:52:58,838 - --- validate (epoch=31)-----------
2023-01-14 20:52:58,839 - 101 samples (240 per mini-batch)
2023-01-14 20:52:59,925 - Epoch: [31][    1/    1]    Loss 0.152954    Top1 94.059406    Top5 100.000000    
2023-01-14 20:52:59,963 - ==> Top1: 94.059    Top5: 100.000    Loss: 0.153

2023-01-14 20:52:59,980 - ==> Best [Top1: 97.030   Top5: 99.010   Sparsity:0.00   Params: 80096 on epoch: 21]
2023-01-14 20:52:59,980 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:53:00,031 - 

2023-01-14 20:53:00,031 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:53:01,983 - Epoch: [32][    4/    4]    Overall Loss 0.065977    Objective Loss 0.065977    Top1 97.453704    Top5 100.000000    LR 0.001000    Time 0.487510    
2023-01-14 20:53:02,032 - --- validate (epoch=32)-----------
2023-01-14 20:53:02,033 - 101 samples (240 per mini-batch)
2023-01-14 20:53:03,310 - Epoch: [32][    1/    1]    Loss 0.129131    Top1 95.049505    Top5 100.000000    
2023-01-14 20:53:03,360 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.129

2023-01-14 20:53:03,370 - ==> Best [Top1: 97.030   Top5: 99.010   Sparsity:0.00   Params: 80096 on epoch: 21]
2023-01-14 20:53:03,370 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:53:03,443 - 

2023-01-14 20:53:03,443 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:53:05,546 - Epoch: [33][    4/    4]    Overall Loss 0.061964    Objective Loss 0.061964    Top1 98.148148    Top5 100.000000    LR 0.001000    Time 0.525111    
2023-01-14 20:53:05,594 - --- validate (epoch=33)-----------
2023-01-14 20:53:05,595 - 101 samples (240 per mini-batch)
2023-01-14 20:53:06,709 - Epoch: [33][    1/    1]    Loss 0.197827    Top1 93.069307    Top5 100.000000    
2023-01-14 20:53:06,759 - ==> Top1: 93.069    Top5: 100.000    Loss: 0.198

2023-01-14 20:53:06,767 - ==> Best [Top1: 97.030   Top5: 99.010   Sparsity:0.00   Params: 80096 on epoch: 21]
2023-01-14 20:53:06,768 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:53:06,847 - 

2023-01-14 20:53:06,848 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:53:08,857 - Epoch: [34][    4/    4]    Overall Loss 0.095557    Objective Loss 0.095557    Top1 97.222222    Top5 100.000000    LR 0.001000    Time 0.501812    
2023-01-14 20:53:08,902 - --- validate (epoch=34)-----------
2023-01-14 20:53:08,902 - 101 samples (240 per mini-batch)
2023-01-14 20:53:10,051 - Epoch: [34][    1/    1]    Loss 0.104357    Top1 96.039604    Top5 100.000000    
2023-01-14 20:53:10,098 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.104

2023-01-14 20:53:10,108 - ==> Best [Top1: 97.030   Top5: 99.010   Sparsity:0.00   Params: 80096 on epoch: 21]
2023-01-14 20:53:10,108 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:53:10,156 - 

2023-01-14 20:53:10,157 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:53:12,168 - Epoch: [35][    4/    4]    Overall Loss 0.099524    Objective Loss 0.099524    Top1 96.759259    Top5 100.000000    LR 0.001000    Time 0.502489    
2023-01-14 20:53:12,212 - --- validate (epoch=35)-----------
2023-01-14 20:53:12,213 - 101 samples (240 per mini-batch)
2023-01-14 20:53:13,399 - Epoch: [35][    1/    1]    Loss 0.157680    Top1 96.039604    Top5 100.000000    
2023-01-14 20:53:13,479 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.158

2023-01-14 20:53:13,488 - ==> Best [Top1: 97.030   Top5: 99.010   Sparsity:0.00   Params: 80096 on epoch: 21]
2023-01-14 20:53:13,489 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:53:13,550 - 

2023-01-14 20:53:13,551 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:53:16,024 - Epoch: [36][    4/    4]    Overall Loss 0.088057    Objective Loss 0.088057    Top1 98.379630    Top5 100.000000    LR 0.001000    Time 0.617897    
2023-01-14 20:53:16,062 - --- validate (epoch=36)-----------
2023-01-14 20:53:16,063 - 101 samples (240 per mini-batch)
2023-01-14 20:53:17,245 - Epoch: [36][    1/    1]    Loss 0.155119    Top1 95.049505    Top5 100.000000    
2023-01-14 20:53:17,296 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.155

2023-01-14 20:53:17,307 - ==> Best [Top1: 97.030   Top5: 99.010   Sparsity:0.00   Params: 80096 on epoch: 21]
2023-01-14 20:53:17,308 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:53:17,353 - 

2023-01-14 20:53:17,353 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:53:19,551 - Epoch: [37][    4/    4]    Overall Loss 0.083404    Objective Loss 0.083404    Top1 98.379630    Top5 100.000000    LR 0.001000    Time 0.549164    
2023-01-14 20:53:19,601 - --- validate (epoch=37)-----------
2023-01-14 20:53:19,602 - 101 samples (240 per mini-batch)
2023-01-14 20:53:20,771 - Epoch: [37][    1/    1]    Loss 0.177491    Top1 95.049505    Top5 100.000000    
2023-01-14 20:53:20,815 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.177

2023-01-14 20:53:20,823 - ==> Best [Top1: 97.030   Top5: 99.010   Sparsity:0.00   Params: 80096 on epoch: 21]
2023-01-14 20:53:20,823 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:53:21,928 - 

2023-01-14 20:53:21,929 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:53:23,634 - Epoch: [38][    4/    4]    Overall Loss 0.074308    Objective Loss 0.074308    Top1 98.379630    Top5 100.000000    LR 0.001000    Time 0.425708    
2023-01-14 20:53:23,681 - --- validate (epoch=38)-----------
2023-01-14 20:53:23,682 - 101 samples (240 per mini-batch)
2023-01-14 20:53:24,780 - Epoch: [38][    1/    1]    Loss 0.115959    Top1 97.029703    Top5 100.000000    
2023-01-14 20:53:24,826 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.116

2023-01-14 20:53:24,835 - ==> Best [Top1: 97.030   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 38]
2023-01-14 20:53:24,835 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:53:24,891 - 

2023-01-14 20:53:24,892 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:53:26,920 - Epoch: [39][    4/    4]    Overall Loss 0.065256    Objective Loss 0.065256    Top1 98.842593    Top5 100.000000    LR 0.001000    Time 0.506668    
2023-01-14 20:53:26,991 - --- validate (epoch=39)-----------
2023-01-14 20:53:26,992 - 101 samples (240 per mini-batch)
2023-01-14 20:53:28,124 - Epoch: [39][    1/    1]    Loss 0.134334    Top1 95.049505    Top5 100.000000    
2023-01-14 20:53:28,164 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.134

2023-01-14 20:53:28,172 - ==> Best [Top1: 97.030   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 38]
2023-01-14 20:53:28,173 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:53:28,219 - 

2023-01-14 20:53:28,220 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:53:30,135 - Epoch: [40][    4/    4]    Overall Loss 0.055184    Objective Loss 0.055184    Top1 98.379630    Top5 100.000000    LR 0.001000    Time 0.478040    
2023-01-14 20:53:30,172 - --- validate (epoch=40)-----------
2023-01-14 20:53:30,173 - 101 samples (240 per mini-batch)
2023-01-14 20:53:31,385 - Epoch: [40][    1/    1]    Loss 0.120286    Top1 95.049505    Top5 100.000000    
2023-01-14 20:53:31,434 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.120

2023-01-14 20:53:31,444 - ==> Best [Top1: 97.030   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 38]
2023-01-14 20:53:31,445 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:53:31,496 - 

2023-01-14 20:53:31,496 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:53:33,480 - Epoch: [41][    4/    4]    Overall Loss 0.044370    Objective Loss 0.044370    Top1 99.537037    Top5 100.000000    LR 0.001000    Time 0.495629    
2023-01-14 20:53:33,533 - --- validate (epoch=41)-----------
2023-01-14 20:53:33,534 - 101 samples (240 per mini-batch)
2023-01-14 20:53:34,660 - Epoch: [41][    1/    1]    Loss 0.108415    Top1 96.039604    Top5 100.000000    
2023-01-14 20:53:34,706 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.108

2023-01-14 20:53:34,713 - ==> Best [Top1: 97.030   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 38]
2023-01-14 20:53:34,714 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:53:34,759 - 

2023-01-14 20:53:34,760 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:53:36,722 - Epoch: [42][    4/    4]    Overall Loss 0.041337    Objective Loss 0.041337    Top1 99.074074    Top5 100.000000    LR 0.001000    Time 0.490242    
2023-01-14 20:53:36,773 - --- validate (epoch=42)-----------
2023-01-14 20:53:36,773 - 101 samples (240 per mini-batch)
2023-01-14 20:53:38,018 - Epoch: [42][    1/    1]    Loss 0.113989    Top1 97.029703    Top5 100.000000    
2023-01-14 20:53:38,073 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.114

2023-01-14 20:53:38,083 - ==> Best [Top1: 97.030   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 42]
2023-01-14 20:53:38,084 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:53:38,126 - 

2023-01-14 20:53:38,126 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:53:40,322 - Epoch: [43][    4/    4]    Overall Loss 0.035531    Objective Loss 0.035531    Top1 99.768519    Top5 100.000000    LR 0.001000    Time 0.548752    
2023-01-14 20:53:40,375 - --- validate (epoch=43)-----------
2023-01-14 20:53:40,375 - 101 samples (240 per mini-batch)
2023-01-14 20:53:41,526 - Epoch: [43][    1/    1]    Loss 0.119298    Top1 96.039604    Top5 100.000000    
2023-01-14 20:53:41,567 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.119

2023-01-14 20:53:41,575 - ==> Best [Top1: 97.030   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 42]
2023-01-14 20:53:41,576 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:53:41,624 - 

2023-01-14 20:53:41,624 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:53:43,830 - Epoch: [44][    4/    4]    Overall Loss 0.030692    Objective Loss 0.030692    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.551127    
2023-01-14 20:53:43,877 - --- validate (epoch=44)-----------
2023-01-14 20:53:43,878 - 101 samples (240 per mini-batch)
2023-01-14 20:53:45,036 - Epoch: [44][    1/    1]    Loss 0.127872    Top1 96.039604    Top5 100.000000    
2023-01-14 20:53:45,076 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.128

2023-01-14 20:53:45,086 - ==> Best [Top1: 97.030   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 42]
2023-01-14 20:53:45,087 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:53:45,136 - 

2023-01-14 20:53:45,136 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:53:47,250 - Epoch: [45][    4/    4]    Overall Loss 0.026484    Objective Loss 0.026484    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.527960    
2023-01-14 20:53:47,291 - --- validate (epoch=45)-----------
2023-01-14 20:53:47,292 - 101 samples (240 per mini-batch)
2023-01-14 20:53:48,396 - Epoch: [45][    1/    1]    Loss 0.097634    Top1 96.039604    Top5 100.000000    
2023-01-14 20:53:48,442 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.098

2023-01-14 20:53:48,454 - ==> Best [Top1: 97.030   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 42]
2023-01-14 20:53:48,455 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:53:48,492 - 

2023-01-14 20:53:48,492 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:53:50,749 - Epoch: [46][    4/    4]    Overall Loss 0.023082    Objective Loss 0.023082    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.563738    
2023-01-14 20:53:50,790 - --- validate (epoch=46)-----------
2023-01-14 20:53:50,791 - 101 samples (240 per mini-batch)
2023-01-14 20:53:51,913 - Epoch: [46][    1/    1]    Loss 0.097347    Top1 95.049505    Top5 100.000000    
2023-01-14 20:53:51,961 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.097

2023-01-14 20:53:51,968 - ==> Best [Top1: 97.030   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 42]
2023-01-14 20:53:51,968 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:53:52,012 - 

2023-01-14 20:53:52,012 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:53:53,773 - Epoch: [47][    4/    4]    Overall Loss 0.022970    Objective Loss 0.022970    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.439898    
2023-01-14 20:53:53,822 - --- validate (epoch=47)-----------
2023-01-14 20:53:53,822 - 101 samples (240 per mini-batch)
2023-01-14 20:53:54,932 - Epoch: [47][    1/    1]    Loss 0.106990    Top1 96.039604    Top5 100.000000    
2023-01-14 20:53:54,990 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.107

2023-01-14 20:53:54,999 - ==> Best [Top1: 97.030   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 42]
2023-01-14 20:53:55,000 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:53:55,041 - 

2023-01-14 20:53:55,041 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:53:56,770 - Epoch: [48][    4/    4]    Overall Loss 0.022737    Objective Loss 0.022737    Top1 99.768519    Top5 100.000000    LR 0.001000    Time 0.431664    
2023-01-14 20:53:56,815 - --- validate (epoch=48)-----------
2023-01-14 20:53:56,816 - 101 samples (240 per mini-batch)
2023-01-14 20:53:58,041 - Epoch: [48][    1/    1]    Loss 0.105712    Top1 95.049505    Top5 100.000000    
2023-01-14 20:53:58,089 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.106

2023-01-14 20:53:58,099 - ==> Best [Top1: 97.030   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 42]
2023-01-14 20:53:58,100 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:53:58,143 - 

2023-01-14 20:53:58,143 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:54:00,622 - Epoch: [49][    4/    4]    Overall Loss 0.022589    Objective Loss 0.022589    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.619199    
2023-01-14 20:54:00,665 - --- validate (epoch=49)-----------
2023-01-14 20:54:00,666 - 101 samples (240 per mini-batch)
2023-01-14 20:54:01,802 - Epoch: [49][    1/    1]    Loss 0.119613    Top1 96.039604    Top5 100.000000    
2023-01-14 20:54:01,847 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.120

2023-01-14 20:54:01,856 - ==> Best [Top1: 97.030   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 42]
2023-01-14 20:54:01,857 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:54:01,968 - 

2023-01-14 20:54:01,968 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:54:03,802 - Epoch: [50][    4/    4]    Overall Loss 0.021419    Objective Loss 0.021419    Top1 99.768519    Top5 100.000000    LR 0.001000    Time 0.458001    
2023-01-14 20:54:03,845 - --- validate (epoch=50)-----------
2023-01-14 20:54:03,846 - 101 samples (240 per mini-batch)
2023-01-14 20:54:04,983 - Epoch: [50][    1/    1]    Loss 0.138595    Top1 96.039604    Top5 100.000000    
2023-01-14 20:54:05,031 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.139

2023-01-14 20:54:05,038 - ==> Best [Top1: 97.030   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 42]
2023-01-14 20:54:05,038 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:54:05,081 - 

2023-01-14 20:54:05,081 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:54:07,489 - Epoch: [51][    4/    4]    Overall Loss 0.019204    Objective Loss 0.019204    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.601531    
2023-01-14 20:54:07,533 - --- validate (epoch=51)-----------
2023-01-14 20:54:07,534 - 101 samples (240 per mini-batch)
2023-01-14 20:54:08,669 - Epoch: [51][    1/    1]    Loss 0.098927    Top1 96.039604    Top5 100.000000    
2023-01-14 20:54:08,720 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.099

2023-01-14 20:54:08,732 - ==> Best [Top1: 97.030   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 42]
2023-01-14 20:54:08,733 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:54:08,786 - 

2023-01-14 20:54:08,786 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:54:10,656 - Epoch: [52][    4/    4]    Overall Loss 0.019028    Objective Loss 0.019028    Top1 99.768519    Top5 100.000000    LR 0.001000    Time 0.467043    
2023-01-14 20:54:10,706 - --- validate (epoch=52)-----------
2023-01-14 20:54:10,706 - 101 samples (240 per mini-batch)
2023-01-14 20:54:11,854 - Epoch: [52][    1/    1]    Loss 0.094520    Top1 97.029703    Top5 100.000000    
2023-01-14 20:54:11,898 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.095

2023-01-14 20:54:11,909 - ==> Best [Top1: 97.030   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 52]
2023-01-14 20:54:11,910 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:54:11,961 - 

2023-01-14 20:54:11,961 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:54:14,044 - Epoch: [53][    4/    4]    Overall Loss 0.018251    Objective Loss 0.018251    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.520198    
2023-01-14 20:54:14,103 - --- validate (epoch=53)-----------
2023-01-14 20:54:14,104 - 101 samples (240 per mini-batch)
2023-01-14 20:54:15,354 - Epoch: [53][    1/    1]    Loss 0.103830    Top1 96.039604    Top5 100.000000    
2023-01-14 20:54:15,395 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.104

2023-01-14 20:54:15,405 - ==> Best [Top1: 97.030   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 52]
2023-01-14 20:54:15,405 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:54:15,452 - 

2023-01-14 20:54:15,452 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:54:17,229 - Epoch: [54][    4/    4]    Overall Loss 0.018491    Objective Loss 0.018491    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.443942    
2023-01-14 20:54:17,283 - --- validate (epoch=54)-----------
2023-01-14 20:54:17,284 - 101 samples (240 per mini-batch)
2023-01-14 20:54:18,377 - Epoch: [54][    1/    1]    Loss 0.105328    Top1 94.059406    Top5 100.000000    
2023-01-14 20:54:18,429 - ==> Top1: 94.059    Top5: 100.000    Loss: 0.105

2023-01-14 20:54:18,442 - ==> Best [Top1: 97.030   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 52]
2023-01-14 20:54:18,443 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:54:18,499 - 

2023-01-14 20:54:18,500 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:54:20,223 - Epoch: [55][    4/    4]    Overall Loss 0.018282    Objective Loss 0.018282    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.430385    
2023-01-14 20:54:20,266 - --- validate (epoch=55)-----------
2023-01-14 20:54:20,267 - 101 samples (240 per mini-batch)
2023-01-14 20:54:21,369 - Epoch: [55][    1/    1]    Loss 0.098966    Top1 97.029703    Top5 100.000000    
2023-01-14 20:54:21,413 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.099

2023-01-14 20:54:21,423 - ==> Best [Top1: 97.030   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 55]
2023-01-14 20:54:21,424 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:54:21,476 - 

2023-01-14 20:54:21,477 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:54:23,551 - Epoch: [56][    4/    4]    Overall Loss 0.016150    Objective Loss 0.016150    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.518199    
2023-01-14 20:54:23,626 - --- validate (epoch=56)-----------
2023-01-14 20:54:23,626 - 101 samples (240 per mini-batch)
2023-01-14 20:54:24,817 - Epoch: [56][    1/    1]    Loss 0.108400    Top1 96.039604    Top5 100.000000    
2023-01-14 20:54:24,860 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.108

2023-01-14 20:54:24,875 - ==> Best [Top1: 97.030   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 55]
2023-01-14 20:54:24,876 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:54:24,936 - 

2023-01-14 20:54:24,937 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:54:26,890 - Epoch: [57][    4/    4]    Overall Loss 0.015901    Objective Loss 0.015901    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.487946    
2023-01-14 20:54:26,936 - --- validate (epoch=57)-----------
2023-01-14 20:54:26,936 - 101 samples (240 per mini-batch)
2023-01-14 20:54:28,082 - Epoch: [57][    1/    1]    Loss 0.097972    Top1 96.039604    Top5 100.000000    
2023-01-14 20:54:28,122 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.098

2023-01-14 20:54:28,132 - ==> Best [Top1: 97.030   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 55]
2023-01-14 20:54:28,133 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:54:28,184 - 

2023-01-14 20:54:28,184 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:54:30,089 - Epoch: [58][    4/    4]    Overall Loss 0.015567    Objective Loss 0.015567    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.475822    
2023-01-14 20:54:30,131 - --- validate (epoch=58)-----------
2023-01-14 20:54:30,131 - 101 samples (240 per mini-batch)
2023-01-14 20:54:31,281 - Epoch: [58][    1/    1]    Loss 0.116465    Top1 96.039604    Top5 100.000000    
2023-01-14 20:54:31,321 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.116

2023-01-14 20:54:31,330 - ==> Best [Top1: 97.030   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 55]
2023-01-14 20:54:31,330 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:54:31,374 - 

2023-01-14 20:54:31,376 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:54:33,941 - Epoch: [59][    4/    4]    Overall Loss 0.015927    Objective Loss 0.015927    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.640993    
2023-01-14 20:54:33,998 - --- validate (epoch=59)-----------
2023-01-14 20:54:33,999 - 101 samples (240 per mini-batch)
2023-01-14 20:54:35,137 - Epoch: [59][    1/    1]    Loss 0.102686    Top1 97.029703    Top5 100.000000    
2023-01-14 20:54:35,182 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.103

2023-01-14 20:54:35,193 - ==> Best [Top1: 97.030   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 59]
2023-01-14 20:54:35,194 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:54:35,237 - 

2023-01-14 20:54:35,238 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:54:37,121 - Epoch: [60][    4/    4]    Overall Loss 0.013297    Objective Loss 0.013297    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.470485    
2023-01-14 20:54:37,164 - --- validate (epoch=60)-----------
2023-01-14 20:54:37,164 - 101 samples (240 per mini-batch)
2023-01-14 20:54:38,308 - Epoch: [60][    1/    1]    Loss 0.096309    Top1 97.029703    Top5 100.000000    
2023-01-14 20:54:38,357 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.096

2023-01-14 20:54:38,366 - ==> Best [Top1: 97.030   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 60]
2023-01-14 20:54:38,367 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:54:38,414 - 

2023-01-14 20:54:38,415 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:54:40,623 - Epoch: [61][    4/    4]    Overall Loss 0.013048    Objective Loss 0.013048    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.551769    
2023-01-14 20:54:40,669 - --- validate (epoch=61)-----------
2023-01-14 20:54:40,670 - 101 samples (240 per mini-batch)
2023-01-14 20:54:41,830 - Epoch: [61][    1/    1]    Loss 0.079115    Top1 96.039604    Top5 100.000000    
2023-01-14 20:54:41,878 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.079

2023-01-14 20:54:41,886 - ==> Best [Top1: 97.030   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 60]
2023-01-14 20:54:41,887 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:54:41,932 - 

2023-01-14 20:54:41,932 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:54:44,135 - Epoch: [62][    4/    4]    Overall Loss 0.013877    Objective Loss 0.013877    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.550401    
2023-01-14 20:54:44,180 - --- validate (epoch=62)-----------
2023-01-14 20:54:44,180 - 101 samples (240 per mini-batch)
2023-01-14 20:54:45,333 - Epoch: [62][    1/    1]    Loss 0.101537    Top1 97.029703    Top5 100.000000    
2023-01-14 20:54:45,385 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.102

2023-01-14 20:54:45,402 - ==> Best [Top1: 97.030   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 62]
2023-01-14 20:54:45,403 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:54:45,450 - 

2023-01-14 20:54:45,451 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:54:47,476 - Epoch: [63][    4/    4]    Overall Loss 0.013052    Objective Loss 0.013052    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.505644    
2023-01-14 20:54:47,528 - --- validate (epoch=63)-----------
2023-01-14 20:54:47,529 - 101 samples (240 per mini-batch)
2023-01-14 20:54:48,674 - Epoch: [63][    1/    1]    Loss 0.091886    Top1 95.049505    Top5 100.000000    
2023-01-14 20:54:48,717 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.092

2023-01-14 20:54:48,727 - ==> Best [Top1: 97.030   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 62]
2023-01-14 20:54:48,727 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:54:48,769 - 

2023-01-14 20:54:48,770 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:54:50,664 - Epoch: [64][    4/    4]    Overall Loss 0.013487    Objective Loss 0.013487    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.473162    
2023-01-14 20:54:50,703 - --- validate (epoch=64)-----------
2023-01-14 20:54:50,703 - 101 samples (240 per mini-batch)
2023-01-14 20:54:51,792 - Epoch: [64][    1/    1]    Loss 0.094330    Top1 97.029703    Top5 100.000000    
2023-01-14 20:54:51,837 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.094

2023-01-14 20:54:51,849 - ==> Best [Top1: 97.030   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 64]
2023-01-14 20:54:51,852 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:54:51,907 - 

2023-01-14 20:54:51,907 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:54:53,842 - Epoch: [65][    4/    4]    Overall Loss 0.011584    Objective Loss 0.011584    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.483257    
2023-01-14 20:54:53,889 - --- validate (epoch=65)-----------
2023-01-14 20:54:53,889 - 101 samples (240 per mini-batch)
2023-01-14 20:54:55,046 - Epoch: [65][    1/    1]    Loss 0.105025    Top1 96.039604    Top5 100.000000    
2023-01-14 20:54:55,085 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.105

2023-01-14 20:54:55,092 - ==> Best [Top1: 97.030   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 64]
2023-01-14 20:54:55,092 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:54:55,141 - 

2023-01-14 20:54:55,141 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:54:57,041 - Epoch: [66][    4/    4]    Overall Loss 0.011032    Objective Loss 0.011032    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.474457    
2023-01-14 20:54:57,081 - --- validate (epoch=66)-----------
2023-01-14 20:54:57,082 - 101 samples (240 per mini-batch)
2023-01-14 20:54:58,186 - Epoch: [66][    1/    1]    Loss 0.090523    Top1 96.039604    Top5 100.000000    
2023-01-14 20:54:58,234 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.091

2023-01-14 20:54:58,244 - ==> Best [Top1: 97.030   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 64]
2023-01-14 20:54:58,245 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:54:58,288 - 

2023-01-14 20:54:58,289 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:55:00,192 - Epoch: [67][    4/    4]    Overall Loss 0.011617    Objective Loss 0.011617    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.475473    
2023-01-14 20:55:00,237 - --- validate (epoch=67)-----------
2023-01-14 20:55:00,238 - 101 samples (240 per mini-batch)
2023-01-14 20:55:01,393 - Epoch: [67][    1/    1]    Loss 0.126411    Top1 95.049505    Top5 100.000000    
2023-01-14 20:55:01,435 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.126

2023-01-14 20:55:01,444 - ==> Best [Top1: 97.030   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 64]
2023-01-14 20:55:01,444 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:55:01,484 - 

2023-01-14 20:55:01,485 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:55:03,886 - Epoch: [68][    4/    4]    Overall Loss 0.011657    Objective Loss 0.011657    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.599965    
2023-01-14 20:55:03,935 - --- validate (epoch=68)-----------
2023-01-14 20:55:03,936 - 101 samples (240 per mini-batch)
2023-01-14 20:55:05,078 - Epoch: [68][    1/    1]    Loss 0.105632    Top1 96.039604    Top5 100.000000    
2023-01-14 20:55:05,122 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.106

2023-01-14 20:55:05,132 - ==> Best [Top1: 97.030   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 64]
2023-01-14 20:55:05,133 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:55:05,173 - 

2023-01-14 20:55:05,173 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:55:07,214 - Epoch: [69][    4/    4]    Overall Loss 0.010683    Objective Loss 0.010683    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.509855    
2023-01-14 20:55:07,253 - --- validate (epoch=69)-----------
2023-01-14 20:55:07,254 - 101 samples (240 per mini-batch)
2023-01-14 20:55:08,276 - Epoch: [69][    1/    1]    Loss 0.094560    Top1 97.029703    Top5 100.000000    
2023-01-14 20:55:08,315 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.095

2023-01-14 20:55:08,323 - ==> Best [Top1: 97.030   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 69]
2023-01-14 20:55:08,323 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:55:08,371 - 

2023-01-14 20:55:08,372 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:55:10,271 - Epoch: [70][    4/    4]    Overall Loss 0.010818    Objective Loss 0.010818    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.474586    
2023-01-14 20:55:10,316 - --- validate (epoch=70)-----------
2023-01-14 20:55:10,317 - 101 samples (240 per mini-batch)
2023-01-14 20:55:11,452 - Epoch: [70][    1/    1]    Loss 0.109972    Top1 95.049505    Top5 100.000000    
2023-01-14 20:55:11,498 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.110

2023-01-14 20:55:11,507 - ==> Best [Top1: 97.030   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 69]
2023-01-14 20:55:11,508 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:55:11,564 - 

2023-01-14 20:55:11,565 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:55:13,087 - Epoch: [71][    4/    4]    Overall Loss 0.009926    Objective Loss 0.009926    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.380121    
2023-01-14 20:55:13,130 - --- validate (epoch=71)-----------
2023-01-14 20:55:13,131 - 101 samples (240 per mini-batch)
2023-01-14 20:55:14,286 - Epoch: [71][    1/    1]    Loss 0.106271    Top1 97.029703    Top5 100.000000    
2023-01-14 20:55:14,321 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.106

2023-01-14 20:55:14,331 - ==> Best [Top1: 97.030   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 71]
2023-01-14 20:55:14,331 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:55:14,380 - 

2023-01-14 20:55:14,381 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:55:16,157 - Epoch: [72][    4/    4]    Overall Loss 0.010566    Objective Loss 0.010566    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.443757    
2023-01-14 20:55:16,202 - --- validate (epoch=72)-----------
2023-01-14 20:55:16,203 - 101 samples (240 per mini-batch)
2023-01-14 20:55:17,321 - Epoch: [72][    1/    1]    Loss 0.092542    Top1 97.029703    Top5 100.000000    
2023-01-14 20:55:17,367 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.093

2023-01-14 20:55:17,375 - ==> Best [Top1: 97.030   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 72]
2023-01-14 20:55:17,376 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:55:17,418 - 

2023-01-14 20:55:17,418 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:55:19,940 - Epoch: [73][    4/    4]    Overall Loss 0.010494    Objective Loss 0.010494    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.630091    
2023-01-14 20:55:19,978 - --- validate (epoch=73)-----------
2023-01-14 20:55:19,979 - 101 samples (240 per mini-batch)
2023-01-14 20:55:21,119 - Epoch: [73][    1/    1]    Loss 0.106092    Top1 96.039604    Top5 100.000000    
2023-01-14 20:55:21,158 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.106

2023-01-14 20:55:21,169 - ==> Best [Top1: 97.030   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 72]
2023-01-14 20:55:21,170 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:55:21,214 - 

2023-01-14 20:55:21,214 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:55:22,745 - Epoch: [74][    4/    4]    Overall Loss 0.009556    Objective Loss 0.009556    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.382157    
2023-01-14 20:55:22,798 - --- validate (epoch=74)-----------
2023-01-14 20:55:22,798 - 101 samples (240 per mini-batch)
2023-01-14 20:55:24,008 - Epoch: [74][    1/    1]    Loss 0.076925    Top1 98.019802    Top5 100.000000    
2023-01-14 20:55:24,066 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.077

2023-01-14 20:55:24,079 - ==> Best [Top1: 98.020   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 74]
2023-01-14 20:55:24,080 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:55:24,130 - 

2023-01-14 20:55:24,130 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:55:26,475 - Epoch: [75][    4/    4]    Overall Loss 0.009954    Objective Loss 0.009954    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.585876    
2023-01-14 20:55:26,522 - --- validate (epoch=75)-----------
2023-01-14 20:55:26,522 - 101 samples (240 per mini-batch)
2023-01-14 20:55:27,637 - Epoch: [75][    1/    1]    Loss 0.112327    Top1 96.039604    Top5 100.000000    
2023-01-14 20:55:27,672 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.112

2023-01-14 20:55:27,683 - ==> Best [Top1: 98.020   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 74]
2023-01-14 20:55:27,684 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:55:27,726 - 

2023-01-14 20:55:27,727 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:55:30,157 - Epoch: [76][    4/    4]    Overall Loss 0.010683    Objective Loss 0.010683    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.607332    
2023-01-14 20:55:30,196 - --- validate (epoch=76)-----------
2023-01-14 20:55:30,197 - 101 samples (240 per mini-batch)
2023-01-14 20:55:31,349 - Epoch: [76][    1/    1]    Loss 0.109137    Top1 95.049505    Top5 100.000000    
2023-01-14 20:55:31,391 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.109

2023-01-14 20:55:31,402 - ==> Best [Top1: 98.020   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 74]
2023-01-14 20:55:31,402 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:55:31,461 - 

2023-01-14 20:55:31,462 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:55:33,579 - Epoch: [77][    4/    4]    Overall Loss 0.009994    Objective Loss 0.009994    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.528464    
2023-01-14 20:55:33,639 - --- validate (epoch=77)-----------
2023-01-14 20:55:33,639 - 101 samples (240 per mini-batch)
2023-01-14 20:55:34,845 - Epoch: [77][    1/    1]    Loss 0.099984    Top1 97.029703    Top5 100.000000    
2023-01-14 20:55:34,897 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.100

2023-01-14 20:55:34,905 - ==> Best [Top1: 98.020   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 74]
2023-01-14 20:55:34,905 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:55:34,941 - 

2023-01-14 20:55:34,942 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:55:36,930 - Epoch: [78][    4/    4]    Overall Loss 0.009272    Objective Loss 0.009272    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.496645    
2023-01-14 20:55:36,968 - --- validate (epoch=78)-----------
2023-01-14 20:55:36,968 - 101 samples (240 per mini-batch)
2023-01-14 20:55:38,007 - Epoch: [78][    1/    1]    Loss 0.083474    Top1 97.029703    Top5 100.000000    
2023-01-14 20:55:38,054 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.083

2023-01-14 20:55:38,067 - ==> Best [Top1: 98.020   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 74]
2023-01-14 20:55:38,067 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:55:38,110 - 

2023-01-14 20:55:38,111 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:55:39,750 - Epoch: [79][    4/    4]    Overall Loss 0.008740    Objective Loss 0.008740    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.409393    
2023-01-14 20:55:39,792 - --- validate (epoch=79)-----------
2023-01-14 20:55:39,793 - 101 samples (240 per mini-batch)
2023-01-14 20:55:40,845 - Epoch: [79][    1/    1]    Loss 0.075434    Top1 97.029703    Top5 100.000000    
2023-01-14 20:55:40,897 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.075

2023-01-14 20:55:40,920 - ==> Best [Top1: 98.020   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 74]
2023-01-14 20:55:40,921 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:55:40,984 - 

2023-01-14 20:55:40,984 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:55:43,072 - Epoch: [80][    4/    4]    Overall Loss 0.008685    Objective Loss 0.008685    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.521595    
2023-01-14 20:55:43,113 - --- validate (epoch=80)-----------
2023-01-14 20:55:43,113 - 101 samples (240 per mini-batch)
2023-01-14 20:55:44,273 - Epoch: [80][    1/    1]    Loss 0.106437    Top1 97.029703    Top5 100.000000    
2023-01-14 20:55:44,311 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.106

2023-01-14 20:55:44,320 - ==> Best [Top1: 98.020   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 74]
2023-01-14 20:55:44,320 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:55:44,369 - 

2023-01-14 20:55:44,369 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:55:45,919 - Epoch: [81][    4/    4]    Overall Loss 0.008251    Objective Loss 0.008251    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.386958    
2023-01-14 20:55:45,966 - --- validate (epoch=81)-----------
2023-01-14 20:55:45,967 - 101 samples (240 per mini-batch)
2023-01-14 20:55:47,085 - Epoch: [81][    1/    1]    Loss 0.095989    Top1 97.029703    Top5 100.000000    
2023-01-14 20:55:47,123 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.096

2023-01-14 20:55:47,132 - ==> Best [Top1: 98.020   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 74]
2023-01-14 20:55:47,133 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:55:47,173 - 

2023-01-14 20:55:47,175 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:55:48,650 - Epoch: [82][    4/    4]    Overall Loss 0.008366    Objective Loss 0.008366    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.368060    
2023-01-14 20:55:48,684 - --- validate (epoch=82)-----------
2023-01-14 20:55:48,686 - 101 samples (240 per mini-batch)
2023-01-14 20:55:49,760 - Epoch: [82][    1/    1]    Loss 0.101357    Top1 98.019802    Top5 100.000000    
2023-01-14 20:55:49,799 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.101

2023-01-14 20:55:49,813 - ==> Best [Top1: 98.020   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 82]
2023-01-14 20:55:49,813 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:55:49,852 - 

2023-01-14 20:55:49,852 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:55:51,638 - Epoch: [83][    4/    4]    Overall Loss 0.008267    Objective Loss 0.008267    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.446039    
2023-01-14 20:55:51,678 - --- validate (epoch=83)-----------
2023-01-14 20:55:51,678 - 101 samples (240 per mini-batch)
2023-01-14 20:55:52,795 - Epoch: [83][    1/    1]    Loss 0.092619    Top1 97.029703    Top5 100.000000    
2023-01-14 20:55:52,834 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.093

2023-01-14 20:55:52,843 - ==> Best [Top1: 98.020   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 82]
2023-01-14 20:55:52,844 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:55:52,889 - 

2023-01-14 20:55:52,889 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:55:54,954 - Epoch: [84][    4/    4]    Overall Loss 0.008144    Objective Loss 0.008144    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.515775    
2023-01-14 20:55:54,999 - --- validate (epoch=84)-----------
2023-01-14 20:55:54,999 - 101 samples (240 per mini-batch)
2023-01-14 20:55:56,148 - Epoch: [84][    1/    1]    Loss 0.094907    Top1 97.029703    Top5 100.000000    
2023-01-14 20:55:56,196 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.095

2023-01-14 20:55:56,205 - ==> Best [Top1: 98.020   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 82]
2023-01-14 20:55:56,206 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:55:56,246 - 

2023-01-14 20:55:56,247 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:55:58,002 - Epoch: [85][    4/    4]    Overall Loss 0.008429    Objective Loss 0.008429    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.438405    
2023-01-14 20:55:58,048 - --- validate (epoch=85)-----------
2023-01-14 20:55:58,049 - 101 samples (240 per mini-batch)
2023-01-14 20:55:59,323 - Epoch: [85][    1/    1]    Loss 0.098118    Top1 96.039604    Top5 100.000000    
2023-01-14 20:55:59,361 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.098

2023-01-14 20:55:59,372 - ==> Best [Top1: 98.020   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 82]
2023-01-14 20:55:59,372 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:55:59,409 - 

2023-01-14 20:55:59,409 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:56:01,499 - Epoch: [86][    4/    4]    Overall Loss 0.007921    Objective Loss 0.007921    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.522129    
2023-01-14 20:56:01,541 - --- validate (epoch=86)-----------
2023-01-14 20:56:01,541 - 101 samples (240 per mini-batch)
2023-01-14 20:56:02,819 - Epoch: [86][    1/    1]    Loss 0.080457    Top1 97.029703    Top5 100.000000    
2023-01-14 20:56:02,860 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.080

2023-01-14 20:56:02,870 - ==> Best [Top1: 98.020   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 82]
2023-01-14 20:56:02,871 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:56:02,902 - 

2023-01-14 20:56:02,904 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:56:05,203 - Epoch: [87][    4/    4]    Overall Loss 0.007999    Objective Loss 0.007999    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.574082    
2023-01-14 20:56:05,241 - --- validate (epoch=87)-----------
2023-01-14 20:56:05,242 - 101 samples (240 per mini-batch)
2023-01-14 20:56:06,311 - Epoch: [87][    1/    1]    Loss 0.088642    Top1 97.029703    Top5 100.000000    
2023-01-14 20:56:06,353 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.089

2023-01-14 20:56:06,370 - ==> Best [Top1: 98.020   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 82]
2023-01-14 20:56:06,371 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:56:06,423 - 

2023-01-14 20:56:06,424 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:56:08,362 - Epoch: [88][    4/    4]    Overall Loss 0.008284    Objective Loss 0.008284    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.484195    
2023-01-14 20:56:08,408 - --- validate (epoch=88)-----------
2023-01-14 20:56:08,408 - 101 samples (240 per mini-batch)
2023-01-14 20:56:09,521 - Epoch: [88][    1/    1]    Loss 0.106281    Top1 97.029703    Top5 100.000000    
2023-01-14 20:56:09,552 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.106

2023-01-14 20:56:09,566 - ==> Best [Top1: 98.020   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 82]
2023-01-14 20:56:09,567 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:56:09,616 - 

2023-01-14 20:56:09,617 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:56:11,364 - Epoch: [89][    4/    4]    Overall Loss 0.007871    Objective Loss 0.007871    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.436362    
2023-01-14 20:56:11,405 - --- validate (epoch=89)-----------
2023-01-14 20:56:11,406 - 101 samples (240 per mini-batch)
2023-01-14 20:56:12,423 - Epoch: [89][    1/    1]    Loss 0.072556    Top1 99.009901    Top5 100.000000    
2023-01-14 20:56:12,461 - ==> Top1: 99.010    Top5: 100.000    Loss: 0.073

2023-01-14 20:56:12,472 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 89]
2023-01-14 20:56:12,473 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:56:12,515 - 

2023-01-14 20:56:12,516 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:56:15,097 - Epoch: [90][    4/    4]    Overall Loss 0.008403    Objective Loss 0.008403    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.644884    
2023-01-14 20:56:15,141 - --- validate (epoch=90)-----------
2023-01-14 20:56:15,141 - 101 samples (240 per mini-batch)
2023-01-14 20:56:16,373 - Epoch: [90][    1/    1]    Loss 0.094020    Top1 96.039604    Top5 100.000000    
2023-01-14 20:56:16,422 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.094

2023-01-14 20:56:16,433 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 89]
2023-01-14 20:56:16,434 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:56:16,478 - 

2023-01-14 20:56:16,479 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:56:18,240 - Epoch: [91][    4/    4]    Overall Loss 0.007751    Objective Loss 0.007751    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.440072    
2023-01-14 20:56:18,281 - --- validate (epoch=91)-----------
2023-01-14 20:56:18,282 - 101 samples (240 per mini-batch)
2023-01-14 20:56:19,442 - Epoch: [91][    1/    1]    Loss 0.104163    Top1 96.039604    Top5 100.000000    
2023-01-14 20:56:19,479 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.104

2023-01-14 20:56:19,487 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 89]
2023-01-14 20:56:19,488 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:56:19,524 - 

2023-01-14 20:56:19,525 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:56:21,607 - Epoch: [92][    4/    4]    Overall Loss 0.008198    Objective Loss 0.008198    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.519536    
2023-01-14 20:56:21,645 - --- validate (epoch=92)-----------
2023-01-14 20:56:21,647 - 101 samples (240 per mini-batch)
2023-01-14 20:56:22,709 - Epoch: [92][    1/    1]    Loss 0.116158    Top1 95.049505    Top5 100.000000    
2023-01-14 20:56:22,751 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.116

2023-01-14 20:56:22,760 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 89]
2023-01-14 20:56:22,760 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:56:22,809 - 

2023-01-14 20:56:22,810 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:56:24,998 - Epoch: [93][    4/    4]    Overall Loss 0.007884    Objective Loss 0.007884    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.546453    
2023-01-14 20:56:25,047 - --- validate (epoch=93)-----------
2023-01-14 20:56:25,047 - 101 samples (240 per mini-batch)
2023-01-14 20:56:26,246 - Epoch: [93][    1/    1]    Loss 0.064919    Top1 98.019802    Top5 100.000000    
2023-01-14 20:56:26,288 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.065

2023-01-14 20:56:26,307 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 89]
2023-01-14 20:56:26,308 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:56:26,351 - 

2023-01-14 20:56:26,351 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:56:28,460 - Epoch: [94][    4/    4]    Overall Loss 0.007934    Objective Loss 0.007934    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.526973    
2023-01-14 20:56:28,503 - --- validate (epoch=94)-----------
2023-01-14 20:56:28,503 - 101 samples (240 per mini-batch)
2023-01-14 20:56:29,590 - Epoch: [94][    1/    1]    Loss 0.071155    Top1 98.019802    Top5 100.000000    
2023-01-14 20:56:29,627 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.071

2023-01-14 20:56:29,644 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 89]
2023-01-14 20:56:29,644 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:56:29,698 - 

2023-01-14 20:56:29,699 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:56:31,688 - Epoch: [95][    4/    4]    Overall Loss 0.008039    Objective Loss 0.008039    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.497043    
2023-01-14 20:56:31,731 - --- validate (epoch=95)-----------
2023-01-14 20:56:31,732 - 101 samples (240 per mini-batch)
2023-01-14 20:56:32,833 - Epoch: [95][    1/    1]    Loss 0.089284    Top1 97.029703    Top5 100.000000    
2023-01-14 20:56:32,877 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.089

2023-01-14 20:56:32,887 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 89]
2023-01-14 20:56:32,887 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:56:32,929 - 

2023-01-14 20:56:32,929 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:56:34,827 - Epoch: [96][    4/    4]    Overall Loss 0.008014    Objective Loss 0.008014    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.474011    
2023-01-14 20:56:34,866 - --- validate (epoch=96)-----------
2023-01-14 20:56:34,867 - 101 samples (240 per mini-batch)
2023-01-14 20:56:36,041 - Epoch: [96][    1/    1]    Loss 0.084646    Top1 97.029703    Top5 100.000000    
2023-01-14 20:56:36,079 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.085

2023-01-14 20:56:36,094 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 89]
2023-01-14 20:56:36,094 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:56:36,135 - 

2023-01-14 20:56:36,135 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:56:38,716 - Epoch: [97][    4/    4]    Overall Loss 0.007643    Objective Loss 0.007643    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.644671    
2023-01-14 20:56:38,781 - --- validate (epoch=97)-----------
2023-01-14 20:56:38,782 - 101 samples (240 per mini-batch)
2023-01-14 20:56:39,862 - Epoch: [97][    1/    1]    Loss 0.109428    Top1 97.029703    Top5 100.000000    
2023-01-14 20:56:39,903 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.109

2023-01-14 20:56:39,911 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 89]
2023-01-14 20:56:39,912 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:56:39,950 - 

2023-01-14 20:56:39,952 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:56:42,008 - Epoch: [98][    4/    4]    Overall Loss 0.007531    Objective Loss 0.007531    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.512936    
2023-01-14 20:56:42,048 - --- validate (epoch=98)-----------
2023-01-14 20:56:42,049 - 101 samples (240 per mini-batch)
2023-01-14 20:56:43,151 - Epoch: [98][    1/    1]    Loss 0.095463    Top1 97.029703    Top5 100.000000    
2023-01-14 20:56:43,191 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.095

2023-01-14 20:56:43,205 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 89]
2023-01-14 20:56:43,205 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:56:43,245 - 

2023-01-14 20:56:43,245 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:56:45,374 - Epoch: [99][    4/    4]    Overall Loss 0.007398    Objective Loss 0.007398    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.531876    
2023-01-14 20:56:45,413 - --- validate (epoch=99)-----------
2023-01-14 20:56:45,414 - 101 samples (240 per mini-batch)
2023-01-14 20:56:46,530 - Epoch: [99][    1/    1]    Loss 0.087645    Top1 97.029703    Top5 100.000000    
2023-01-14 20:56:46,572 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.088

2023-01-14 20:56:46,584 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 89]
2023-01-14 20:56:46,584 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:56:46,630 - 

2023-01-14 20:56:46,631 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:56:48,566 - Epoch: [100][    4/    4]    Overall Loss 0.007677    Objective Loss 0.007677    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.483004    
2023-01-14 20:56:48,622 - --- validate (epoch=100)-----------
2023-01-14 20:56:48,623 - 101 samples (240 per mini-batch)
2023-01-14 20:56:49,848 - Epoch: [100][    1/    1]    Loss 0.066023    Top1 99.009901    Top5 100.000000    
2023-01-14 20:56:49,885 - ==> Top1: 99.010    Top5: 100.000    Loss: 0.066

2023-01-14 20:56:49,903 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 100]
2023-01-14 20:56:49,903 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:56:49,952 - 

2023-01-14 20:56:49,953 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:56:51,943 - Epoch: [101][    4/    4]    Overall Loss 0.007884    Objective Loss 0.007884    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.497250    
2023-01-14 20:56:51,991 - --- validate (epoch=101)-----------
2023-01-14 20:56:51,992 - 101 samples (240 per mini-batch)
2023-01-14 20:56:53,184 - Epoch: [101][    1/    1]    Loss 0.073492    Top1 97.029703    Top5 100.000000    
2023-01-14 20:56:53,216 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.073

2023-01-14 20:56:53,236 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 100]
2023-01-14 20:56:53,236 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:56:53,288 - 

2023-01-14 20:56:53,289 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:56:55,283 - Epoch: [102][    4/    4]    Overall Loss 0.007449    Objective Loss 0.007449    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.498201    
2023-01-14 20:56:55,333 - --- validate (epoch=102)-----------
2023-01-14 20:56:55,334 - 101 samples (240 per mini-batch)
2023-01-14 20:56:56,466 - Epoch: [102][    1/    1]    Loss 0.112993    Top1 96.039604    Top5 100.000000    
2023-01-14 20:56:56,506 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.113

2023-01-14 20:56:56,515 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 100]
2023-01-14 20:56:56,516 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:56:56,554 - 

2023-01-14 20:56:56,555 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:56:58,288 - Epoch: [103][    4/    4]    Overall Loss 0.007724    Objective Loss 0.007724    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.432873    
2023-01-14 20:56:58,328 - --- validate (epoch=103)-----------
2023-01-14 20:56:58,329 - 101 samples (240 per mini-batch)
2023-01-14 20:56:59,483 - Epoch: [103][    1/    1]    Loss 0.089541    Top1 97.029703    Top5 100.000000    
2023-01-14 20:56:59,526 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.090

2023-01-14 20:56:59,535 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 100]
2023-01-14 20:56:59,535 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:56:59,579 - 

2023-01-14 20:56:59,579 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:57:01,107 - Epoch: [104][    4/    4]    Overall Loss 0.007592    Objective Loss 0.007592    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.381641    
2023-01-14 20:57:01,155 - --- validate (epoch=104)-----------
2023-01-14 20:57:01,156 - 101 samples (240 per mini-batch)
2023-01-14 20:57:02,174 - Epoch: [104][    1/    1]    Loss 0.082921    Top1 97.029703    Top5 100.000000    
2023-01-14 20:57:02,218 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.083

2023-01-14 20:57:02,228 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 100]
2023-01-14 20:57:02,229 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:57:02,275 - 

2023-01-14 20:57:02,275 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:57:04,536 - Epoch: [105][    4/    4]    Overall Loss 0.007850    Objective Loss 0.007850    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.564674    
2023-01-14 20:57:04,584 - --- validate (epoch=105)-----------
2023-01-14 20:57:04,585 - 101 samples (240 per mini-batch)
2023-01-14 20:57:05,760 - Epoch: [105][    1/    1]    Loss 0.096908    Top1 96.039604    Top5 100.000000    
2023-01-14 20:57:05,799 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.097

2023-01-14 20:57:05,817 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 100]
2023-01-14 20:57:05,817 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:57:05,871 - 

2023-01-14 20:57:05,872 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:57:07,495 - Epoch: [106][    4/    4]    Overall Loss 0.007898    Objective Loss 0.007898    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.405316    
2023-01-14 20:57:07,531 - --- validate (epoch=106)-----------
2023-01-14 20:57:07,532 - 101 samples (240 per mini-batch)
2023-01-14 20:57:08,679 - Epoch: [106][    1/    1]    Loss 0.117838    Top1 95.049505    Top5 100.000000    
2023-01-14 20:57:08,722 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.118

2023-01-14 20:57:08,733 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 100]
2023-01-14 20:57:08,734 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:57:08,777 - 

2023-01-14 20:57:08,778 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:57:10,700 - Epoch: [107][    4/    4]    Overall Loss 0.007731    Objective Loss 0.007731    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.480255    
2023-01-14 20:57:10,737 - --- validate (epoch=107)-----------
2023-01-14 20:57:10,738 - 101 samples (240 per mini-batch)
2023-01-14 20:57:11,833 - Epoch: [107][    1/    1]    Loss 0.089917    Top1 97.029703    Top5 100.000000    
2023-01-14 20:57:11,872 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.090

2023-01-14 20:57:11,880 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 100]
2023-01-14 20:57:11,881 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:57:11,916 - 

2023-01-14 20:57:11,917 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:57:14,072 - Epoch: [108][    4/    4]    Overall Loss 0.007521    Objective Loss 0.007521    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.538442    
2023-01-14 20:57:14,138 - --- validate (epoch=108)-----------
2023-01-14 20:57:14,139 - 101 samples (240 per mini-batch)
2023-01-14 20:57:15,377 - Epoch: [108][    1/    1]    Loss 0.079182    Top1 98.019802    Top5 100.000000    
2023-01-14 20:57:15,414 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.079

2023-01-14 20:57:15,431 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 100]
2023-01-14 20:57:15,431 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:57:15,486 - 

2023-01-14 20:57:15,486 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:57:17,354 - Epoch: [109][    4/    4]    Overall Loss 0.007574    Objective Loss 0.007574    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.466197    
2023-01-14 20:57:17,411 - --- validate (epoch=109)-----------
2023-01-14 20:57:17,412 - 101 samples (240 per mini-batch)
2023-01-14 20:57:18,493 - Epoch: [109][    1/    1]    Loss 0.082306    Top1 96.039604    Top5 100.000000    
2023-01-14 20:57:18,537 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.082

2023-01-14 20:57:18,553 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 100]
2023-01-14 20:57:18,554 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:57:18,601 - 

2023-01-14 20:57:18,602 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:57:20,061 - Epoch: [110][    4/    4]    Overall Loss 0.007779    Objective Loss 0.007779    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.364448    
2023-01-14 20:57:20,111 - --- validate (epoch=110)-----------
2023-01-14 20:57:20,112 - 101 samples (240 per mini-batch)
2023-01-14 20:57:21,247 - Epoch: [110][    1/    1]    Loss 0.096955    Top1 96.039604    Top5 100.000000    
2023-01-14 20:57:21,281 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.097

2023-01-14 20:57:21,289 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 100]
2023-01-14 20:57:21,290 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:57:21,329 - 

2023-01-14 20:57:21,329 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:57:23,587 - Epoch: [111][    4/    4]    Overall Loss 0.007280    Objective Loss 0.007280    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.563840    
2023-01-14 20:57:23,658 - --- validate (epoch=111)-----------
2023-01-14 20:57:23,659 - 101 samples (240 per mini-batch)
2023-01-14 20:57:24,903 - Epoch: [111][    1/    1]    Loss 0.091311    Top1 97.029703    Top5 100.000000    
2023-01-14 20:57:24,954 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.091

2023-01-14 20:57:24,967 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 100]
2023-01-14 20:57:24,967 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:57:25,009 - 

2023-01-14 20:57:25,009 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:57:27,289 - Epoch: [112][    4/    4]    Overall Loss 0.007673    Objective Loss 0.007673    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.569676    
2023-01-14 20:57:27,340 - --- validate (epoch=112)-----------
2023-01-14 20:57:27,341 - 101 samples (240 per mini-batch)
2023-01-14 20:57:28,534 - Epoch: [112][    1/    1]    Loss 0.071297    Top1 98.019802    Top5 100.000000    
2023-01-14 20:57:28,582 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.071

2023-01-14 20:57:28,593 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 100]
2023-01-14 20:57:28,596 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:57:28,638 - 

2023-01-14 20:57:28,638 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:57:30,659 - Epoch: [113][    4/    4]    Overall Loss 0.007861    Objective Loss 0.007861    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.504898    
2023-01-14 20:57:30,697 - --- validate (epoch=113)-----------
2023-01-14 20:57:30,698 - 101 samples (240 per mini-batch)
2023-01-14 20:57:31,788 - Epoch: [113][    1/    1]    Loss 0.058409    Top1 99.009901    Top5 100.000000    
2023-01-14 20:57:31,835 - ==> Top1: 99.010    Top5: 100.000    Loss: 0.058

2023-01-14 20:57:31,845 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 113]
2023-01-14 20:57:31,846 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:57:31,890 - 

2023-01-14 20:57:31,891 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:57:33,923 - Epoch: [114][    4/    4]    Overall Loss 0.007410    Objective Loss 0.007410    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.507518    
2023-01-14 20:57:33,962 - --- validate (epoch=114)-----------
2023-01-14 20:57:33,963 - 101 samples (240 per mini-batch)
2023-01-14 20:57:35,069 - Epoch: [114][    1/    1]    Loss 0.092576    Top1 97.029703    Top5 100.000000    
2023-01-14 20:57:35,113 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.093

2023-01-14 20:57:35,133 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 113]
2023-01-14 20:57:35,133 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:57:35,187 - 

2023-01-14 20:57:35,188 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:57:36,714 - Epoch: [115][    4/    4]    Overall Loss 0.007292    Objective Loss 0.007292    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.380950    
2023-01-14 20:57:36,754 - --- validate (epoch=115)-----------
2023-01-14 20:57:36,755 - 101 samples (240 per mini-batch)
2023-01-14 20:57:37,926 - Epoch: [115][    1/    1]    Loss 0.092066    Top1 97.029703    Top5 100.000000    
2023-01-14 20:57:37,970 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.092

2023-01-14 20:57:37,986 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 113]
2023-01-14 20:57:37,986 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:57:38,039 - 

2023-01-14 20:57:38,040 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:57:39,843 - Epoch: [116][    4/    4]    Overall Loss 0.007615    Objective Loss 0.007615    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.450434    
2023-01-14 20:57:39,886 - --- validate (epoch=116)-----------
2023-01-14 20:57:39,886 - 101 samples (240 per mini-batch)
2023-01-14 20:57:40,869 - Epoch: [116][    1/    1]    Loss 0.089938    Top1 97.029703    Top5 100.000000    
2023-01-14 20:57:40,912 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.090

2023-01-14 20:57:40,929 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 113]
2023-01-14 20:57:40,930 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:57:40,977 - 

2023-01-14 20:57:40,978 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:57:42,851 - Epoch: [117][    4/    4]    Overall Loss 0.008017    Objective Loss 0.008017    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.468034    
2023-01-14 20:57:42,892 - --- validate (epoch=117)-----------
2023-01-14 20:57:42,892 - 101 samples (240 per mini-batch)
2023-01-14 20:57:43,975 - Epoch: [117][    1/    1]    Loss 0.099487    Top1 97.029703    Top5 100.000000    
2023-01-14 20:57:44,014 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.099

2023-01-14 20:57:44,029 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 113]
2023-01-14 20:57:44,029 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:57:44,071 - 

2023-01-14 20:57:44,072 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:57:45,731 - Epoch: [118][    4/    4]    Overall Loss 0.007427    Objective Loss 0.007427    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.414553    
2023-01-14 20:57:45,769 - --- validate (epoch=118)-----------
2023-01-14 20:57:45,770 - 101 samples (240 per mini-batch)
2023-01-14 20:57:46,892 - Epoch: [118][    1/    1]    Loss 0.078215    Top1 98.019802    Top5 100.000000    
2023-01-14 20:57:46,930 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.078

2023-01-14 20:57:46,945 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 113]
2023-01-14 20:57:46,945 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:57:46,992 - 

2023-01-14 20:57:46,992 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:57:49,257 - Epoch: [119][    4/    4]    Overall Loss 0.007481    Objective Loss 0.007481    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.565839    
2023-01-14 20:57:49,302 - --- validate (epoch=119)-----------
2023-01-14 20:57:49,303 - 101 samples (240 per mini-batch)
2023-01-14 20:57:50,412 - Epoch: [119][    1/    1]    Loss 0.113152    Top1 96.039604    Top5 100.000000    
2023-01-14 20:57:50,463 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.113

2023-01-14 20:57:50,477 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 113]
2023-01-14 20:57:50,478 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:57:50,533 - 

2023-01-14 20:57:50,534 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:57:52,724 - Epoch: [120][    4/    4]    Overall Loss 0.007414    Objective Loss 0.007414    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.546575    
2023-01-14 20:57:52,766 - --- validate (epoch=120)-----------
2023-01-14 20:57:52,766 - 101 samples (240 per mini-batch)
2023-01-14 20:57:53,917 - Epoch: [120][    1/    1]    Loss 0.094130    Top1 97.029703    Top5 100.000000    
2023-01-14 20:57:53,957 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.094

2023-01-14 20:57:53,967 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 113]
2023-01-14 20:57:53,968 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:57:54,015 - 

2023-01-14 20:57:54,015 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:57:55,973 - Epoch: [121][    4/    4]    Overall Loss 0.007210    Objective Loss 0.007210    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.488700    
2023-01-14 20:57:56,010 - --- validate (epoch=121)-----------
2023-01-14 20:57:56,011 - 101 samples (240 per mini-batch)
2023-01-14 20:57:57,078 - Epoch: [121][    1/    1]    Loss 0.118088    Top1 96.039604    Top5 100.000000    
2023-01-14 20:57:57,120 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.118

2023-01-14 20:57:57,130 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 113]
2023-01-14 20:57:57,131 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:57:57,186 - 

2023-01-14 20:57:57,187 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:57:59,435 - Epoch: [122][    4/    4]    Overall Loss 0.007276    Objective Loss 0.007276    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.561676    
2023-01-14 20:57:59,474 - --- validate (epoch=122)-----------
2023-01-14 20:57:59,475 - 101 samples (240 per mini-batch)
2023-01-14 20:58:00,570 - Epoch: [122][    1/    1]    Loss 0.074286    Top1 98.019802    Top5 100.000000    
2023-01-14 20:58:00,607 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.074

2023-01-14 20:58:00,620 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 113]
2023-01-14 20:58:00,622 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:58:00,667 - 

2023-01-14 20:58:00,667 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:58:02,593 - Epoch: [123][    4/    4]    Overall Loss 0.007618    Objective Loss 0.007618    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.481006    
2023-01-14 20:58:02,632 - --- validate (epoch=123)-----------
2023-01-14 20:58:02,633 - 101 samples (240 per mini-batch)
2023-01-14 20:58:03,751 - Epoch: [123][    1/    1]    Loss 0.095564    Top1 96.039604    Top5 100.000000    
2023-01-14 20:58:03,792 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.096

2023-01-14 20:58:03,802 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 113]
2023-01-14 20:58:03,802 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:58:03,847 - 

2023-01-14 20:58:03,848 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:58:06,274 - Epoch: [124][    4/    4]    Overall Loss 0.007610    Objective Loss 0.007610    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.606202    
2023-01-14 20:58:06,330 - --- validate (epoch=124)-----------
2023-01-14 20:58:06,331 - 101 samples (240 per mini-batch)
2023-01-14 20:58:07,445 - Epoch: [124][    1/    1]    Loss 0.064082    Top1 99.009901    Top5 100.000000    
2023-01-14 20:58:07,484 - ==> Top1: 99.010    Top5: 100.000    Loss: 0.064

2023-01-14 20:58:07,493 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 124]
2023-01-14 20:58:07,494 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:58:07,537 - 

2023-01-14 20:58:07,538 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:58:09,530 - Epoch: [125][    4/    4]    Overall Loss 0.007462    Objective Loss 0.007462    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.497507    
2023-01-14 20:58:09,624 - --- validate (epoch=125)-----------
2023-01-14 20:58:09,624 - 101 samples (240 per mini-batch)
2023-01-14 20:58:10,849 - Epoch: [125][    1/    1]    Loss 0.092554    Top1 97.029703    Top5 100.000000    
2023-01-14 20:58:10,912 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.093

2023-01-14 20:58:10,921 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 124]
2023-01-14 20:58:10,921 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:58:10,965 - 

2023-01-14 20:58:10,966 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:58:13,494 - Epoch: [126][    4/    4]    Overall Loss 0.007477    Objective Loss 0.007477    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.631673    
2023-01-14 20:58:13,552 - --- validate (epoch=126)-----------
2023-01-14 20:58:13,553 - 101 samples (240 per mini-batch)
2023-01-14 20:58:14,688 - Epoch: [126][    1/    1]    Loss 0.091885    Top1 98.019802    Top5 100.000000    
2023-01-14 20:58:14,735 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.092

2023-01-14 20:58:14,745 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 124]
2023-01-14 20:58:14,745 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:58:14,794 - 

2023-01-14 20:58:14,795 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:58:16,393 - Epoch: [127][    4/    4]    Overall Loss 0.007248    Objective Loss 0.007248    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.398965    
2023-01-14 20:58:16,448 - --- validate (epoch=127)-----------
2023-01-14 20:58:16,448 - 101 samples (240 per mini-batch)
2023-01-14 20:58:17,542 - Epoch: [127][    1/    1]    Loss 0.110304    Top1 96.039604    Top5 100.000000    
2023-01-14 20:58:17,579 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.110

2023-01-14 20:58:17,591 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 124]
2023-01-14 20:58:17,592 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:58:17,635 - 

2023-01-14 20:58:17,636 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:58:19,380 - Epoch: [128][    4/    4]    Overall Loss 0.007250    Objective Loss 0.007250    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.435894    
2023-01-14 20:58:19,424 - --- validate (epoch=128)-----------
2023-01-14 20:58:19,424 - 101 samples (240 per mini-batch)
2023-01-14 20:58:20,543 - Epoch: [128][    1/    1]    Loss 0.092552    Top1 97.029703    Top5 100.000000    
2023-01-14 20:58:20,592 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.093

2023-01-14 20:58:20,602 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 124]
2023-01-14 20:58:20,603 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:58:20,646 - 

2023-01-14 20:58:20,646 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:58:22,869 - Epoch: [129][    4/    4]    Overall Loss 0.007362    Objective Loss 0.007362    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.555459    
2023-01-14 20:58:22,904 - --- validate (epoch=129)-----------
2023-01-14 20:58:22,905 - 101 samples (240 per mini-batch)
2023-01-14 20:58:24,017 - Epoch: [129][    1/    1]    Loss 0.103532    Top1 96.039604    Top5 100.000000    
2023-01-14 20:58:24,058 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.104

2023-01-14 20:58:24,071 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 124]
2023-01-14 20:58:24,074 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:58:24,111 - 

2023-01-14 20:58:24,111 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:58:25,952 - Epoch: [130][    4/    4]    Overall Loss 0.007276    Objective Loss 0.007276    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.460043    
2023-01-14 20:58:25,992 - --- validate (epoch=130)-----------
2023-01-14 20:58:25,993 - 101 samples (240 per mini-batch)
2023-01-14 20:58:27,098 - Epoch: [130][    1/    1]    Loss 0.088277    Top1 97.029703    Top5 100.000000    
2023-01-14 20:58:27,150 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.088

2023-01-14 20:58:27,166 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 124]
2023-01-14 20:58:27,166 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:58:27,214 - 

2023-01-14 20:58:27,214 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:58:28,929 - Epoch: [131][    4/    4]    Overall Loss 0.007126    Objective Loss 0.007126    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.428286    
2023-01-14 20:58:28,971 - --- validate (epoch=131)-----------
2023-01-14 20:58:28,972 - 101 samples (240 per mini-batch)
2023-01-14 20:58:30,038 - Epoch: [131][    1/    1]    Loss 0.089695    Top1 96.039604    Top5 100.000000    
2023-01-14 20:58:30,080 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.090

2023-01-14 20:58:30,092 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 124]
2023-01-14 20:58:30,094 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:58:30,130 - 

2023-01-14 20:58:30,130 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:58:32,066 - Epoch: [132][    4/    4]    Overall Loss 0.007167    Objective Loss 0.007167    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.483609    
2023-01-14 20:58:32,108 - --- validate (epoch=132)-----------
2023-01-14 20:58:32,109 - 101 samples (240 per mini-batch)
2023-01-14 20:58:33,264 - Epoch: [132][    1/    1]    Loss 0.124145    Top1 94.059406    Top5 100.000000    
2023-01-14 20:58:33,298 - ==> Top1: 94.059    Top5: 100.000    Loss: 0.124

2023-01-14 20:58:33,310 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 124]
2023-01-14 20:58:33,310 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:58:33,350 - 

2023-01-14 20:58:33,351 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:58:35,247 - Epoch: [133][    4/    4]    Overall Loss 0.007424    Objective Loss 0.007424    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.473592    
2023-01-14 20:58:35,288 - --- validate (epoch=133)-----------
2023-01-14 20:58:35,288 - 101 samples (240 per mini-batch)
2023-01-14 20:58:36,434 - Epoch: [133][    1/    1]    Loss 0.071239    Top1 98.019802    Top5 100.000000    
2023-01-14 20:58:36,471 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.071

2023-01-14 20:58:36,481 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 124]
2023-01-14 20:58:36,482 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:58:36,543 - 

2023-01-14 20:58:36,544 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:58:38,810 - Epoch: [134][    4/    4]    Overall Loss 0.007377    Objective Loss 0.007377    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.566249    
2023-01-14 20:58:38,854 - --- validate (epoch=134)-----------
2023-01-14 20:58:38,855 - 101 samples (240 per mini-batch)
2023-01-14 20:58:39,974 - Epoch: [134][    1/    1]    Loss 0.102392    Top1 97.029703    Top5 100.000000    
2023-01-14 20:58:40,015 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.102

2023-01-14 20:58:40,025 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 124]
2023-01-14 20:58:40,025 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:58:40,071 - 

2023-01-14 20:58:40,071 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:58:41,886 - Epoch: [135][    4/    4]    Overall Loss 0.007113    Objective Loss 0.007113    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.453152    
2023-01-14 20:58:41,934 - --- validate (epoch=135)-----------
2023-01-14 20:58:41,935 - 101 samples (240 per mini-batch)
2023-01-14 20:58:43,093 - Epoch: [135][    1/    1]    Loss 0.110625    Top1 96.039604    Top5 100.000000    
2023-01-14 20:58:43,133 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.111

2023-01-14 20:58:43,151 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 124]
2023-01-14 20:58:43,151 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:58:43,191 - 

2023-01-14 20:58:43,191 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:58:44,994 - Epoch: [136][    4/    4]    Overall Loss 0.007229    Objective Loss 0.007229    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.450366    
2023-01-14 20:58:45,037 - --- validate (epoch=136)-----------
2023-01-14 20:58:45,038 - 101 samples (240 per mini-batch)
2023-01-14 20:58:46,158 - Epoch: [136][    1/    1]    Loss 0.060524    Top1 99.009901    Top5 100.000000    
2023-01-14 20:58:46,208 - ==> Top1: 99.010    Top5: 100.000    Loss: 0.061

2023-01-14 20:58:46,221 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 136]
2023-01-14 20:58:46,222 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:58:46,266 - 

2023-01-14 20:58:46,266 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:58:48,472 - Epoch: [137][    4/    4]    Overall Loss 0.007127    Objective Loss 0.007127    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.551198    
2023-01-14 20:58:48,526 - --- validate (epoch=137)-----------
2023-01-14 20:58:48,527 - 101 samples (240 per mini-batch)
2023-01-14 20:58:49,610 - Epoch: [137][    1/    1]    Loss 0.080952    Top1 98.019802    Top5 100.000000    
2023-01-14 20:58:49,644 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.081

2023-01-14 20:58:49,666 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 136]
2023-01-14 20:58:49,666 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:58:49,725 - 

2023-01-14 20:58:49,726 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:58:52,024 - Epoch: [138][    4/    4]    Overall Loss 0.007223    Objective Loss 0.007223    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.574254    
2023-01-14 20:58:52,062 - --- validate (epoch=138)-----------
2023-01-14 20:58:52,063 - 101 samples (240 per mini-batch)
2023-01-14 20:58:53,182 - Epoch: [138][    1/    1]    Loss 0.077347    Top1 96.039604    Top5 100.000000    
2023-01-14 20:58:53,228 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.077

2023-01-14 20:58:53,244 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 136]
2023-01-14 20:58:53,244 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:58:53,291 - 

2023-01-14 20:58:53,291 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:58:55,349 - Epoch: [139][    4/    4]    Overall Loss 0.006779    Objective Loss 0.006779    Top1 100.000000    Top5 100.000000    LR 0.000200    Time 0.514002    
2023-01-14 20:58:55,399 - --- validate (epoch=139)-----------
2023-01-14 20:58:55,400 - 101 samples (240 per mini-batch)
2023-01-14 20:58:56,561 - Epoch: [139][    1/    1]    Loss 0.090117    Top1 97.029703    Top5 100.000000    
2023-01-14 20:58:56,642 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.090

2023-01-14 20:58:56,664 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 136]
2023-01-14 20:58:56,664 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:58:56,725 - 

2023-01-14 20:58:56,725 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:58:58,687 - Epoch: [140][    4/    4]    Overall Loss 0.007206    Objective Loss 0.007206    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.488939    
2023-01-14 20:58:58,723 - --- validate (epoch=140)-----------
2023-01-14 20:58:58,724 - 101 samples (240 per mini-batch)
2023-01-14 20:58:59,855 - Epoch: [140][    1/    1]    Loss 0.112127    Top1 96.039604    Top5 100.000000    
2023-01-14 20:58:59,897 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.112

2023-01-14 20:58:59,910 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 136]
2023-01-14 20:58:59,911 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:58:59,958 - 

2023-01-14 20:58:59,959 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:59:01,716 - Epoch: [141][    4/    4]    Overall Loss 0.007164    Objective Loss 0.007164    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.439047    
2023-01-14 20:59:01,758 - --- validate (epoch=141)-----------
2023-01-14 20:59:01,759 - 101 samples (240 per mini-batch)
2023-01-14 20:59:02,762 - Epoch: [141][    1/    1]    Loss 0.073689    Top1 98.019802    Top5 100.000000    
2023-01-14 20:59:02,807 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.074

2023-01-14 20:59:02,821 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 136]
2023-01-14 20:59:02,823 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:59:02,867 - 

2023-01-14 20:59:02,868 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:59:04,751 - Epoch: [142][    4/    4]    Overall Loss 0.007206    Objective Loss 0.007206    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.469895    
2023-01-14 20:59:04,790 - --- validate (epoch=142)-----------
2023-01-14 20:59:04,791 - 101 samples (240 per mini-batch)
2023-01-14 20:59:06,048 - Epoch: [142][    1/    1]    Loss 0.096861    Top1 96.039604    Top5 100.000000    
2023-01-14 20:59:06,106 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.097

2023-01-14 20:59:06,118 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 136]
2023-01-14 20:59:06,119 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:59:06,161 - 

2023-01-14 20:59:06,161 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:59:08,073 - Epoch: [143][    4/    4]    Overall Loss 0.006987    Objective Loss 0.006987    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.477484    
2023-01-14 20:59:08,111 - --- validate (epoch=143)-----------
2023-01-14 20:59:08,112 - 101 samples (240 per mini-batch)
2023-01-14 20:59:09,242 - Epoch: [143][    1/    1]    Loss 0.081247    Top1 98.019802    Top5 100.000000    
2023-01-14 20:59:09,281 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.081

2023-01-14 20:59:09,290 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 136]
2023-01-14 20:59:09,291 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:59:09,340 - 

2023-01-14 20:59:09,340 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:59:11,418 - Epoch: [144][    4/    4]    Overall Loss 0.007150    Objective Loss 0.007150    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.519253    
2023-01-14 20:59:11,457 - --- validate (epoch=144)-----------
2023-01-14 20:59:11,458 - 101 samples (240 per mini-batch)
2023-01-14 20:59:12,472 - Epoch: [144][    1/    1]    Loss 0.087025    Top1 97.029703    Top5 100.000000    
2023-01-14 20:59:12,523 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.087

2023-01-14 20:59:12,536 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 136]
2023-01-14 20:59:12,539 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:59:12,578 - 

2023-01-14 20:59:12,578 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:59:14,203 - Epoch: [145][    4/    4]    Overall Loss 0.006952    Objective Loss 0.006952    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.404740    
2023-01-14 20:59:14,249 - --- validate (epoch=145)-----------
2023-01-14 20:59:14,250 - 101 samples (240 per mini-batch)
2023-01-14 20:59:15,478 - Epoch: [145][    1/    1]    Loss 0.089126    Top1 97.029703    Top5 100.000000    
2023-01-14 20:59:15,549 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.089

2023-01-14 20:59:15,558 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 136]
2023-01-14 20:59:15,558 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:59:15,608 - 

2023-01-14 20:59:15,608 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:59:17,667 - Epoch: [146][    4/    4]    Overall Loss 0.007011    Objective Loss 0.007011    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.514407    
2023-01-14 20:59:17,734 - --- validate (epoch=146)-----------
2023-01-14 20:59:17,735 - 101 samples (240 per mini-batch)
2023-01-14 20:59:18,923 - Epoch: [146][    1/    1]    Loss 0.085874    Top1 97.029703    Top5 100.000000    
2023-01-14 20:59:18,964 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.086

2023-01-14 20:59:18,984 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 136]
2023-01-14 20:59:18,984 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:59:19,032 - 

2023-01-14 20:59:19,032 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:59:20,821 - Epoch: [147][    4/    4]    Overall Loss 0.006698    Objective Loss 0.006698    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.446671    
2023-01-14 20:59:20,863 - --- validate (epoch=147)-----------
2023-01-14 20:59:20,864 - 101 samples (240 per mini-batch)
2023-01-14 20:59:21,952 - Epoch: [147][    1/    1]    Loss 0.088059    Top1 97.029703    Top5 100.000000    
2023-01-14 20:59:22,004 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.088

2023-01-14 20:59:22,024 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 136]
2023-01-14 20:59:22,024 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:59:22,070 - 

2023-01-14 20:59:22,070 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:59:24,027 - Epoch: [148][    4/    4]    Overall Loss 0.007006    Objective Loss 0.007006    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.488722    
2023-01-14 20:59:24,097 - --- validate (epoch=148)-----------
2023-01-14 20:59:24,098 - 101 samples (240 per mini-batch)
2023-01-14 20:59:25,205 - Epoch: [148][    1/    1]    Loss 0.073285    Top1 98.019802    Top5 100.000000    
2023-01-14 20:59:25,246 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.073

2023-01-14 20:59:25,255 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 136]
2023-01-14 20:59:25,255 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:59:25,307 - 

2023-01-14 20:59:25,308 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:59:27,381 - Epoch: [149][    4/    4]    Overall Loss 0.006763    Objective Loss 0.006763    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.517664    
2023-01-14 20:59:27,428 - --- validate (epoch=149)-----------
2023-01-14 20:59:27,429 - 101 samples (240 per mini-batch)
2023-01-14 20:59:28,529 - Epoch: [149][    1/    1]    Loss 0.082195    Top1 98.019802    Top5 100.000000    
2023-01-14 20:59:28,567 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.082

2023-01-14 20:59:28,580 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 136]
2023-01-14 20:59:28,582 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:59:28,624 - 

2023-01-14 20:59:28,624 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:59:30,665 - Epoch: [150][    4/    4]    Overall Loss 0.006924    Objective Loss 0.006924    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.509921    
2023-01-14 20:59:30,707 - --- validate (epoch=150)-----------
2023-01-14 20:59:30,707 - 101 samples (240 per mini-batch)
2023-01-14 20:59:31,730 - Epoch: [150][    1/    1]    Loss 0.078648    Top1 98.019802    Top5 100.000000    
2023-01-14 20:59:31,775 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.079

2023-01-14 20:59:31,785 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 136]
2023-01-14 20:59:31,786 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:59:31,832 - 

2023-01-14 20:59:31,833 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:59:33,690 - Epoch: [151][    4/    4]    Overall Loss 0.006930    Objective Loss 0.006930    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.464015    
2023-01-14 20:59:33,732 - --- validate (epoch=151)-----------
2023-01-14 20:59:33,732 - 101 samples (240 per mini-batch)
2023-01-14 20:59:34,851 - Epoch: [151][    1/    1]    Loss 0.113552    Top1 95.049505    Top5 100.000000    
2023-01-14 20:59:34,901 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.114

2023-01-14 20:59:34,911 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 136]
2023-01-14 20:59:34,911 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:59:34,950 - 

2023-01-14 20:59:34,950 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:59:36,937 - Epoch: [152][    4/    4]    Overall Loss 0.006756    Objective Loss 0.006756    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.495843    
2023-01-14 20:59:36,982 - --- validate (epoch=152)-----------
2023-01-14 20:59:36,983 - 101 samples (240 per mini-batch)
2023-01-14 20:59:38,076 - Epoch: [152][    1/    1]    Loss 0.083544    Top1 97.029703    Top5 100.000000    
2023-01-14 20:59:38,118 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.084

2023-01-14 20:59:38,129 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 136]
2023-01-14 20:59:38,129 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:59:38,170 - 

2023-01-14 20:59:38,170 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:59:40,470 - Epoch: [153][    4/    4]    Overall Loss 0.007029    Objective Loss 0.007029    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.574542    
2023-01-14 20:59:40,515 - --- validate (epoch=153)-----------
2023-01-14 20:59:40,515 - 101 samples (240 per mini-batch)
2023-01-14 20:59:41,705 - Epoch: [153][    1/    1]    Loss 0.065703    Top1 99.009901    Top5 100.000000    
2023-01-14 20:59:41,748 - ==> Top1: 99.010    Top5: 100.000    Loss: 0.066

2023-01-14 20:59:41,763 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 153]
2023-01-14 20:59:41,763 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:59:41,796 - 

2023-01-14 20:59:41,797 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:59:43,742 - Epoch: [154][    4/    4]    Overall Loss 0.006809    Objective Loss 0.006809    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.486005    
2023-01-14 20:59:43,782 - --- validate (epoch=154)-----------
2023-01-14 20:59:43,783 - 101 samples (240 per mini-batch)
2023-01-14 20:59:44,905 - Epoch: [154][    1/    1]    Loss 0.079541    Top1 98.019802    Top5 100.000000    
2023-01-14 20:59:44,936 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.080

2023-01-14 20:59:44,951 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 153]
2023-01-14 20:59:44,951 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:59:44,995 - 

2023-01-14 20:59:44,995 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:59:46,916 - Epoch: [155][    4/    4]    Overall Loss 0.006931    Objective Loss 0.006931    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.479901    
2023-01-14 20:59:46,954 - --- validate (epoch=155)-----------
2023-01-14 20:59:46,955 - 101 samples (240 per mini-batch)
2023-01-14 20:59:48,057 - Epoch: [155][    1/    1]    Loss 0.085762    Top1 97.029703    Top5 100.000000    
2023-01-14 20:59:48,098 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.086

2023-01-14 20:59:48,115 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 153]
2023-01-14 20:59:48,116 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:59:48,169 - 

2023-01-14 20:59:48,169 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:59:50,303 - Epoch: [156][    4/    4]    Overall Loss 0.007034    Objective Loss 0.007034    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.532919    
2023-01-14 20:59:50,344 - --- validate (epoch=156)-----------
2023-01-14 20:59:50,345 - 101 samples (240 per mini-batch)
2023-01-14 20:59:51,507 - Epoch: [156][    1/    1]    Loss 0.087595    Top1 97.029703    Top5 100.000000    
2023-01-14 20:59:51,557 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.088

2023-01-14 20:59:51,567 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 153]
2023-01-14 20:59:51,567 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:59:51,611 - 

2023-01-14 20:59:51,612 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:59:53,365 - Epoch: [157][    4/    4]    Overall Loss 0.006710    Objective Loss 0.006710    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.437846    
2023-01-14 20:59:53,417 - --- validate (epoch=157)-----------
2023-01-14 20:59:53,418 - 101 samples (240 per mini-batch)
2023-01-14 20:59:54,513 - Epoch: [157][    1/    1]    Loss 0.100990    Top1 97.029703    Top5 100.000000    
2023-01-14 20:59:54,549 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.101

2023-01-14 20:59:54,560 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 153]
2023-01-14 20:59:54,560 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:59:54,619 - 

2023-01-14 20:59:54,620 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:59:56,340 - Epoch: [158][    4/    4]    Overall Loss 0.007181    Objective Loss 0.007181    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.429742    
2023-01-14 20:59:56,389 - --- validate (epoch=158)-----------
2023-01-14 20:59:56,390 - 101 samples (240 per mini-batch)
2023-01-14 20:59:57,465 - Epoch: [158][    1/    1]    Loss 0.082288    Top1 97.029703    Top5 100.000000    
2023-01-14 20:59:57,504 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.082

2023-01-14 20:59:57,521 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 153]
2023-01-14 20:59:57,521 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 20:59:57,574 - 

2023-01-14 20:59:57,575 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 20:59:59,533 - Epoch: [159][    4/    4]    Overall Loss 0.006855    Objective Loss 0.006855    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.488976    
2023-01-14 20:59:59,577 - --- validate (epoch=159)-----------
2023-01-14 20:59:59,577 - 101 samples (240 per mini-batch)
2023-01-14 21:00:00,706 - Epoch: [159][    1/    1]    Loss 0.114593    Top1 96.039604    Top5 100.000000    
2023-01-14 21:00:00,747 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.115

2023-01-14 21:00:00,753 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 153]
2023-01-14 21:00:00,754 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:00:00,797 - 

2023-01-14 21:00:00,797 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:00:02,677 - Epoch: [160][    4/    4]    Overall Loss 0.006804    Objective Loss 0.006804    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.469496    
2023-01-14 21:00:02,715 - --- validate (epoch=160)-----------
2023-01-14 21:00:02,716 - 101 samples (240 per mini-batch)
2023-01-14 21:00:03,873 - Epoch: [160][    1/    1]    Loss 0.060538    Top1 98.019802    Top5 100.000000    
2023-01-14 21:00:03,917 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.061

2023-01-14 21:00:03,926 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 153]
2023-01-14 21:00:03,926 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:00:03,961 - 

2023-01-14 21:00:03,961 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:00:06,358 - Epoch: [161][    4/    4]    Overall Loss 0.007070    Objective Loss 0.007070    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.598718    
2023-01-14 21:00:06,401 - --- validate (epoch=161)-----------
2023-01-14 21:00:06,401 - 101 samples (240 per mini-batch)
2023-01-14 21:00:07,524 - Epoch: [161][    1/    1]    Loss 0.086385    Top1 97.029703    Top5 100.000000    
2023-01-14 21:00:07,563 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.086

2023-01-14 21:00:07,572 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 153]
2023-01-14 21:00:07,573 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:00:07,622 - 

2023-01-14 21:00:07,624 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:00:10,077 - Epoch: [162][    4/    4]    Overall Loss 0.006849    Objective Loss 0.006849    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.612959    
2023-01-14 21:00:10,114 - --- validate (epoch=162)-----------
2023-01-14 21:00:10,114 - 101 samples (240 per mini-batch)
2023-01-14 21:00:11,251 - Epoch: [162][    1/    1]    Loss 0.091440    Top1 97.029703    Top5 100.000000    
2023-01-14 21:00:11,293 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.091

2023-01-14 21:00:11,301 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 153]
2023-01-14 21:00:11,302 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:00:11,343 - 

2023-01-14 21:00:11,344 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:00:13,266 - Epoch: [163][    4/    4]    Overall Loss 0.006936    Objective Loss 0.006936    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.480127    
2023-01-14 21:00:13,307 - --- validate (epoch=163)-----------
2023-01-14 21:00:13,307 - 101 samples (240 per mini-batch)
2023-01-14 21:00:14,390 - Epoch: [163][    1/    1]    Loss 0.086669    Top1 98.019802    Top5 100.000000    
2023-01-14 21:00:14,430 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.087

2023-01-14 21:00:14,440 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 153]
2023-01-14 21:00:14,441 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:00:14,490 - 

2023-01-14 21:00:14,490 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:00:16,613 - Epoch: [164][    4/    4]    Overall Loss 0.006806    Objective Loss 0.006806    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.530271    
2023-01-14 21:00:16,661 - --- validate (epoch=164)-----------
2023-01-14 21:00:16,662 - 101 samples (240 per mini-batch)
2023-01-14 21:00:17,867 - Epoch: [164][    1/    1]    Loss 0.111818    Top1 96.039604    Top5 100.000000    
2023-01-14 21:00:17,904 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.112

2023-01-14 21:00:17,923 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 153]
2023-01-14 21:00:17,924 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:00:17,971 - 

2023-01-14 21:00:17,972 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:00:19,929 - Epoch: [165][    4/    4]    Overall Loss 0.007074    Objective Loss 0.007074    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.488802    
2023-01-14 21:00:19,971 - --- validate (epoch=165)-----------
2023-01-14 21:00:19,972 - 101 samples (240 per mini-batch)
2023-01-14 21:00:21,085 - Epoch: [165][    1/    1]    Loss 0.095743    Top1 97.029703    Top5 100.000000    
2023-01-14 21:00:21,127 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.096

2023-01-14 21:00:21,139 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 153]
2023-01-14 21:00:21,140 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:00:21,179 - 

2023-01-14 21:00:21,180 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:00:23,769 - Epoch: [166][    4/    4]    Overall Loss 0.006877    Objective Loss 0.006877    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.647038    
2023-01-14 21:00:23,808 - --- validate (epoch=166)-----------
2023-01-14 21:00:23,809 - 101 samples (240 per mini-batch)
2023-01-14 21:00:24,904 - Epoch: [166][    1/    1]    Loss 0.074909    Top1 97.029703    Top5 100.000000    
2023-01-14 21:00:24,946 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.075

2023-01-14 21:00:24,968 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 153]
2023-01-14 21:00:24,968 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:00:25,020 - 

2023-01-14 21:00:25,020 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:00:26,939 - Epoch: [167][    4/    4]    Overall Loss 0.006840    Objective Loss 0.006840    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.479278    
2023-01-14 21:00:26,977 - --- validate (epoch=167)-----------
2023-01-14 21:00:26,978 - 101 samples (240 per mini-batch)
2023-01-14 21:00:28,015 - Epoch: [167][    1/    1]    Loss 0.087413    Top1 98.019802    Top5 100.000000    
2023-01-14 21:00:28,068 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.087

2023-01-14 21:00:28,076 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 153]
2023-01-14 21:00:28,077 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:00:28,123 - 

2023-01-14 21:00:28,124 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:00:30,162 - Epoch: [168][    4/    4]    Overall Loss 0.007049    Objective Loss 0.007049    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.509187    
2023-01-14 21:00:30,207 - --- validate (epoch=168)-----------
2023-01-14 21:00:30,207 - 101 samples (240 per mini-batch)
2023-01-14 21:00:31,352 - Epoch: [168][    1/    1]    Loss 0.067310    Top1 98.019802    Top5 100.000000    
2023-01-14 21:00:31,382 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.067

2023-01-14 21:00:31,398 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 153]
2023-01-14 21:00:31,398 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:00:31,453 - 

2023-01-14 21:00:31,453 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:00:33,666 - Epoch: [169][    4/    4]    Overall Loss 0.006571    Objective Loss 0.006571    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.552956    
2023-01-14 21:00:33,706 - --- validate (epoch=169)-----------
2023-01-14 21:00:33,706 - 101 samples (240 per mini-batch)
2023-01-14 21:00:34,718 - Epoch: [169][    1/    1]    Loss 0.075740    Top1 98.019802    Top5 100.000000    
2023-01-14 21:00:34,759 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.076

2023-01-14 21:00:34,768 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 153]
2023-01-14 21:00:34,769 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:00:34,814 - 

2023-01-14 21:00:34,814 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:00:36,548 - Epoch: [170][    4/    4]    Overall Loss 0.007079    Objective Loss 0.007079    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.433187    
2023-01-14 21:00:36,595 - --- validate (epoch=170)-----------
2023-01-14 21:00:36,596 - 101 samples (240 per mini-batch)
2023-01-14 21:00:37,682 - Epoch: [170][    1/    1]    Loss 0.093723    Top1 97.029703    Top5 100.000000    
2023-01-14 21:00:37,720 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.094

2023-01-14 21:00:37,732 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 153]
2023-01-14 21:00:37,732 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:00:37,770 - 

2023-01-14 21:00:37,771 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:00:39,621 - Epoch: [171][    4/    4]    Overall Loss 0.006865    Objective Loss 0.006865    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.462068    
2023-01-14 21:00:39,697 - --- validate (epoch=171)-----------
2023-01-14 21:00:39,698 - 101 samples (240 per mini-batch)
2023-01-14 21:00:40,862 - Epoch: [171][    1/    1]    Loss 0.065274    Top1 99.009901    Top5 100.000000    
2023-01-14 21:00:40,917 - ==> Top1: 99.010    Top5: 100.000    Loss: 0.065

2023-01-14 21:00:40,928 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 171]
2023-01-14 21:00:40,929 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:00:40,974 - 

2023-01-14 21:00:40,975 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:00:42,869 - Epoch: [172][    4/    4]    Overall Loss 0.006744    Objective Loss 0.006744    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.473139    
2023-01-14 21:00:42,912 - --- validate (epoch=172)-----------
2023-01-14 21:00:42,913 - 101 samples (240 per mini-batch)
2023-01-14 21:00:44,005 - Epoch: [172][    1/    1]    Loss 0.073887    Top1 98.019802    Top5 100.000000    
2023-01-14 21:00:44,046 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.074

2023-01-14 21:00:44,062 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 171]
2023-01-14 21:00:44,063 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:00:44,100 - 

2023-01-14 21:00:44,101 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:00:46,041 - Epoch: [173][    4/    4]    Overall Loss 0.006883    Objective Loss 0.006883    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.484700    
2023-01-14 21:00:46,078 - --- validate (epoch=173)-----------
2023-01-14 21:00:46,078 - 101 samples (240 per mini-batch)
2023-01-14 21:00:47,238 - Epoch: [173][    1/    1]    Loss 0.081779    Top1 97.029703    Top5 100.000000    
2023-01-14 21:00:47,280 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.082

2023-01-14 21:00:47,290 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 171]
2023-01-14 21:00:47,291 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:00:47,341 - 

2023-01-14 21:00:47,342 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:00:49,314 - Epoch: [174][    4/    4]    Overall Loss 0.006633    Objective Loss 0.006633    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.492809    
2023-01-14 21:00:49,372 - --- validate (epoch=174)-----------
2023-01-14 21:00:49,372 - 101 samples (240 per mini-batch)
2023-01-14 21:00:50,460 - Epoch: [174][    1/    1]    Loss 0.093448    Top1 97.029703    Top5 100.000000    
2023-01-14 21:00:50,505 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.093

2023-01-14 21:00:50,515 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 171]
2023-01-14 21:00:50,516 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:00:50,579 - 

2023-01-14 21:00:50,580 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:00:52,235 - Epoch: [175][    4/    4]    Overall Loss 0.006876    Objective Loss 0.006876    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.412895    
2023-01-14 21:00:52,283 - --- validate (epoch=175)-----------
2023-01-14 21:00:52,285 - 101 samples (240 per mini-batch)
2023-01-14 21:00:53,364 - Epoch: [175][    1/    1]    Loss 0.094183    Top1 96.039604    Top5 100.000000    
2023-01-14 21:00:53,400 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.094

2023-01-14 21:00:53,420 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 171]
2023-01-14 21:00:53,421 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:00:53,471 - 

2023-01-14 21:00:53,471 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:00:55,797 - Epoch: [176][    4/    4]    Overall Loss 0.007258    Objective Loss 0.007258    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.580938    
2023-01-14 21:00:55,846 - --- validate (epoch=176)-----------
2023-01-14 21:00:55,847 - 101 samples (240 per mini-batch)
2023-01-14 21:00:56,971 - Epoch: [176][    1/    1]    Loss 0.086114    Top1 98.019802    Top5 100.000000    
2023-01-14 21:00:57,014 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.086

2023-01-14 21:00:57,024 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 171]
2023-01-14 21:00:57,025 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:00:57,061 - 

2023-01-14 21:00:57,062 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:00:58,666 - Epoch: [177][    4/    4]    Overall Loss 0.006937    Objective Loss 0.006937    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.400598    
2023-01-14 21:00:58,704 - --- validate (epoch=177)-----------
2023-01-14 21:00:58,704 - 101 samples (240 per mini-batch)
2023-01-14 21:00:59,954 - Epoch: [177][    1/    1]    Loss 0.081057    Top1 98.019802    Top5 100.000000    
2023-01-14 21:00:59,987 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.081

2023-01-14 21:01:00,005 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 171]
2023-01-14 21:01:00,005 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:01:00,067 - 

2023-01-14 21:01:00,068 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:01:01,991 - Epoch: [178][    4/    4]    Overall Loss 0.006691    Objective Loss 0.006691    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.480361    
2023-01-14 21:01:02,030 - --- validate (epoch=178)-----------
2023-01-14 21:01:02,031 - 101 samples (240 per mini-batch)
2023-01-14 21:01:03,160 - Epoch: [178][    1/    1]    Loss 0.064832    Top1 99.009901    Top5 100.000000    
2023-01-14 21:01:03,200 - ==> Top1: 99.010    Top5: 100.000    Loss: 0.065

2023-01-14 21:01:03,215 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 178]
2023-01-14 21:01:03,216 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:01:03,261 - 

2023-01-14 21:01:03,262 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:01:05,132 - Epoch: [179][    4/    4]    Overall Loss 0.007053    Objective Loss 0.007053    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.467146    
2023-01-14 21:01:05,172 - --- validate (epoch=179)-----------
2023-01-14 21:01:05,173 - 101 samples (240 per mini-batch)
2023-01-14 21:01:06,325 - Epoch: [179][    1/    1]    Loss 0.089576    Top1 97.029703    Top5 100.000000    
2023-01-14 21:01:06,366 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.090

2023-01-14 21:01:06,376 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 178]
2023-01-14 21:01:06,377 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:01:06,426 - 

2023-01-14 21:01:06,426 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:01:08,481 - Epoch: [180][    4/    4]    Overall Loss 0.006806    Objective Loss 0.006806    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.513241    
2023-01-14 21:01:08,526 - --- validate (epoch=180)-----------
2023-01-14 21:01:08,527 - 101 samples (240 per mini-batch)
2023-01-14 21:01:09,811 - Epoch: [180][    1/    1]    Loss 0.075770    Top1 98.019802    Top5 100.000000    
2023-01-14 21:01:09,847 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.076

2023-01-14 21:01:09,857 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 178]
2023-01-14 21:01:09,858 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:01:09,904 - 

2023-01-14 21:01:09,904 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:01:12,365 - Epoch: [181][    4/    4]    Overall Loss 0.006864    Objective Loss 0.006864    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.614830    
2023-01-14 21:01:12,410 - --- validate (epoch=181)-----------
2023-01-14 21:01:12,411 - 101 samples (240 per mini-batch)
2023-01-14 21:01:13,543 - Epoch: [181][    1/    1]    Loss 0.100106    Top1 97.029703    Top5 100.000000    
2023-01-14 21:01:13,624 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.100

2023-01-14 21:01:13,645 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 178]
2023-01-14 21:01:13,646 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:01:13,709 - 

2023-01-14 21:01:13,709 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:01:15,903 - Epoch: [182][    4/    4]    Overall Loss 0.006931    Objective Loss 0.006931    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.547938    
2023-01-14 21:01:15,951 - --- validate (epoch=182)-----------
2023-01-14 21:01:15,952 - 101 samples (240 per mini-batch)
2023-01-14 21:01:17,048 - Epoch: [182][    1/    1]    Loss 0.091244    Top1 97.029703    Top5 100.000000    
2023-01-14 21:01:17,102 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.091

2023-01-14 21:01:17,115 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 178]
2023-01-14 21:01:17,115 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:01:17,157 - 

2023-01-14 21:01:17,157 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:01:19,040 - Epoch: [183][    4/    4]    Overall Loss 0.006728    Objective Loss 0.006728    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.470369    
2023-01-14 21:01:19,090 - --- validate (epoch=183)-----------
2023-01-14 21:01:19,090 - 101 samples (240 per mini-batch)
2023-01-14 21:01:20,211 - Epoch: [183][    1/    1]    Loss 0.099414    Top1 96.039604    Top5 100.000000    
2023-01-14 21:01:20,248 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.099

2023-01-14 21:01:20,261 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 178]
2023-01-14 21:01:20,261 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:01:20,308 - 

2023-01-14 21:01:20,308 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:01:22,740 - Epoch: [184][    4/    4]    Overall Loss 0.006687    Objective Loss 0.006687    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.607619    
2023-01-14 21:01:22,779 - --- validate (epoch=184)-----------
2023-01-14 21:01:22,780 - 101 samples (240 per mini-batch)
2023-01-14 21:01:23,916 - Epoch: [184][    1/    1]    Loss 0.096191    Top1 96.039604    Top5 100.000000    
2023-01-14 21:01:23,991 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.096

2023-01-14 21:01:23,999 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 178]
2023-01-14 21:01:23,999 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:01:24,050 - 

2023-01-14 21:01:24,051 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:01:26,115 - Epoch: [185][    4/    4]    Overall Loss 0.006844    Objective Loss 0.006844    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.514827    
2023-01-14 21:01:26,152 - --- validate (epoch=185)-----------
2023-01-14 21:01:26,153 - 101 samples (240 per mini-batch)
2023-01-14 21:01:27,305 - Epoch: [185][    1/    1]    Loss 0.086172    Top1 97.029703    Top5 100.000000    
2023-01-14 21:01:27,350 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.086

2023-01-14 21:01:27,362 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 178]
2023-01-14 21:01:27,362 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:01:27,400 - 

2023-01-14 21:01:27,400 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:01:29,302 - Epoch: [186][    4/    4]    Overall Loss 0.006830    Objective Loss 0.006830    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.474800    
2023-01-14 21:01:29,341 - --- validate (epoch=186)-----------
2023-01-14 21:01:29,342 - 101 samples (240 per mini-batch)
2023-01-14 21:01:30,460 - Epoch: [186][    1/    1]    Loss 0.068971    Top1 99.009901    Top5 100.000000    
2023-01-14 21:01:30,499 - ==> Top1: 99.010    Top5: 100.000    Loss: 0.069

2023-01-14 21:01:30,510 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 186]
2023-01-14 21:01:30,510 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:01:30,553 - 

2023-01-14 21:01:30,553 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:01:32,424 - Epoch: [187][    4/    4]    Overall Loss 0.006859    Objective Loss 0.006859    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.467351    
2023-01-14 21:01:32,472 - --- validate (epoch=187)-----------
2023-01-14 21:01:32,473 - 101 samples (240 per mini-batch)
2023-01-14 21:01:33,556 - Epoch: [187][    1/    1]    Loss 0.112550    Top1 96.039604    Top5 100.000000    
2023-01-14 21:01:33,600 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.113

2023-01-14 21:01:33,624 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 186]
2023-01-14 21:01:33,624 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:01:33,677 - 

2023-01-14 21:01:33,678 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:01:36,107 - Epoch: [188][    4/    4]    Overall Loss 0.006939    Objective Loss 0.006939    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.607091    
2023-01-14 21:01:36,148 - --- validate (epoch=188)-----------
2023-01-14 21:01:36,149 - 101 samples (240 per mini-batch)
2023-01-14 21:01:37,246 - Epoch: [188][    1/    1]    Loss 0.116771    Top1 96.039604    Top5 100.000000    
2023-01-14 21:01:37,283 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.117

2023-01-14 21:01:37,296 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 186]
2023-01-14 21:01:37,298 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:01:37,342 - 

2023-01-14 21:01:37,343 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:01:38,999 - Epoch: [189][    4/    4]    Overall Loss 0.006708    Objective Loss 0.006708    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.413649    
2023-01-14 21:01:39,052 - --- validate (epoch=189)-----------
2023-01-14 21:01:39,052 - 101 samples (240 per mini-batch)
2023-01-14 21:01:40,255 - Epoch: [189][    1/    1]    Loss 0.081831    Top1 98.019802    Top5 100.000000    
2023-01-14 21:01:40,302 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.082

2023-01-14 21:01:40,323 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 186]
2023-01-14 21:01:40,324 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:01:40,390 - 

2023-01-14 21:01:40,391 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:01:42,503 - Epoch: [190][    4/    4]    Overall Loss 0.006734    Objective Loss 0.006734    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.527609    
2023-01-14 21:01:42,542 - --- validate (epoch=190)-----------
2023-01-14 21:01:42,543 - 101 samples (240 per mini-batch)
2023-01-14 21:01:43,670 - Epoch: [190][    1/    1]    Loss 0.114491    Top1 95.049505    Top5 100.000000    
2023-01-14 21:01:43,706 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.114

2023-01-14 21:01:43,718 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 186]
2023-01-14 21:01:43,718 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:01:43,759 - 

2023-01-14 21:01:43,759 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:01:45,554 - Epoch: [191][    4/    4]    Overall Loss 0.006541    Objective Loss 0.006541    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.448185    
2023-01-14 21:01:45,594 - --- validate (epoch=191)-----------
2023-01-14 21:01:45,595 - 101 samples (240 per mini-batch)
2023-01-14 21:01:46,711 - Epoch: [191][    1/    1]    Loss 0.116355    Top1 95.049505    Top5 100.000000    
2023-01-14 21:01:46,750 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.116

2023-01-14 21:01:46,760 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 186]
2023-01-14 21:01:46,761 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:01:46,803 - 

2023-01-14 21:01:46,803 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:01:48,712 - Epoch: [192][    4/    4]    Overall Loss 0.006738    Objective Loss 0.006738    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.476563    
2023-01-14 21:01:48,769 - --- validate (epoch=192)-----------
2023-01-14 21:01:48,770 - 101 samples (240 per mini-batch)
2023-01-14 21:01:50,003 - Epoch: [192][    1/    1]    Loss 0.066040    Top1 98.019802    Top5 100.000000    
2023-01-14 21:01:50,050 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.066

2023-01-14 21:01:50,059 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 186]
2023-01-14 21:01:50,059 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:01:50,105 - 

2023-01-14 21:01:50,106 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:01:52,396 - Epoch: [193][    4/    4]    Overall Loss 0.006805    Objective Loss 0.006805    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.572067    
2023-01-14 21:01:52,453 - --- validate (epoch=193)-----------
2023-01-14 21:01:52,454 - 101 samples (240 per mini-batch)
2023-01-14 21:01:53,678 - Epoch: [193][    1/    1]    Loss 0.096011    Top1 97.029703    Top5 100.000000    
2023-01-14 21:01:53,723 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.096

2023-01-14 21:01:53,735 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 186]
2023-01-14 21:01:53,735 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:01:53,785 - 

2023-01-14 21:01:53,786 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:01:55,752 - Epoch: [194][    4/    4]    Overall Loss 0.006699    Objective Loss 0.006699    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.491332    
2023-01-14 21:01:55,791 - --- validate (epoch=194)-----------
2023-01-14 21:01:55,791 - 101 samples (240 per mini-batch)
2023-01-14 21:01:56,929 - Epoch: [194][    1/    1]    Loss 0.111058    Top1 96.039604    Top5 100.000000    
2023-01-14 21:01:56,966 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.111

2023-01-14 21:01:56,977 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 186]
2023-01-14 21:01:56,978 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:01:57,013 - 

2023-01-14 21:01:57,013 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:01:59,262 - Epoch: [195][    4/    4]    Overall Loss 0.006749    Objective Loss 0.006749    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.561985    
2023-01-14 21:01:59,305 - --- validate (epoch=195)-----------
2023-01-14 21:01:59,306 - 101 samples (240 per mini-batch)
2023-01-14 21:02:00,403 - Epoch: [195][    1/    1]    Loss 0.092633    Top1 97.029703    Top5 100.000000    
2023-01-14 21:02:00,448 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.093

2023-01-14 21:02:00,457 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 186]
2023-01-14 21:02:00,457 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:02:00,494 - 

2023-01-14 21:02:00,494 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:02:02,415 - Epoch: [196][    4/    4]    Overall Loss 0.006721    Objective Loss 0.006721    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.479911    
2023-01-14 21:02:02,453 - --- validate (epoch=196)-----------
2023-01-14 21:02:02,454 - 101 samples (240 per mini-batch)
2023-01-14 21:02:03,558 - Epoch: [196][    1/    1]    Loss 0.085177    Top1 97.029703    Top5 100.000000    
2023-01-14 21:02:03,597 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.085

2023-01-14 21:02:03,616 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 186]
2023-01-14 21:02:03,616 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:02:03,673 - 

2023-01-14 21:02:03,673 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:02:05,459 - Epoch: [197][    4/    4]    Overall Loss 0.006764    Objective Loss 0.006764    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.445934    
2023-01-14 21:02:05,497 - --- validate (epoch=197)-----------
2023-01-14 21:02:05,497 - 101 samples (240 per mini-batch)
2023-01-14 21:02:06,648 - Epoch: [197][    1/    1]    Loss 0.092284    Top1 96.039604    Top5 100.000000    
2023-01-14 21:02:06,697 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.092

2023-01-14 21:02:06,706 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 186]
2023-01-14 21:02:06,707 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:02:06,735 - 

2023-01-14 21:02:06,736 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:02:08,471 - Epoch: [198][    4/    4]    Overall Loss 0.006795    Objective Loss 0.006795    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.433275    
2023-01-14 21:02:08,509 - --- validate (epoch=198)-----------
2023-01-14 21:02:08,509 - 101 samples (240 per mini-batch)
2023-01-14 21:02:09,806 - Epoch: [198][    1/    1]    Loss 0.067681    Top1 99.009901    Top5 100.000000    
2023-01-14 21:02:09,873 - ==> Top1: 99.010    Top5: 100.000    Loss: 0.068

2023-01-14 21:02:09,880 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:02:09,881 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:02:09,925 - 

2023-01-14 21:02:09,926 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:02:11,834 - Epoch: [199][    4/    4]    Overall Loss 0.007069    Objective Loss 0.007069    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.476670    
2023-01-14 21:02:11,875 - --- validate (epoch=199)-----------
2023-01-14 21:02:11,876 - 101 samples (240 per mini-batch)
2023-01-14 21:02:12,988 - Epoch: [199][    1/    1]    Loss 0.078850    Top1 98.019802    Top5 100.000000    
2023-01-14 21:02:13,034 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.079

2023-01-14 21:02:13,044 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:02:13,044 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:02:13,084 - 

2023-01-14 21:02:13,085 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:02:15,147 - Epoch: [200][    4/    4]    Overall Loss 0.006624    Objective Loss 0.006624    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.514726    
2023-01-14 21:02:15,189 - --- validate (epoch=200)-----------
2023-01-14 21:02:15,190 - 101 samples (240 per mini-batch)
2023-01-14 21:02:16,337 - Epoch: [200][    1/    1]    Loss 0.086715    Top1 98.019802    Top5 100.000000    
2023-01-14 21:02:16,378 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.087

2023-01-14 21:02:16,390 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:02:16,391 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:02:16,441 - 

2023-01-14 21:02:16,441 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:02:18,343 - Epoch: [201][    4/    4]    Overall Loss 0.006743    Objective Loss 0.006743    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.475148    
2023-01-14 21:02:18,386 - --- validate (epoch=201)-----------
2023-01-14 21:02:18,387 - 101 samples (240 per mini-batch)
2023-01-14 21:02:19,544 - Epoch: [201][    1/    1]    Loss 0.081556    Top1 98.019802    Top5 100.000000    
2023-01-14 21:02:19,590 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.082

2023-01-14 21:02:19,598 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:02:19,599 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:02:19,635 - 

2023-01-14 21:02:19,635 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:02:21,713 - Epoch: [202][    4/    4]    Overall Loss 0.006617    Objective Loss 0.006617    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.519116    
2023-01-14 21:02:21,759 - --- validate (epoch=202)-----------
2023-01-14 21:02:21,760 - 101 samples (240 per mini-batch)
2023-01-14 21:02:22,884 - Epoch: [202][    1/    1]    Loss 0.080553    Top1 98.019802    Top5 100.000000    
2023-01-14 21:02:22,918 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.081

2023-01-14 21:02:22,932 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:02:22,932 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:02:22,985 - 

2023-01-14 21:02:22,986 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:02:24,579 - Epoch: [203][    4/    4]    Overall Loss 0.006900    Objective Loss 0.006900    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.397849    
2023-01-14 21:02:24,623 - --- validate (epoch=203)-----------
2023-01-14 21:02:24,624 - 101 samples (240 per mini-batch)
2023-01-14 21:02:25,716 - Epoch: [203][    1/    1]    Loss 0.101280    Top1 97.029703    Top5 100.000000    
2023-01-14 21:02:25,756 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.101

2023-01-14 21:02:25,768 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:02:25,769 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:02:25,808 - 

2023-01-14 21:02:25,809 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:02:27,690 - Epoch: [204][    4/    4]    Overall Loss 0.006696    Objective Loss 0.006696    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.469378    
2023-01-14 21:02:27,731 - --- validate (epoch=204)-----------
2023-01-14 21:02:27,732 - 101 samples (240 per mini-batch)
2023-01-14 21:02:28,850 - Epoch: [204][    1/    1]    Loss 0.078260    Top1 97.029703    Top5 100.000000    
2023-01-14 21:02:28,892 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.078

2023-01-14 21:02:28,903 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:02:28,905 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:02:28,948 - 

2023-01-14 21:02:28,949 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:02:30,889 - Epoch: [205][    4/    4]    Overall Loss 0.006691    Objective Loss 0.006691    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.484799    
2023-01-14 21:02:30,933 - --- validate (epoch=205)-----------
2023-01-14 21:02:30,933 - 101 samples (240 per mini-batch)
2023-01-14 21:02:32,027 - Epoch: [205][    1/    1]    Loss 0.082789    Top1 97.029703    Top5 100.000000    
2023-01-14 21:02:32,071 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.083

2023-01-14 21:02:32,087 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:02:32,087 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:02:32,133 - 

2023-01-14 21:02:32,134 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:02:33,758 - Epoch: [206][    4/    4]    Overall Loss 0.006565    Objective Loss 0.006565    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.405740    
2023-01-14 21:02:33,809 - --- validate (epoch=206)-----------
2023-01-14 21:02:33,810 - 101 samples (240 per mini-batch)
2023-01-14 21:02:35,050 - Epoch: [206][    1/    1]    Loss 0.110462    Top1 95.049505    Top5 100.000000    
2023-01-14 21:02:35,095 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.110

2023-01-14 21:02:35,104 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:02:35,104 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:02:35,150 - 

2023-01-14 21:02:35,151 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:02:37,112 - Epoch: [207][    4/    4]    Overall Loss 0.006487    Objective Loss 0.006487    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.489996    
2023-01-14 21:02:37,169 - --- validate (epoch=207)-----------
2023-01-14 21:02:37,170 - 101 samples (240 per mini-batch)
2023-01-14 21:02:38,287 - Epoch: [207][    1/    1]    Loss 0.115707    Top1 96.039604    Top5 100.000000    
2023-01-14 21:02:38,322 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.116

2023-01-14 21:02:38,332 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:02:38,333 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:02:38,382 - 

2023-01-14 21:02:38,383 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:02:40,600 - Epoch: [208][    4/    4]    Overall Loss 0.006774    Objective Loss 0.006774    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.554080    
2023-01-14 21:02:40,648 - --- validate (epoch=208)-----------
2023-01-14 21:02:40,649 - 101 samples (240 per mini-batch)
2023-01-14 21:02:41,750 - Epoch: [208][    1/    1]    Loss 0.087149    Top1 97.029703    Top5 100.000000    
2023-01-14 21:02:41,787 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.087

2023-01-14 21:02:41,796 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:02:41,796 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:02:41,845 - 

2023-01-14 21:02:41,846 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:02:43,797 - Epoch: [209][    4/    4]    Overall Loss 0.006827    Objective Loss 0.006827    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.487337    
2023-01-14 21:02:43,842 - --- validate (epoch=209)-----------
2023-01-14 21:02:43,843 - 101 samples (240 per mini-batch)
2023-01-14 21:02:44,960 - Epoch: [209][    1/    1]    Loss 0.090518    Top1 97.029703    Top5 100.000000    
2023-01-14 21:02:44,998 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.091

2023-01-14 21:02:45,011 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:02:45,012 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:02:45,053 - 

2023-01-14 21:02:45,054 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:02:47,322 - Epoch: [210][    4/    4]    Overall Loss 0.006669    Objective Loss 0.006669    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.566659    
2023-01-14 21:02:47,372 - --- validate (epoch=210)-----------
2023-01-14 21:02:47,373 - 101 samples (240 per mini-batch)
2023-01-14 21:02:48,445 - Epoch: [210][    1/    1]    Loss 0.075487    Top1 97.029703    Top5 100.000000    
2023-01-14 21:02:48,482 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.075

2023-01-14 21:02:48,499 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:02:48,500 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:02:48,543 - 

2023-01-14 21:02:48,543 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:02:50,866 - Epoch: [211][    4/    4]    Overall Loss 0.006985    Objective Loss 0.006985    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.580289    
2023-01-14 21:02:50,907 - --- validate (epoch=211)-----------
2023-01-14 21:02:50,908 - 101 samples (240 per mini-batch)
2023-01-14 21:02:52,116 - Epoch: [211][    1/    1]    Loss 0.113045    Top1 95.049505    Top5 100.000000    
2023-01-14 21:02:52,153 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.113

2023-01-14 21:02:52,174 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:02:52,174 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:02:52,215 - 

2023-01-14 21:02:52,215 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:02:54,187 - Epoch: [212][    4/    4]    Overall Loss 0.006578    Objective Loss 0.006578    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.492273    
2023-01-14 21:02:54,223 - --- validate (epoch=212)-----------
2023-01-14 21:02:54,224 - 101 samples (240 per mini-batch)
2023-01-14 21:02:55,367 - Epoch: [212][    1/    1]    Loss 0.096477    Top1 96.039604    Top5 100.000000    
2023-01-14 21:02:55,403 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.096

2023-01-14 21:02:55,413 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:02:55,414 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:02:55,463 - 

2023-01-14 21:02:55,463 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:02:57,221 - Epoch: [213][    4/    4]    Overall Loss 0.006625    Objective Loss 0.006625    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.439062    
2023-01-14 21:02:57,269 - --- validate (epoch=213)-----------
2023-01-14 21:02:57,270 - 101 samples (240 per mini-batch)
2023-01-14 21:02:58,388 - Epoch: [213][    1/    1]    Loss 0.096490    Top1 96.039604    Top5 100.000000    
2023-01-14 21:02:58,424 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.096

2023-01-14 21:02:58,435 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:02:58,435 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:02:58,483 - 

2023-01-14 21:02:58,483 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:03:00,721 - Epoch: [214][    4/    4]    Overall Loss 0.006635    Objective Loss 0.006635    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.558961    
2023-01-14 21:03:00,765 - --- validate (epoch=214)-----------
2023-01-14 21:03:00,765 - 101 samples (240 per mini-batch)
2023-01-14 21:03:01,914 - Epoch: [214][    1/    1]    Loss 0.111017    Top1 96.039604    Top5 100.000000    
2023-01-14 21:03:01,954 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.111

2023-01-14 21:03:01,966 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:03:01,967 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:03:02,013 - 

2023-01-14 21:03:02,014 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:03:04,031 - Epoch: [215][    4/    4]    Overall Loss 0.006448    Objective Loss 0.006448    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.504009    
2023-01-14 21:03:04,086 - --- validate (epoch=215)-----------
2023-01-14 21:03:04,087 - 101 samples (240 per mini-batch)
2023-01-14 21:03:05,185 - Epoch: [215][    1/    1]    Loss 0.115431    Top1 96.039604    Top5 100.000000    
2023-01-14 21:03:05,227 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.115

2023-01-14 21:03:05,244 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:03:05,244 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:03:05,288 - 

2023-01-14 21:03:05,288 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:03:07,077 - Epoch: [216][    4/    4]    Overall Loss 0.006578    Objective Loss 0.006578    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.446689    
2023-01-14 21:03:07,120 - --- validate (epoch=216)-----------
2023-01-14 21:03:07,121 - 101 samples (240 per mini-batch)
2023-01-14 21:03:08,280 - Epoch: [216][    1/    1]    Loss 0.109923    Top1 97.029703    Top5 100.000000    
2023-01-14 21:03:08,336 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.110

2023-01-14 21:03:08,349 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:03:08,350 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:03:08,385 - 

2023-01-14 21:03:08,385 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:03:10,958 - Epoch: [217][    4/    4]    Overall Loss 0.006662    Objective Loss 0.006662    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.642816    
2023-01-14 21:03:11,030 - --- validate (epoch=217)-----------
2023-01-14 21:03:11,030 - 101 samples (240 per mini-batch)
2023-01-14 21:03:12,135 - Epoch: [217][    1/    1]    Loss 0.088933    Top1 97.029703    Top5 100.000000    
2023-01-14 21:03:12,177 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.089

2023-01-14 21:03:12,186 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:03:12,187 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:03:12,232 - 

2023-01-14 21:03:12,233 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:03:13,984 - Epoch: [218][    4/    4]    Overall Loss 0.006674    Objective Loss 0.006674    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.437440    
2023-01-14 21:03:14,023 - --- validate (epoch=218)-----------
2023-01-14 21:03:14,024 - 101 samples (240 per mini-batch)
2023-01-14 21:03:15,239 - Epoch: [218][    1/    1]    Loss 0.095728    Top1 97.029703    Top5 100.000000    
2023-01-14 21:03:15,274 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.096

2023-01-14 21:03:15,291 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:03:15,292 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:03:15,338 - 

2023-01-14 21:03:15,339 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:03:17,335 - Epoch: [219][    4/    4]    Overall Loss 0.006579    Objective Loss 0.006579    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.498419    
2023-01-14 21:03:17,394 - --- validate (epoch=219)-----------
2023-01-14 21:03:17,394 - 101 samples (240 per mini-batch)
2023-01-14 21:03:18,487 - Epoch: [219][    1/    1]    Loss 0.101635    Top1 97.029703    Top5 100.000000    
2023-01-14 21:03:18,531 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.102

2023-01-14 21:03:18,540 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:03:18,540 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:03:18,570 - 

2023-01-14 21:03:18,571 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:03:20,466 - Epoch: [220][    4/    4]    Overall Loss 0.006554    Objective Loss 0.006554    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.473148    
2023-01-14 21:03:20,517 - --- validate (epoch=220)-----------
2023-01-14 21:03:20,519 - 101 samples (240 per mini-batch)
2023-01-14 21:03:21,516 - Epoch: [220][    1/    1]    Loss 0.120705    Top1 95.049505    Top5 100.000000    
2023-01-14 21:03:21,560 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.121

2023-01-14 21:03:21,568 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:03:21,569 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:03:21,605 - 

2023-01-14 21:03:21,605 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:03:23,343 - Epoch: [221][    4/    4]    Overall Loss 0.006472    Objective Loss 0.006472    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.434168    
2023-01-14 21:03:23,390 - --- validate (epoch=221)-----------
2023-01-14 21:03:23,391 - 101 samples (240 per mini-batch)
2023-01-14 21:03:24,519 - Epoch: [221][    1/    1]    Loss 0.075634    Top1 97.029703    Top5 100.000000    
2023-01-14 21:03:24,558 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.076

2023-01-14 21:03:24,568 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:03:24,568 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:03:24,605 - 

2023-01-14 21:03:24,606 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:03:26,347 - Epoch: [222][    4/    4]    Overall Loss 0.006673    Objective Loss 0.006673    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.434955    
2023-01-14 21:03:26,393 - --- validate (epoch=222)-----------
2023-01-14 21:03:26,394 - 101 samples (240 per mini-batch)
2023-01-14 21:03:27,384 - Epoch: [222][    1/    1]    Loss 0.095572    Top1 97.029703    Top5 100.000000    
2023-01-14 21:03:27,422 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.096

2023-01-14 21:03:27,438 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:03:27,438 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:03:27,484 - 

2023-01-14 21:03:27,485 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:03:29,736 - Epoch: [223][    4/    4]    Overall Loss 0.006620    Objective Loss 0.006620    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.562384    
2023-01-14 21:03:29,780 - --- validate (epoch=223)-----------
2023-01-14 21:03:29,781 - 101 samples (240 per mini-batch)
2023-01-14 21:03:30,908 - Epoch: [223][    1/    1]    Loss 0.116951    Top1 95.049505    Top5 100.000000    
2023-01-14 21:03:30,950 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.117

2023-01-14 21:03:30,959 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:03:30,960 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:03:31,010 - 

2023-01-14 21:03:31,011 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:03:33,035 - Epoch: [224][    4/    4]    Overall Loss 0.006526    Objective Loss 0.006526    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.505219    
2023-01-14 21:03:33,101 - --- validate (epoch=224)-----------
2023-01-14 21:03:33,101 - 101 samples (240 per mini-batch)
2023-01-14 21:03:34,241 - Epoch: [224][    1/    1]    Loss 0.101466    Top1 96.039604    Top5 100.000000    
2023-01-14 21:03:34,280 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.101

2023-01-14 21:03:34,292 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:03:34,292 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:03:34,337 - 

2023-01-14 21:03:34,337 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:03:36,230 - Epoch: [225][    4/    4]    Overall Loss 0.006621    Objective Loss 0.006621    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.473045    
2023-01-14 21:03:36,271 - --- validate (epoch=225)-----------
2023-01-14 21:03:36,272 - 101 samples (240 per mini-batch)
2023-01-14 21:03:37,260 - Epoch: [225][    1/    1]    Loss 0.081803    Top1 98.019802    Top5 100.000000    
2023-01-14 21:03:37,308 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.082

2023-01-14 21:03:37,321 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:03:37,322 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:03:37,375 - 

2023-01-14 21:03:37,376 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:03:39,587 - Epoch: [226][    4/    4]    Overall Loss 0.006517    Objective Loss 0.006517    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.552079    
2023-01-14 21:03:39,629 - --- validate (epoch=226)-----------
2023-01-14 21:03:39,630 - 101 samples (240 per mini-batch)
2023-01-14 21:03:40,759 - Epoch: [226][    1/    1]    Loss 0.097282    Top1 97.029703    Top5 100.000000    
2023-01-14 21:03:40,803 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.097

2023-01-14 21:03:40,811 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:03:40,811 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:03:40,848 - 

2023-01-14 21:03:40,849 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:03:42,594 - Epoch: [227][    4/    4]    Overall Loss 0.006573    Objective Loss 0.006573    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.435790    
2023-01-14 21:03:42,631 - --- validate (epoch=227)-----------
2023-01-14 21:03:42,632 - 101 samples (240 per mini-batch)
2023-01-14 21:03:43,731 - Epoch: [227][    1/    1]    Loss 0.113628    Top1 96.039604    Top5 100.000000    
2023-01-14 21:03:43,781 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.114

2023-01-14 21:03:43,791 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:03:43,792 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:03:43,842 - 

2023-01-14 21:03:43,842 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:03:45,910 - Epoch: [228][    4/    4]    Overall Loss 0.006647    Objective Loss 0.006647    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.516596    
2023-01-14 21:03:45,950 - --- validate (epoch=228)-----------
2023-01-14 21:03:45,951 - 101 samples (240 per mini-batch)
2023-01-14 21:03:47,047 - Epoch: [228][    1/    1]    Loss 0.104294    Top1 96.039604    Top5 100.000000    
2023-01-14 21:03:47,083 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.104

2023-01-14 21:03:47,098 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:03:47,098 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:03:47,140 - 

2023-01-14 21:03:47,141 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:03:49,140 - Epoch: [229][    4/    4]    Overall Loss 0.006615    Objective Loss 0.006615    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.499349    
2023-01-14 21:03:49,184 - --- validate (epoch=229)-----------
2023-01-14 21:03:49,185 - 101 samples (240 per mini-batch)
2023-01-14 21:03:50,482 - Epoch: [229][    1/    1]    Loss 0.112617    Top1 95.049505    Top5 100.000000    
2023-01-14 21:03:50,529 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.113

2023-01-14 21:03:50,541 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:03:50,542 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:03:50,597 - 

2023-01-14 21:03:50,598 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:03:52,696 - Epoch: [230][    4/    4]    Overall Loss 0.006641    Objective Loss 0.006641    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.524066    
2023-01-14 21:03:52,747 - --- validate (epoch=230)-----------
2023-01-14 21:03:52,748 - 101 samples (240 per mini-batch)
2023-01-14 21:03:53,847 - Epoch: [230][    1/    1]    Loss 0.089036    Top1 97.029703    Top5 100.000000    
2023-01-14 21:03:53,900 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.089

2023-01-14 21:03:53,912 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:03:53,912 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:03:53,950 - 

2023-01-14 21:03:53,951 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:03:55,844 - Epoch: [231][    4/    4]    Overall Loss 0.006606    Objective Loss 0.006606    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.472899    
2023-01-14 21:03:55,888 - --- validate (epoch=231)-----------
2023-01-14 21:03:55,889 - 101 samples (240 per mini-batch)
2023-01-14 21:03:57,019 - Epoch: [231][    1/    1]    Loss 0.088053    Top1 98.019802    Top5 100.000000    
2023-01-14 21:03:57,054 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.088

2023-01-14 21:03:57,068 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:03:57,070 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:03:57,114 - 

2023-01-14 21:03:57,115 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:03:59,010 - Epoch: [232][    4/    4]    Overall Loss 0.006339    Objective Loss 0.006339    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.473410    
2023-01-14 21:03:59,052 - --- validate (epoch=232)-----------
2023-01-14 21:03:59,053 - 101 samples (240 per mini-batch)
2023-01-14 21:04:00,125 - Epoch: [232][    1/    1]    Loss 0.087771    Top1 96.039604    Top5 100.000000    
2023-01-14 21:04:00,175 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.088

2023-01-14 21:04:00,190 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:04:00,190 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:04:00,229 - 

2023-01-14 21:04:00,230 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:04:02,030 - Epoch: [233][    4/    4]    Overall Loss 0.006401    Objective Loss 0.006401    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.449603    
2023-01-14 21:04:02,083 - --- validate (epoch=233)-----------
2023-01-14 21:04:02,083 - 101 samples (240 per mini-batch)
2023-01-14 21:04:03,199 - Epoch: [233][    1/    1]    Loss 0.114159    Top1 95.049505    Top5 100.000000    
2023-01-14 21:04:03,244 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.114

2023-01-14 21:04:03,254 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:04:03,255 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:04:03,298 - 

2023-01-14 21:04:03,298 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:04:05,263 - Epoch: [234][    4/    4]    Overall Loss 0.006622    Objective Loss 0.006622    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.490721    
2023-01-14 21:04:05,305 - --- validate (epoch=234)-----------
2023-01-14 21:04:05,306 - 101 samples (240 per mini-batch)
2023-01-14 21:04:06,491 - Epoch: [234][    1/    1]    Loss 0.091450    Top1 96.039604    Top5 100.000000    
2023-01-14 21:04:06,542 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.091

2023-01-14 21:04:06,560 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:04:06,560 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:04:06,612 - 

2023-01-14 21:04:06,613 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:04:08,783 - Epoch: [235][    4/    4]    Overall Loss 0.006896    Objective Loss 0.006896    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.542027    
2023-01-14 21:04:08,833 - --- validate (epoch=235)-----------
2023-01-14 21:04:08,834 - 101 samples (240 per mini-batch)
2023-01-14 21:04:10,090 - Epoch: [235][    1/    1]    Loss 0.091640    Top1 96.039604    Top5 100.000000    
2023-01-14 21:04:10,126 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.092

2023-01-14 21:04:10,137 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:04:10,139 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:04:10,182 - 

2023-01-14 21:04:10,182 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:04:12,046 - Epoch: [236][    4/    4]    Overall Loss 0.006583    Objective Loss 0.006583    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.465656    
2023-01-14 21:04:12,085 - --- validate (epoch=236)-----------
2023-01-14 21:04:12,086 - 101 samples (240 per mini-batch)
2023-01-14 21:04:13,215 - Epoch: [236][    1/    1]    Loss 0.101913    Top1 97.029703    Top5 100.000000    
2023-01-14 21:04:13,262 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.102

2023-01-14 21:04:13,272 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:04:13,272 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:04:13,322 - 

2023-01-14 21:04:13,322 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:04:15,585 - Epoch: [237][    4/    4]    Overall Loss 0.006420    Objective Loss 0.006420    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.565324    
2023-01-14 21:04:15,625 - --- validate (epoch=237)-----------
2023-01-14 21:04:15,626 - 101 samples (240 per mini-batch)
2023-01-14 21:04:16,772 - Epoch: [237][    1/    1]    Loss 0.102138    Top1 97.029703    Top5 100.000000    
2023-01-14 21:04:16,809 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.102

2023-01-14 21:04:16,822 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:04:16,823 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:04:16,868 - 

2023-01-14 21:04:16,868 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:04:18,751 - Epoch: [238][    4/    4]    Overall Loss 0.006220    Objective Loss 0.006220    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.470304    
2023-01-14 21:04:18,793 - --- validate (epoch=238)-----------
2023-01-14 21:04:18,794 - 101 samples (240 per mini-batch)
2023-01-14 21:04:19,980 - Epoch: [238][    1/    1]    Loss 0.093645    Top1 97.029703    Top5 100.000000    
2023-01-14 21:04:20,039 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.094

2023-01-14 21:04:20,048 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:04:20,049 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:04:20,086 - 

2023-01-14 21:04:20,087 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:04:22,598 - Epoch: [239][    4/    4]    Overall Loss 0.006528    Objective Loss 0.006528    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.627323    
2023-01-14 21:04:22,636 - --- validate (epoch=239)-----------
2023-01-14 21:04:22,637 - 101 samples (240 per mini-batch)
2023-01-14 21:04:23,822 - Epoch: [239][    1/    1]    Loss 0.082188    Top1 97.029703    Top5 100.000000    
2023-01-14 21:04:23,862 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.082

2023-01-14 21:04:23,871 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:04:23,873 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:04:23,917 - 

2023-01-14 21:04:23,918 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:04:25,956 - Epoch: [240][    4/    4]    Overall Loss 0.006495    Objective Loss 0.006495    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.509275    
2023-01-14 21:04:25,999 - --- validate (epoch=240)-----------
2023-01-14 21:04:26,000 - 101 samples (240 per mini-batch)
2023-01-14 21:04:27,092 - Epoch: [240][    1/    1]    Loss 0.085125    Top1 98.019802    Top5 100.000000    
2023-01-14 21:04:27,131 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.085

2023-01-14 21:04:27,147 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:04:27,147 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:04:27,185 - 

2023-01-14 21:04:27,186 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:04:29,117 - Epoch: [241][    4/    4]    Overall Loss 0.006616    Objective Loss 0.006616    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.482327    
2023-01-14 21:04:29,161 - --- validate (epoch=241)-----------
2023-01-14 21:04:29,162 - 101 samples (240 per mini-batch)
2023-01-14 21:04:30,285 - Epoch: [241][    1/    1]    Loss 0.110381    Top1 95.049505    Top5 100.000000    
2023-01-14 21:04:30,318 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.110

2023-01-14 21:04:30,332 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 198]
2023-01-14 21:04:30,332 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:04:30,379 - 

2023-01-14 21:04:30,380 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:04:32,292 - Epoch: [242][    4/    4]    Overall Loss 0.006589    Objective Loss 0.006589    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.477611    
2023-01-14 21:04:32,344 - --- validate (epoch=242)-----------
2023-01-14 21:04:32,344 - 101 samples (240 per mini-batch)
2023-01-14 21:04:33,358 - Epoch: [242][    1/    1]    Loss 0.064586    Top1 99.009901    Top5 100.000000    
2023-01-14 21:04:33,395 - ==> Top1: 99.010    Top5: 100.000    Loss: 0.065

2023-01-14 21:04:33,409 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 242]
2023-01-14 21:04:33,410 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:04:33,455 - 

2023-01-14 21:04:33,455 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:04:35,045 - Epoch: [243][    4/    4]    Overall Loss 0.006412    Objective Loss 0.006412    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.397078    
2023-01-14 21:04:35,096 - --- validate (epoch=243)-----------
2023-01-14 21:04:35,096 - 101 samples (240 per mini-batch)
2023-01-14 21:04:36,302 - Epoch: [243][    1/    1]    Loss 0.083421    Top1 98.019802    Top5 100.000000    
2023-01-14 21:04:36,343 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.083

2023-01-14 21:04:36,354 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 242]
2023-01-14 21:04:36,354 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:04:36,389 - 

2023-01-14 21:04:36,390 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:04:37,879 - Epoch: [244][    4/    4]    Overall Loss 0.006738    Objective Loss 0.006738    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.371671    
2023-01-14 21:04:37,926 - --- validate (epoch=244)-----------
2023-01-14 21:04:37,927 - 101 samples (240 per mini-batch)
2023-01-14 21:04:39,051 - Epoch: [244][    1/    1]    Loss 0.113772    Top1 96.039604    Top5 100.000000    
2023-01-14 21:04:39,096 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.114

2023-01-14 21:04:39,105 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 242]
2023-01-14 21:04:39,106 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:04:39,145 - 

2023-01-14 21:04:39,146 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:04:40,902 - Epoch: [245][    4/    4]    Overall Loss 0.006451    Objective Loss 0.006451    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.438668    
2023-01-14 21:04:40,940 - --- validate (epoch=245)-----------
2023-01-14 21:04:40,941 - 101 samples (240 per mini-batch)
2023-01-14 21:04:42,035 - Epoch: [245][    1/    1]    Loss 0.095997    Top1 96.039604    Top5 100.000000    
2023-01-14 21:04:42,074 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.096

2023-01-14 21:04:42,084 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 242]
2023-01-14 21:04:42,084 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:04:42,123 - 

2023-01-14 21:04:42,124 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:04:44,218 - Epoch: [246][    4/    4]    Overall Loss 0.006686    Objective Loss 0.006686    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.523323    
2023-01-14 21:04:44,282 - --- validate (epoch=246)-----------
2023-01-14 21:04:44,283 - 101 samples (240 per mini-batch)
2023-01-14 21:04:45,430 - Epoch: [246][    1/    1]    Loss 0.100420    Top1 97.029703    Top5 100.000000    
2023-01-14 21:04:45,473 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.100

2023-01-14 21:04:45,485 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 242]
2023-01-14 21:04:45,486 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:04:45,541 - 

2023-01-14 21:04:45,541 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:04:47,613 - Epoch: [247][    4/    4]    Overall Loss 0.006852    Objective Loss 0.006852    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.517485    
2023-01-14 21:04:47,658 - --- validate (epoch=247)-----------
2023-01-14 21:04:47,659 - 101 samples (240 per mini-batch)
2023-01-14 21:04:48,938 - Epoch: [247][    1/    1]    Loss 0.062988    Top1 99.009901    Top5 100.000000    
2023-01-14 21:04:48,980 - ==> Top1: 99.010    Top5: 100.000    Loss: 0.063

2023-01-14 21:04:48,989 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 247]
2023-01-14 21:04:48,989 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:04:49,025 - 

2023-01-14 21:04:49,025 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:04:50,952 - Epoch: [248][    4/    4]    Overall Loss 0.006523    Objective Loss 0.006523    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.480817    
2023-01-14 21:04:50,992 - --- validate (epoch=248)-----------
2023-01-14 21:04:50,993 - 101 samples (240 per mini-batch)
2023-01-14 21:04:52,068 - Epoch: [248][    1/    1]    Loss 0.073078    Top1 97.029703    Top5 100.000000    
2023-01-14 21:04:52,115 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.073

2023-01-14 21:04:52,130 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 247]
2023-01-14 21:04:52,131 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:04:52,179 - 

2023-01-14 21:04:52,180 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:04:54,123 - Epoch: [249][    4/    4]    Overall Loss 0.006664    Objective Loss 0.006664    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.485496    
2023-01-14 21:04:54,163 - --- validate (epoch=249)-----------
2023-01-14 21:04:54,164 - 101 samples (240 per mini-batch)
2023-01-14 21:04:55,256 - Epoch: [249][    1/    1]    Loss 0.095666    Top1 96.039604    Top5 100.000000    
2023-01-14 21:04:55,301 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.096

2023-01-14 21:04:55,310 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 247]
2023-01-14 21:04:55,311 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:04:55,347 - 

2023-01-14 21:04:55,347 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:04:57,808 - Epoch: [250][    4/    4]    Overall Loss 0.006628    Objective Loss 0.006628    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.614925    
2023-01-14 21:04:57,847 - --- validate (epoch=250)-----------
2023-01-14 21:04:57,848 - 101 samples (240 per mini-batch)
2023-01-14 21:04:58,948 - Epoch: [250][    1/    1]    Loss 0.082487    Top1 98.019802    Top5 100.000000    
2023-01-14 21:04:58,985 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.082

2023-01-14 21:04:58,992 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 247]
2023-01-14 21:04:58,993 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:04:59,034 - 

2023-01-14 21:04:59,035 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:05:01,806 - Epoch: [251][    4/    4]    Overall Loss 0.006462    Objective Loss 0.006462    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.692386    
2023-01-14 21:05:01,844 - --- validate (epoch=251)-----------
2023-01-14 21:05:01,845 - 101 samples (240 per mini-batch)
2023-01-14 21:05:02,945 - Epoch: [251][    1/    1]    Loss 0.113550    Top1 96.039604    Top5 100.000000    
2023-01-14 21:05:02,985 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.114

2023-01-14 21:05:02,996 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 247]
2023-01-14 21:05:02,997 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:05:03,038 - 

2023-01-14 21:05:03,039 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:05:04,682 - Epoch: [252][    4/    4]    Overall Loss 0.006613    Objective Loss 0.006613    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.410200    
2023-01-14 21:05:04,751 - --- validate (epoch=252)-----------
2023-01-14 21:05:04,752 - 101 samples (240 per mini-batch)
2023-01-14 21:05:05,967 - Epoch: [252][    1/    1]    Loss 0.056450    Top1 99.009901    Top5 100.000000    
2023-01-14 21:05:06,007 - ==> Top1: 99.010    Top5: 100.000    Loss: 0.056

2023-01-14 21:05:06,023 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 252]
2023-01-14 21:05:06,024 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:05:06,071 - 

2023-01-14 21:05:06,072 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:05:07,526 - Epoch: [253][    4/    4]    Overall Loss 0.006465    Objective Loss 0.006465    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.363327    
2023-01-14 21:05:07,562 - --- validate (epoch=253)-----------
2023-01-14 21:05:07,563 - 101 samples (240 per mini-batch)
2023-01-14 21:05:08,698 - Epoch: [253][    1/    1]    Loss 0.101767    Top1 96.039604    Top5 100.000000    
2023-01-14 21:05:08,738 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.102

2023-01-14 21:05:08,748 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 252]
2023-01-14 21:05:08,749 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:05:08,799 - 

2023-01-14 21:05:08,799 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:05:11,157 - Epoch: [254][    4/    4]    Overall Loss 0.006647    Objective Loss 0.006647    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.588975    
2023-01-14 21:05:11,196 - --- validate (epoch=254)-----------
2023-01-14 21:05:11,197 - 101 samples (240 per mini-batch)
2023-01-14 21:05:12,220 - Epoch: [254][    1/    1]    Loss 0.088743    Top1 96.039604    Top5 100.000000    
2023-01-14 21:05:12,259 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.089

2023-01-14 21:05:12,268 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 252]
2023-01-14 21:05:12,269 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:05:12,310 - 

2023-01-14 21:05:12,311 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:05:14,159 - Epoch: [255][    4/    4]    Overall Loss 0.006464    Objective Loss 0.006464    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.461754    
2023-01-14 21:05:14,218 - --- validate (epoch=255)-----------
2023-01-14 21:05:14,219 - 101 samples (240 per mini-batch)
2023-01-14 21:05:15,337 - Epoch: [255][    1/    1]    Loss 0.091650    Top1 96.039604    Top5 100.000000    
2023-01-14 21:05:15,380 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.092

2023-01-14 21:05:15,388 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 252]
2023-01-14 21:05:15,389 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:05:15,426 - 

2023-01-14 21:05:15,427 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:05:17,433 - Epoch: [256][    4/    4]    Overall Loss 0.006734    Objective Loss 0.006734    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.501140    
2023-01-14 21:05:17,476 - --- validate (epoch=256)-----------
2023-01-14 21:05:17,477 - 101 samples (240 per mini-batch)
2023-01-14 21:05:18,574 - Epoch: [256][    1/    1]    Loss 0.103556    Top1 96.039604    Top5 100.000000    
2023-01-14 21:05:18,606 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.104

2023-01-14 21:05:18,615 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 252]
2023-01-14 21:05:18,616 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:05:18,646 - 

2023-01-14 21:05:18,647 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:05:20,421 - Epoch: [257][    4/    4]    Overall Loss 0.006448    Objective Loss 0.006448    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.443268    
2023-01-14 21:05:20,464 - --- validate (epoch=257)-----------
2023-01-14 21:05:20,465 - 101 samples (240 per mini-batch)
2023-01-14 21:05:21,746 - Epoch: [257][    1/    1]    Loss 0.083191    Top1 97.029703    Top5 100.000000    
2023-01-14 21:05:21,777 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.083

2023-01-14 21:05:21,785 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 252]
2023-01-14 21:05:21,786 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:05:21,813 - 

2023-01-14 21:05:21,814 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:05:24,082 - Epoch: [258][    4/    4]    Overall Loss 0.006724    Objective Loss 0.006724    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.566434    
2023-01-14 21:05:24,123 - --- validate (epoch=258)-----------
2023-01-14 21:05:24,124 - 101 samples (240 per mini-batch)
2023-01-14 21:05:25,262 - Epoch: [258][    1/    1]    Loss 0.063908    Top1 98.019802    Top5 100.000000    
2023-01-14 21:05:25,299 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.064

2023-01-14 21:05:25,308 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 252]
2023-01-14 21:05:25,308 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:05:25,346 - 

2023-01-14 21:05:25,347 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:05:27,144 - Epoch: [259][    4/    4]    Overall Loss 0.006445    Objective Loss 0.006445    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.448677    
2023-01-14 21:05:27,183 - --- validate (epoch=259)-----------
2023-01-14 21:05:27,184 - 101 samples (240 per mini-batch)
2023-01-14 21:05:28,294 - Epoch: [259][    1/    1]    Loss 0.089855    Top1 98.019802    Top5 100.000000    
2023-01-14 21:05:28,325 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.090

2023-01-14 21:05:28,335 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 252]
2023-01-14 21:05:28,336 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:05:28,374 - 

2023-01-14 21:05:28,374 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:05:30,113 - Epoch: [260][    4/    4]    Overall Loss 0.006458    Objective Loss 0.006458    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.434487    
2023-01-14 21:05:30,146 - --- validate (epoch=260)-----------
2023-01-14 21:05:30,147 - 101 samples (240 per mini-batch)
2023-01-14 21:05:31,274 - Epoch: [260][    1/    1]    Loss 0.073366    Top1 97.029703    Top5 100.000000    
2023-01-14 21:05:31,308 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.073

2023-01-14 21:05:31,319 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 252]
2023-01-14 21:05:31,319 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:05:31,352 - 

2023-01-14 21:05:31,353 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:05:33,485 - Epoch: [261][    4/    4]    Overall Loss 0.006316    Objective Loss 0.006316    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.532814    
2023-01-14 21:05:33,518 - --- validate (epoch=261)-----------
2023-01-14 21:05:33,519 - 101 samples (240 per mini-batch)
2023-01-14 21:05:34,596 - Epoch: [261][    1/    1]    Loss 0.087602    Top1 97.029703    Top5 100.000000    
2023-01-14 21:05:34,631 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.088

2023-01-14 21:05:34,643 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 252]
2023-01-14 21:05:34,643 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:05:34,676 - 

2023-01-14 21:05:34,676 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:05:36,806 - Epoch: [262][    4/    4]    Overall Loss 0.006338    Objective Loss 0.006338    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.532243    
2023-01-14 21:05:36,840 - --- validate (epoch=262)-----------
2023-01-14 21:05:36,840 - 101 samples (240 per mini-batch)
2023-01-14 21:05:37,945 - Epoch: [262][    1/    1]    Loss 0.077947    Top1 97.029703    Top5 100.000000    
2023-01-14 21:05:37,976 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.078

2023-01-14 21:05:37,992 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 252]
2023-01-14 21:05:37,992 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:05:38,038 - 

2023-01-14 21:05:38,039 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:05:39,963 - Epoch: [263][    4/    4]    Overall Loss 0.006159    Objective Loss 0.006159    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.480663    
2023-01-14 21:05:40,004 - --- validate (epoch=263)-----------
2023-01-14 21:05:40,005 - 101 samples (240 per mini-batch)
2023-01-14 21:05:41,145 - Epoch: [263][    1/    1]    Loss 0.079528    Top1 98.019802    Top5 100.000000    
2023-01-14 21:05:41,179 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.080

2023-01-14 21:05:41,190 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 252]
2023-01-14 21:05:41,191 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:05:41,224 - 

2023-01-14 21:05:41,225 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:05:42,847 - Epoch: [264][    4/    4]    Overall Loss 0.006484    Objective Loss 0.006484    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.405402    
2023-01-14 21:05:42,889 - --- validate (epoch=264)-----------
2023-01-14 21:05:42,890 - 101 samples (240 per mini-batch)
2023-01-14 21:05:44,001 - Epoch: [264][    1/    1]    Loss 0.068418    Top1 99.009901    Top5 100.000000    
2023-01-14 21:05:44,042 - ==> Top1: 99.010    Top5: 100.000    Loss: 0.068

2023-01-14 21:05:44,053 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:05:44,053 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:05:44,094 - 

2023-01-14 21:05:44,094 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:05:46,056 - Epoch: [265][    4/    4]    Overall Loss 0.006492    Objective Loss 0.006492    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.490042    
2023-01-14 21:05:46,096 - --- validate (epoch=265)-----------
2023-01-14 21:05:46,097 - 101 samples (240 per mini-batch)
2023-01-14 21:05:47,218 - Epoch: [265][    1/    1]    Loss 0.094745    Top1 97.029703    Top5 100.000000    
2023-01-14 21:05:47,249 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.095

2023-01-14 21:05:47,260 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:05:47,260 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:05:47,303 - 

2023-01-14 21:05:47,303 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:05:49,179 - Epoch: [266][    4/    4]    Overall Loss 0.006064    Objective Loss 0.006064    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.468092    
2023-01-14 21:05:49,219 - --- validate (epoch=266)-----------
2023-01-14 21:05:49,220 - 101 samples (240 per mini-batch)
2023-01-14 21:05:50,413 - Epoch: [266][    1/    1]    Loss 0.098733    Top1 96.039604    Top5 100.000000    
2023-01-14 21:05:50,462 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.099

2023-01-14 21:05:50,473 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:05:50,474 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:05:50,512 - 

2023-01-14 21:05:50,513 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:05:52,600 - Epoch: [267][    4/    4]    Overall Loss 0.006556    Objective Loss 0.006556    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.520794    
2023-01-14 21:05:52,642 - --- validate (epoch=267)-----------
2023-01-14 21:05:52,643 - 101 samples (240 per mini-batch)
2023-01-14 21:05:53,756 - Epoch: [267][    1/    1]    Loss 0.102861    Top1 97.029703    Top5 100.000000    
2023-01-14 21:05:53,794 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.103

2023-01-14 21:05:53,805 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:05:53,805 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:05:53,843 - 

2023-01-14 21:05:53,844 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:05:55,704 - Epoch: [268][    4/    4]    Overall Loss 0.006574    Objective Loss 0.006574    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.464579    
2023-01-14 21:05:55,745 - --- validate (epoch=268)-----------
2023-01-14 21:05:55,745 - 101 samples (240 per mini-batch)
2023-01-14 21:05:56,770 - Epoch: [268][    1/    1]    Loss 0.109134    Top1 96.039604    Top5 100.000000    
2023-01-14 21:05:56,812 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.109

2023-01-14 21:05:56,824 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:05:56,825 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:05:56,875 - 

2023-01-14 21:05:56,876 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:05:58,733 - Epoch: [269][    4/    4]    Overall Loss 0.006580    Objective Loss 0.006580    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.464000    
2023-01-14 21:05:58,768 - --- validate (epoch=269)-----------
2023-01-14 21:05:58,768 - 101 samples (240 per mini-batch)
2023-01-14 21:05:59,953 - Epoch: [269][    1/    1]    Loss 0.086980    Top1 97.029703    Top5 100.000000    
2023-01-14 21:06:00,008 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.087

2023-01-14 21:06:00,015 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:06:00,016 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:06:00,049 - 

2023-01-14 21:06:00,050 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:06:02,303 - Epoch: [270][    4/    4]    Overall Loss 0.006479    Objective Loss 0.006479    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.562788    
2023-01-14 21:06:02,340 - --- validate (epoch=270)-----------
2023-01-14 21:06:02,341 - 101 samples (240 per mini-batch)
2023-01-14 21:06:03,545 - Epoch: [270][    1/    1]    Loss 0.073195    Top1 97.029703    Top5 100.000000    
2023-01-14 21:06:03,578 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.073

2023-01-14 21:06:03,592 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:06:03,593 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:06:03,640 - 

2023-01-14 21:06:03,641 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:06:05,153 - Epoch: [271][    4/    4]    Overall Loss 0.006447    Objective Loss 0.006447    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.377842    
2023-01-14 21:06:05,189 - --- validate (epoch=271)-----------
2023-01-14 21:06:05,190 - 101 samples (240 per mini-batch)
2023-01-14 21:06:06,279 - Epoch: [271][    1/    1]    Loss 0.083477    Top1 97.029703    Top5 100.000000    
2023-01-14 21:06:06,311 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.083

2023-01-14 21:06:06,321 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:06:06,321 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:06:06,351 - 

2023-01-14 21:06:06,351 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:06:08,285 - Epoch: [272][    4/    4]    Overall Loss 0.006456    Objective Loss 0.006456    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.483020    
2023-01-14 21:06:08,326 - --- validate (epoch=272)-----------
2023-01-14 21:06:08,327 - 101 samples (240 per mini-batch)
2023-01-14 21:06:09,447 - Epoch: [272][    1/    1]    Loss 0.080035    Top1 97.029703    Top5 100.000000    
2023-01-14 21:06:09,493 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.080

2023-01-14 21:06:09,505 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:06:09,505 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:06:09,548 - 

2023-01-14 21:06:09,549 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:06:11,799 - Epoch: [273][    4/    4]    Overall Loss 0.006503    Objective Loss 0.006503    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.562083    
2023-01-14 21:06:11,837 - --- validate (epoch=273)-----------
2023-01-14 21:06:11,838 - 101 samples (240 per mini-batch)
2023-01-14 21:06:13,010 - Epoch: [273][    1/    1]    Loss 0.070631    Top1 98.019802    Top5 100.000000    
2023-01-14 21:06:13,048 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.071

2023-01-14 21:06:13,060 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:06:13,060 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:06:13,099 - 

2023-01-14 21:06:13,099 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:06:14,995 - Epoch: [274][    4/    4]    Overall Loss 0.006408    Objective Loss 0.006408    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.473622    
2023-01-14 21:06:15,028 - --- validate (epoch=274)-----------
2023-01-14 21:06:15,029 - 101 samples (240 per mini-batch)
2023-01-14 21:06:16,135 - Epoch: [274][    1/    1]    Loss 0.102479    Top1 96.039604    Top5 100.000000    
2023-01-14 21:06:16,170 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.102

2023-01-14 21:06:16,181 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:06:16,182 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:06:16,222 - 

2023-01-14 21:06:16,222 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:06:18,147 - Epoch: [275][    4/    4]    Overall Loss 0.006657    Objective Loss 0.006657    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.480781    
2023-01-14 21:06:18,191 - --- validate (epoch=275)-----------
2023-01-14 21:06:18,191 - 101 samples (240 per mini-batch)
2023-01-14 21:06:19,312 - Epoch: [275][    1/    1]    Loss 0.107808    Top1 96.039604    Top5 100.000000    
2023-01-14 21:06:19,346 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.108

2023-01-14 21:06:19,360 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:06:19,360 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:06:19,396 - 

2023-01-14 21:06:19,396 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:06:21,025 - Epoch: [276][    4/    4]    Overall Loss 0.006639    Objective Loss 0.006639    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.406863    
2023-01-14 21:06:21,071 - --- validate (epoch=276)-----------
2023-01-14 21:06:21,072 - 101 samples (240 per mini-batch)
2023-01-14 21:06:22,215 - Epoch: [276][    1/    1]    Loss 0.072327    Top1 98.019802    Top5 100.000000    
2023-01-14 21:06:22,247 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.072

2023-01-14 21:06:22,259 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:06:22,259 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:06:22,295 - 

2023-01-14 21:06:22,295 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:06:24,361 - Epoch: [277][    4/    4]    Overall Loss 0.006585    Objective Loss 0.006585    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.516153    
2023-01-14 21:06:24,414 - --- validate (epoch=277)-----------
2023-01-14 21:06:24,415 - 101 samples (240 per mini-batch)
2023-01-14 21:06:25,481 - Epoch: [277][    1/    1]    Loss 0.093201    Top1 97.029703    Top5 100.000000    
2023-01-14 21:06:25,520 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.093

2023-01-14 21:06:25,533 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:06:25,533 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:06:25,567 - 

2023-01-14 21:06:25,567 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:06:27,371 - Epoch: [278][    4/    4]    Overall Loss 0.006481    Objective Loss 0.006481    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.450528    
2023-01-14 21:06:27,407 - --- validate (epoch=278)-----------
2023-01-14 21:06:27,407 - 101 samples (240 per mini-batch)
2023-01-14 21:06:28,535 - Epoch: [278][    1/    1]    Loss 0.091714    Top1 97.029703    Top5 100.000000    
2023-01-14 21:06:28,571 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.092

2023-01-14 21:06:28,580 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:06:28,581 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:06:28,611 - 

2023-01-14 21:06:28,611 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:06:30,554 - Epoch: [279][    4/    4]    Overall Loss 0.006436    Objective Loss 0.006436    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.485445    
2023-01-14 21:06:30,591 - --- validate (epoch=279)-----------
2023-01-14 21:06:30,592 - 101 samples (240 per mini-batch)
2023-01-14 21:06:31,753 - Epoch: [279][    1/    1]    Loss 0.119329    Top1 95.049505    Top5 100.000000    
2023-01-14 21:06:31,784 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.119

2023-01-14 21:06:31,797 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:06:31,797 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:06:31,828 - 

2023-01-14 21:06:31,829 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:06:33,748 - Epoch: [280][    4/    4]    Overall Loss 0.006663    Objective Loss 0.006663    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.479497    
2023-01-14 21:06:33,780 - --- validate (epoch=280)-----------
2023-01-14 21:06:33,781 - 101 samples (240 per mini-batch)
2023-01-14 21:06:34,779 - Epoch: [280][    1/    1]    Loss 0.099469    Top1 97.029703    Top5 100.000000    
2023-01-14 21:06:34,818 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.099

2023-01-14 21:06:34,828 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:06:34,828 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:06:34,854 - 

2023-01-14 21:06:34,854 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:06:36,747 - Epoch: [281][    4/    4]    Overall Loss 0.006665    Objective Loss 0.006665    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.472944    
2023-01-14 21:06:36,780 - --- validate (epoch=281)-----------
2023-01-14 21:06:36,780 - 101 samples (240 per mini-batch)
2023-01-14 21:06:37,935 - Epoch: [281][    1/    1]    Loss 0.091122    Top1 97.029703    Top5 100.000000    
2023-01-14 21:06:37,968 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.091

2023-01-14 21:06:37,978 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:06:37,979 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:06:38,008 - 

2023-01-14 21:06:38,009 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:06:39,784 - Epoch: [282][    4/    4]    Overall Loss 0.006581    Objective Loss 0.006581    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.443516    
2023-01-14 21:06:39,818 - --- validate (epoch=282)-----------
2023-01-14 21:06:39,819 - 101 samples (240 per mini-batch)
2023-01-14 21:06:40,966 - Epoch: [282][    1/    1]    Loss 0.094727    Top1 96.039604    Top5 100.000000    
2023-01-14 21:06:41,002 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.095

2023-01-14 21:06:41,011 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:06:41,012 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:06:41,038 - 

2023-01-14 21:06:41,039 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:06:42,470 - Epoch: [283][    4/    4]    Overall Loss 0.006365    Objective Loss 0.006365    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.357594    
2023-01-14 21:06:42,507 - --- validate (epoch=283)-----------
2023-01-14 21:06:42,508 - 101 samples (240 per mini-batch)
2023-01-14 21:06:43,580 - Epoch: [283][    1/    1]    Loss 0.077238    Top1 98.019802    Top5 100.000000    
2023-01-14 21:06:43,619 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.077

2023-01-14 21:06:43,633 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:06:43,633 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:06:43,673 - 

2023-01-14 21:06:43,673 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:06:45,633 - Epoch: [284][    4/    4]    Overall Loss 0.006603    Objective Loss 0.006603    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.489577    
2023-01-14 21:06:45,670 - --- validate (epoch=284)-----------
2023-01-14 21:06:45,671 - 101 samples (240 per mini-batch)
2023-01-14 21:06:46,749 - Epoch: [284][    1/    1]    Loss 0.108476    Top1 96.039604    Top5 100.000000    
2023-01-14 21:06:46,783 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.108

2023-01-14 21:06:46,799 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:06:46,799 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:06:46,855 - 

2023-01-14 21:06:46,856 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:06:48,639 - Epoch: [285][    4/    4]    Overall Loss 0.006336    Objective Loss 0.006336    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.445568    
2023-01-14 21:06:48,675 - --- validate (epoch=285)-----------
2023-01-14 21:06:48,676 - 101 samples (240 per mini-batch)
2023-01-14 21:06:49,844 - Epoch: [285][    1/    1]    Loss 0.089295    Top1 97.029703    Top5 100.000000    
2023-01-14 21:06:49,882 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.089

2023-01-14 21:06:49,891 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:06:49,891 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:06:49,922 - 

2023-01-14 21:06:49,923 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:06:51,965 - Epoch: [286][    4/    4]    Overall Loss 0.006803    Objective Loss 0.006803    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.510033    
2023-01-14 21:06:51,999 - --- validate (epoch=286)-----------
2023-01-14 21:06:52,000 - 101 samples (240 per mini-batch)
2023-01-14 21:06:53,037 - Epoch: [286][    1/    1]    Loss 0.095294    Top1 96.039604    Top5 100.000000    
2023-01-14 21:06:53,069 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.095

2023-01-14 21:06:53,079 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:06:53,079 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:06:53,108 - 

2023-01-14 21:06:53,108 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:06:54,999 - Epoch: [287][    4/    4]    Overall Loss 0.006296    Objective Loss 0.006296    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.472449    
2023-01-14 21:06:55,046 - --- validate (epoch=287)-----------
2023-01-14 21:06:55,046 - 101 samples (240 per mini-batch)
2023-01-14 21:06:56,175 - Epoch: [287][    1/    1]    Loss 0.118166    Top1 95.049505    Top5 100.000000    
2023-01-14 21:06:56,211 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.118

2023-01-14 21:06:56,221 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:06:56,221 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:06:56,253 - 

2023-01-14 21:06:56,254 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:06:58,218 - Epoch: [288][    4/    4]    Overall Loss 0.006372    Objective Loss 0.006372    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.490714    
2023-01-14 21:06:58,255 - --- validate (epoch=288)-----------
2023-01-14 21:06:58,255 - 101 samples (240 per mini-batch)
2023-01-14 21:06:59,339 - Epoch: [288][    1/    1]    Loss 0.084649    Top1 98.019802    Top5 100.000000    
2023-01-14 21:06:59,373 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.085

2023-01-14 21:06:59,385 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:06:59,385 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:06:59,416 - 

2023-01-14 21:06:59,417 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:07:01,067 - Epoch: [289][    4/    4]    Overall Loss 0.006648    Objective Loss 0.006648    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.412296    
2023-01-14 21:07:01,104 - --- validate (epoch=289)-----------
2023-01-14 21:07:01,104 - 101 samples (240 per mini-batch)
2023-01-14 21:07:02,197 - Epoch: [289][    1/    1]    Loss 0.099928    Top1 97.029703    Top5 100.000000    
2023-01-14 21:07:02,237 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.100

2023-01-14 21:07:02,247 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:07:02,248 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:07:02,289 - 

2023-01-14 21:07:02,290 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:07:04,052 - Epoch: [290][    4/    4]    Overall Loss 0.006380    Objective Loss 0.006380    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.440275    
2023-01-14 21:07:04,093 - --- validate (epoch=290)-----------
2023-01-14 21:07:04,094 - 101 samples (240 per mini-batch)
2023-01-14 21:07:05,221 - Epoch: [290][    1/    1]    Loss 0.064802    Top1 98.019802    Top5 100.000000    
2023-01-14 21:07:05,257 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.065

2023-01-14 21:07:05,267 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:07:05,267 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:07:05,302 - 

2023-01-14 21:07:05,302 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:07:07,089 - Epoch: [291][    4/    4]    Overall Loss 0.006200    Objective Loss 0.006200    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.446463    
2023-01-14 21:07:07,122 - --- validate (epoch=291)-----------
2023-01-14 21:07:07,122 - 101 samples (240 per mini-batch)
2023-01-14 21:07:08,122 - Epoch: [291][    1/    1]    Loss 0.084778    Top1 98.019802    Top5 100.000000    
2023-01-14 21:07:08,158 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.085

2023-01-14 21:07:08,168 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:07:08,168 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:07:08,198 - 

2023-01-14 21:07:08,199 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:07:09,958 - Epoch: [292][    4/    4]    Overall Loss 0.006440    Objective Loss 0.006440    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.439466    
2023-01-14 21:07:09,993 - --- validate (epoch=292)-----------
2023-01-14 21:07:09,994 - 101 samples (240 per mini-batch)
2023-01-14 21:07:11,038 - Epoch: [292][    1/    1]    Loss 0.086010    Top1 97.029703    Top5 100.000000    
2023-01-14 21:07:11,070 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.086

2023-01-14 21:07:11,087 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:07:11,088 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:07:11,135 - 

2023-01-14 21:07:11,136 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:07:13,107 - Epoch: [293][    4/    4]    Overall Loss 0.006519    Objective Loss 0.006519    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.492239    
2023-01-14 21:07:13,149 - --- validate (epoch=293)-----------
2023-01-14 21:07:13,150 - 101 samples (240 per mini-batch)
2023-01-14 21:07:14,287 - Epoch: [293][    1/    1]    Loss 0.100893    Top1 97.029703    Top5 100.000000    
2023-01-14 21:07:14,323 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.101

2023-01-14 21:07:14,334 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:07:14,335 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:07:14,369 - 

2023-01-14 21:07:14,370 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:07:16,276 - Epoch: [294][    4/    4]    Overall Loss 0.006215    Objective Loss 0.006215    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.476380    
2023-01-14 21:07:16,312 - --- validate (epoch=294)-----------
2023-01-14 21:07:16,312 - 101 samples (240 per mini-batch)
2023-01-14 21:07:17,410 - Epoch: [294][    1/    1]    Loss 0.066457    Top1 98.019802    Top5 100.000000    
2023-01-14 21:07:17,451 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.066

2023-01-14 21:07:17,463 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:07:17,463 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:07:17,510 - 

2023-01-14 21:07:17,511 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:07:19,320 - Epoch: [295][    4/    4]    Overall Loss 0.006298    Objective Loss 0.006298    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.452055    
2023-01-14 21:07:19,355 - --- validate (epoch=295)-----------
2023-01-14 21:07:19,355 - 101 samples (240 per mini-batch)
2023-01-14 21:07:20,446 - Epoch: [295][    1/    1]    Loss 0.092257    Top1 97.029703    Top5 100.000000    
2023-01-14 21:07:20,479 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.092

2023-01-14 21:07:20,497 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:07:20,497 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:07:20,533 - 

2023-01-14 21:07:20,534 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:07:22,036 - Epoch: [296][    4/    4]    Overall Loss 0.006442    Objective Loss 0.006442    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.375052    
2023-01-14 21:07:22,069 - --- validate (epoch=296)-----------
2023-01-14 21:07:22,069 - 101 samples (240 per mini-batch)
2023-01-14 21:07:23,189 - Epoch: [296][    1/    1]    Loss 0.072081    Top1 98.019802    Top5 100.000000    
2023-01-14 21:07:23,227 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.072

2023-01-14 21:07:23,237 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:07:23,237 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:07:23,264 - 

2023-01-14 21:07:23,265 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:07:25,006 - Epoch: [297][    4/    4]    Overall Loss 0.006472    Objective Loss 0.006472    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.434504    
2023-01-14 21:07:25,041 - --- validate (epoch=297)-----------
2023-01-14 21:07:25,042 - 101 samples (240 per mini-batch)
2023-01-14 21:07:26,053 - Epoch: [297][    1/    1]    Loss 0.078875    Top1 97.029703    Top5 100.000000    
2023-01-14 21:07:26,103 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.079

2023-01-14 21:07:26,115 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:07:26,115 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:07:26,157 - 

2023-01-14 21:07:26,157 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:07:28,033 - Epoch: [298][    4/    4]    Overall Loss 0.006314    Objective Loss 0.006314    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.468619    
2023-01-14 21:07:28,077 - --- validate (epoch=298)-----------
2023-01-14 21:07:28,077 - 101 samples (240 per mini-batch)
2023-01-14 21:07:29,304 - Epoch: [298][    1/    1]    Loss 0.081621    Top1 98.019802    Top5 100.000000    
2023-01-14 21:07:29,335 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.082

2023-01-14 21:07:29,351 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:07:29,351 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:07:29,386 - 

2023-01-14 21:07:29,386 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:07:31,085 - Epoch: [299][    4/    4]    Overall Loss 0.006245    Objective Loss 0.006245    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.424427    
2023-01-14 21:07:31,123 - --- validate (epoch=299)-----------
2023-01-14 21:07:31,123 - 101 samples (240 per mini-batch)
2023-01-14 21:07:32,247 - Epoch: [299][    1/    1]    Loss 0.097956    Top1 97.029703    Top5 100.000000    
2023-01-14 21:07:32,285 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.098

2023-01-14 21:07:32,296 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:07:32,296 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:07:32,329 - 

2023-01-14 21:07:32,330 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:07:34,214 - Epoch: [300][    4/    4]    Overall Loss 0.006287    Objective Loss 0.006287    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.470676    
2023-01-14 21:07:34,248 - --- validate (epoch=300)-----------
2023-01-14 21:07:34,249 - 101 samples (240 per mini-batch)
2023-01-14 21:07:35,264 - Epoch: [300][    1/    1]    Loss 0.089121    Top1 97.029703    Top5 100.000000    
2023-01-14 21:07:35,314 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.089

2023-01-14 21:07:35,328 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:07:35,330 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:07:35,372 - 

2023-01-14 21:07:35,372 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:07:37,467 - Epoch: [301][    4/    4]    Overall Loss 0.006505    Objective Loss 0.006505    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.523386    
2023-01-14 21:07:37,502 - --- validate (epoch=301)-----------
2023-01-14 21:07:37,503 - 101 samples (240 per mini-batch)
2023-01-14 21:07:38,606 - Epoch: [301][    1/    1]    Loss 0.092206    Top1 97.029703    Top5 100.000000    
2023-01-14 21:07:38,634 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.092

2023-01-14 21:07:38,643 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:07:38,644 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:07:38,673 - 

2023-01-14 21:07:38,673 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:07:40,442 - Epoch: [302][    4/    4]    Overall Loss 0.006268    Objective Loss 0.006268    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.441795    
2023-01-14 21:07:40,482 - --- validate (epoch=302)-----------
2023-01-14 21:07:40,483 - 101 samples (240 per mini-batch)
2023-01-14 21:07:41,562 - Epoch: [302][    1/    1]    Loss 0.084877    Top1 98.019802    Top5 100.000000    
2023-01-14 21:07:41,593 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.085

2023-01-14 21:07:41,609 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:07:41,610 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:07:41,650 - 

2023-01-14 21:07:41,650 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:07:43,437 - Epoch: [303][    4/    4]    Overall Loss 0.006563    Objective Loss 0.006563    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.446279    
2023-01-14 21:07:43,476 - --- validate (epoch=303)-----------
2023-01-14 21:07:43,477 - 101 samples (240 per mini-batch)
2023-01-14 21:07:44,554 - Epoch: [303][    1/    1]    Loss 0.089287    Top1 97.029703    Top5 100.000000    
2023-01-14 21:07:44,584 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.089

2023-01-14 21:07:44,600 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:07:44,600 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:07:44,640 - 

2023-01-14 21:07:44,640 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:07:46,486 - Epoch: [304][    4/    4]    Overall Loss 0.006301    Objective Loss 0.006301    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.460947    
2023-01-14 21:07:46,531 - --- validate (epoch=304)-----------
2023-01-14 21:07:46,532 - 101 samples (240 per mini-batch)
2023-01-14 21:07:47,617 - Epoch: [304][    1/    1]    Loss 0.077089    Top1 98.019802    Top5 100.000000    
2023-01-14 21:07:47,657 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.077

2023-01-14 21:07:47,665 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:07:47,665 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:07:47,695 - 

2023-01-14 21:07:47,695 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:07:49,653 - Epoch: [305][    4/    4]    Overall Loss 0.006300    Objective Loss 0.006300    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.489024    
2023-01-14 21:07:49,693 - --- validate (epoch=305)-----------
2023-01-14 21:07:49,693 - 101 samples (240 per mini-batch)
2023-01-14 21:07:50,830 - Epoch: [305][    1/    1]    Loss 0.063007    Top1 98.019802    Top5 100.000000    
2023-01-14 21:07:50,862 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.063

2023-01-14 21:07:50,871 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:07:50,872 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:07:50,903 - 

2023-01-14 21:07:50,904 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:07:52,242 - Epoch: [306][    4/    4]    Overall Loss 0.006252    Objective Loss 0.006252    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.334214    
2023-01-14 21:07:52,275 - --- validate (epoch=306)-----------
2023-01-14 21:07:52,276 - 101 samples (240 per mini-batch)
2023-01-14 21:07:53,330 - Epoch: [306][    1/    1]    Loss 0.102380    Top1 97.029703    Top5 100.000000    
2023-01-14 21:07:53,367 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.102

2023-01-14 21:07:53,379 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:07:53,379 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:07:53,414 - 

2023-01-14 21:07:53,415 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:07:55,158 - Epoch: [307][    4/    4]    Overall Loss 0.006166    Objective Loss 0.006166    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.435594    
2023-01-14 21:07:55,190 - --- validate (epoch=307)-----------
2023-01-14 21:07:55,191 - 101 samples (240 per mini-batch)
2023-01-14 21:07:56,294 - Epoch: [307][    1/    1]    Loss 0.072250    Top1 98.019802    Top5 100.000000    
2023-01-14 21:07:56,336 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.072

2023-01-14 21:07:56,353 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:07:56,353 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:07:56,400 - 

2023-01-14 21:07:56,401 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:07:58,046 - Epoch: [308][    4/    4]    Overall Loss 0.006196    Objective Loss 0.006196    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.410949    
2023-01-14 21:07:58,084 - --- validate (epoch=308)-----------
2023-01-14 21:07:58,084 - 101 samples (240 per mini-batch)
2023-01-14 21:07:59,223 - Epoch: [308][    1/    1]    Loss 0.090975    Top1 96.039604    Top5 100.000000    
2023-01-14 21:07:59,253 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.091

2023-01-14 21:07:59,264 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:07:59,264 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:07:59,292 - 

2023-01-14 21:07:59,292 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:08:00,884 - Epoch: [309][    4/    4]    Overall Loss 0.006598    Objective Loss 0.006598    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.397764    
2023-01-14 21:08:00,928 - --- validate (epoch=309)-----------
2023-01-14 21:08:00,928 - 101 samples (240 per mini-batch)
2023-01-14 21:08:02,071 - Epoch: [309][    1/    1]    Loss 0.104166    Top1 97.029703    Top5 100.000000    
2023-01-14 21:08:02,103 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.104

2023-01-14 21:08:02,113 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:08:02,113 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:08:02,145 - 

2023-01-14 21:08:02,145 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:08:04,249 - Epoch: [310][    4/    4]    Overall Loss 0.006294    Objective Loss 0.006294    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.525547    
2023-01-14 21:08:04,282 - --- validate (epoch=310)-----------
2023-01-14 21:08:04,284 - 101 samples (240 per mini-batch)
2023-01-14 21:08:05,407 - Epoch: [310][    1/    1]    Loss 0.104908    Top1 97.029703    Top5 100.000000    
2023-01-14 21:08:05,442 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.105

2023-01-14 21:08:05,451 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:08:05,452 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:08:05,485 - 

2023-01-14 21:08:05,485 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:08:07,058 - Epoch: [311][    4/    4]    Overall Loss 0.006273    Objective Loss 0.006273    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.392820    
2023-01-14 21:08:07,092 - --- validate (epoch=311)-----------
2023-01-14 21:08:07,092 - 101 samples (240 per mini-batch)
2023-01-14 21:08:08,096 - Epoch: [311][    1/    1]    Loss 0.069186    Top1 98.019802    Top5 100.000000    
2023-01-14 21:08:08,128 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.069

2023-01-14 21:08:08,138 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:08:08,139 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:08:08,175 - 

2023-01-14 21:08:08,175 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:08:10,402 - Epoch: [312][    4/    4]    Overall Loss 0.006265    Objective Loss 0.006265    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.556520    
2023-01-14 21:08:10,438 - --- validate (epoch=312)-----------
2023-01-14 21:08:10,439 - 101 samples (240 per mini-batch)
2023-01-14 21:08:11,601 - Epoch: [312][    1/    1]    Loss 0.085401    Top1 98.019802    Top5 100.000000    
2023-01-14 21:08:11,632 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.085

2023-01-14 21:08:11,643 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:08:11,644 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:08:11,684 - 

2023-01-14 21:08:11,684 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:08:13,492 - Epoch: [313][    4/    4]    Overall Loss 0.006307    Objective Loss 0.006307    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.451656    
2023-01-14 21:08:13,523 - --- validate (epoch=313)-----------
2023-01-14 21:08:13,524 - 101 samples (240 per mini-batch)
2023-01-14 21:08:14,619 - Epoch: [313][    1/    1]    Loss 0.098284    Top1 96.039604    Top5 100.000000    
2023-01-14 21:08:14,653 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.098

2023-01-14 21:08:14,662 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:08:14,663 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:08:14,690 - 

2023-01-14 21:08:14,690 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:08:16,508 - Epoch: [314][    4/    4]    Overall Loss 0.006328    Objective Loss 0.006328    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.454022    
2023-01-14 21:08:16,546 - --- validate (epoch=314)-----------
2023-01-14 21:08:16,547 - 101 samples (240 per mini-batch)
2023-01-14 21:08:17,603 - Epoch: [314][    1/    1]    Loss 0.083654    Top1 97.029703    Top5 100.000000    
2023-01-14 21:08:17,635 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.084

2023-01-14 21:08:17,649 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:08:17,649 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:08:17,685 - 

2023-01-14 21:08:17,685 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:08:19,466 - Epoch: [315][    4/    4]    Overall Loss 0.006348    Objective Loss 0.006348    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.444623    
2023-01-14 21:08:19,497 - --- validate (epoch=315)-----------
2023-01-14 21:08:19,497 - 101 samples (240 per mini-batch)
2023-01-14 21:08:20,493 - Epoch: [315][    1/    1]    Loss 0.090708    Top1 97.029703    Top5 100.000000    
2023-01-14 21:08:20,520 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.091

2023-01-14 21:08:20,530 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:08:20,530 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:08:20,560 - 

2023-01-14 21:08:20,561 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:08:22,789 - Epoch: [316][    4/    4]    Overall Loss 0.006475    Objective Loss 0.006475    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.556874    
2023-01-14 21:08:22,825 - --- validate (epoch=316)-----------
2023-01-14 21:08:22,826 - 101 samples (240 per mini-batch)
2023-01-14 21:08:23,998 - Epoch: [316][    1/    1]    Loss 0.092611    Top1 97.029703    Top5 100.000000    
2023-01-14 21:08:24,034 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.093

2023-01-14 21:08:24,046 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:08:24,046 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:08:24,079 - 

2023-01-14 21:08:24,080 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:08:25,969 - Epoch: [317][    4/    4]    Overall Loss 0.006256    Objective Loss 0.006256    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.472043    
2023-01-14 21:08:26,002 - --- validate (epoch=317)-----------
2023-01-14 21:08:26,003 - 101 samples (240 per mini-batch)
2023-01-14 21:08:27,031 - Epoch: [317][    1/    1]    Loss 0.095355    Top1 97.029703    Top5 100.000000    
2023-01-14 21:08:27,066 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.095

2023-01-14 21:08:27,077 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:08:27,077 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:08:27,110 - 

2023-01-14 21:08:27,110 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:08:28,985 - Epoch: [318][    4/    4]    Overall Loss 0.006490    Objective Loss 0.006490    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.468305    
2023-01-14 21:08:29,033 - --- validate (epoch=318)-----------
2023-01-14 21:08:29,034 - 101 samples (240 per mini-batch)
2023-01-14 21:08:30,165 - Epoch: [318][    1/    1]    Loss 0.077411    Top1 98.019802    Top5 100.000000    
2023-01-14 21:08:30,200 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.077

2023-01-14 21:08:30,210 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:08:30,210 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:08:30,241 - 

2023-01-14 21:08:30,242 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:08:32,156 - Epoch: [319][    4/    4]    Overall Loss 0.006649    Objective Loss 0.006649    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.478187    
2023-01-14 21:08:32,186 - --- validate (epoch=319)-----------
2023-01-14 21:08:32,187 - 101 samples (240 per mini-batch)
2023-01-14 21:08:33,298 - Epoch: [319][    1/    1]    Loss 0.088275    Top1 97.029703    Top5 100.000000    
2023-01-14 21:08:33,329 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.088

2023-01-14 21:08:33,345 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:08:33,345 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:08:33,398 - 

2023-01-14 21:08:33,399 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:08:35,091 - Epoch: [320][    4/    4]    Overall Loss 0.006453    Objective Loss 0.006453    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.422162    
2023-01-14 21:08:35,120 - --- validate (epoch=320)-----------
2023-01-14 21:08:35,121 - 101 samples (240 per mini-batch)
2023-01-14 21:08:36,201 - Epoch: [320][    1/    1]    Loss 0.106947    Top1 96.039604    Top5 100.000000    
2023-01-14 21:08:36,234 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.107

2023-01-14 21:08:36,246 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:08:36,246 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:08:36,275 - 

2023-01-14 21:08:36,275 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:08:38,189 - Epoch: [321][    4/    4]    Overall Loss 0.006087    Objective Loss 0.006087    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.478077    
2023-01-14 21:08:38,226 - --- validate (epoch=321)-----------
2023-01-14 21:08:38,227 - 101 samples (240 per mini-batch)
2023-01-14 21:08:39,349 - Epoch: [321][    1/    1]    Loss 0.081528    Top1 98.019802    Top5 100.000000    
2023-01-14 21:08:39,383 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.082

2023-01-14 21:08:39,397 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:08:39,397 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:08:39,436 - 

2023-01-14 21:08:39,436 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:08:41,213 - Epoch: [322][    4/    4]    Overall Loss 0.006442    Objective Loss 0.006442    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.443950    
2023-01-14 21:08:41,249 - --- validate (epoch=322)-----------
2023-01-14 21:08:41,250 - 101 samples (240 per mini-batch)
2023-01-14 21:08:42,353 - Epoch: [322][    1/    1]    Loss 0.082536    Top1 97.029703    Top5 100.000000    
2023-01-14 21:08:42,394 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.083

2023-01-14 21:08:42,409 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:08:42,410 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:08:42,454 - 

2023-01-14 21:08:42,455 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:08:44,268 - Epoch: [323][    4/    4]    Overall Loss 0.006213    Objective Loss 0.006213    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.452588    
2023-01-14 21:08:44,303 - --- validate (epoch=323)-----------
2023-01-14 21:08:44,304 - 101 samples (240 per mini-batch)
2023-01-14 21:08:45,291 - Epoch: [323][    1/    1]    Loss 0.094369    Top1 97.029703    Top5 100.000000    
2023-01-14 21:08:45,331 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.094

2023-01-14 21:08:45,339 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:08:45,340 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:08:45,379 - 

2023-01-14 21:08:45,380 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:08:47,626 - Epoch: [324][    4/    4]    Overall Loss 0.006142    Objective Loss 0.006142    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.561404    
2023-01-14 21:08:47,668 - --- validate (epoch=324)-----------
2023-01-14 21:08:47,669 - 101 samples (240 per mini-batch)
2023-01-14 21:08:48,869 - Epoch: [324][    1/    1]    Loss 0.096303    Top1 97.029703    Top5 100.000000    
2023-01-14 21:08:48,906 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.096

2023-01-14 21:08:48,916 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:08:48,916 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:08:48,954 - 

2023-01-14 21:08:48,955 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:08:50,931 - Epoch: [325][    4/    4]    Overall Loss 0.006257    Objective Loss 0.006257    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.493737    
2023-01-14 21:08:50,973 - --- validate (epoch=325)-----------
2023-01-14 21:08:50,974 - 101 samples (240 per mini-batch)
2023-01-14 21:08:51,987 - Epoch: [325][    1/    1]    Loss 0.087667    Top1 97.029703    Top5 100.000000    
2023-01-14 21:08:52,025 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.088

2023-01-14 21:08:52,036 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:08:52,036 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:08:52,071 - 

2023-01-14 21:08:52,071 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:08:53,669 - Epoch: [326][    4/    4]    Overall Loss 0.006299    Objective Loss 0.006299    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.399168    
2023-01-14 21:08:53,707 - --- validate (epoch=326)-----------
2023-01-14 21:08:53,707 - 101 samples (240 per mini-batch)
2023-01-14 21:08:54,833 - Epoch: [326][    1/    1]    Loss 0.117752    Top1 95.049505    Top5 100.000000    
2023-01-14 21:08:54,865 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.118

2023-01-14 21:08:54,876 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:08:54,877 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:08:54,922 - 

2023-01-14 21:08:54,923 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:08:57,475 - Epoch: [327][    4/    4]    Overall Loss 0.006550    Objective Loss 0.006550    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.637717    
2023-01-14 21:08:57,509 - --- validate (epoch=327)-----------
2023-01-14 21:08:57,510 - 101 samples (240 per mini-batch)
2023-01-14 21:08:58,526 - Epoch: [327][    1/    1]    Loss 0.105651    Top1 97.029703    Top5 100.000000    
2023-01-14 21:08:58,559 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.106

2023-01-14 21:08:58,570 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:08:58,570 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:08:58,599 - 

2023-01-14 21:08:58,601 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:09:00,542 - Epoch: [328][    4/    4]    Overall Loss 0.006179    Objective Loss 0.006179    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.484585    
2023-01-14 21:09:00,575 - --- validate (epoch=328)-----------
2023-01-14 21:09:00,576 - 101 samples (240 per mini-batch)
2023-01-14 21:09:01,636 - Epoch: [328][    1/    1]    Loss 0.079984    Top1 98.019802    Top5 100.000000    
2023-01-14 21:09:01,665 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.080

2023-01-14 21:09:01,682 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:09:01,682 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:09:01,722 - 

2023-01-14 21:09:01,722 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:09:03,578 - Epoch: [329][    4/    4]    Overall Loss 0.006348    Objective Loss 0.006348    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.463547    
2023-01-14 21:09:03,614 - --- validate (epoch=329)-----------
2023-01-14 21:09:03,616 - 101 samples (240 per mini-batch)
2023-01-14 21:09:04,709 - Epoch: [329][    1/    1]    Loss 0.100745    Top1 96.039604    Top5 100.000000    
2023-01-14 21:09:04,746 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.101

2023-01-14 21:09:04,755 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:09:04,756 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:09:04,788 - 

2023-01-14 21:09:04,789 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:09:06,993 - Epoch: [330][    4/    4]    Overall Loss 0.005939    Objective Loss 0.005939    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.550830    
2023-01-14 21:09:07,027 - --- validate (epoch=330)-----------
2023-01-14 21:09:07,028 - 101 samples (240 per mini-batch)
2023-01-14 21:09:08,201 - Epoch: [330][    1/    1]    Loss 0.072772    Top1 97.029703    Top5 100.000000    
2023-01-14 21:09:08,229 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.073

2023-01-14 21:09:08,240 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:09:08,240 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:09:08,275 - 

2023-01-14 21:09:08,275 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:09:10,049 - Epoch: [331][    4/    4]    Overall Loss 0.006367    Objective Loss 0.006367    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.442516    
2023-01-14 21:09:10,095 - --- validate (epoch=331)-----------
2023-01-14 21:09:10,095 - 101 samples (240 per mini-batch)
2023-01-14 21:09:11,171 - Epoch: [331][    1/    1]    Loss 0.086089    Top1 98.019802    Top5 100.000000    
2023-01-14 21:09:11,205 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.086

2023-01-14 21:09:11,221 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:09:11,222 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:09:11,261 - 

2023-01-14 21:09:11,261 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:09:12,875 - Epoch: [332][    4/    4]    Overall Loss 0.006258    Objective Loss 0.006258    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.403228    
2023-01-14 21:09:12,915 - --- validate (epoch=332)-----------
2023-01-14 21:09:12,915 - 101 samples (240 per mini-batch)
2023-01-14 21:09:13,930 - Epoch: [332][    1/    1]    Loss 0.091400    Top1 96.039604    Top5 100.000000    
2023-01-14 21:09:13,965 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.091

2023-01-14 21:09:13,977 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:09:13,978 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:09:14,024 - 

2023-01-14 21:09:14,025 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:09:15,893 - Epoch: [333][    4/    4]    Overall Loss 0.006105    Objective Loss 0.006105    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.466201    
2023-01-14 21:09:15,927 - --- validate (epoch=333)-----------
2023-01-14 21:09:15,928 - 101 samples (240 per mini-batch)
2023-01-14 21:09:17,067 - Epoch: [333][    1/    1]    Loss 0.106412    Top1 96.039604    Top5 100.000000    
2023-01-14 21:09:17,103 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.106

2023-01-14 21:09:17,112 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:09:17,113 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:09:17,143 - 

2023-01-14 21:09:17,144 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:09:18,946 - Epoch: [334][    4/    4]    Overall Loss 0.006282    Objective Loss 0.006282    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.450270    
2023-01-14 21:09:18,983 - --- validate (epoch=334)-----------
2023-01-14 21:09:18,983 - 101 samples (240 per mini-batch)
2023-01-14 21:09:20,057 - Epoch: [334][    1/    1]    Loss 0.091636    Top1 97.029703    Top5 100.000000    
2023-01-14 21:09:20,091 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.092

2023-01-14 21:09:20,104 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:09:20,104 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:09:20,137 - 

2023-01-14 21:09:20,137 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:09:21,919 - Epoch: [335][    4/    4]    Overall Loss 0.006440    Objective Loss 0.006440    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.445169    
2023-01-14 21:09:21,953 - --- validate (epoch=335)-----------
2023-01-14 21:09:21,953 - 101 samples (240 per mini-batch)
2023-01-14 21:09:22,978 - Epoch: [335][    1/    1]    Loss 0.108026    Top1 96.039604    Top5 100.000000    
2023-01-14 21:09:23,012 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.108

2023-01-14 21:09:23,022 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:09:23,023 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:09:23,077 - 

2023-01-14 21:09:23,078 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:09:25,300 - Epoch: [336][    4/    4]    Overall Loss 0.006082    Objective Loss 0.006082    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.554848    
2023-01-14 21:09:25,336 - --- validate (epoch=336)-----------
2023-01-14 21:09:25,337 - 101 samples (240 per mini-batch)
2023-01-14 21:09:26,450 - Epoch: [336][    1/    1]    Loss 0.094833    Top1 97.029703    Top5 100.000000    
2023-01-14 21:09:26,483 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.095

2023-01-14 21:09:26,494 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:09:26,494 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:09:26,565 - 

2023-01-14 21:09:26,566 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:09:27,961 - Epoch: [337][    4/    4]    Overall Loss 0.006175    Objective Loss 0.006175    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.348076    
2023-01-14 21:09:27,999 - --- validate (epoch=337)-----------
2023-01-14 21:09:28,000 - 101 samples (240 per mini-batch)
2023-01-14 21:09:29,126 - Epoch: [337][    1/    1]    Loss 0.091394    Top1 97.029703    Top5 100.000000    
2023-01-14 21:09:29,169 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.091

2023-01-14 21:09:29,179 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:09:29,179 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:09:29,225 - 

2023-01-14 21:09:29,226 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:09:30,986 - Epoch: [338][    4/    4]    Overall Loss 0.006344    Objective Loss 0.006344    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.439690    
2023-01-14 21:09:31,019 - --- validate (epoch=338)-----------
2023-01-14 21:09:31,019 - 101 samples (240 per mini-batch)
2023-01-14 21:09:32,020 - Epoch: [338][    1/    1]    Loss 0.070885    Top1 98.019802    Top5 100.000000    
2023-01-14 21:09:32,049 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.071

2023-01-14 21:09:32,060 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:09:32,060 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:09:32,090 - 

2023-01-14 21:09:32,090 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:09:33,683 - Epoch: [339][    4/    4]    Overall Loss 0.006189    Objective Loss 0.006189    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.397851    
2023-01-14 21:09:33,721 - --- validate (epoch=339)-----------
2023-01-14 21:09:33,722 - 101 samples (240 per mini-batch)
2023-01-14 21:09:34,807 - Epoch: [339][    1/    1]    Loss 0.098604    Top1 97.029703    Top5 100.000000    
2023-01-14 21:09:34,850 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.099

2023-01-14 21:09:34,862 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:09:34,862 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:09:34,908 - 

2023-01-14 21:09:34,909 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:09:36,499 - Epoch: [340][    4/    4]    Overall Loss 0.006429    Objective Loss 0.006429    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.397064    
2023-01-14 21:09:36,532 - --- validate (epoch=340)-----------
2023-01-14 21:09:36,532 - 101 samples (240 per mini-batch)
2023-01-14 21:09:37,559 - Epoch: [340][    1/    1]    Loss 0.100305    Top1 97.029703    Top5 100.000000    
2023-01-14 21:09:37,597 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.100

2023-01-14 21:09:37,608 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:09:37,608 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:09:37,638 - 

2023-01-14 21:09:37,639 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:09:39,243 - Epoch: [341][    4/    4]    Overall Loss 0.006223    Objective Loss 0.006223    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.400839    
2023-01-14 21:09:39,277 - --- validate (epoch=341)-----------
2023-01-14 21:09:39,277 - 101 samples (240 per mini-batch)
2023-01-14 21:09:40,381 - Epoch: [341][    1/    1]    Loss 0.106325    Top1 95.049505    Top5 100.000000    
2023-01-14 21:09:40,420 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.106

2023-01-14 21:09:40,430 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:09:40,430 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:09:40,471 - 

2023-01-14 21:09:40,471 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:09:42,430 - Epoch: [342][    4/    4]    Overall Loss 0.006219    Objective Loss 0.006219    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.489367    
2023-01-14 21:09:42,468 - --- validate (epoch=342)-----------
2023-01-14 21:09:42,469 - 101 samples (240 per mini-batch)
2023-01-14 21:09:43,577 - Epoch: [342][    1/    1]    Loss 0.117916    Top1 95.049505    Top5 100.000000    
2023-01-14 21:09:43,612 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.118

2023-01-14 21:09:43,623 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:09:43,624 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:09:43,664 - 

2023-01-14 21:09:43,664 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:09:45,721 - Epoch: [343][    4/    4]    Overall Loss 0.006391    Objective Loss 0.006391    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.513918    
2023-01-14 21:09:45,760 - --- validate (epoch=343)-----------
2023-01-14 21:09:45,761 - 101 samples (240 per mini-batch)
2023-01-14 21:09:46,925 - Epoch: [343][    1/    1]    Loss 0.114536    Top1 96.039604    Top5 100.000000    
2023-01-14 21:09:46,956 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.115

2023-01-14 21:09:46,967 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:09:46,969 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:09:47,003 - 

2023-01-14 21:09:47,004 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:09:48,398 - Epoch: [344][    4/    4]    Overall Loss 0.006214    Objective Loss 0.006214    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.348228    
2023-01-14 21:09:48,432 - --- validate (epoch=344)-----------
2023-01-14 21:09:48,433 - 101 samples (240 per mini-batch)
2023-01-14 21:09:49,592 - Epoch: [344][    1/    1]    Loss 0.074801    Top1 97.029703    Top5 100.000000    
2023-01-14 21:09:49,620 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.075

2023-01-14 21:09:49,631 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:09:49,632 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:09:49,661 - 

2023-01-14 21:09:49,662 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:09:51,577 - Epoch: [345][    4/    4]    Overall Loss 0.006373    Objective Loss 0.006373    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.478493    
2023-01-14 21:09:51,623 - --- validate (epoch=345)-----------
2023-01-14 21:09:51,624 - 101 samples (240 per mini-batch)
2023-01-14 21:09:52,737 - Epoch: [345][    1/    1]    Loss 0.072791    Top1 97.029703    Top5 100.000000    
2023-01-14 21:09:52,778 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.073

2023-01-14 21:09:52,787 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:09:52,787 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:09:52,828 - 

2023-01-14 21:09:52,829 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:09:54,588 - Epoch: [346][    4/    4]    Overall Loss 0.006215    Objective Loss 0.006215    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.439456    
2023-01-14 21:09:54,621 - --- validate (epoch=346)-----------
2023-01-14 21:09:54,621 - 101 samples (240 per mini-batch)
2023-01-14 21:09:55,718 - Epoch: [346][    1/    1]    Loss 0.067265    Top1 98.019802    Top5 100.000000    
2023-01-14 21:09:55,752 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.067

2023-01-14 21:09:55,768 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:09:55,768 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:09:55,817 - 

2023-01-14 21:09:55,817 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:09:57,971 - Epoch: [347][    4/    4]    Overall Loss 0.006189    Objective Loss 0.006189    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.538169    
2023-01-14 21:09:58,002 - --- validate (epoch=347)-----------
2023-01-14 21:09:58,003 - 101 samples (240 per mini-batch)
2023-01-14 21:09:59,122 - Epoch: [347][    1/    1]    Loss 0.079557    Top1 97.029703    Top5 100.000000    
2023-01-14 21:09:59,154 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.080

2023-01-14 21:09:59,165 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:09:59,165 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:09:59,197 - 

2023-01-14 21:09:59,197 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:10:01,120 - Epoch: [348][    4/    4]    Overall Loss 0.006178    Objective Loss 0.006178    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.480516    
2023-01-14 21:10:01,165 - --- validate (epoch=348)-----------
2023-01-14 21:10:01,165 - 101 samples (240 per mini-batch)
2023-01-14 21:10:02,186 - Epoch: [348][    1/    1]    Loss 0.070428    Top1 97.029703    Top5 100.000000    
2023-01-14 21:10:02,221 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.070

2023-01-14 21:10:02,232 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:10:02,233 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:10:02,263 - 

2023-01-14 21:10:02,263 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:10:03,995 - Epoch: [349][    4/    4]    Overall Loss 0.006056    Objective Loss 0.006056    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.432511    
2023-01-14 21:10:04,026 - --- validate (epoch=349)-----------
2023-01-14 21:10:04,027 - 101 samples (240 per mini-batch)
2023-01-14 21:10:05,132 - Epoch: [349][    1/    1]    Loss 0.120739    Top1 94.059406    Top5 100.000000    
2023-01-14 21:10:05,163 - ==> Top1: 94.059    Top5: 100.000    Loss: 0.121

2023-01-14 21:10:05,174 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 264]
2023-01-14 21:10:05,175 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:10:05,202 - 

2023-01-14 21:10:05,202 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:10:07,152 - Epoch: [350][    4/    4]    Overall Loss 0.006277    Objective Loss 0.006277    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.487125    
2023-01-14 21:10:07,190 - --- validate (epoch=350)-----------
2023-01-14 21:10:07,191 - 101 samples (240 per mini-batch)
2023-01-14 21:10:08,275 - Epoch: [350][    1/    1]    Loss 0.066667    Top1 99.009901    Top5 100.000000    
2023-01-14 21:10:08,304 - ==> Top1: 99.010    Top5: 100.000    Loss: 0.067

2023-01-14 21:10:08,317 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 350]
2023-01-14 21:10:08,318 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:10:08,358 - 

2023-01-14 21:10:08,358 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:10:10,671 - Epoch: [351][    4/    4]    Overall Loss 0.006083    Objective Loss 0.006083    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.577853    
2023-01-14 21:10:10,715 - --- validate (epoch=351)-----------
2023-01-14 21:10:10,717 - 101 samples (240 per mini-batch)
2023-01-14 21:10:11,852 - Epoch: [351][    1/    1]    Loss 0.099858    Top1 97.029703    Top5 100.000000    
2023-01-14 21:10:11,891 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.100

2023-01-14 21:10:11,901 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 350]
2023-01-14 21:10:11,901 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:10:11,934 - 

2023-01-14 21:10:11,934 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:10:13,715 - Epoch: [352][    4/    4]    Overall Loss 0.005837    Objective Loss 0.005837    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.444988    
2023-01-14 21:10:13,762 - --- validate (epoch=352)-----------
2023-01-14 21:10:13,763 - 101 samples (240 per mini-batch)
2023-01-14 21:10:14,845 - Epoch: [352][    1/    1]    Loss 0.113327    Top1 95.049505    Top5 100.000000    
2023-01-14 21:10:14,886 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.113

2023-01-14 21:10:14,899 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 350]
2023-01-14 21:10:14,899 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:10:14,943 - 

2023-01-14 21:10:14,943 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:10:16,704 - Epoch: [353][    4/    4]    Overall Loss 0.006160    Objective Loss 0.006160    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.439810    
2023-01-14 21:10:16,732 - --- validate (epoch=353)-----------
2023-01-14 21:10:16,733 - 101 samples (240 per mini-batch)
2023-01-14 21:10:17,835 - Epoch: [353][    1/    1]    Loss 0.119502    Top1 95.049505    Top5 100.000000    
2023-01-14 21:10:17,872 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.120

2023-01-14 21:10:17,888 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 350]
2023-01-14 21:10:17,889 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:10:17,936 - 

2023-01-14 21:10:17,936 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:10:19,906 - Epoch: [354][    4/    4]    Overall Loss 0.006037    Objective Loss 0.006037    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.492106    
2023-01-14 21:10:19,942 - --- validate (epoch=354)-----------
2023-01-14 21:10:19,943 - 101 samples (240 per mini-batch)
2023-01-14 21:10:21,054 - Epoch: [354][    1/    1]    Loss 0.061989    Top1 99.009901    Top5 100.000000    
2023-01-14 21:10:21,088 - ==> Top1: 99.010    Top5: 100.000    Loss: 0.062

2023-01-14 21:10:21,100 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:10:21,100 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:10:21,131 - 

2023-01-14 21:10:21,131 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:10:22,954 - Epoch: [355][    4/    4]    Overall Loss 0.006293    Objective Loss 0.006293    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.455225    
2023-01-14 21:10:23,000 - --- validate (epoch=355)-----------
2023-01-14 21:10:23,001 - 101 samples (240 per mini-batch)
2023-01-14 21:10:24,116 - Epoch: [355][    1/    1]    Loss 0.121711    Top1 95.049505    Top5 100.000000    
2023-01-14 21:10:24,151 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.122

2023-01-14 21:10:24,161 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:10:24,162 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:10:24,201 - 

2023-01-14 21:10:24,201 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:10:26,126 - Epoch: [356][    4/    4]    Overall Loss 0.006390    Objective Loss 0.006390    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.480869    
2023-01-14 21:10:26,158 - --- validate (epoch=356)-----------
2023-01-14 21:10:26,158 - 101 samples (240 per mini-batch)
2023-01-14 21:10:27,155 - Epoch: [356][    1/    1]    Loss 0.078187    Top1 98.019802    Top5 100.000000    
2023-01-14 21:10:27,190 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.078

2023-01-14 21:10:27,199 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:10:27,199 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:10:27,232 - 

2023-01-14 21:10:27,233 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:10:29,176 - Epoch: [357][    4/    4]    Overall Loss 0.006245    Objective Loss 0.006245    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.485481    
2023-01-14 21:10:29,212 - --- validate (epoch=357)-----------
2023-01-14 21:10:29,213 - 101 samples (240 per mini-batch)
2023-01-14 21:10:30,332 - Epoch: [357][    1/    1]    Loss 0.096175    Top1 95.049505    Top5 100.000000    
2023-01-14 21:10:30,365 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.096

2023-01-14 21:10:30,375 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:10:30,376 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:10:30,410 - 

2023-01-14 21:10:30,410 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:10:32,295 - Epoch: [358][    4/    4]    Overall Loss 0.006393    Objective Loss 0.006393    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.470880    
2023-01-14 21:10:32,329 - --- validate (epoch=358)-----------
2023-01-14 21:10:32,330 - 101 samples (240 per mini-batch)
2023-01-14 21:10:33,424 - Epoch: [358][    1/    1]    Loss 0.081959    Top1 97.029703    Top5 100.000000    
2023-01-14 21:10:33,455 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.082

2023-01-14 21:10:33,470 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:10:33,470 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:10:33,566 - 

2023-01-14 21:10:33,566 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:10:35,340 - Epoch: [359][    4/    4]    Overall Loss 0.005888    Objective Loss 0.005888    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.443173    
2023-01-14 21:10:35,375 - --- validate (epoch=359)-----------
2023-01-14 21:10:35,376 - 101 samples (240 per mini-batch)
2023-01-14 21:10:36,485 - Epoch: [359][    1/    1]    Loss 0.070543    Top1 98.019802    Top5 100.000000    
2023-01-14 21:10:36,522 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.071

2023-01-14 21:10:36,532 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:10:36,533 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:10:36,578 - 

2023-01-14 21:10:36,578 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:10:38,531 - Epoch: [360][    4/    4]    Overall Loss 0.006197    Objective Loss 0.006197    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.487815    
2023-01-14 21:10:38,566 - --- validate (epoch=360)-----------
2023-01-14 21:10:38,567 - 101 samples (240 per mini-batch)
2023-01-14 21:10:39,673 - Epoch: [360][    1/    1]    Loss 0.090962    Top1 96.039604    Top5 100.000000    
2023-01-14 21:10:39,708 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.091

2023-01-14 21:10:39,719 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:10:39,719 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:10:39,750 - 

2023-01-14 21:10:39,750 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:10:41,682 - Epoch: [361][    4/    4]    Overall Loss 0.006326    Objective Loss 0.006326    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.482637    
2023-01-14 21:10:41,715 - --- validate (epoch=361)-----------
2023-01-14 21:10:41,715 - 101 samples (240 per mini-batch)
2023-01-14 21:10:42,743 - Epoch: [361][    1/    1]    Loss 0.098317    Top1 97.029703    Top5 100.000000    
2023-01-14 21:10:42,785 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.098

2023-01-14 21:10:42,801 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:10:42,801 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:10:42,839 - 

2023-01-14 21:10:42,840 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:10:44,887 - Epoch: [362][    4/    4]    Overall Loss 0.006112    Objective Loss 0.006112    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.511447    
2023-01-14 21:10:44,924 - --- validate (epoch=362)-----------
2023-01-14 21:10:44,925 - 101 samples (240 per mini-batch)
2023-01-14 21:10:46,000 - Epoch: [362][    1/    1]    Loss 0.075861    Top1 97.029703    Top5 100.000000    
2023-01-14 21:10:46,034 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.076

2023-01-14 21:10:46,048 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:10:46,048 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:10:46,094 - 

2023-01-14 21:10:46,094 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:10:48,048 - Epoch: [363][    4/    4]    Overall Loss 0.006072    Objective Loss 0.006072    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.488167    
2023-01-14 21:10:48,080 - --- validate (epoch=363)-----------
2023-01-14 21:10:48,081 - 101 samples (240 per mini-batch)
2023-01-14 21:10:49,098 - Epoch: [363][    1/    1]    Loss 0.058733    Top1 98.019802    Top5 100.000000    
2023-01-14 21:10:49,132 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.059

2023-01-14 21:10:49,142 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:10:49,142 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:10:49,169 - 

2023-01-14 21:10:49,170 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:10:50,791 - Epoch: [364][    4/    4]    Overall Loss 0.006275    Objective Loss 0.006275    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.405139    
2023-01-14 21:10:50,829 - --- validate (epoch=364)-----------
2023-01-14 21:10:50,829 - 101 samples (240 per mini-batch)
2023-01-14 21:10:51,900 - Epoch: [364][    1/    1]    Loss 0.096857    Top1 96.039604    Top5 100.000000    
2023-01-14 21:10:51,935 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.097

2023-01-14 21:10:51,945 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:10:51,946 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:10:51,973 - 

2023-01-14 21:10:51,973 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:10:53,916 - Epoch: [365][    4/    4]    Overall Loss 0.005904    Objective Loss 0.005904    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.485438    
2023-01-14 21:10:53,956 - --- validate (epoch=365)-----------
2023-01-14 21:10:53,956 - 101 samples (240 per mini-batch)
2023-01-14 21:10:55,082 - Epoch: [365][    1/    1]    Loss 0.092883    Top1 96.039604    Top5 100.000000    
2023-01-14 21:10:55,121 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.093

2023-01-14 21:10:55,131 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:10:55,132 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:10:55,166 - 

2023-01-14 21:10:55,167 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:10:56,951 - Epoch: [366][    4/    4]    Overall Loss 0.006219    Objective Loss 0.006219    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.445844    
2023-01-14 21:10:56,989 - --- validate (epoch=366)-----------
2023-01-14 21:10:56,990 - 101 samples (240 per mini-batch)
2023-01-14 21:10:58,117 - Epoch: [366][    1/    1]    Loss 0.093304    Top1 98.019802    Top5 100.000000    
2023-01-14 21:10:58,167 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.093

2023-01-14 21:10:58,175 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:10:58,176 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:10:58,210 - 

2023-01-14 21:10:58,211 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:11:00,276 - Epoch: [367][    4/    4]    Overall Loss 0.006104    Objective Loss 0.006104    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.515934    
2023-01-14 21:11:00,321 - --- validate (epoch=367)-----------
2023-01-14 21:11:00,322 - 101 samples (240 per mini-batch)
2023-01-14 21:11:01,416 - Epoch: [367][    1/    1]    Loss 0.102704    Top1 97.029703    Top5 100.000000    
2023-01-14 21:11:01,453 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.103

2023-01-14 21:11:01,470 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:11:01,470 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:11:01,522 - 

2023-01-14 21:11:01,523 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:11:03,308 - Epoch: [368][    4/    4]    Overall Loss 0.006050    Objective Loss 0.006050    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.445945    
2023-01-14 21:11:03,346 - --- validate (epoch=368)-----------
2023-01-14 21:11:03,346 - 101 samples (240 per mini-batch)
2023-01-14 21:11:04,427 - Epoch: [368][    1/    1]    Loss 0.116409    Top1 96.039604    Top5 100.000000    
2023-01-14 21:11:04,459 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.116

2023-01-14 21:11:04,476 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:11:04,476 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:11:04,518 - 

2023-01-14 21:11:04,518 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:11:06,476 - Epoch: [369][    4/    4]    Overall Loss 0.006101    Objective Loss 0.006101    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.489102    
2023-01-14 21:11:06,509 - --- validate (epoch=369)-----------
2023-01-14 21:11:06,510 - 101 samples (240 per mini-batch)
2023-01-14 21:11:07,526 - Epoch: [369][    1/    1]    Loss 0.064420    Top1 98.019802    Top5 100.000000    
2023-01-14 21:11:07,560 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.064

2023-01-14 21:11:07,573 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:11:07,574 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:11:07,607 - 

2023-01-14 21:11:07,608 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:11:09,652 - Epoch: [370][    4/    4]    Overall Loss 0.006016    Objective Loss 0.006016    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.510799    
2023-01-14 21:11:09,690 - --- validate (epoch=370)-----------
2023-01-14 21:11:09,691 - 101 samples (240 per mini-batch)
2023-01-14 21:11:10,847 - Epoch: [370][    1/    1]    Loss 0.084895    Top1 98.019802    Top5 100.000000    
2023-01-14 21:11:10,883 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.085

2023-01-14 21:11:10,892 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:11:10,892 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:11:10,919 - 

2023-01-14 21:11:10,920 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:11:12,670 - Epoch: [371][    4/    4]    Overall Loss 0.006135    Objective Loss 0.006135    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.437403    
2023-01-14 21:11:12,703 - --- validate (epoch=371)-----------
2023-01-14 21:11:12,703 - 101 samples (240 per mini-batch)
2023-01-14 21:11:13,730 - Epoch: [371][    1/    1]    Loss 0.109691    Top1 96.039604    Top5 100.000000    
2023-01-14 21:11:13,768 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.110

2023-01-14 21:11:13,780 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:11:13,780 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:11:13,822 - 

2023-01-14 21:11:13,823 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:11:15,824 - Epoch: [372][    4/    4]    Overall Loss 0.006138    Objective Loss 0.006138    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.499994    
2023-01-14 21:11:15,857 - --- validate (epoch=372)-----------
2023-01-14 21:11:15,858 - 101 samples (240 per mini-batch)
2023-01-14 21:11:16,896 - Epoch: [372][    1/    1]    Loss 0.085369    Top1 97.029703    Top5 100.000000    
2023-01-14 21:11:16,934 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.085

2023-01-14 21:11:16,945 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:11:16,945 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:11:16,972 - 

2023-01-14 21:11:16,972 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:11:18,751 - Epoch: [373][    4/    4]    Overall Loss 0.006172    Objective Loss 0.006172    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.444381    
2023-01-14 21:11:18,790 - --- validate (epoch=373)-----------
2023-01-14 21:11:18,790 - 101 samples (240 per mini-batch)
2023-01-14 21:11:19,910 - Epoch: [373][    1/    1]    Loss 0.066958    Top1 98.019802    Top5 100.000000    
2023-01-14 21:11:19,946 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.067

2023-01-14 21:11:19,957 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:11:19,958 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:11:19,994 - 

2023-01-14 21:11:19,994 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:11:21,884 - Epoch: [374][    4/    4]    Overall Loss 0.006082    Objective Loss 0.006082    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.472315    
2023-01-14 21:11:21,933 - --- validate (epoch=374)-----------
2023-01-14 21:11:21,933 - 101 samples (240 per mini-batch)
2023-01-14 21:11:22,997 - Epoch: [374][    1/    1]    Loss 0.094496    Top1 97.029703    Top5 100.000000    
2023-01-14 21:11:23,033 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.094

2023-01-14 21:11:23,050 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:11:23,050 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:11:23,103 - 

2023-01-14 21:11:23,104 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:11:24,811 - Epoch: [375][    4/    4]    Overall Loss 0.006375    Objective Loss 0.006375    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.426121    
2023-01-14 21:11:24,845 - --- validate (epoch=375)-----------
2023-01-14 21:11:24,846 - 101 samples (240 per mini-batch)
2023-01-14 21:11:25,953 - Epoch: [375][    1/    1]    Loss 0.103867    Top1 96.039604    Top5 100.000000    
2023-01-14 21:11:25,994 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.104

2023-01-14 21:11:26,007 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:11:26,007 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:11:26,043 - 

2023-01-14 21:11:26,043 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:11:27,775 - Epoch: [376][    4/    4]    Overall Loss 0.006224    Objective Loss 0.006224    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.432682    
2023-01-14 21:11:27,814 - --- validate (epoch=376)-----------
2023-01-14 21:11:27,814 - 101 samples (240 per mini-batch)
2023-01-14 21:11:28,917 - Epoch: [376][    1/    1]    Loss 0.086262    Top1 97.029703    Top5 100.000000    
2023-01-14 21:11:28,952 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.086

2023-01-14 21:11:28,962 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:11:28,962 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:11:28,999 - 

2023-01-14 21:11:28,999 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:11:30,637 - Epoch: [377][    4/    4]    Overall Loss 0.006130    Objective Loss 0.006130    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.409039    
2023-01-14 21:11:30,680 - --- validate (epoch=377)-----------
2023-01-14 21:11:30,680 - 101 samples (240 per mini-batch)
2023-01-14 21:11:31,818 - Epoch: [377][    1/    1]    Loss 0.085175    Top1 97.029703    Top5 100.000000    
2023-01-14 21:11:31,856 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.085

2023-01-14 21:11:31,867 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:11:31,867 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:11:31,907 - 

2023-01-14 21:11:31,907 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:11:33,968 - Epoch: [378][    4/    4]    Overall Loss 0.005968    Objective Loss 0.005968    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.514801    
2023-01-14 21:11:34,005 - --- validate (epoch=378)-----------
2023-01-14 21:11:34,005 - 101 samples (240 per mini-batch)
2023-01-14 21:11:35,090 - Epoch: [378][    1/    1]    Loss 0.104507    Top1 97.029703    Top5 100.000000    
2023-01-14 21:11:35,123 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.105

2023-01-14 21:11:35,141 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:11:35,141 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:11:35,174 - 

2023-01-14 21:11:35,174 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:11:37,324 - Epoch: [379][    4/    4]    Overall Loss 0.006221    Objective Loss 0.006221    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.537055    
2023-01-14 21:11:37,363 - --- validate (epoch=379)-----------
2023-01-14 21:11:37,364 - 101 samples (240 per mini-batch)
2023-01-14 21:11:38,473 - Epoch: [379][    1/    1]    Loss 0.080956    Top1 97.029703    Top5 100.000000    
2023-01-14 21:11:38,505 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.081

2023-01-14 21:11:38,518 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:11:38,518 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:11:38,552 - 

2023-01-14 21:11:38,552 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:11:39,996 - Epoch: [380][    4/    4]    Overall Loss 0.006174    Objective Loss 0.006174    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.360695    
2023-01-14 21:11:40,037 - --- validate (epoch=380)-----------
2023-01-14 21:11:40,038 - 101 samples (240 per mini-batch)
2023-01-14 21:11:41,155 - Epoch: [380][    1/    1]    Loss 0.105698    Top1 96.039604    Top5 100.000000    
2023-01-14 21:11:41,192 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.106

2023-01-14 21:11:41,203 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:11:41,203 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:11:41,229 - 

2023-01-14 21:11:41,229 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:11:43,365 - Epoch: [381][    4/    4]    Overall Loss 0.006138    Objective Loss 0.006138    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.533546    
2023-01-14 21:11:43,395 - --- validate (epoch=381)-----------
2023-01-14 21:11:43,396 - 101 samples (240 per mini-batch)
2023-01-14 21:11:44,480 - Epoch: [381][    1/    1]    Loss 0.064797    Top1 98.019802    Top5 100.000000    
2023-01-14 21:11:44,519 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.065

2023-01-14 21:11:44,535 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:11:44,535 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:11:44,574 - 

2023-01-14 21:11:44,574 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:11:46,033 - Epoch: [382][    4/    4]    Overall Loss 0.006221    Objective Loss 0.006221    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.364460    
2023-01-14 21:11:46,073 - --- validate (epoch=382)-----------
2023-01-14 21:11:46,073 - 101 samples (240 per mini-batch)
2023-01-14 21:11:47,174 - Epoch: [382][    1/    1]    Loss 0.065494    Top1 98.019802    Top5 100.000000    
2023-01-14 21:11:47,222 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.065

2023-01-14 21:11:47,234 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:11:47,235 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:11:47,276 - 

2023-01-14 21:11:47,277 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:11:49,356 - Epoch: [383][    4/    4]    Overall Loss 0.006092    Objective Loss 0.006092    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.519120    
2023-01-14 21:11:49,388 - --- validate (epoch=383)-----------
2023-01-14 21:11:49,388 - 101 samples (240 per mini-batch)
2023-01-14 21:11:50,506 - Epoch: [383][    1/    1]    Loss 0.113673    Top1 96.039604    Top5 100.000000    
2023-01-14 21:11:50,539 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.114

2023-01-14 21:11:50,555 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:11:50,556 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:11:50,586 - 

2023-01-14 21:11:50,587 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:11:52,240 - Epoch: [384][    4/    4]    Overall Loss 0.006178    Objective Loss 0.006178    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.412928    
2023-01-14 21:11:52,280 - --- validate (epoch=384)-----------
2023-01-14 21:11:52,280 - 101 samples (240 per mini-batch)
2023-01-14 21:11:53,352 - Epoch: [384][    1/    1]    Loss 0.091370    Top1 96.039604    Top5 100.000000    
2023-01-14 21:11:53,381 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.091

2023-01-14 21:11:53,398 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:11:53,398 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:11:53,449 - 

2023-01-14 21:11:53,449 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:11:55,377 - Epoch: [385][    4/    4]    Overall Loss 0.005999    Objective Loss 0.005999    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.481688    
2023-01-14 21:11:55,410 - --- validate (epoch=385)-----------
2023-01-14 21:11:55,411 - 101 samples (240 per mini-batch)
2023-01-14 21:11:56,446 - Epoch: [385][    1/    1]    Loss 0.113126    Top1 95.049505    Top5 100.000000    
2023-01-14 21:11:56,483 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.113

2023-01-14 21:11:56,495 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:11:56,497 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:11:56,531 - 

2023-01-14 21:11:56,531 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:11:58,428 - Epoch: [386][    4/    4]    Overall Loss 0.006187    Objective Loss 0.006187    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.473750    
2023-01-14 21:11:58,460 - --- validate (epoch=386)-----------
2023-01-14 21:11:58,461 - 101 samples (240 per mini-batch)
2023-01-14 21:11:59,594 - Epoch: [386][    1/    1]    Loss 0.099427    Top1 97.029703    Top5 100.000000    
2023-01-14 21:11:59,628 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.099

2023-01-14 21:11:59,637 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:11:59,637 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:11:59,670 - 

2023-01-14 21:11:59,670 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:12:01,587 - Epoch: [387][    4/    4]    Overall Loss 0.006173    Objective Loss 0.006173    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.478929    
2023-01-14 21:12:01,627 - --- validate (epoch=387)-----------
2023-01-14 21:12:01,628 - 101 samples (240 per mini-batch)
2023-01-14 21:12:02,638 - Epoch: [387][    1/    1]    Loss 0.097418    Top1 96.039604    Top5 100.000000    
2023-01-14 21:12:02,675 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.097

2023-01-14 21:12:02,684 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:12:02,684 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:12:02,725 - 

2023-01-14 21:12:02,725 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:12:04,445 - Epoch: [388][    4/    4]    Overall Loss 0.006010    Objective Loss 0.006010    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.429712    
2023-01-14 21:12:04,481 - --- validate (epoch=388)-----------
2023-01-14 21:12:04,482 - 101 samples (240 per mini-batch)
2023-01-14 21:12:05,643 - Epoch: [388][    1/    1]    Loss 0.113236    Top1 95.049505    Top5 100.000000    
2023-01-14 21:12:05,681 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.113

2023-01-14 21:12:05,693 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:12:05,693 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:12:05,727 - 

2023-01-14 21:12:05,728 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:12:07,433 - Epoch: [389][    4/    4]    Overall Loss 0.006150    Objective Loss 0.006150    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.426024    
2023-01-14 21:12:07,474 - --- validate (epoch=389)-----------
2023-01-14 21:12:07,474 - 101 samples (240 per mini-batch)
2023-01-14 21:12:08,497 - Epoch: [389][    1/    1]    Loss 0.092029    Top1 97.029703    Top5 100.000000    
2023-01-14 21:12:08,529 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.092

2023-01-14 21:12:08,542 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:12:08,543 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:12:08,572 - 

2023-01-14 21:12:08,573 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:12:10,461 - Epoch: [390][    4/    4]    Overall Loss 0.006269    Objective Loss 0.006269    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.471825    
2023-01-14 21:12:10,501 - --- validate (epoch=390)-----------
2023-01-14 21:12:10,501 - 101 samples (240 per mini-batch)
2023-01-14 21:12:11,509 - Epoch: [390][    1/    1]    Loss 0.104582    Top1 96.039604    Top5 100.000000    
2023-01-14 21:12:11,539 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.105

2023-01-14 21:12:11,547 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:12:11,548 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:12:11,576 - 

2023-01-14 21:12:11,577 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:12:13,200 - Epoch: [391][    4/    4]    Overall Loss 0.005949    Objective Loss 0.005949    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.405430    
2023-01-14 21:12:13,245 - --- validate (epoch=391)-----------
2023-01-14 21:12:13,246 - 101 samples (240 per mini-batch)
2023-01-14 21:12:14,358 - Epoch: [391][    1/    1]    Loss 0.061500    Top1 98.019802    Top5 100.000000    
2023-01-14 21:12:14,395 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.062

2023-01-14 21:12:14,407 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:12:14,407 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:12:14,442 - 

2023-01-14 21:12:14,443 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:12:16,467 - Epoch: [392][    4/    4]    Overall Loss 0.005998    Objective Loss 0.005998    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.505772    
2023-01-14 21:12:16,504 - --- validate (epoch=392)-----------
2023-01-14 21:12:16,505 - 101 samples (240 per mini-batch)
2023-01-14 21:12:17,541 - Epoch: [392][    1/    1]    Loss 0.082311    Top1 97.029703    Top5 100.000000    
2023-01-14 21:12:17,571 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.082

2023-01-14 21:12:17,585 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:12:17,585 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:12:17,621 - 

2023-01-14 21:12:17,621 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:12:19,731 - Epoch: [393][    4/    4]    Overall Loss 0.005809    Objective Loss 0.005809    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.527205    
2023-01-14 21:12:19,767 - --- validate (epoch=393)-----------
2023-01-14 21:12:19,768 - 101 samples (240 per mini-batch)
2023-01-14 21:12:20,861 - Epoch: [393][    1/    1]    Loss 0.069748    Top1 98.019802    Top5 100.000000    
2023-01-14 21:12:20,899 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.070

2023-01-14 21:12:20,912 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:12:20,913 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:12:20,942 - 

2023-01-14 21:12:20,943 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:12:22,715 - Epoch: [394][    4/    4]    Overall Loss 0.005983    Objective Loss 0.005983    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.442753    
2023-01-14 21:12:22,751 - --- validate (epoch=394)-----------
2023-01-14 21:12:22,752 - 101 samples (240 per mini-batch)
2023-01-14 21:12:23,838 - Epoch: [394][    1/    1]    Loss 0.076509    Top1 97.029703    Top5 100.000000    
2023-01-14 21:12:23,879 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.077

2023-01-14 21:12:23,892 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:12:23,893 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:12:23,932 - 

2023-01-14 21:12:23,934 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:12:25,450 - Epoch: [395][    4/    4]    Overall Loss 0.006206    Objective Loss 0.006206    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.378129    
2023-01-14 21:12:25,487 - --- validate (epoch=395)-----------
2023-01-14 21:12:25,488 - 101 samples (240 per mini-batch)
2023-01-14 21:12:26,665 - Epoch: [395][    1/    1]    Loss 0.075618    Top1 98.019802    Top5 100.000000    
2023-01-14 21:12:26,698 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.076

2023-01-14 21:12:26,715 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:12:26,715 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:12:26,763 - 

2023-01-14 21:12:26,763 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:12:28,585 - Epoch: [396][    4/    4]    Overall Loss 0.005869    Objective Loss 0.005869    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.455251    
2023-01-14 21:12:28,616 - --- validate (epoch=396)-----------
2023-01-14 21:12:28,617 - 101 samples (240 per mini-batch)
2023-01-14 21:12:29,708 - Epoch: [396][    1/    1]    Loss 0.090345    Top1 96.039604    Top5 100.000000    
2023-01-14 21:12:29,739 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.090

2023-01-14 21:12:29,755 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:12:29,755 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:12:29,783 - 

2023-01-14 21:12:29,784 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:12:31,966 - Epoch: [397][    4/    4]    Overall Loss 0.005947    Objective Loss 0.005947    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.545209    
2023-01-14 21:12:32,002 - --- validate (epoch=397)-----------
2023-01-14 21:12:32,003 - 101 samples (240 per mini-batch)
2023-01-14 21:12:33,063 - Epoch: [397][    1/    1]    Loss 0.102265    Top1 96.039604    Top5 100.000000    
2023-01-14 21:12:33,100 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.102

2023-01-14 21:12:33,115 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:12:33,115 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:12:33,152 - 

2023-01-14 21:12:33,153 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:12:35,431 - Epoch: [398][    4/    4]    Overall Loss 0.005878    Objective Loss 0.005878    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.569379    
2023-01-14 21:12:35,465 - --- validate (epoch=398)-----------
2023-01-14 21:12:35,466 - 101 samples (240 per mini-batch)
2023-01-14 21:12:36,585 - Epoch: [398][    1/    1]    Loss 0.078344    Top1 97.029703    Top5 100.000000    
2023-01-14 21:12:36,624 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.078

2023-01-14 21:12:36,637 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:12:36,638 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:12:36,672 - 

2023-01-14 21:12:36,673 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:12:38,599 - Epoch: [399][    4/    4]    Overall Loss 0.005938    Objective Loss 0.005938    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.481334    
2023-01-14 21:12:38,637 - --- validate (epoch=399)-----------
2023-01-14 21:12:38,637 - 101 samples (240 per mini-batch)
2023-01-14 21:12:39,654 - Epoch: [399][    1/    1]    Loss 0.108963    Top1 96.039604    Top5 100.000000    
2023-01-14 21:12:39,689 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.109

2023-01-14 21:12:39,698 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:12:39,699 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:12:39,732 - 

2023-01-14 21:12:39,732 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:12:41,616 - Epoch: [400][    4/    4]    Overall Loss 0.005950    Objective Loss 0.005950    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.470788    
2023-01-14 21:12:41,646 - --- validate (epoch=400)-----------
2023-01-14 21:12:41,647 - 101 samples (240 per mini-batch)
2023-01-14 21:12:42,828 - Epoch: [400][    1/    1]    Loss 0.075587    Top1 98.019802    Top5 100.000000    
2023-01-14 21:12:42,863 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.076

2023-01-14 21:12:42,873 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:12:42,873 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:12:42,909 - 

2023-01-14 21:12:42,909 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:12:44,510 - Epoch: [401][    4/    4]    Overall Loss 0.005957    Objective Loss 0.005957    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.400029    
2023-01-14 21:12:44,548 - --- validate (epoch=401)-----------
2023-01-14 21:12:44,549 - 101 samples (240 per mini-batch)
2023-01-14 21:12:45,649 - Epoch: [401][    1/    1]    Loss 0.101112    Top1 95.049505    Top5 100.000000    
2023-01-14 21:12:45,682 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.101

2023-01-14 21:12:45,692 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:12:45,692 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:12:45,721 - 

2023-01-14 21:12:45,722 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:12:47,490 - Epoch: [402][    4/    4]    Overall Loss 0.005817    Objective Loss 0.005817    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.441654    
2023-01-14 21:12:47,527 - --- validate (epoch=402)-----------
2023-01-14 21:12:47,529 - 101 samples (240 per mini-batch)
2023-01-14 21:12:48,651 - Epoch: [402][    1/    1]    Loss 0.081700    Top1 97.029703    Top5 100.000000    
2023-01-14 21:12:48,688 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.082

2023-01-14 21:12:48,757 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:12:48,758 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:12:48,792 - 

2023-01-14 21:12:48,792 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:12:50,904 - Epoch: [403][    4/    4]    Overall Loss 0.005908    Objective Loss 0.005908    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.527605    
2023-01-14 21:12:50,939 - --- validate (epoch=403)-----------
2023-01-14 21:12:50,939 - 101 samples (240 per mini-batch)
2023-01-14 21:12:52,041 - Epoch: [403][    1/    1]    Loss 0.093709    Top1 97.029703    Top5 100.000000    
2023-01-14 21:12:52,071 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.094

2023-01-14 21:12:52,083 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:12:52,083 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:12:52,117 - 

2023-01-14 21:12:52,118 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:12:53,935 - Epoch: [404][    4/    4]    Overall Loss 0.005755    Objective Loss 0.005755    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.453914    
2023-01-14 21:12:53,978 - --- validate (epoch=404)-----------
2023-01-14 21:12:53,980 - 101 samples (240 per mini-batch)
2023-01-14 21:12:55,154 - Epoch: [404][    1/    1]    Loss 0.098889    Top1 97.029703    Top5 100.000000    
2023-01-14 21:12:55,195 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.099

2023-01-14 21:12:55,209 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:12:55,209 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:12:55,243 - 

2023-01-14 21:12:55,243 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:12:57,073 - Epoch: [405][    4/    4]    Overall Loss 0.005934    Objective Loss 0.005934    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.456943    
2023-01-14 21:12:57,103 - --- validate (epoch=405)-----------
2023-01-14 21:12:57,104 - 101 samples (240 per mini-batch)
2023-01-14 21:12:58,185 - Epoch: [405][    1/    1]    Loss 0.087529    Top1 98.019802    Top5 100.000000    
2023-01-14 21:12:58,218 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.088

2023-01-14 21:12:58,230 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:12:58,231 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:12:58,266 - 

2023-01-14 21:12:58,266 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:13:00,081 - Epoch: [406][    4/    4]    Overall Loss 0.005864    Objective Loss 0.005864    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.453362    
2023-01-14 21:13:00,115 - --- validate (epoch=406)-----------
2023-01-14 21:13:00,115 - 101 samples (240 per mini-batch)
2023-01-14 21:13:01,115 - Epoch: [406][    1/    1]    Loss 0.080665    Top1 97.029703    Top5 100.000000    
2023-01-14 21:13:01,150 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.081

2023-01-14 21:13:01,159 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:13:01,159 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:13:01,189 - 

2023-01-14 21:13:01,189 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:13:02,932 - Epoch: [407][    4/    4]    Overall Loss 0.005821    Objective Loss 0.005821    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.435525    
2023-01-14 21:13:02,977 - --- validate (epoch=407)-----------
2023-01-14 21:13:02,977 - 101 samples (240 per mini-batch)
2023-01-14 21:13:04,122 - Epoch: [407][    1/    1]    Loss 0.075569    Top1 97.029703    Top5 100.000000    
2023-01-14 21:13:04,161 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.076

2023-01-14 21:13:04,172 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:13:04,173 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:13:04,205 - 

2023-01-14 21:13:04,205 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:13:06,080 - Epoch: [408][    4/    4]    Overall Loss 0.005803    Objective Loss 0.005803    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.468283    
2023-01-14 21:13:06,120 - --- validate (epoch=408)-----------
2023-01-14 21:13:06,121 - 101 samples (240 per mini-batch)
2023-01-14 21:13:07,141 - Epoch: [408][    1/    1]    Loss 0.115124    Top1 94.059406    Top5 100.000000    
2023-01-14 21:13:07,173 - ==> Top1: 94.059    Top5: 100.000    Loss: 0.115

2023-01-14 21:13:07,186 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:13:07,186 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:13:07,214 - 

2023-01-14 21:13:07,214 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:13:08,964 - Epoch: [409][    4/    4]    Overall Loss 0.006020    Objective Loss 0.006020    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.437230    
2023-01-14 21:13:08,995 - --- validate (epoch=409)-----------
2023-01-14 21:13:08,996 - 101 samples (240 per mini-batch)
2023-01-14 21:13:10,098 - Epoch: [409][    1/    1]    Loss 0.103612    Top1 95.049505    Top5 100.000000    
2023-01-14 21:13:10,141 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.104

2023-01-14 21:13:10,151 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:13:10,152 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:13:10,191 - 

2023-01-14 21:13:10,192 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:13:12,127 - Epoch: [410][    4/    4]    Overall Loss 0.005976    Objective Loss 0.005976    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.483512    
2023-01-14 21:13:12,170 - --- validate (epoch=410)-----------
2023-01-14 21:13:12,171 - 101 samples (240 per mini-batch)
2023-01-14 21:13:13,251 - Epoch: [410][    1/    1]    Loss 0.107460    Top1 96.039604    Top5 100.000000    
2023-01-14 21:13:13,287 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.107

2023-01-14 21:13:13,299 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:13:13,299 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:13:13,345 - 

2023-01-14 21:13:13,345 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:13:15,023 - Epoch: [411][    4/    4]    Overall Loss 0.006115    Objective Loss 0.006115    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.419253    
2023-01-14 21:13:15,057 - --- validate (epoch=411)-----------
2023-01-14 21:13:15,058 - 101 samples (240 per mini-batch)
2023-01-14 21:13:16,109 - Epoch: [411][    1/    1]    Loss 0.080771    Top1 97.029703    Top5 100.000000    
2023-01-14 21:13:16,148 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.081

2023-01-14 21:13:16,163 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:13:16,163 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:13:16,209 - 

2023-01-14 21:13:16,209 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:13:17,881 - Epoch: [412][    4/    4]    Overall Loss 0.005680    Objective Loss 0.005680    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.417646    
2023-01-14 21:13:17,918 - --- validate (epoch=412)-----------
2023-01-14 21:13:17,918 - 101 samples (240 per mini-batch)
2023-01-14 21:13:19,023 - Epoch: [412][    1/    1]    Loss 0.089818    Top1 97.029703    Top5 100.000000    
2023-01-14 21:13:19,061 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.090

2023-01-14 21:13:19,071 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:13:19,071 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:13:19,108 - 

2023-01-14 21:13:19,108 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:13:21,222 - Epoch: [413][    4/    4]    Overall Loss 0.006063    Objective Loss 0.006063    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.528033    
2023-01-14 21:13:21,270 - --- validate (epoch=413)-----------
2023-01-14 21:13:21,271 - 101 samples (240 per mini-batch)
2023-01-14 21:13:22,383 - Epoch: [413][    1/    1]    Loss 0.088858    Top1 98.019802    Top5 100.000000    
2023-01-14 21:13:22,418 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.089

2023-01-14 21:13:22,433 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:13:22,433 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:13:22,466 - 

2023-01-14 21:13:22,466 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:13:24,198 - Epoch: [414][    4/    4]    Overall Loss 0.006061    Objective Loss 0.006061    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.432489    
2023-01-14 21:13:24,239 - --- validate (epoch=414)-----------
2023-01-14 21:13:24,239 - 101 samples (240 per mini-batch)
2023-01-14 21:13:25,327 - Epoch: [414][    1/    1]    Loss 0.093714    Top1 96.039604    Top5 100.000000    
2023-01-14 21:13:25,361 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.094

2023-01-14 21:13:25,377 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:13:25,377 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:13:25,416 - 

2023-01-14 21:13:25,416 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:13:26,878 - Epoch: [415][    4/    4]    Overall Loss 0.006075    Objective Loss 0.006075    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.364653    
2023-01-14 21:13:26,916 - --- validate (epoch=415)-----------
2023-01-14 21:13:26,916 - 101 samples (240 per mini-batch)
2023-01-14 21:13:27,924 - Epoch: [415][    1/    1]    Loss 0.103930    Top1 97.029703    Top5 100.000000    
2023-01-14 21:13:27,956 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.104

2023-01-14 21:13:27,968 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:13:27,968 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:13:28,003 - 

2023-01-14 21:13:28,004 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:13:29,763 - Epoch: [416][    4/    4]    Overall Loss 0.005971    Objective Loss 0.005971    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.439645    
2023-01-14 21:13:29,802 - --- validate (epoch=416)-----------
2023-01-14 21:13:29,802 - 101 samples (240 per mini-batch)
2023-01-14 21:13:30,864 - Epoch: [416][    1/    1]    Loss 0.082932    Top1 98.019802    Top5 100.000000    
2023-01-14 21:13:30,899 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.083

2023-01-14 21:13:30,913 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:13:30,913 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:13:30,956 - 

2023-01-14 21:13:30,956 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:13:32,646 - Epoch: [417][    4/    4]    Overall Loss 0.006052    Objective Loss 0.006052    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.421924    
2023-01-14 21:13:32,685 - --- validate (epoch=417)-----------
2023-01-14 21:13:32,686 - 101 samples (240 per mini-batch)
2023-01-14 21:13:33,799 - Epoch: [417][    1/    1]    Loss 0.090599    Top1 97.029703    Top5 100.000000    
2023-01-14 21:13:33,831 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.091

2023-01-14 21:13:33,844 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:13:33,844 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:13:33,877 - 

2023-01-14 21:13:33,878 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:13:35,831 - Epoch: [418][    4/    4]    Overall Loss 0.006038    Objective Loss 0.006038    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.487925    
2023-01-14 21:13:35,871 - --- validate (epoch=418)-----------
2023-01-14 21:13:35,871 - 101 samples (240 per mini-batch)
2023-01-14 21:13:36,981 - Epoch: [418][    1/    1]    Loss 0.084099    Top1 96.039604    Top5 100.000000    
2023-01-14 21:13:37,011 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.084

2023-01-14 21:13:37,021 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:13:37,022 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:13:37,059 - 

2023-01-14 21:13:37,059 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:13:38,918 - Epoch: [419][    4/    4]    Overall Loss 0.006010    Objective Loss 0.006010    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.464478    
2023-01-14 21:13:38,948 - --- validate (epoch=419)-----------
2023-01-14 21:13:38,949 - 101 samples (240 per mini-batch)
2023-01-14 21:13:39,976 - Epoch: [419][    1/    1]    Loss 0.088628    Top1 97.029703    Top5 100.000000    
2023-01-14 21:13:40,011 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.089

2023-01-14 21:13:40,019 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:13:40,019 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:13:40,052 - 

2023-01-14 21:13:40,052 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:13:41,954 - Epoch: [420][    4/    4]    Overall Loss 0.006100    Objective Loss 0.006100    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.475277    
2023-01-14 21:13:41,992 - --- validate (epoch=420)-----------
2023-01-14 21:13:41,993 - 101 samples (240 per mini-batch)
2023-01-14 21:13:43,091 - Epoch: [420][    1/    1]    Loss 0.110304    Top1 95.049505    Top5 100.000000    
2023-01-14 21:13:43,144 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.110

2023-01-14 21:13:43,160 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:13:43,160 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:13:43,207 - 

2023-01-14 21:13:43,208 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:13:45,194 - Epoch: [421][    4/    4]    Overall Loss 0.006181    Objective Loss 0.006181    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.495977    
2023-01-14 21:13:45,236 - --- validate (epoch=421)-----------
2023-01-14 21:13:45,236 - 101 samples (240 per mini-batch)
2023-01-14 21:13:46,430 - Epoch: [421][    1/    1]    Loss 0.105252    Top1 96.039604    Top5 100.000000    
2023-01-14 21:13:46,474 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.105

2023-01-14 21:13:46,490 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:13:46,491 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:13:46,543 - 

2023-01-14 21:13:46,543 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:13:48,320 - Epoch: [422][    4/    4]    Overall Loss 0.006126    Objective Loss 0.006126    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.443697    
2023-01-14 21:13:48,353 - --- validate (epoch=422)-----------
2023-01-14 21:13:48,354 - 101 samples (240 per mini-batch)
2023-01-14 21:13:49,479 - Epoch: [422][    1/    1]    Loss 0.073496    Top1 97.029703    Top5 100.000000    
2023-01-14 21:13:49,516 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.073

2023-01-14 21:13:49,528 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:13:49,529 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:13:49,561 - 

2023-01-14 21:13:49,562 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:13:51,327 - Epoch: [423][    4/    4]    Overall Loss 0.005906    Objective Loss 0.005906    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.440997    
2023-01-14 21:13:51,365 - --- validate (epoch=423)-----------
2023-01-14 21:13:51,365 - 101 samples (240 per mini-batch)
2023-01-14 21:13:52,532 - Epoch: [423][    1/    1]    Loss 0.109798    Top1 95.049505    Top5 100.000000    
2023-01-14 21:13:52,569 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.110

2023-01-14 21:13:52,580 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:13:52,580 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:13:52,614 - 

2023-01-14 21:13:52,614 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:13:54,529 - Epoch: [424][    4/    4]    Overall Loss 0.005978    Objective Loss 0.005978    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.478426    
2023-01-14 21:13:54,569 - --- validate (epoch=424)-----------
2023-01-14 21:13:54,569 - 101 samples (240 per mini-batch)
2023-01-14 21:13:55,703 - Epoch: [424][    1/    1]    Loss 0.069753    Top1 98.019802    Top5 100.000000    
2023-01-14 21:13:55,745 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.070

2023-01-14 21:13:55,757 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:13:55,758 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:13:55,790 - 

2023-01-14 21:13:55,790 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:13:57,532 - Epoch: [425][    4/    4]    Overall Loss 0.005939    Objective Loss 0.005939    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.435140    
2023-01-14 21:13:57,566 - --- validate (epoch=425)-----------
2023-01-14 21:13:57,567 - 101 samples (240 per mini-batch)
2023-01-14 21:13:58,587 - Epoch: [425][    1/    1]    Loss 0.099731    Top1 97.029703    Top5 100.000000    
2023-01-14 21:13:58,643 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.100

2023-01-14 21:13:58,655 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:13:58,657 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:13:58,690 - 

2023-01-14 21:13:58,691 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:14:00,903 - Epoch: [426][    4/    4]    Overall Loss 0.005932    Objective Loss 0.005932    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.552583    
2023-01-14 21:14:00,934 - --- validate (epoch=426)-----------
2023-01-14 21:14:00,935 - 101 samples (240 per mini-batch)
2023-01-14 21:14:02,089 - Epoch: [426][    1/    1]    Loss 0.073866    Top1 97.029703    Top5 100.000000    
2023-01-14 21:14:02,124 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.074

2023-01-14 21:14:02,137 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:14:02,137 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:14:02,168 - 

2023-01-14 21:14:02,168 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:14:03,919 - Epoch: [427][    4/    4]    Overall Loss 0.005843    Objective Loss 0.005843    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.437456    
2023-01-14 21:14:03,950 - --- validate (epoch=427)-----------
2023-01-14 21:14:03,951 - 101 samples (240 per mini-batch)
2023-01-14 21:14:05,024 - Epoch: [427][    1/    1]    Loss 0.092231    Top1 97.029703    Top5 100.000000    
2023-01-14 21:14:05,072 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.092

2023-01-14 21:14:05,090 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:14:05,090 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:14:05,139 - 

2023-01-14 21:14:05,139 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:14:06,944 - Epoch: [428][    4/    4]    Overall Loss 0.006003    Objective Loss 0.006003    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.450891    
2023-01-14 21:14:06,988 - --- validate (epoch=428)-----------
2023-01-14 21:14:06,989 - 101 samples (240 per mini-batch)
2023-01-14 21:14:08,108 - Epoch: [428][    1/    1]    Loss 0.072650    Top1 98.019802    Top5 100.000000    
2023-01-14 21:14:08,163 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.073

2023-01-14 21:14:08,175 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:14:08,176 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:14:08,199 - 

2023-01-14 21:14:08,200 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:14:10,449 - Epoch: [429][    4/    4]    Overall Loss 0.005887    Objective Loss 0.005887    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.562052    
2023-01-14 21:14:10,488 - --- validate (epoch=429)-----------
2023-01-14 21:14:10,489 - 101 samples (240 per mini-batch)
2023-01-14 21:14:11,580 - Epoch: [429][    1/    1]    Loss 0.091423    Top1 97.029703    Top5 100.000000    
2023-01-14 21:14:11,619 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.091

2023-01-14 21:14:11,633 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:14:11,634 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:14:11,670 - 

2023-01-14 21:14:11,670 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:14:13,442 - Epoch: [430][    4/    4]    Overall Loss 0.005726    Objective Loss 0.005726    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.442654    
2023-01-14 21:14:13,487 - --- validate (epoch=430)-----------
2023-01-14 21:14:13,488 - 101 samples (240 per mini-batch)
2023-01-14 21:14:14,493 - Epoch: [430][    1/    1]    Loss 0.071773    Top1 98.019802    Top5 100.000000    
2023-01-14 21:14:14,527 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.072

2023-01-14 21:14:14,539 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:14:14,540 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:14:14,574 - 

2023-01-14 21:14:14,574 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:14:16,326 - Epoch: [431][    4/    4]    Overall Loss 0.006004    Objective Loss 0.006004    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.437730    
2023-01-14 21:14:16,362 - --- validate (epoch=431)-----------
2023-01-14 21:14:16,363 - 101 samples (240 per mini-batch)
2023-01-14 21:14:17,449 - Epoch: [431][    1/    1]    Loss 0.112931    Top1 95.049505    Top5 100.000000    
2023-01-14 21:14:17,485 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.113

2023-01-14 21:14:17,497 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:14:17,498 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:14:17,535 - 

2023-01-14 21:14:17,536 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:14:19,363 - Epoch: [432][    4/    4]    Overall Loss 0.005921    Objective Loss 0.005921    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.456339    
2023-01-14 21:14:19,413 - --- validate (epoch=432)-----------
2023-01-14 21:14:19,414 - 101 samples (240 per mini-batch)
2023-01-14 21:14:20,534 - Epoch: [432][    1/    1]    Loss 0.091197    Top1 97.029703    Top5 100.000000    
2023-01-14 21:14:20,569 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.091

2023-01-14 21:14:20,583 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:14:20,583 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:14:20,620 - 

2023-01-14 21:14:20,621 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:14:22,983 - Epoch: [433][    4/    4]    Overall Loss 0.006222    Objective Loss 0.006222    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.590159    
2023-01-14 21:14:23,024 - --- validate (epoch=433)-----------
2023-01-14 21:14:23,025 - 101 samples (240 per mini-batch)
2023-01-14 21:14:24,048 - Epoch: [433][    1/    1]    Loss 0.098387    Top1 97.029703    Top5 100.000000    
2023-01-14 21:14:24,079 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.098

2023-01-14 21:14:24,091 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:14:24,091 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:14:24,126 - 

2023-01-14 21:14:24,126 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:14:26,206 - Epoch: [434][    4/    4]    Overall Loss 0.006108    Objective Loss 0.006108    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.519669    
2023-01-14 21:14:26,252 - --- validate (epoch=434)-----------
2023-01-14 21:14:26,252 - 101 samples (240 per mini-batch)
2023-01-14 21:14:27,359 - Epoch: [434][    1/    1]    Loss 0.106899    Top1 95.049505    Top5 100.000000    
2023-01-14 21:14:27,400 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.107

2023-01-14 21:14:27,413 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:14:27,414 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:14:27,454 - 

2023-01-14 21:14:27,455 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:14:29,091 - Epoch: [435][    4/    4]    Overall Loss 0.006065    Objective Loss 0.006065    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.408698    
2023-01-14 21:14:29,140 - --- validate (epoch=435)-----------
2023-01-14 21:14:29,141 - 101 samples (240 per mini-batch)
2023-01-14 21:14:30,163 - Epoch: [435][    1/    1]    Loss 0.099746    Top1 97.029703    Top5 100.000000    
2023-01-14 21:14:30,195 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.100

2023-01-14 21:14:30,208 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:14:30,208 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:14:30,242 - 

2023-01-14 21:14:30,243 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:14:31,722 - Epoch: [436][    4/    4]    Overall Loss 0.006081    Objective Loss 0.006081    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.369556    
2023-01-14 21:14:31,752 - --- validate (epoch=436)-----------
2023-01-14 21:14:31,753 - 101 samples (240 per mini-batch)
2023-01-14 21:14:32,837 - Epoch: [436][    1/    1]    Loss 0.074101    Top1 98.019802    Top5 100.000000    
2023-01-14 21:14:32,873 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.074

2023-01-14 21:14:32,892 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:14:32,892 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:14:32,945 - 

2023-01-14 21:14:32,946 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:14:34,744 - Epoch: [437][    4/    4]    Overall Loss 0.005953    Objective Loss 0.005953    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.449246    
2023-01-14 21:14:34,780 - --- validate (epoch=437)-----------
2023-01-14 21:14:34,781 - 101 samples (240 per mini-batch)
2023-01-14 21:14:35,777 - Epoch: [437][    1/    1]    Loss 0.100131    Top1 95.049505    Top5 100.000000    
2023-01-14 21:14:35,814 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.100

2023-01-14 21:14:35,824 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:14:35,825 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:14:35,859 - 

2023-01-14 21:14:35,859 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:14:37,613 - Epoch: [438][    4/    4]    Overall Loss 0.005795    Objective Loss 0.005795    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.438173    
2023-01-14 21:14:37,649 - --- validate (epoch=438)-----------
2023-01-14 21:14:37,650 - 101 samples (240 per mini-batch)
2023-01-14 21:14:38,793 - Epoch: [438][    1/    1]    Loss 0.096965    Top1 97.029703    Top5 100.000000    
2023-01-14 21:14:38,832 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.097

2023-01-14 21:14:38,845 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:14:38,845 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:14:38,874 - 

2023-01-14 21:14:38,874 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:14:40,467 - Epoch: [439][    4/    4]    Overall Loss 0.005761    Objective Loss 0.005761    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.397935    
2023-01-14 21:14:40,508 - --- validate (epoch=439)-----------
2023-01-14 21:14:40,509 - 101 samples (240 per mini-batch)
2023-01-14 21:14:41,597 - Epoch: [439][    1/    1]    Loss 0.117163    Top1 95.049505    Top5 100.000000    
2023-01-14 21:14:41,632 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.117

2023-01-14 21:14:41,643 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:14:41,643 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:14:41,692 - 

2023-01-14 21:14:41,692 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:14:43,617 - Epoch: [440][    4/    4]    Overall Loss 0.005960    Objective Loss 0.005960    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.480730    
2023-01-14 21:14:43,654 - --- validate (epoch=440)-----------
2023-01-14 21:14:43,655 - 101 samples (240 per mini-batch)
2023-01-14 21:14:44,760 - Epoch: [440][    1/    1]    Loss 0.088447    Top1 98.019802    Top5 100.000000    
2023-01-14 21:14:44,800 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.088

2023-01-14 21:14:44,811 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:14:44,812 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:14:44,843 - 

2023-01-14 21:14:44,844 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:14:46,603 - Epoch: [441][    4/    4]    Overall Loss 0.006015    Objective Loss 0.006015    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.439332    
2023-01-14 21:14:46,636 - --- validate (epoch=441)-----------
2023-01-14 21:14:46,636 - 101 samples (240 per mini-batch)
2023-01-14 21:14:47,749 - Epoch: [441][    1/    1]    Loss 0.082936    Top1 96.039604    Top5 100.000000    
2023-01-14 21:14:47,784 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.083

2023-01-14 21:14:47,799 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:14:47,800 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:14:47,841 - 

2023-01-14 21:14:47,841 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:14:50,133 - Epoch: [442][    4/    4]    Overall Loss 0.005886    Objective Loss 0.005886    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.572543    
2023-01-14 21:14:50,174 - --- validate (epoch=442)-----------
2023-01-14 21:14:50,175 - 101 samples (240 per mini-batch)
2023-01-14 21:14:51,269 - Epoch: [442][    1/    1]    Loss 0.077864    Top1 97.029703    Top5 100.000000    
2023-01-14 21:14:51,313 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.078

2023-01-14 21:14:51,332 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:14:51,332 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:14:51,369 - 

2023-01-14 21:14:51,369 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:14:53,175 - Epoch: [443][    4/    4]    Overall Loss 0.006129    Objective Loss 0.006129    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.451296    
2023-01-14 21:14:53,212 - --- validate (epoch=443)-----------
2023-01-14 21:14:53,212 - 101 samples (240 per mini-batch)
2023-01-14 21:14:54,214 - Epoch: [443][    1/    1]    Loss 0.086866    Top1 96.039604    Top5 100.000000    
2023-01-14 21:14:54,245 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.087

2023-01-14 21:14:54,256 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:14:54,256 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:14:54,285 - 

2023-01-14 21:14:54,286 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:14:56,363 - Epoch: [444][    4/    4]    Overall Loss 0.005929    Objective Loss 0.005929    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.518946    
2023-01-14 21:14:56,406 - --- validate (epoch=444)-----------
2023-01-14 21:14:56,407 - 101 samples (240 per mini-batch)
2023-01-14 21:14:57,495 - Epoch: [444][    1/    1]    Loss 0.079993    Top1 97.029703    Top5 100.000000    
2023-01-14 21:14:57,531 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.080

2023-01-14 21:14:57,548 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:14:57,548 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:14:57,579 - 

2023-01-14 21:14:57,579 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:14:59,364 - Epoch: [445][    4/    4]    Overall Loss 0.005957    Objective Loss 0.005957    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.445730    
2023-01-14 21:14:59,400 - --- validate (epoch=445)-----------
2023-01-14 21:14:59,401 - 101 samples (240 per mini-batch)
2023-01-14 21:15:00,494 - Epoch: [445][    1/    1]    Loss 0.103606    Top1 96.039604    Top5 100.000000    
2023-01-14 21:15:00,524 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.104

2023-01-14 21:15:00,536 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:15:00,536 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:15:00,574 - 

2023-01-14 21:15:00,574 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:15:02,400 - Epoch: [446][    4/    4]    Overall Loss 0.006125    Objective Loss 0.006125    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.456055    
2023-01-14 21:15:02,434 - --- validate (epoch=446)-----------
2023-01-14 21:15:02,435 - 101 samples (240 per mini-batch)
2023-01-14 21:15:03,521 - Epoch: [446][    1/    1]    Loss 0.093755    Top1 97.029703    Top5 100.000000    
2023-01-14 21:15:03,561 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.094

2023-01-14 21:15:03,575 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:15:03,575 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:15:03,613 - 

2023-01-14 21:15:03,613 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:15:05,234 - Epoch: [447][    4/    4]    Overall Loss 0.006106    Objective Loss 0.006106    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.404674    
2023-01-14 21:15:05,281 - --- validate (epoch=447)-----------
2023-01-14 21:15:05,282 - 101 samples (240 per mini-batch)
2023-01-14 21:15:06,437 - Epoch: [447][    1/    1]    Loss 0.084689    Top1 96.039604    Top5 100.000000    
2023-01-14 21:15:06,474 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.085

2023-01-14 21:15:06,484 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:15:06,485 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:15:06,525 - 

2023-01-14 21:15:06,526 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:15:07,946 - Epoch: [448][    4/    4]    Overall Loss 0.005833    Objective Loss 0.005833    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.354675    
2023-01-14 21:15:07,982 - --- validate (epoch=448)-----------
2023-01-14 21:15:07,983 - 101 samples (240 per mini-batch)
2023-01-14 21:15:09,102 - Epoch: [448][    1/    1]    Loss 0.108246    Top1 96.039604    Top5 100.000000    
2023-01-14 21:15:09,143 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.108

2023-01-14 21:15:09,154 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:15:09,155 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:15:09,184 - 

2023-01-14 21:15:09,184 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:15:11,065 - Epoch: [449][    4/    4]    Overall Loss 0.005927    Objective Loss 0.005927    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.469877    
2023-01-14 21:15:11,111 - --- validate (epoch=449)-----------
2023-01-14 21:15:11,111 - 101 samples (240 per mini-batch)
2023-01-14 21:15:12,241 - Epoch: [449][    1/    1]    Loss 0.074923    Top1 98.019802    Top5 100.000000    
2023-01-14 21:15:12,282 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.075

2023-01-14 21:15:12,292 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:15:12,293 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:15:12,332 - 

2023-01-14 21:15:12,333 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:15:14,119 - Epoch: [450][    4/    4]    Overall Loss 0.005839    Objective Loss 0.005839    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.445839    
2023-01-14 21:15:14,167 - --- validate (epoch=450)-----------
2023-01-14 21:15:14,168 - 101 samples (240 per mini-batch)
2023-01-14 21:15:15,312 - Epoch: [450][    1/    1]    Loss 0.087586    Top1 98.019802    Top5 100.000000    
2023-01-14 21:15:15,349 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.088

2023-01-14 21:15:15,361 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:15:15,361 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:15:15,400 - 

2023-01-14 21:15:15,400 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:15:17,293 - Epoch: [451][    4/    4]    Overall Loss 0.005820    Objective Loss 0.005820    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.472636    
2023-01-14 21:15:17,335 - --- validate (epoch=451)-----------
2023-01-14 21:15:17,337 - 101 samples (240 per mini-batch)
2023-01-14 21:15:18,496 - Epoch: [451][    1/    1]    Loss 0.093002    Top1 97.029703    Top5 100.000000    
2023-01-14 21:15:18,530 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.093

2023-01-14 21:15:18,543 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:15:18,544 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:15:18,582 - 

2023-01-14 21:15:18,582 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:15:20,147 - Epoch: [452][    4/    4]    Overall Loss 0.005895    Objective Loss 0.005895    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.390741    
2023-01-14 21:15:20,191 - --- validate (epoch=452)-----------
2023-01-14 21:15:20,192 - 101 samples (240 per mini-batch)
2023-01-14 21:15:21,188 - Epoch: [452][    1/    1]    Loss 0.073916    Top1 98.019802    Top5 100.000000    
2023-01-14 21:15:21,219 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.074

2023-01-14 21:15:21,234 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:15:21,235 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:15:21,268 - 

2023-01-14 21:15:21,268 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:15:23,159 - Epoch: [453][    4/    4]    Overall Loss 0.005767    Objective Loss 0.005767    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.472353    
2023-01-14 21:15:23,199 - --- validate (epoch=453)-----------
2023-01-14 21:15:23,199 - 101 samples (240 per mini-batch)
2023-01-14 21:15:24,282 - Epoch: [453][    1/    1]    Loss 0.084765    Top1 97.029703    Top5 100.000000    
2023-01-14 21:15:24,312 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.085

2023-01-14 21:15:24,328 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:15:24,328 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:15:24,360 - 

2023-01-14 21:15:24,361 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:15:26,183 - Epoch: [454][    4/    4]    Overall Loss 0.005783    Objective Loss 0.005783    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.455379    
2023-01-14 21:15:26,229 - --- validate (epoch=454)-----------
2023-01-14 21:15:26,229 - 101 samples (240 per mini-batch)
2023-01-14 21:15:27,321 - Epoch: [454][    1/    1]    Loss 0.085158    Top1 98.019802    Top5 100.000000    
2023-01-14 21:15:27,357 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.085

2023-01-14 21:15:27,368 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:15:27,368 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:15:27,406 - 

2023-01-14 21:15:27,407 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:15:28,951 - Epoch: [455][    4/    4]    Overall Loss 0.006258    Objective Loss 0.006258    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.385673    
2023-01-14 21:15:28,987 - --- validate (epoch=455)-----------
2023-01-14 21:15:28,988 - 101 samples (240 per mini-batch)
2023-01-14 21:15:30,042 - Epoch: [455][    1/    1]    Loss 0.107212    Top1 96.039604    Top5 100.000000    
2023-01-14 21:15:30,074 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.107

2023-01-14 21:15:30,083 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:15:30,083 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:15:30,112 - 

2023-01-14 21:15:30,112 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:15:31,891 - Epoch: [456][    4/    4]    Overall Loss 0.005779    Objective Loss 0.005779    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.444502    
2023-01-14 21:15:31,925 - --- validate (epoch=456)-----------
2023-01-14 21:15:31,926 - 101 samples (240 per mini-batch)
2023-01-14 21:15:32,995 - Epoch: [456][    1/    1]    Loss 0.062843    Top1 98.019802    Top5 100.000000    
2023-01-14 21:15:33,031 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.063

2023-01-14 21:15:33,047 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 354]
2023-01-14 21:15:33,047 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:15:33,092 - 

2023-01-14 21:15:33,092 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:15:35,238 - Epoch: [457][    4/    4]    Overall Loss 0.005970    Objective Loss 0.005970    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.536014    
2023-01-14 21:15:35,272 - --- validate (epoch=457)-----------
2023-01-14 21:15:35,273 - 101 samples (240 per mini-batch)
2023-01-14 21:15:36,396 - Epoch: [457][    1/    1]    Loss 0.064762    Top1 99.009901    Top5 100.000000    
2023-01-14 21:15:36,431 - ==> Top1: 99.010    Top5: 100.000    Loss: 0.065

2023-01-14 21:15:36,441 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 457]
2023-01-14 21:15:36,441 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:15:36,473 - 

2023-01-14 21:15:36,473 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:15:38,390 - Epoch: [458][    4/    4]    Overall Loss 0.005954    Objective Loss 0.005954    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.478990    
2023-01-14 21:15:38,425 - --- validate (epoch=458)-----------
2023-01-14 21:15:38,425 - 101 samples (240 per mini-batch)
2023-01-14 21:15:39,535 - Epoch: [458][    1/    1]    Loss 0.093262    Top1 96.039604    Top5 100.000000    
2023-01-14 21:15:39,571 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.093

2023-01-14 21:15:39,585 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 457]
2023-01-14 21:15:39,586 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:15:39,636 - 

2023-01-14 21:15:39,637 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:15:42,046 - Epoch: [459][    4/    4]    Overall Loss 0.005903    Objective Loss 0.005903    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.601801    
2023-01-14 21:15:42,086 - --- validate (epoch=459)-----------
2023-01-14 21:15:42,086 - 101 samples (240 per mini-batch)
2023-01-14 21:15:43,212 - Epoch: [459][    1/    1]    Loss 0.099179    Top1 97.029703    Top5 100.000000    
2023-01-14 21:15:43,248 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.099

2023-01-14 21:15:43,267 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 457]
2023-01-14 21:15:43,267 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:15:43,300 - 

2023-01-14 21:15:43,300 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:15:45,098 - Epoch: [460][    4/    4]    Overall Loss 0.005969    Objective Loss 0.005969    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.449154    
2023-01-14 21:15:45,150 - --- validate (epoch=460)-----------
2023-01-14 21:15:45,151 - 101 samples (240 per mini-batch)
2023-01-14 21:15:46,292 - Epoch: [460][    1/    1]    Loss 0.096875    Top1 97.029703    Top5 100.000000    
2023-01-14 21:15:46,327 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.097

2023-01-14 21:15:46,337 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 457]
2023-01-14 21:15:46,337 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:15:46,374 - 

2023-01-14 21:15:46,374 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:15:48,263 - Epoch: [461][    4/    4]    Overall Loss 0.005921    Objective Loss 0.005921    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.471989    
2023-01-14 21:15:48,300 - --- validate (epoch=461)-----------
2023-01-14 21:15:48,301 - 101 samples (240 per mini-batch)
2023-01-14 21:15:49,388 - Epoch: [461][    1/    1]    Loss 0.080528    Top1 98.019802    Top5 100.000000    
2023-01-14 21:15:49,424 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.081

2023-01-14 21:15:49,440 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 457]
2023-01-14 21:15:49,440 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:15:49,496 - 

2023-01-14 21:15:49,497 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:15:51,276 - Epoch: [462][    4/    4]    Overall Loss 0.005844    Objective Loss 0.005844    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.444266    
2023-01-14 21:15:51,313 - --- validate (epoch=462)-----------
2023-01-14 21:15:51,314 - 101 samples (240 per mini-batch)
2023-01-14 21:15:52,332 - Epoch: [462][    1/    1]    Loss 0.112934    Top1 95.049505    Top5 100.000000    
2023-01-14 21:15:52,367 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.113

2023-01-14 21:15:52,376 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 457]
2023-01-14 21:15:52,377 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:15:52,401 - 

2023-01-14 21:15:52,402 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:15:54,127 - Epoch: [463][    4/    4]    Overall Loss 0.006015    Objective Loss 0.006015    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.430973    
2023-01-14 21:15:54,169 - --- validate (epoch=463)-----------
2023-01-14 21:15:54,170 - 101 samples (240 per mini-batch)
2023-01-14 21:15:55,307 - Epoch: [463][    1/    1]    Loss 0.085675    Top1 97.029703    Top5 100.000000    
2023-01-14 21:15:55,344 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.086

2023-01-14 21:15:55,353 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 457]
2023-01-14 21:15:55,353 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:15:55,390 - 

2023-01-14 21:15:55,391 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:15:57,003 - Epoch: [464][    4/    4]    Overall Loss 0.005842    Objective Loss 0.005842    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.402585    
2023-01-14 21:15:57,041 - --- validate (epoch=464)-----------
2023-01-14 21:15:57,041 - 101 samples (240 per mini-batch)
2023-01-14 21:15:58,147 - Epoch: [464][    1/    1]    Loss 0.070040    Top1 98.019802    Top5 100.000000    
2023-01-14 21:15:58,185 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.070

2023-01-14 21:15:58,195 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 457]
2023-01-14 21:15:58,195 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:15:58,224 - 

2023-01-14 21:15:58,225 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:16:00,030 - Epoch: [465][    4/    4]    Overall Loss 0.005910    Objective Loss 0.005910    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.451082    
2023-01-14 21:16:00,074 - --- validate (epoch=465)-----------
2023-01-14 21:16:00,075 - 101 samples (240 per mini-batch)
2023-01-14 21:16:01,169 - Epoch: [465][    1/    1]    Loss 0.085690    Top1 97.029703    Top5 100.000000    
2023-01-14 21:16:01,213 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.086

2023-01-14 21:16:01,244 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 457]
2023-01-14 21:16:01,244 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:16:01,278 - 

2023-01-14 21:16:01,279 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:16:02,682 - Epoch: [466][    4/    4]    Overall Loss 0.005873    Objective Loss 0.005873    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.350552    
2023-01-14 21:16:02,719 - --- validate (epoch=466)-----------
2023-01-14 21:16:02,719 - 101 samples (240 per mini-batch)
2023-01-14 21:16:03,721 - Epoch: [466][    1/    1]    Loss 0.071476    Top1 98.019802    Top5 100.000000    
2023-01-14 21:16:03,754 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.071

2023-01-14 21:16:03,764 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 457]
2023-01-14 21:16:03,764 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:16:03,795 - 

2023-01-14 21:16:03,795 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:16:06,027 - Epoch: [467][    4/    4]    Overall Loss 0.006056    Objective Loss 0.006056    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.557670    
2023-01-14 21:16:06,064 - --- validate (epoch=467)-----------
2023-01-14 21:16:06,065 - 101 samples (240 per mini-batch)
2023-01-14 21:16:07,170 - Epoch: [467][    1/    1]    Loss 0.085579    Top1 97.029703    Top5 100.000000    
2023-01-14 21:16:07,203 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.086

2023-01-14 21:16:07,220 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 457]
2023-01-14 21:16:07,220 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:16:07,252 - 

2023-01-14 21:16:07,253 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:16:09,189 - Epoch: [468][    4/    4]    Overall Loss 0.005606    Objective Loss 0.005606    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.483811    
2023-01-14 21:16:09,225 - --- validate (epoch=468)-----------
2023-01-14 21:16:09,225 - 101 samples (240 per mini-batch)
2023-01-14 21:16:10,254 - Epoch: [468][    1/    1]    Loss 0.103640    Top1 96.039604    Top5 100.000000    
2023-01-14 21:16:10,285 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.104

2023-01-14 21:16:10,297 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 457]
2023-01-14 21:16:10,297 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:16:10,331 - 

2023-01-14 21:16:10,332 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:16:12,094 - Epoch: [469][    4/    4]    Overall Loss 0.005914    Objective Loss 0.005914    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.440073    
2023-01-14 21:16:12,128 - --- validate (epoch=469)-----------
2023-01-14 21:16:12,129 - 101 samples (240 per mini-batch)
2023-01-14 21:16:13,248 - Epoch: [469][    1/    1]    Loss 0.069988    Top1 98.019802    Top5 100.000000    
2023-01-14 21:16:13,283 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.070

2023-01-14 21:16:13,298 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 457]
2023-01-14 21:16:13,298 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:16:13,334 - 

2023-01-14 21:16:13,335 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:16:15,558 - Epoch: [470][    4/    4]    Overall Loss 0.005886    Objective Loss 0.005886    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.555405    
2023-01-14 21:16:15,600 - --- validate (epoch=470)-----------
2023-01-14 21:16:15,601 - 101 samples (240 per mini-batch)
2023-01-14 21:16:16,714 - Epoch: [470][    1/    1]    Loss 0.107934    Top1 96.039604    Top5 100.000000    
2023-01-14 21:16:16,748 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.108

2023-01-14 21:16:16,763 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 457]
2023-01-14 21:16:16,764 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:16:16,799 - 

2023-01-14 21:16:16,799 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:16:18,749 - Epoch: [471][    4/    4]    Overall Loss 0.005707    Objective Loss 0.005707    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.487071    
2023-01-14 21:16:18,783 - --- validate (epoch=471)-----------
2023-01-14 21:16:18,784 - 101 samples (240 per mini-batch)
2023-01-14 21:16:19,874 - Epoch: [471][    1/    1]    Loss 0.068811    Top1 98.019802    Top5 100.000000    
2023-01-14 21:16:19,906 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.069

2023-01-14 21:16:19,922 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 457]
2023-01-14 21:16:19,922 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:16:19,958 - 

2023-01-14 21:16:19,959 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:16:21,670 - Epoch: [472][    4/    4]    Overall Loss 0.005772    Objective Loss 0.005772    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.427562    
2023-01-14 21:16:21,704 - --- validate (epoch=472)-----------
2023-01-14 21:16:21,705 - 101 samples (240 per mini-batch)
2023-01-14 21:16:22,774 - Epoch: [472][    1/    1]    Loss 0.105426    Top1 95.049505    Top5 100.000000    
2023-01-14 21:16:22,813 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.105

2023-01-14 21:16:22,823 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 457]
2023-01-14 21:16:22,823 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:16:22,857 - 

2023-01-14 21:16:22,857 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:16:24,628 - Epoch: [473][    4/    4]    Overall Loss 0.005871    Objective Loss 0.005871    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.442347    
2023-01-14 21:16:24,665 - --- validate (epoch=473)-----------
2023-01-14 21:16:24,666 - 101 samples (240 per mini-batch)
2023-01-14 21:16:25,734 - Epoch: [473][    1/    1]    Loss 0.083028    Top1 97.029703    Top5 100.000000    
2023-01-14 21:16:25,771 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.083

2023-01-14 21:16:25,786 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 457]
2023-01-14 21:16:25,786 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:16:25,833 - 

2023-01-14 21:16:25,834 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:16:27,233 - Epoch: [474][    4/    4]    Overall Loss 0.005794    Objective Loss 0.005794    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.349547    
2023-01-14 21:16:27,271 - --- validate (epoch=474)-----------
2023-01-14 21:16:27,271 - 101 samples (240 per mini-batch)
2023-01-14 21:16:28,339 - Epoch: [474][    1/    1]    Loss 0.093121    Top1 96.039604    Top5 100.000000    
2023-01-14 21:16:28,379 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.093

2023-01-14 21:16:28,389 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 457]
2023-01-14 21:16:28,390 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:16:28,415 - 

2023-01-14 21:16:28,416 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:16:30,301 - Epoch: [475][    4/    4]    Overall Loss 0.005943    Objective Loss 0.005943    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.470957    
2023-01-14 21:16:30,337 - --- validate (epoch=475)-----------
2023-01-14 21:16:30,338 - 101 samples (240 per mini-batch)
2023-01-14 21:16:31,361 - Epoch: [475][    1/    1]    Loss 0.067506    Top1 98.019802    Top5 100.000000    
2023-01-14 21:16:31,394 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.068

2023-01-14 21:16:31,405 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 457]
2023-01-14 21:16:31,406 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:16:31,451 - 

2023-01-14 21:16:31,452 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:16:33,498 - Epoch: [476][    4/    4]    Overall Loss 0.006001    Objective Loss 0.006001    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.511159    
2023-01-14 21:16:33,544 - --- validate (epoch=476)-----------
2023-01-14 21:16:33,545 - 101 samples (240 per mini-batch)
2023-01-14 21:16:34,690 - Epoch: [476][    1/    1]    Loss 0.076545    Top1 97.029703    Top5 100.000000    
2023-01-14 21:16:34,727 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.077

2023-01-14 21:16:34,737 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 457]
2023-01-14 21:16:34,737 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:16:34,768 - 

2023-01-14 21:16:34,770 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:16:36,546 - Epoch: [477][    4/    4]    Overall Loss 0.005811    Objective Loss 0.005811    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.443446    
2023-01-14 21:16:36,584 - --- validate (epoch=477)-----------
2023-01-14 21:16:36,584 - 101 samples (240 per mini-batch)
2023-01-14 21:16:37,647 - Epoch: [477][    1/    1]    Loss 0.059439    Top1 98.019802    Top5 100.000000    
2023-01-14 21:16:37,680 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.059

2023-01-14 21:16:37,697 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 457]
2023-01-14 21:16:37,697 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:16:37,747 - 

2023-01-14 21:16:37,748 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:16:39,695 - Epoch: [478][    4/    4]    Overall Loss 0.005734    Objective Loss 0.005734    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.486147    
2023-01-14 21:16:39,737 - --- validate (epoch=478)-----------
2023-01-14 21:16:39,737 - 101 samples (240 per mini-batch)
2023-01-14 21:16:40,833 - Epoch: [478][    1/    1]    Loss 0.070214    Top1 97.029703    Top5 100.000000    
2023-01-14 21:16:40,866 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.070

2023-01-14 21:16:40,881 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 457]
2023-01-14 21:16:40,881 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:16:40,929 - 

2023-01-14 21:16:40,929 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:16:42,405 - Epoch: [479][    4/    4]    Overall Loss 0.005960    Objective Loss 0.005960    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.368455    
2023-01-14 21:16:42,453 - --- validate (epoch=479)-----------
2023-01-14 21:16:42,455 - 101 samples (240 per mini-batch)
2023-01-14 21:16:43,605 - Epoch: [479][    1/    1]    Loss 0.076423    Top1 96.039604    Top5 100.000000    
2023-01-14 21:16:43,637 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.076

2023-01-14 21:16:43,651 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 457]
2023-01-14 21:16:43,651 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:16:43,684 - 

2023-01-14 21:16:43,684 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:16:45,411 - Epoch: [480][    4/    4]    Overall Loss 0.005891    Objective Loss 0.005891    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.431316    
2023-01-14 21:16:45,472 - --- validate (epoch=480)-----------
2023-01-14 21:16:45,472 - 101 samples (240 per mini-batch)
2023-01-14 21:16:46,620 - Epoch: [480][    1/    1]    Loss 0.108952    Top1 95.049505    Top5 100.000000    
2023-01-14 21:16:46,654 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.109

2023-01-14 21:16:46,666 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 457]
2023-01-14 21:16:46,667 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:16:46,694 - 

2023-01-14 21:16:46,694 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:16:48,580 - Epoch: [481][    4/    4]    Overall Loss 0.006044    Objective Loss 0.006044    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.471024    
2023-01-14 21:16:48,613 - --- validate (epoch=481)-----------
2023-01-14 21:16:48,614 - 101 samples (240 per mini-batch)
2023-01-14 21:16:49,749 - Epoch: [481][    1/    1]    Loss 0.072508    Top1 97.029703    Top5 100.000000    
2023-01-14 21:16:49,788 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.073

2023-01-14 21:16:49,798 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 457]
2023-01-14 21:16:49,798 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:16:49,831 - 

2023-01-14 21:16:49,835 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:16:51,677 - Epoch: [482][    4/    4]    Overall Loss 0.005782    Objective Loss 0.005782    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.459976    
2023-01-14 21:16:51,712 - --- validate (epoch=482)-----------
2023-01-14 21:16:51,713 - 101 samples (240 per mini-batch)
2023-01-14 21:16:52,814 - Epoch: [482][    1/    1]    Loss 0.060812    Top1 99.009901    Top5 100.000000    
2023-01-14 21:16:52,842 - ==> Top1: 99.010    Top5: 100.000    Loss: 0.061

2023-01-14 21:16:52,855 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:16:52,856 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:16:52,887 - 

2023-01-14 21:16:52,887 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:16:54,780 - Epoch: [483][    4/    4]    Overall Loss 0.005902    Objective Loss 0.005902    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.472828    
2023-01-14 21:16:54,818 - --- validate (epoch=483)-----------
2023-01-14 21:16:54,818 - 101 samples (240 per mini-batch)
2023-01-14 21:16:55,901 - Epoch: [483][    1/    1]    Loss 0.084498    Top1 96.039604    Top5 100.000000    
2023-01-14 21:16:55,935 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.084

2023-01-14 21:16:55,948 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:16:55,948 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:16:55,990 - 

2023-01-14 21:16:55,990 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:16:57,848 - Epoch: [484][    4/    4]    Overall Loss 0.005973    Objective Loss 0.005973    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.464117    
2023-01-14 21:16:57,882 - --- validate (epoch=484)-----------
2023-01-14 21:16:57,883 - 101 samples (240 per mini-batch)
2023-01-14 21:16:58,953 - Epoch: [484][    1/    1]    Loss 0.090544    Top1 97.029703    Top5 100.000000    
2023-01-14 21:16:58,983 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.091

2023-01-14 21:16:58,996 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:16:58,996 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:16:59,025 - 

2023-01-14 21:16:59,025 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:17:01,201 - Epoch: [485][    4/    4]    Overall Loss 0.005825    Objective Loss 0.005825    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.543585    
2023-01-14 21:17:01,249 - --- validate (epoch=485)-----------
2023-01-14 21:17:01,249 - 101 samples (240 per mini-batch)
2023-01-14 21:17:02,364 - Epoch: [485][    1/    1]    Loss 0.061661    Top1 98.019802    Top5 100.000000    
2023-01-14 21:17:02,401 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.062

2023-01-14 21:17:02,411 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:17:02,411 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:17:02,452 - 

2023-01-14 21:17:02,453 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:17:04,191 - Epoch: [486][    4/    4]    Overall Loss 0.005743    Objective Loss 0.005743    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.434292    
2023-01-14 21:17:04,228 - --- validate (epoch=486)-----------
2023-01-14 21:17:04,230 - 101 samples (240 per mini-batch)
2023-01-14 21:17:05,341 - Epoch: [486][    1/    1]    Loss 0.082892    Top1 97.029703    Top5 100.000000    
2023-01-14 21:17:05,375 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.083

2023-01-14 21:17:05,391 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:17:05,391 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:17:05,433 - 

2023-01-14 21:17:05,433 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:17:07,347 - Epoch: [487][    4/    4]    Overall Loss 0.005778    Objective Loss 0.005778    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.478130    
2023-01-14 21:17:07,380 - --- validate (epoch=487)-----------
2023-01-14 21:17:07,381 - 101 samples (240 per mini-batch)
2023-01-14 21:17:08,557 - Epoch: [487][    1/    1]    Loss 0.095257    Top1 97.029703    Top5 100.000000    
2023-01-14 21:17:08,594 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.095

2023-01-14 21:17:08,604 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:17:08,604 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:17:08,642 - 

2023-01-14 21:17:08,643 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:17:10,352 - Epoch: [488][    4/    4]    Overall Loss 0.005740    Objective Loss 0.005740    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.427103    
2023-01-14 21:17:10,389 - --- validate (epoch=488)-----------
2023-01-14 21:17:10,389 - 101 samples (240 per mini-batch)
2023-01-14 21:17:11,543 - Epoch: [488][    1/    1]    Loss 0.077167    Top1 97.029703    Top5 100.000000    
2023-01-14 21:17:11,576 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.077

2023-01-14 21:17:11,587 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:17:11,587 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:17:11,622 - 

2023-01-14 21:17:11,622 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:17:13,252 - Epoch: [489][    4/    4]    Overall Loss 0.006036    Objective Loss 0.006036    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.407171    
2023-01-14 21:17:13,284 - --- validate (epoch=489)-----------
2023-01-14 21:17:13,285 - 101 samples (240 per mini-batch)
2023-01-14 21:17:14,376 - Epoch: [489][    1/    1]    Loss 0.096653    Top1 97.029703    Top5 100.000000    
2023-01-14 21:17:14,420 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.097

2023-01-14 21:17:14,429 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:17:14,430 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:17:14,461 - 

2023-01-14 21:17:14,462 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:17:16,390 - Epoch: [490][    4/    4]    Overall Loss 0.005986    Objective Loss 0.005986    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.481749    
2023-01-14 21:17:16,426 - --- validate (epoch=490)-----------
2023-01-14 21:17:16,427 - 101 samples (240 per mini-batch)
2023-01-14 21:17:17,451 - Epoch: [490][    1/    1]    Loss 0.081963    Top1 98.019802    Top5 100.000000    
2023-01-14 21:17:17,491 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.082

2023-01-14 21:17:17,501 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:17:17,502 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:17:17,535 - 

2023-01-14 21:17:17,536 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:17:19,288 - Epoch: [491][    4/    4]    Overall Loss 0.005913    Objective Loss 0.005913    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.437791    
2023-01-14 21:17:19,322 - --- validate (epoch=491)-----------
2023-01-14 21:17:19,323 - 101 samples (240 per mini-batch)
2023-01-14 21:17:20,449 - Epoch: [491][    1/    1]    Loss 0.113504    Top1 96.039604    Top5 100.000000    
2023-01-14 21:17:20,479 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.114

2023-01-14 21:17:20,491 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:17:20,491 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:17:20,520 - 

2023-01-14 21:17:20,521 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:17:22,642 - Epoch: [492][    4/    4]    Overall Loss 0.005755    Objective Loss 0.005755    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.530027    
2023-01-14 21:17:22,677 - --- validate (epoch=492)-----------
2023-01-14 21:17:22,678 - 101 samples (240 per mini-batch)
2023-01-14 21:17:23,776 - Epoch: [492][    1/    1]    Loss 0.107474    Top1 95.049505    Top5 100.000000    
2023-01-14 21:17:23,817 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.107

2023-01-14 21:17:23,828 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:17:23,828 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:17:23,866 - 

2023-01-14 21:17:23,866 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:17:25,988 - Epoch: [493][    4/    4]    Overall Loss 0.005963    Objective Loss 0.005963    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.529842    
2023-01-14 21:17:26,018 - --- validate (epoch=493)-----------
2023-01-14 21:17:26,019 - 101 samples (240 per mini-batch)
2023-01-14 21:17:27,085 - Epoch: [493][    1/    1]    Loss 0.111493    Top1 95.049505    Top5 100.000000    
2023-01-14 21:17:27,122 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.111

2023-01-14 21:17:27,140 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:17:27,141 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:17:27,171 - 

2023-01-14 21:17:27,171 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:17:29,185 - Epoch: [494][    4/    4]    Overall Loss 0.005901    Objective Loss 0.005901    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.503219    
2023-01-14 21:17:29,218 - --- validate (epoch=494)-----------
2023-01-14 21:17:29,219 - 101 samples (240 per mini-batch)
2023-01-14 21:17:30,335 - Epoch: [494][    1/    1]    Loss 0.091150    Top1 96.039604    Top5 100.000000    
2023-01-14 21:17:30,369 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.091

2023-01-14 21:17:30,378 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:17:30,378 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:17:30,406 - 

2023-01-14 21:17:30,406 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:17:32,661 - Epoch: [495][    4/    4]    Overall Loss 0.005957    Objective Loss 0.005957    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.563442    
2023-01-14 21:17:32,697 - --- validate (epoch=495)-----------
2023-01-14 21:17:32,698 - 101 samples (240 per mini-batch)
2023-01-14 21:17:33,837 - Epoch: [495][    1/    1]    Loss 0.085224    Top1 97.029703    Top5 100.000000    
2023-01-14 21:17:33,878 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.085

2023-01-14 21:17:33,890 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:17:33,891 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:17:33,921 - 

2023-01-14 21:17:33,921 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:17:35,718 - Epoch: [496][    4/    4]    Overall Loss 0.005935    Objective Loss 0.005935    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.448947    
2023-01-14 21:17:35,762 - --- validate (epoch=496)-----------
2023-01-14 21:17:35,763 - 101 samples (240 per mini-batch)
2023-01-14 21:17:36,865 - Epoch: [496][    1/    1]    Loss 0.084192    Top1 96.039604    Top5 100.000000    
2023-01-14 21:17:36,898 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.084

2023-01-14 21:17:36,911 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:17:36,911 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:17:36,941 - 

2023-01-14 21:17:36,942 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:17:38,329 - Epoch: [497][    4/    4]    Overall Loss 0.005891    Objective Loss 0.005891    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.346500    
2023-01-14 21:17:38,362 - --- validate (epoch=497)-----------
2023-01-14 21:17:38,362 - 101 samples (240 per mini-batch)
2023-01-14 21:17:39,390 - Epoch: [497][    1/    1]    Loss 0.081705    Top1 96.039604    Top5 100.000000    
2023-01-14 21:17:39,423 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.082

2023-01-14 21:17:39,436 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:17:39,437 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:17:39,471 - 

2023-01-14 21:17:39,471 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:17:41,332 - Epoch: [498][    4/    4]    Overall Loss 0.005865    Objective Loss 0.005865    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.464788    
2023-01-14 21:17:41,377 - --- validate (epoch=498)-----------
2023-01-14 21:17:41,378 - 101 samples (240 per mini-batch)
2023-01-14 21:17:42,407 - Epoch: [498][    1/    1]    Loss 0.094887    Top1 97.029703    Top5 100.000000    
2023-01-14 21:17:42,438 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.095

2023-01-14 21:17:42,452 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:17:42,452 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:17:42,485 - 

2023-01-14 21:17:42,485 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:17:43,962 - Epoch: [499][    4/    4]    Overall Loss 0.006084    Objective Loss 0.006084    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.368723    
2023-01-14 21:17:44,001 - --- validate (epoch=499)-----------
2023-01-14 21:17:44,002 - 101 samples (240 per mini-batch)
2023-01-14 21:17:45,059 - Epoch: [499][    1/    1]    Loss 0.081014    Top1 96.039604    Top5 100.000000    
2023-01-14 21:17:45,090 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.081

2023-01-14 21:17:45,104 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:17:45,104 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:17:45,141 - 

2023-01-14 21:17:45,142 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:17:47,100 - Epoch: [500][    4/    4]    Overall Loss 0.005830    Objective Loss 0.005830    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.489261    
2023-01-14 21:17:47,138 - --- validate (epoch=500)-----------
2023-01-14 21:17:47,139 - 101 samples (240 per mini-batch)
2023-01-14 21:17:48,221 - Epoch: [500][    1/    1]    Loss 0.084813    Top1 97.029703    Top5 100.000000    
2023-01-14 21:17:48,252 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.085

2023-01-14 21:17:48,264 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:17:48,264 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:17:48,308 - 

2023-01-14 21:17:48,308 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:17:50,089 - Epoch: [501][    4/    4]    Overall Loss 0.005894    Objective Loss 0.005894    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.444754    
2023-01-14 21:17:50,121 - --- validate (epoch=501)-----------
2023-01-14 21:17:50,122 - 101 samples (240 per mini-batch)
2023-01-14 21:17:51,198 - Epoch: [501][    1/    1]    Loss 0.111330    Top1 94.059406    Top5 100.000000    
2023-01-14 21:17:51,228 - ==> Top1: 94.059    Top5: 100.000    Loss: 0.111

2023-01-14 21:17:51,248 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:17:51,249 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:17:51,305 - 

2023-01-14 21:17:51,306 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:17:52,736 - Epoch: [502][    4/    4]    Overall Loss 0.005895    Objective Loss 0.005895    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.357133    
2023-01-14 21:17:52,766 - --- validate (epoch=502)-----------
2023-01-14 21:17:52,767 - 101 samples (240 per mini-batch)
2023-01-14 21:17:53,870 - Epoch: [502][    1/    1]    Loss 0.088160    Top1 97.029703    Top5 100.000000    
2023-01-14 21:17:53,908 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.088

2023-01-14 21:17:53,922 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:17:53,923 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:17:53,962 - 

2023-01-14 21:17:53,963 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:17:55,767 - Epoch: [503][    4/    4]    Overall Loss 0.005772    Objective Loss 0.005772    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.450813    
2023-01-14 21:17:55,806 - --- validate (epoch=503)-----------
2023-01-14 21:17:55,807 - 101 samples (240 per mini-batch)
2023-01-14 21:17:56,938 - Epoch: [503][    1/    1]    Loss 0.099896    Top1 97.029703    Top5 100.000000    
2023-01-14 21:17:56,971 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.100

2023-01-14 21:17:56,984 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:17:56,984 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:17:57,017 - 

2023-01-14 21:17:57,018 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:17:59,101 - Epoch: [504][    4/    4]    Overall Loss 0.005829    Objective Loss 0.005829    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.520343    
2023-01-14 21:17:59,131 - --- validate (epoch=504)-----------
2023-01-14 21:17:59,132 - 101 samples (240 per mini-batch)
2023-01-14 21:18:00,232 - Epoch: [504][    1/    1]    Loss 0.071474    Top1 97.029703    Top5 100.000000    
2023-01-14 21:18:00,264 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.071

2023-01-14 21:18:00,279 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:18:00,279 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:18:00,316 - 

2023-01-14 21:18:00,317 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:18:02,164 - Epoch: [505][    4/    4]    Overall Loss 0.005833    Objective Loss 0.005833    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.461605    
2023-01-14 21:18:02,202 - --- validate (epoch=505)-----------
2023-01-14 21:18:02,203 - 101 samples (240 per mini-batch)
2023-01-14 21:18:03,343 - Epoch: [505][    1/    1]    Loss 0.062805    Top1 97.029703    Top5 100.000000    
2023-01-14 21:18:03,378 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.063

2023-01-14 21:18:03,387 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:18:03,388 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:18:03,424 - 

2023-01-14 21:18:03,425 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:18:04,887 - Epoch: [506][    4/    4]    Overall Loss 0.005913    Objective Loss 0.005913    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.365233    
2023-01-14 21:18:04,931 - --- validate (epoch=506)-----------
2023-01-14 21:18:04,931 - 101 samples (240 per mini-batch)
2023-01-14 21:18:05,961 - Epoch: [506][    1/    1]    Loss 0.079482    Top1 98.019802    Top5 100.000000    
2023-01-14 21:18:05,993 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.079

2023-01-14 21:18:06,007 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:18:06,007 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:18:06,042 - 

2023-01-14 21:18:06,042 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:18:07,492 - Epoch: [507][    4/    4]    Overall Loss 0.005767    Objective Loss 0.005767    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.362194    
2023-01-14 21:18:07,528 - --- validate (epoch=507)-----------
2023-01-14 21:18:07,529 - 101 samples (240 per mini-batch)
2023-01-14 21:18:08,669 - Epoch: [507][    1/    1]    Loss 0.076651    Top1 97.029703    Top5 100.000000    
2023-01-14 21:18:08,703 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.077

2023-01-14 21:18:08,716 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:18:08,717 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:18:08,746 - 

2023-01-14 21:18:08,747 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:18:10,669 - Epoch: [508][    4/    4]    Overall Loss 0.005943    Objective Loss 0.005943    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.479692    
2023-01-14 21:18:10,712 - --- validate (epoch=508)-----------
2023-01-14 21:18:10,713 - 101 samples (240 per mini-batch)
2023-01-14 21:18:11,842 - Epoch: [508][    1/    1]    Loss 0.099398    Top1 97.029703    Top5 100.000000    
2023-01-14 21:18:11,876 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.099

2023-01-14 21:18:11,892 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:18:11,893 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:18:11,930 - 

2023-01-14 21:18:11,930 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:18:13,708 - Epoch: [509][    4/    4]    Overall Loss 0.005707    Objective Loss 0.005707    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.444229    
2023-01-14 21:18:13,752 - --- validate (epoch=509)-----------
2023-01-14 21:18:13,752 - 101 samples (240 per mini-batch)
2023-01-14 21:18:14,817 - Epoch: [509][    1/    1]    Loss 0.098848    Top1 95.049505    Top5 100.000000    
2023-01-14 21:18:14,854 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.099

2023-01-14 21:18:14,873 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:18:14,874 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:18:14,942 - 

2023-01-14 21:18:14,943 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:18:16,598 - Epoch: [510][    4/    4]    Overall Loss 0.005996    Objective Loss 0.005996    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.413391    
2023-01-14 21:18:16,636 - --- validate (epoch=510)-----------
2023-01-14 21:18:16,637 - 101 samples (240 per mini-batch)
2023-01-14 21:18:17,729 - Epoch: [510][    1/    1]    Loss 0.084777    Top1 98.019802    Top5 100.000000    
2023-01-14 21:18:17,771 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.085

2023-01-14 21:18:17,783 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:18:17,783 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:18:17,825 - 

2023-01-14 21:18:17,826 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:18:19,619 - Epoch: [511][    4/    4]    Overall Loss 0.005790    Objective Loss 0.005790    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.447891    
2023-01-14 21:18:19,657 - --- validate (epoch=511)-----------
2023-01-14 21:18:19,658 - 101 samples (240 per mini-batch)
2023-01-14 21:18:20,771 - Epoch: [511][    1/    1]    Loss 0.090123    Top1 97.029703    Top5 100.000000    
2023-01-14 21:18:20,810 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.090

2023-01-14 21:18:20,821 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:18:20,821 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:18:20,855 - 

2023-01-14 21:18:20,855 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:18:22,590 - Epoch: [512][    4/    4]    Overall Loss 0.005722    Objective Loss 0.005722    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.433461    
2023-01-14 21:18:22,626 - --- validate (epoch=512)-----------
2023-01-14 21:18:22,627 - 101 samples (240 per mini-batch)
2023-01-14 21:18:23,743 - Epoch: [512][    1/    1]    Loss 0.084390    Top1 97.029703    Top5 100.000000    
2023-01-14 21:18:23,777 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.084

2023-01-14 21:18:23,788 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:18:23,788 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:18:23,824 - 

2023-01-14 21:18:23,824 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:18:25,655 - Epoch: [513][    4/    4]    Overall Loss 0.005754    Objective Loss 0.005754    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.457307    
2023-01-14 21:18:25,694 - --- validate (epoch=513)-----------
2023-01-14 21:18:25,695 - 101 samples (240 per mini-batch)
2023-01-14 21:18:26,757 - Epoch: [513][    1/    1]    Loss 0.091384    Top1 97.029703    Top5 100.000000    
2023-01-14 21:18:26,789 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.091

2023-01-14 21:18:26,799 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:18:26,799 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:18:26,831 - 

2023-01-14 21:18:26,832 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:18:28,635 - Epoch: [514][    4/    4]    Overall Loss 0.005648    Objective Loss 0.005648    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.450435    
2023-01-14 21:18:28,677 - --- validate (epoch=514)-----------
2023-01-14 21:18:28,677 - 101 samples (240 per mini-batch)
2023-01-14 21:18:29,724 - Epoch: [514][    1/    1]    Loss 0.084416    Top1 97.029703    Top5 100.000000    
2023-01-14 21:18:29,763 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.084

2023-01-14 21:18:29,779 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:18:29,779 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:18:29,834 - 

2023-01-14 21:18:29,834 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:18:32,134 - Epoch: [515][    4/    4]    Overall Loss 0.005760    Objective Loss 0.005760    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.574554    
2023-01-14 21:18:32,178 - --- validate (epoch=515)-----------
2023-01-14 21:18:32,179 - 101 samples (240 per mini-batch)
2023-01-14 21:18:33,328 - Epoch: [515][    1/    1]    Loss 0.095105    Top1 97.029703    Top5 100.000000    
2023-01-14 21:18:33,360 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.095

2023-01-14 21:18:33,374 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:18:33,374 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:18:33,404 - 

2023-01-14 21:18:33,405 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:18:35,152 - Epoch: [516][    4/    4]    Overall Loss 0.005740    Objective Loss 0.005740    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.436464    
2023-01-14 21:18:35,186 - --- validate (epoch=516)-----------
2023-01-14 21:18:35,187 - 101 samples (240 per mini-batch)
2023-01-14 21:18:36,334 - Epoch: [516][    1/    1]    Loss 0.095037    Top1 97.029703    Top5 100.000000    
2023-01-14 21:18:36,380 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.095

2023-01-14 21:18:36,396 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:18:36,396 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:18:36,437 - 

2023-01-14 21:18:36,438 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:18:38,330 - Epoch: [517][    4/    4]    Overall Loss 0.005981    Objective Loss 0.005981    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.472752    
2023-01-14 21:18:38,368 - --- validate (epoch=517)-----------
2023-01-14 21:18:38,369 - 101 samples (240 per mini-batch)
2023-01-14 21:18:39,513 - Epoch: [517][    1/    1]    Loss 0.065373    Top1 98.019802    Top5 100.000000    
2023-01-14 21:18:39,547 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.065

2023-01-14 21:18:39,558 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:18:39,558 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:18:39,593 - 

2023-01-14 21:18:39,593 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:18:41,327 - Epoch: [518][    4/    4]    Overall Loss 0.005806    Objective Loss 0.005806    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.433170    
2023-01-14 21:18:41,362 - --- validate (epoch=518)-----------
2023-01-14 21:18:41,362 - 101 samples (240 per mini-batch)
2023-01-14 21:18:42,522 - Epoch: [518][    1/    1]    Loss 0.070680    Top1 97.029703    Top5 100.000000    
2023-01-14 21:18:42,554 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.071

2023-01-14 21:18:42,570 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:18:42,571 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:18:42,600 - 

2023-01-14 21:18:42,600 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:18:44,070 - Epoch: [519][    4/    4]    Overall Loss 0.005753    Objective Loss 0.005753    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.367090    
2023-01-14 21:18:44,112 - --- validate (epoch=519)-----------
2023-01-14 21:18:44,112 - 101 samples (240 per mini-batch)
2023-01-14 21:18:45,195 - Epoch: [519][    1/    1]    Loss 0.100293    Top1 95.049505    Top5 100.000000    
2023-01-14 21:18:45,227 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.100

2023-01-14 21:18:45,239 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:18:45,239 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:18:45,274 - 

2023-01-14 21:18:45,275 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:18:47,099 - Epoch: [520][    4/    4]    Overall Loss 0.005972    Objective Loss 0.005972    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.455806    
2023-01-14 21:18:47,137 - --- validate (epoch=520)-----------
2023-01-14 21:18:47,137 - 101 samples (240 per mini-batch)
2023-01-14 21:18:48,221 - Epoch: [520][    1/    1]    Loss 0.082917    Top1 96.039604    Top5 100.000000    
2023-01-14 21:18:48,261 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.083

2023-01-14 21:18:48,272 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:18:48,273 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:18:48,304 - 

2023-01-14 21:18:48,305 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:18:50,200 - Epoch: [521][    4/    4]    Overall Loss 0.005692    Objective Loss 0.005692    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.473444    
2023-01-14 21:18:50,236 - --- validate (epoch=521)-----------
2023-01-14 21:18:50,236 - 101 samples (240 per mini-batch)
2023-01-14 21:18:51,259 - Epoch: [521][    1/    1]    Loss 0.058582    Top1 97.029703    Top5 100.000000    
2023-01-14 21:18:51,291 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.059

2023-01-14 21:18:51,302 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:18:51,302 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:18:51,327 - 

2023-01-14 21:18:51,327 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:18:53,715 - Epoch: [522][    4/    4]    Overall Loss 0.005775    Objective Loss 0.005775    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.596744    
2023-01-14 21:18:53,761 - --- validate (epoch=522)-----------
2023-01-14 21:18:53,762 - 101 samples (240 per mini-batch)
2023-01-14 21:18:54,870 - Epoch: [522][    1/    1]    Loss 0.077560    Top1 96.039604    Top5 100.000000    
2023-01-14 21:18:54,905 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.078

2023-01-14 21:18:54,919 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:18:54,920 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:18:54,953 - 

2023-01-14 21:18:54,953 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:18:57,091 - Epoch: [523][    4/    4]    Overall Loss 0.005609    Objective Loss 0.005609    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.534245    
2023-01-14 21:18:57,135 - --- validate (epoch=523)-----------
2023-01-14 21:18:57,136 - 101 samples (240 per mini-batch)
2023-01-14 21:18:58,266 - Epoch: [523][    1/    1]    Loss 0.078055    Top1 97.029703    Top5 100.000000    
2023-01-14 21:18:58,294 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.078

2023-01-14 21:18:58,305 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:18:58,305 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:18:58,335 - 

2023-01-14 21:18:58,336 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:19:00,329 - Epoch: [524][    4/    4]    Overall Loss 0.005882    Objective Loss 0.005882    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.498107    
2023-01-14 21:19:00,373 - --- validate (epoch=524)-----------
2023-01-14 21:19:00,373 - 101 samples (240 per mini-batch)
2023-01-14 21:19:01,470 - Epoch: [524][    1/    1]    Loss 0.104387    Top1 96.039604    Top5 100.000000    
2023-01-14 21:19:01,505 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.104

2023-01-14 21:19:01,515 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:19:01,515 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:19:01,552 - 

2023-01-14 21:19:01,552 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:19:02,978 - Epoch: [525][    4/    4]    Overall Loss 0.005720    Objective Loss 0.005720    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.356146    
2023-01-14 21:19:03,016 - --- validate (epoch=525)-----------
2023-01-14 21:19:03,016 - 101 samples (240 per mini-batch)
2023-01-14 21:19:04,090 - Epoch: [525][    1/    1]    Loss 0.099780    Top1 95.049505    Top5 100.000000    
2023-01-14 21:19:04,122 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.100

2023-01-14 21:19:04,140 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:19:04,141 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:19:04,176 - 

2023-01-14 21:19:04,177 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:19:05,873 - Epoch: [526][    4/    4]    Overall Loss 0.005744    Objective Loss 0.005744    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.423654    
2023-01-14 21:19:05,913 - --- validate (epoch=526)-----------
2023-01-14 21:19:05,913 - 101 samples (240 per mini-batch)
2023-01-14 21:19:06,945 - Epoch: [526][    1/    1]    Loss 0.089363    Top1 96.039604    Top5 100.000000    
2023-01-14 21:19:06,977 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.089

2023-01-14 21:19:06,990 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 482]
2023-01-14 21:19:06,990 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:19:07,021 - 

2023-01-14 21:19:07,022 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:19:08,541 - Epoch: [527][    4/    4]    Overall Loss 0.005726    Objective Loss 0.005726    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.379509    
2023-01-14 21:19:08,579 - --- validate (epoch=527)-----------
2023-01-14 21:19:08,580 - 101 samples (240 per mini-batch)
2023-01-14 21:19:09,676 - Epoch: [527][    1/    1]    Loss 0.061771    Top1 99.009901    Top5 100.000000    
2023-01-14 21:19:09,710 - ==> Top1: 99.010    Top5: 100.000    Loss: 0.062

2023-01-14 21:19:09,719 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 527]
2023-01-14 21:19:09,719 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:19:09,751 - 

2023-01-14 21:19:09,751 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:19:11,498 - Epoch: [528][    4/    4]    Overall Loss 0.005713    Objective Loss 0.005713    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.436397    
2023-01-14 21:19:11,536 - --- validate (epoch=528)-----------
2023-01-14 21:19:11,537 - 101 samples (240 per mini-batch)
2023-01-14 21:19:12,615 - Epoch: [528][    1/    1]    Loss 0.120472    Top1 95.049505    Top5 100.000000    
2023-01-14 21:19:12,649 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.120

2023-01-14 21:19:12,663 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 527]
2023-01-14 21:19:12,663 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:19:12,703 - 

2023-01-14 21:19:12,703 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:19:14,864 - Epoch: [529][    4/    4]    Overall Loss 0.005761    Objective Loss 0.005761    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.539908    
2023-01-14 21:19:14,899 - --- validate (epoch=529)-----------
2023-01-14 21:19:14,900 - 101 samples (240 per mini-batch)
2023-01-14 21:19:15,896 - Epoch: [529][    1/    1]    Loss 0.073025    Top1 97.029703    Top5 100.000000    
2023-01-14 21:19:15,928 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.073

2023-01-14 21:19:15,938 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 527]
2023-01-14 21:19:15,938 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:19:15,966 - 

2023-01-14 21:19:15,967 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:19:17,710 - Epoch: [530][    4/    4]    Overall Loss 0.005700    Objective Loss 0.005700    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.435515    
2023-01-14 21:19:17,749 - --- validate (epoch=530)-----------
2023-01-14 21:19:17,749 - 101 samples (240 per mini-batch)
2023-01-14 21:19:18,740 - Epoch: [530][    1/    1]    Loss 0.060396    Top1 98.019802    Top5 100.000000    
2023-01-14 21:19:18,785 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.060

2023-01-14 21:19:18,795 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 527]
2023-01-14 21:19:18,796 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:19:18,836 - 

2023-01-14 21:19:18,837 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:19:20,706 - Epoch: [531][    4/    4]    Overall Loss 0.005415    Objective Loss 0.005415    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.467001    
2023-01-14 21:19:20,737 - --- validate (epoch=531)-----------
2023-01-14 21:19:20,738 - 101 samples (240 per mini-batch)
2023-01-14 21:19:21,877 - Epoch: [531][    1/    1]    Loss 0.079881    Top1 97.029703    Top5 100.000000    
2023-01-14 21:19:21,910 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.080

2023-01-14 21:19:21,922 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 527]
2023-01-14 21:19:21,923 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:19:21,958 - 

2023-01-14 21:19:21,958 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:19:23,713 - Epoch: [532][    4/    4]    Overall Loss 0.005806    Objective Loss 0.005806    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.438510    
2023-01-14 21:19:23,745 - --- validate (epoch=532)-----------
2023-01-14 21:19:23,745 - 101 samples (240 per mini-batch)
2023-01-14 21:19:24,774 - Epoch: [532][    1/    1]    Loss 0.087429    Top1 97.029703    Top5 100.000000    
2023-01-14 21:19:24,802 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.087

2023-01-14 21:19:24,815 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 527]
2023-01-14 21:19:24,815 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:19:24,854 - 

2023-01-14 21:19:24,854 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:19:27,212 - Epoch: [533][    4/    4]    Overall Loss 0.005733    Objective Loss 0.005733    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.589062    
2023-01-14 21:19:27,247 - --- validate (epoch=533)-----------
2023-01-14 21:19:27,248 - 101 samples (240 per mini-batch)
2023-01-14 21:19:28,344 - Epoch: [533][    1/    1]    Loss 0.084179    Top1 96.039604    Top5 100.000000    
2023-01-14 21:19:28,373 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.084

2023-01-14 21:19:28,393 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 527]
2023-01-14 21:19:28,394 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:19:28,451 - 

2023-01-14 21:19:28,451 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:19:30,121 - Epoch: [534][    4/    4]    Overall Loss 0.005900    Objective Loss 0.005900    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.416858    
2023-01-14 21:19:30,159 - --- validate (epoch=534)-----------
2023-01-14 21:19:30,160 - 101 samples (240 per mini-batch)
2023-01-14 21:19:31,291 - Epoch: [534][    1/    1]    Loss 0.100963    Top1 96.039604    Top5 100.000000    
2023-01-14 21:19:31,321 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.101

2023-01-14 21:19:31,331 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 527]
2023-01-14 21:19:31,332 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:19:31,359 - 

2023-01-14 21:19:31,359 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:19:33,136 - Epoch: [535][    4/    4]    Overall Loss 0.005801    Objective Loss 0.005801    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.443888    
2023-01-14 21:19:33,174 - --- validate (epoch=535)-----------
2023-01-14 21:19:33,174 - 101 samples (240 per mini-batch)
2023-01-14 21:19:34,318 - Epoch: [535][    1/    1]    Loss 0.099086    Top1 96.039604    Top5 100.000000    
2023-01-14 21:19:34,358 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.099

2023-01-14 21:19:34,367 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 527]
2023-01-14 21:19:34,368 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:19:34,424 - 

2023-01-14 21:19:34,424 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:19:36,342 - Epoch: [536][    4/    4]    Overall Loss 0.005495    Objective Loss 0.005495    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.478964    
2023-01-14 21:19:36,375 - --- validate (epoch=536)-----------
2023-01-14 21:19:36,375 - 101 samples (240 per mini-batch)
2023-01-14 21:19:37,487 - Epoch: [536][    1/    1]    Loss 0.109855    Top1 95.049505    Top5 100.000000    
2023-01-14 21:19:37,524 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.110

2023-01-14 21:19:37,534 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 527]
2023-01-14 21:19:37,535 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:19:37,568 - 

2023-01-14 21:19:37,569 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:19:39,685 - Epoch: [537][    4/    4]    Overall Loss 0.005613    Objective Loss 0.005613    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.528891    
2023-01-14 21:19:39,726 - --- validate (epoch=537)-----------
2023-01-14 21:19:39,727 - 101 samples (240 per mini-batch)
2023-01-14 21:19:40,845 - Epoch: [537][    1/    1]    Loss 0.100038    Top1 96.039604    Top5 100.000000    
2023-01-14 21:19:40,881 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.100

2023-01-14 21:19:40,891 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 527]
2023-01-14 21:19:40,892 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:19:40,922 - 

2023-01-14 21:19:40,923 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:19:42,640 - Epoch: [538][    4/    4]    Overall Loss 0.005767    Objective Loss 0.005767    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.429079    
2023-01-14 21:19:42,674 - --- validate (epoch=538)-----------
2023-01-14 21:19:42,675 - 101 samples (240 per mini-batch)
2023-01-14 21:19:43,695 - Epoch: [538][    1/    1]    Loss 0.078152    Top1 97.029703    Top5 100.000000    
2023-01-14 21:19:43,733 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.078

2023-01-14 21:19:43,746 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 527]
2023-01-14 21:19:43,747 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:19:43,790 - 

2023-01-14 21:19:43,791 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:19:45,571 - Epoch: [539][    4/    4]    Overall Loss 0.005687    Objective Loss 0.005687    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.444646    
2023-01-14 21:19:45,611 - --- validate (epoch=539)-----------
2023-01-14 21:19:45,611 - 101 samples (240 per mini-batch)
2023-01-14 21:19:46,657 - Epoch: [539][    1/    1]    Loss 0.061172    Top1 98.019802    Top5 100.000000    
2023-01-14 21:19:46,687 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.061

2023-01-14 21:19:46,701 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 527]
2023-01-14 21:19:46,701 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:19:46,737 - 

2023-01-14 21:19:46,738 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:19:48,732 - Epoch: [540][    4/    4]    Overall Loss 0.005708    Objective Loss 0.005708    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.498338    
2023-01-14 21:19:48,779 - --- validate (epoch=540)-----------
2023-01-14 21:19:48,780 - 101 samples (240 per mini-batch)
2023-01-14 21:19:49,890 - Epoch: [540][    1/    1]    Loss 0.071155    Top1 96.039604    Top5 100.000000    
2023-01-14 21:19:49,920 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.071

2023-01-14 21:19:49,934 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 527]
2023-01-14 21:19:49,934 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:19:49,968 - 

2023-01-14 21:19:49,969 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:19:52,219 - Epoch: [541][    4/    4]    Overall Loss 0.005672    Objective Loss 0.005672    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.562137    
2023-01-14 21:19:52,254 - --- validate (epoch=541)-----------
2023-01-14 21:19:52,255 - 101 samples (240 per mini-batch)
2023-01-14 21:19:53,410 - Epoch: [541][    1/    1]    Loss 0.065967    Top1 97.029703    Top5 100.000000    
2023-01-14 21:19:53,449 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.066

2023-01-14 21:19:53,460 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 527]
2023-01-14 21:19:53,460 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:19:53,492 - 

2023-01-14 21:19:53,492 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:19:55,025 - Epoch: [542][    4/    4]    Overall Loss 0.005905    Objective Loss 0.005905    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.383039    
2023-01-14 21:19:55,066 - --- validate (epoch=542)-----------
2023-01-14 21:19:55,066 - 101 samples (240 per mini-batch)
2023-01-14 21:19:56,099 - Epoch: [542][    1/    1]    Loss 0.084174    Top1 97.029703    Top5 100.000000    
2023-01-14 21:19:56,131 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.084

2023-01-14 21:19:56,143 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 527]
2023-01-14 21:19:56,143 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:19:56,195 - 

2023-01-14 21:19:56,195 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:19:57,781 - Epoch: [543][    4/    4]    Overall Loss 0.005606    Objective Loss 0.005606    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.395892    
2023-01-14 21:19:57,818 - --- validate (epoch=543)-----------
2023-01-14 21:19:57,819 - 101 samples (240 per mini-batch)
2023-01-14 21:19:58,932 - Epoch: [543][    1/    1]    Loss 0.060432    Top1 98.019802    Top5 100.000000    
2023-01-14 21:19:58,971 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.060

2023-01-14 21:19:58,984 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 527]
2023-01-14 21:19:58,984 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:19:59,028 - 

2023-01-14 21:19:59,029 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:20:00,903 - Epoch: [544][    4/    4]    Overall Loss 0.005923    Objective Loss 0.005923    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.468161    
2023-01-14 21:20:00,939 - --- validate (epoch=544)-----------
2023-01-14 21:20:00,940 - 101 samples (240 per mini-batch)
2023-01-14 21:20:02,097 - Epoch: [544][    1/    1]    Loss 0.085759    Top1 97.029703    Top5 100.000000    
2023-01-14 21:20:02,132 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.086

2023-01-14 21:20:02,144 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 527]
2023-01-14 21:20:02,145 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:20:02,179 - 

2023-01-14 21:20:02,179 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:20:04,434 - Epoch: [545][    4/    4]    Overall Loss 0.005964    Objective Loss 0.005964    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.563378    
2023-01-14 21:20:04,467 - --- validate (epoch=545)-----------
2023-01-14 21:20:04,468 - 101 samples (240 per mini-batch)
2023-01-14 21:20:05,605 - Epoch: [545][    1/    1]    Loss 0.106312    Top1 96.039604    Top5 100.000000    
2023-01-14 21:20:05,638 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.106

2023-01-14 21:20:05,650 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 527]
2023-01-14 21:20:05,650 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:20:05,680 - 

2023-01-14 21:20:05,681 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:20:07,425 - Epoch: [546][    4/    4]    Overall Loss 0.005861    Objective Loss 0.005861    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.435648    
2023-01-14 21:20:07,469 - --- validate (epoch=546)-----------
2023-01-14 21:20:07,469 - 101 samples (240 per mini-batch)
2023-01-14 21:20:08,494 - Epoch: [546][    1/    1]    Loss 0.058530    Top1 99.009901    Top5 100.000000    
2023-01-14 21:20:08,523 - ==> Top1: 99.010    Top5: 100.000    Loss: 0.059

2023-01-14 21:20:08,536 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 546]
2023-01-14 21:20:08,537 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:20:08,577 - 

2023-01-14 21:20:08,578 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:20:10,114 - Epoch: [547][    4/    4]    Overall Loss 0.005747    Objective Loss 0.005747    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.383780    
2023-01-14 21:20:10,147 - --- validate (epoch=547)-----------
2023-01-14 21:20:10,148 - 101 samples (240 per mini-batch)
2023-01-14 21:20:11,163 - Epoch: [547][    1/    1]    Loss 0.071365    Top1 98.019802    Top5 100.000000    
2023-01-14 21:20:11,200 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.071

2023-01-14 21:20:11,213 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 546]
2023-01-14 21:20:11,214 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:20:11,253 - 

2023-01-14 21:20:11,253 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:20:13,133 - Epoch: [548][    4/    4]    Overall Loss 0.005886    Objective Loss 0.005886    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.469385    
2023-01-14 21:20:13,174 - --- validate (epoch=548)-----------
2023-01-14 21:20:13,175 - 101 samples (240 per mini-batch)
2023-01-14 21:20:14,260 - Epoch: [548][    1/    1]    Loss 0.098323    Top1 96.039604    Top5 100.000000    
2023-01-14 21:20:14,292 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.098

2023-01-14 21:20:14,306 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 546]
2023-01-14 21:20:14,307 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:20:14,338 - 

2023-01-14 21:20:14,338 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:20:16,536 - Epoch: [549][    4/    4]    Overall Loss 0.005592    Objective Loss 0.005592    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.548984    
2023-01-14 21:20:16,572 - --- validate (epoch=549)-----------
2023-01-14 21:20:16,573 - 101 samples (240 per mini-batch)
2023-01-14 21:20:17,677 - Epoch: [549][    1/    1]    Loss 0.106794    Top1 94.059406    Top5 100.000000    
2023-01-14 21:20:17,708 - ==> Top1: 94.059    Top5: 100.000    Loss: 0.107

2023-01-14 21:20:17,718 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 546]
2023-01-14 21:20:17,719 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:20:17,746 - 

2023-01-14 21:20:17,747 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:20:19,542 - Epoch: [550][    4/    4]    Overall Loss 0.005839    Objective Loss 0.005839    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.448574    
2023-01-14 21:20:19,585 - --- validate (epoch=550)-----------
2023-01-14 21:20:19,585 - 101 samples (240 per mini-batch)
2023-01-14 21:20:20,685 - Epoch: [550][    1/    1]    Loss 0.063026    Top1 98.019802    Top5 100.000000    
2023-01-14 21:20:20,720 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.063

2023-01-14 21:20:20,734 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 546]
2023-01-14 21:20:20,734 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:20:20,770 - 

2023-01-14 21:20:20,771 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:20:22,900 - Epoch: [551][    4/    4]    Overall Loss 0.005583    Objective Loss 0.005583    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.531936    
2023-01-14 21:20:22,940 - --- validate (epoch=551)-----------
2023-01-14 21:20:22,941 - 101 samples (240 per mini-batch)
2023-01-14 21:20:24,057 - Epoch: [551][    1/    1]    Loss 0.083611    Top1 98.019802    Top5 100.000000    
2023-01-14 21:20:24,095 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.084

2023-01-14 21:20:24,105 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 546]
2023-01-14 21:20:24,105 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:20:24,137 - 

2023-01-14 21:20:24,138 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:20:25,886 - Epoch: [552][    4/    4]    Overall Loss 0.005617    Objective Loss 0.005617    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.436691    
2023-01-14 21:20:25,932 - --- validate (epoch=552)-----------
2023-01-14 21:20:25,933 - 101 samples (240 per mini-batch)
2023-01-14 21:20:27,067 - Epoch: [552][    1/    1]    Loss 0.096527    Top1 96.039604    Top5 100.000000    
2023-01-14 21:20:27,104 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.097

2023-01-14 21:20:27,116 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 546]
2023-01-14 21:20:27,116 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:20:27,154 - 

2023-01-14 21:20:27,155 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:20:29,206 - Epoch: [553][    4/    4]    Overall Loss 0.005848    Objective Loss 0.005848    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.511922    
2023-01-14 21:20:29,253 - --- validate (epoch=553)-----------
2023-01-14 21:20:29,254 - 101 samples (240 per mini-batch)
2023-01-14 21:20:30,360 - Epoch: [553][    1/    1]    Loss 0.068770    Top1 97.029703    Top5 100.000000    
2023-01-14 21:20:30,392 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.069

2023-01-14 21:20:30,406 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 546]
2023-01-14 21:20:30,406 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:20:30,437 - 

2023-01-14 21:20:30,437 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:20:32,199 - Epoch: [554][    4/    4]    Overall Loss 0.005721    Objective Loss 0.005721    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.440230    
2023-01-14 21:20:32,237 - --- validate (epoch=554)-----------
2023-01-14 21:20:32,238 - 101 samples (240 per mini-batch)
2023-01-14 21:20:33,270 - Epoch: [554][    1/    1]    Loss 0.088346    Top1 97.029703    Top5 100.000000    
2023-01-14 21:20:33,312 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.088

2023-01-14 21:20:33,323 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 546]
2023-01-14 21:20:33,324 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:20:33,352 - 

2023-01-14 21:20:33,352 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:20:34,888 - Epoch: [555][    4/    4]    Overall Loss 0.005774    Objective Loss 0.005774    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.383672    
2023-01-14 21:20:34,936 - --- validate (epoch=555)-----------
2023-01-14 21:20:34,937 - 101 samples (240 per mini-batch)
2023-01-14 21:20:35,948 - Epoch: [555][    1/    1]    Loss 0.087474    Top1 96.039604    Top5 100.000000    
2023-01-14 21:20:35,988 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.087

2023-01-14 21:20:36,000 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 546]
2023-01-14 21:20:36,002 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:20:36,034 - 

2023-01-14 21:20:36,035 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:20:37,762 - Epoch: [556][    4/    4]    Overall Loss 0.005821    Objective Loss 0.005821    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.431569    
2023-01-14 21:20:37,794 - --- validate (epoch=556)-----------
2023-01-14 21:20:37,795 - 101 samples (240 per mini-batch)
2023-01-14 21:20:38,948 - Epoch: [556][    1/    1]    Loss 0.105665    Top1 96.039604    Top5 100.000000    
2023-01-14 21:20:38,983 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.106

2023-01-14 21:20:38,996 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 546]
2023-01-14 21:20:38,996 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:20:39,025 - 

2023-01-14 21:20:39,026 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:20:40,913 - Epoch: [557][    4/    4]    Overall Loss 0.005778    Objective Loss 0.005778    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.471503    
2023-01-14 21:20:40,959 - --- validate (epoch=557)-----------
2023-01-14 21:20:40,960 - 101 samples (240 per mini-batch)
2023-01-14 21:20:41,975 - Epoch: [557][    1/    1]    Loss 0.069938    Top1 98.019802    Top5 100.000000    
2023-01-14 21:20:42,016 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.070

2023-01-14 21:20:42,026 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 546]
2023-01-14 21:20:42,026 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:20:42,061 - 

2023-01-14 21:20:42,061 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:20:43,656 - Epoch: [558][    4/    4]    Overall Loss 0.005804    Objective Loss 0.005804    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.398443    
2023-01-14 21:20:43,689 - --- validate (epoch=558)-----------
2023-01-14 21:20:43,690 - 101 samples (240 per mini-batch)
2023-01-14 21:20:44,745 - Epoch: [558][    1/    1]    Loss 0.119528    Top1 95.049505    Top5 100.000000    
2023-01-14 21:20:44,780 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.120

2023-01-14 21:20:44,793 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 546]
2023-01-14 21:20:44,794 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:20:44,829 - 

2023-01-14 21:20:44,830 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:20:46,815 - Epoch: [559][    4/    4]    Overall Loss 0.005800    Objective Loss 0.005800    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.495981    
2023-01-14 21:20:46,848 - --- validate (epoch=559)-----------
2023-01-14 21:20:46,848 - 101 samples (240 per mini-batch)
2023-01-14 21:20:47,855 - Epoch: [559][    1/    1]    Loss 0.083901    Top1 97.029703    Top5 100.000000    
2023-01-14 21:20:47,889 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.084

2023-01-14 21:20:47,898 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 546]
2023-01-14 21:20:47,898 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:20:47,936 - 

2023-01-14 21:20:47,936 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:20:50,030 - Epoch: [560][    4/    4]    Overall Loss 0.005791    Objective Loss 0.005791    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.523026    
2023-01-14 21:20:50,063 - --- validate (epoch=560)-----------
2023-01-14 21:20:50,064 - 101 samples (240 per mini-batch)
2023-01-14 21:20:51,130 - Epoch: [560][    1/    1]    Loss 0.077682    Top1 97.029703    Top5 100.000000    
2023-01-14 21:20:51,164 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.078

2023-01-14 21:20:51,178 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 546]
2023-01-14 21:20:51,178 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:20:51,207 - 

2023-01-14 21:20:51,208 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:20:53,185 - Epoch: [561][    4/    4]    Overall Loss 0.005921    Objective Loss 0.005921    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.493965    
2023-01-14 21:20:53,226 - --- validate (epoch=561)-----------
2023-01-14 21:20:53,227 - 101 samples (240 per mini-batch)
2023-01-14 21:20:54,360 - Epoch: [561][    1/    1]    Loss 0.059163    Top1 99.009901    Top5 100.000000    
2023-01-14 21:20:54,395 - ==> Top1: 99.010    Top5: 100.000    Loss: 0.059

2023-01-14 21:20:54,406 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 561]
2023-01-14 21:20:54,406 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:20:54,448 - 

2023-01-14 21:20:54,448 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:20:56,346 - Epoch: [562][    4/    4]    Overall Loss 0.005683    Objective Loss 0.005683    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.474196    
2023-01-14 21:20:56,383 - --- validate (epoch=562)-----------
2023-01-14 21:20:56,384 - 101 samples (240 per mini-batch)
2023-01-14 21:20:57,479 - Epoch: [562][    1/    1]    Loss 0.089999    Top1 97.029703    Top5 100.000000    
2023-01-14 21:20:57,516 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.090

2023-01-14 21:20:57,532 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 561]
2023-01-14 21:20:57,532 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:20:57,579 - 

2023-01-14 21:20:57,580 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:20:59,244 - Epoch: [563][    4/    4]    Overall Loss 0.005771    Objective Loss 0.005771    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.415667    
2023-01-14 21:20:59,279 - --- validate (epoch=563)-----------
2023-01-14 21:20:59,280 - 101 samples (240 per mini-batch)
2023-01-14 21:21:00,395 - Epoch: [563][    1/    1]    Loss 0.071339    Top1 97.029703    Top5 100.000000    
2023-01-14 21:21:00,425 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.071

2023-01-14 21:21:00,436 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 561]
2023-01-14 21:21:00,437 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:21:00,468 - 

2023-01-14 21:21:00,468 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:21:02,426 - Epoch: [564][    4/    4]    Overall Loss 0.005738    Objective Loss 0.005738    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.489304    
2023-01-14 21:21:02,458 - --- validate (epoch=564)-----------
2023-01-14 21:21:02,459 - 101 samples (240 per mini-batch)
2023-01-14 21:21:03,509 - Epoch: [564][    1/    1]    Loss 0.081060    Top1 97.029703    Top5 100.000000    
2023-01-14 21:21:03,539 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.081

2023-01-14 21:21:03,555 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 561]
2023-01-14 21:21:03,556 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:21:03,596 - 

2023-01-14 21:21:03,596 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:21:05,213 - Epoch: [565][    4/    4]    Overall Loss 0.005893    Objective Loss 0.005893    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.404010    
2023-01-14 21:21:05,252 - --- validate (epoch=565)-----------
2023-01-14 21:21:05,252 - 101 samples (240 per mini-batch)
2023-01-14 21:21:06,264 - Epoch: [565][    1/    1]    Loss 0.058739    Top1 99.009901    Top5 100.000000    
2023-01-14 21:21:06,304 - ==> Top1: 99.010    Top5: 100.000    Loss: 0.059

2023-01-14 21:21:06,317 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 565]
2023-01-14 21:21:06,318 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:21:06,349 - 

2023-01-14 21:21:06,349 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:21:08,223 - Epoch: [566][    4/    4]    Overall Loss 0.005712    Objective Loss 0.005712    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.468125    
2023-01-14 21:21:08,259 - --- validate (epoch=566)-----------
2023-01-14 21:21:08,260 - 101 samples (240 per mini-batch)
2023-01-14 21:21:09,427 - Epoch: [566][    1/    1]    Loss 0.104900    Top1 95.049505    Top5 100.000000    
2023-01-14 21:21:09,465 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.105

2023-01-14 21:21:09,476 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 565]
2023-01-14 21:21:09,476 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:21:09,509 - 

2023-01-14 21:21:09,509 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:21:11,265 - Epoch: [567][    4/    4]    Overall Loss 0.005844    Objective Loss 0.005844    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.438706    
2023-01-14 21:21:11,299 - --- validate (epoch=567)-----------
2023-01-14 21:21:11,300 - 101 samples (240 per mini-batch)
2023-01-14 21:21:12,449 - Epoch: [567][    1/    1]    Loss 0.102383    Top1 96.039604    Top5 100.000000    
2023-01-14 21:21:12,484 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.102

2023-01-14 21:21:12,497 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 565]
2023-01-14 21:21:12,497 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:21:12,524 - 

2023-01-14 21:21:12,524 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:21:13,946 - Epoch: [568][    4/    4]    Overall Loss 0.005779    Objective Loss 0.005779    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.355122    
2023-01-14 21:21:13,981 - --- validate (epoch=568)-----------
2023-01-14 21:21:13,982 - 101 samples (240 per mini-batch)
2023-01-14 21:21:14,989 - Epoch: [568][    1/    1]    Loss 0.069366    Top1 97.029703    Top5 100.000000    
2023-01-14 21:21:15,024 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.069

2023-01-14 21:21:15,036 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 565]
2023-01-14 21:21:15,037 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:21:15,070 - 

2023-01-14 21:21:15,071 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:21:16,992 - Epoch: [569][    4/    4]    Overall Loss 0.005879    Objective Loss 0.005879    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.480085    
2023-01-14 21:21:17,040 - --- validate (epoch=569)-----------
2023-01-14 21:21:17,040 - 101 samples (240 per mini-batch)
2023-01-14 21:21:18,122 - Epoch: [569][    1/    1]    Loss 0.079906    Top1 97.029703    Top5 100.000000    
2023-01-14 21:21:18,155 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.080

2023-01-14 21:21:18,166 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 565]
2023-01-14 21:21:18,166 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:21:18,202 - 

2023-01-14 21:21:18,203 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:21:19,640 - Epoch: [570][    4/    4]    Overall Loss 0.005912    Objective Loss 0.005912    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.358900    
2023-01-14 21:21:19,675 - --- validate (epoch=570)-----------
2023-01-14 21:21:19,675 - 101 samples (240 per mini-batch)
2023-01-14 21:21:20,803 - Epoch: [570][    1/    1]    Loss 0.069574    Top1 98.019802    Top5 100.000000    
2023-01-14 21:21:20,840 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.070

2023-01-14 21:21:20,852 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 565]
2023-01-14 21:21:20,852 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:21:20,892 - 

2023-01-14 21:21:20,893 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:21:22,633 - Epoch: [571][    4/    4]    Overall Loss 0.005686    Objective Loss 0.005686    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.434583    
2023-01-14 21:21:22,664 - --- validate (epoch=571)-----------
2023-01-14 21:21:22,665 - 101 samples (240 per mini-batch)
2023-01-14 21:21:23,783 - Epoch: [571][    1/    1]    Loss 0.085611    Top1 97.029703    Top5 100.000000    
2023-01-14 21:21:23,812 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.086

2023-01-14 21:21:23,826 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 565]
2023-01-14 21:21:23,826 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:21:23,856 - 

2023-01-14 21:21:23,856 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:21:26,025 - Epoch: [572][    4/    4]    Overall Loss 0.005549    Objective Loss 0.005549    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.542066    
2023-01-14 21:21:26,056 - --- validate (epoch=572)-----------
2023-01-14 21:21:26,058 - 101 samples (240 per mini-batch)
2023-01-14 21:21:27,133 - Epoch: [572][    1/    1]    Loss 0.073629    Top1 97.029703    Top5 100.000000    
2023-01-14 21:21:27,164 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.074

2023-01-14 21:21:27,181 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 565]
2023-01-14 21:21:27,181 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:21:27,222 - 

2023-01-14 21:21:27,223 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:21:29,176 - Epoch: [573][    4/    4]    Overall Loss 0.005642    Objective Loss 0.005642    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.488015    
2023-01-14 21:21:29,216 - --- validate (epoch=573)-----------
2023-01-14 21:21:29,216 - 101 samples (240 per mini-batch)
2023-01-14 21:21:30,346 - Epoch: [573][    1/    1]    Loss 0.107881    Top1 96.039604    Top5 100.000000    
2023-01-14 21:21:30,379 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.108

2023-01-14 21:21:30,390 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 565]
2023-01-14 21:21:30,390 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:21:30,425 - 

2023-01-14 21:21:30,425 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:21:31,869 - Epoch: [574][    4/    4]    Overall Loss 0.005731    Objective Loss 0.005731    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.360586    
2023-01-14 21:21:31,917 - --- validate (epoch=574)-----------
2023-01-14 21:21:31,917 - 101 samples (240 per mini-batch)
2023-01-14 21:21:32,993 - Epoch: [574][    1/    1]    Loss 0.083846    Top1 97.029703    Top5 100.000000    
2023-01-14 21:21:33,030 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.084

2023-01-14 21:21:33,043 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 565]
2023-01-14 21:21:33,043 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:21:33,080 - 

2023-01-14 21:21:33,080 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:21:34,866 - Epoch: [575][    4/    4]    Overall Loss 0.005578    Objective Loss 0.005578    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.446239    
2023-01-14 21:21:34,900 - --- validate (epoch=575)-----------
2023-01-14 21:21:34,901 - 101 samples (240 per mini-batch)
2023-01-14 21:21:35,918 - Epoch: [575][    1/    1]    Loss 0.082062    Top1 97.029703    Top5 100.000000    
2023-01-14 21:21:35,957 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.082

2023-01-14 21:21:35,969 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 565]
2023-01-14 21:21:35,969 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:21:36,008 - 

2023-01-14 21:21:36,008 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:21:37,555 - Epoch: [576][    4/    4]    Overall Loss 0.005724    Objective Loss 0.005724    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.386237    
2023-01-14 21:21:37,590 - --- validate (epoch=576)-----------
2023-01-14 21:21:37,591 - 101 samples (240 per mini-batch)
2023-01-14 21:21:38,707 - Epoch: [576][    1/    1]    Loss 0.099625    Top1 96.039604    Top5 100.000000    
2023-01-14 21:21:38,741 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.100

2023-01-14 21:21:38,756 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 565]
2023-01-14 21:21:38,756 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:21:38,789 - 

2023-01-14 21:21:38,789 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:21:40,584 - Epoch: [577][    4/    4]    Overall Loss 0.005467    Objective Loss 0.005467    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.448256    
2023-01-14 21:21:40,616 - --- validate (epoch=577)-----------
2023-01-14 21:21:40,617 - 101 samples (240 per mini-batch)
2023-01-14 21:21:41,689 - Epoch: [577][    1/    1]    Loss 0.074689    Top1 98.019802    Top5 100.000000    
2023-01-14 21:21:41,726 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.075

2023-01-14 21:21:41,743 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 565]
2023-01-14 21:21:41,743 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:21:41,787 - 

2023-01-14 21:21:41,787 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:21:44,090 - Epoch: [578][    4/    4]    Overall Loss 0.005475    Objective Loss 0.005475    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.575564    
2023-01-14 21:21:44,125 - --- validate (epoch=578)-----------
2023-01-14 21:21:44,126 - 101 samples (240 per mini-batch)
2023-01-14 21:21:45,219 - Epoch: [578][    1/    1]    Loss 0.084410    Top1 96.039604    Top5 100.000000    
2023-01-14 21:21:45,253 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.084

2023-01-14 21:21:45,267 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 565]
2023-01-14 21:21:45,268 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:21:45,305 - 

2023-01-14 21:21:45,306 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:21:47,467 - Epoch: [579][    4/    4]    Overall Loss 0.005682    Objective Loss 0.005682    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.539917    
2023-01-14 21:21:47,502 - --- validate (epoch=579)-----------
2023-01-14 21:21:47,503 - 101 samples (240 per mini-batch)
2023-01-14 21:21:48,570 - Epoch: [579][    1/    1]    Loss 0.111690    Top1 96.039604    Top5 100.000000    
2023-01-14 21:21:48,608 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.112

2023-01-14 21:21:48,621 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 565]
2023-01-14 21:21:48,622 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:21:48,659 - 

2023-01-14 21:21:48,659 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:21:50,469 - Epoch: [580][    4/    4]    Overall Loss 0.005538    Objective Loss 0.005538    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.452203    
2023-01-14 21:21:50,506 - --- validate (epoch=580)-----------
2023-01-14 21:21:50,507 - 101 samples (240 per mini-batch)
2023-01-14 21:21:51,596 - Epoch: [580][    1/    1]    Loss 0.090249    Top1 97.029703    Top5 100.000000    
2023-01-14 21:21:51,632 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.090

2023-01-14 21:21:51,650 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 565]
2023-01-14 21:21:51,650 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:21:51,683 - 

2023-01-14 21:21:51,683 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:21:53,346 - Epoch: [581][    4/    4]    Overall Loss 0.005452    Objective Loss 0.005452    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.415533    
2023-01-14 21:21:53,383 - --- validate (epoch=581)-----------
2023-01-14 21:21:53,384 - 101 samples (240 per mini-batch)
2023-01-14 21:21:54,526 - Epoch: [581][    1/    1]    Loss 0.099804    Top1 95.049505    Top5 100.000000    
2023-01-14 21:21:54,563 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.100

2023-01-14 21:21:54,574 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 565]
2023-01-14 21:21:54,574 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:21:54,609 - 

2023-01-14 21:21:54,610 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:21:56,344 - Epoch: [582][    4/    4]    Overall Loss 0.005459    Objective Loss 0.005459    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.433170    
2023-01-14 21:21:56,375 - --- validate (epoch=582)-----------
2023-01-14 21:21:56,375 - 101 samples (240 per mini-batch)
2023-01-14 21:21:57,504 - Epoch: [582][    1/    1]    Loss 0.092623    Top1 96.039604    Top5 100.000000    
2023-01-14 21:21:57,551 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.093

2023-01-14 21:21:57,565 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 565]
2023-01-14 21:21:57,566 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:21:57,605 - 

2023-01-14 21:21:57,606 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:21:59,383 - Epoch: [583][    4/    4]    Overall Loss 0.005664    Objective Loss 0.005664    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.443909    
2023-01-14 21:21:59,432 - --- validate (epoch=583)-----------
2023-01-14 21:21:59,433 - 101 samples (240 per mini-batch)
2023-01-14 21:22:00,574 - Epoch: [583][    1/    1]    Loss 0.070563    Top1 97.029703    Top5 100.000000    
2023-01-14 21:22:00,607 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.071

2023-01-14 21:22:00,617 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 565]
2023-01-14 21:22:00,617 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:22:00,654 - 

2023-01-14 21:22:00,655 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:22:02,753 - Epoch: [584][    4/    4]    Overall Loss 0.005765    Objective Loss 0.005765    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.524276    
2023-01-14 21:22:02,794 - --- validate (epoch=584)-----------
2023-01-14 21:22:02,794 - 101 samples (240 per mini-batch)
2023-01-14 21:22:03,873 - Epoch: [584][    1/    1]    Loss 0.063867    Top1 97.029703    Top5 100.000000    
2023-01-14 21:22:03,905 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.064

2023-01-14 21:22:03,919 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 565]
2023-01-14 21:22:03,919 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:22:03,954 - 

2023-01-14 21:22:03,954 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:22:06,102 - Epoch: [585][    4/    4]    Overall Loss 0.005572    Objective Loss 0.005572    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.536702    
2023-01-14 21:22:06,136 - --- validate (epoch=585)-----------
2023-01-14 21:22:06,136 - 101 samples (240 per mini-batch)
2023-01-14 21:22:07,195 - Epoch: [585][    1/    1]    Loss 0.094934    Top1 96.039604    Top5 100.000000    
2023-01-14 21:22:07,225 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.095

2023-01-14 21:22:07,241 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 565]
2023-01-14 21:22:07,241 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:22:07,277 - 

2023-01-14 21:22:07,277 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:22:09,095 - Epoch: [586][    4/    4]    Overall Loss 0.005832    Objective Loss 0.005832    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.454177    
2023-01-14 21:22:09,129 - --- validate (epoch=586)-----------
2023-01-14 21:22:09,131 - 101 samples (240 per mini-batch)
2023-01-14 21:22:10,279 - Epoch: [586][    1/    1]    Loss 0.097600    Top1 97.029703    Top5 100.000000    
2023-01-14 21:22:10,314 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.098

2023-01-14 21:22:10,325 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 565]
2023-01-14 21:22:10,325 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:22:10,360 - 

2023-01-14 21:22:10,361 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:22:12,316 - Epoch: [587][    4/    4]    Overall Loss 0.005666    Objective Loss 0.005666    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.488455    
2023-01-14 21:22:12,345 - --- validate (epoch=587)-----------
2023-01-14 21:22:12,346 - 101 samples (240 per mini-batch)
2023-01-14 21:22:13,423 - Epoch: [587][    1/    1]    Loss 0.077955    Top1 97.029703    Top5 100.000000    
2023-01-14 21:22:13,462 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.078

2023-01-14 21:22:13,472 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 565]
2023-01-14 21:22:13,472 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:22:13,502 - 

2023-01-14 21:22:13,503 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:22:15,336 - Epoch: [588][    4/    4]    Overall Loss 0.005690    Objective Loss 0.005690    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.457997    
2023-01-14 21:22:15,367 - --- validate (epoch=588)-----------
2023-01-14 21:22:15,367 - 101 samples (240 per mini-batch)
2023-01-14 21:22:16,480 - Epoch: [588][    1/    1]    Loss 0.071959    Top1 97.029703    Top5 100.000000    
2023-01-14 21:22:16,518 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.072

2023-01-14 21:22:16,530 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 565]
2023-01-14 21:22:16,530 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:22:16,559 - 

2023-01-14 21:22:16,559 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:22:18,466 - Epoch: [589][    4/    4]    Overall Loss 0.005688    Objective Loss 0.005688    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.476549    
2023-01-14 21:22:18,507 - --- validate (epoch=589)-----------
2023-01-14 21:22:18,508 - 101 samples (240 per mini-batch)
2023-01-14 21:22:19,598 - Epoch: [589][    1/    1]    Loss 0.064194    Top1 98.019802    Top5 100.000000    
2023-01-14 21:22:19,631 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.064

2023-01-14 21:22:19,646 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 565]
2023-01-14 21:22:19,646 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:22:19,677 - 

2023-01-14 21:22:19,677 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:22:21,838 - Epoch: [590][    4/    4]    Overall Loss 0.005470    Objective Loss 0.005470    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.539814    
2023-01-14 21:22:21,870 - --- validate (epoch=590)-----------
2023-01-14 21:22:21,871 - 101 samples (240 per mini-batch)
2023-01-14 21:22:23,008 - Epoch: [590][    1/    1]    Loss 0.080798    Top1 96.039604    Top5 100.000000    
2023-01-14 21:22:23,042 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.081

2023-01-14 21:22:23,053 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 565]
2023-01-14 21:22:23,054 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:22:23,093 - 

2023-01-14 21:22:23,093 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:22:24,839 - Epoch: [591][    4/    4]    Overall Loss 0.005708    Objective Loss 0.005708    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.436240    
2023-01-14 21:22:24,869 - --- validate (epoch=591)-----------
2023-01-14 21:22:24,870 - 101 samples (240 per mini-batch)
2023-01-14 21:22:25,979 - Epoch: [591][    1/    1]    Loss 0.093952    Top1 97.029703    Top5 100.000000    
2023-01-14 21:22:26,053 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.094

2023-01-14 21:22:26,068 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 565]
2023-01-14 21:22:26,069 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:22:26,114 - 

2023-01-14 21:22:26,115 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:22:27,884 - Epoch: [592][    4/    4]    Overall Loss 0.005590    Objective Loss 0.005590    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.441934    
2023-01-14 21:22:27,919 - --- validate (epoch=592)-----------
2023-01-14 21:22:27,919 - 101 samples (240 per mini-batch)
2023-01-14 21:22:29,039 - Epoch: [592][    1/    1]    Loss 0.061417    Top1 99.009901    Top5 100.000000    
2023-01-14 21:22:29,075 - ==> Top1: 99.010    Top5: 100.000    Loss: 0.061

2023-01-14 21:22:29,085 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 592]
2023-01-14 21:22:29,086 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:22:29,133 - 

2023-01-14 21:22:29,134 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:22:31,016 - Epoch: [593][    4/    4]    Overall Loss 0.005645    Objective Loss 0.005645    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.469996    
2023-01-14 21:22:31,048 - --- validate (epoch=593)-----------
2023-01-14 21:22:31,049 - 101 samples (240 per mini-batch)
2023-01-14 21:22:32,170 - Epoch: [593][    1/    1]    Loss 0.061985    Top1 98.019802    Top5 100.000000    
2023-01-14 21:22:32,202 - ==> Top1: 98.020    Top5: 100.000    Loss: 0.062

2023-01-14 21:22:32,215 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 592]
2023-01-14 21:22:32,216 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:22:32,246 - 

2023-01-14 21:22:32,246 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:22:34,263 - Epoch: [594][    4/    4]    Overall Loss 0.005483    Objective Loss 0.005483    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.504028    
2023-01-14 21:22:34,294 - --- validate (epoch=594)-----------
2023-01-14 21:22:34,296 - 101 samples (240 per mini-batch)
2023-01-14 21:22:35,342 - Epoch: [594][    1/    1]    Loss 0.098628    Top1 97.029703    Top5 100.000000    
2023-01-14 21:22:35,376 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.099

2023-01-14 21:22:35,391 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 592]
2023-01-14 21:22:35,391 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:22:35,422 - 

2023-01-14 21:22:35,422 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:22:37,398 - Epoch: [595][    4/    4]    Overall Loss 0.005650    Objective Loss 0.005650    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.493671    
2023-01-14 21:22:37,435 - --- validate (epoch=595)-----------
2023-01-14 21:22:37,436 - 101 samples (240 per mini-batch)
2023-01-14 21:22:38,549 - Epoch: [595][    1/    1]    Loss 0.099444    Top1 96.039604    Top5 100.000000    
2023-01-14 21:22:38,579 - ==> Top1: 96.040    Top5: 100.000    Loss: 0.099

2023-01-14 21:22:38,589 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 592]
2023-01-14 21:22:38,589 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:22:38,619 - 

2023-01-14 21:22:38,619 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:22:40,389 - Epoch: [596][    4/    4]    Overall Loss 0.005822    Objective Loss 0.005822    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.442209    
2023-01-14 21:22:40,434 - --- validate (epoch=596)-----------
2023-01-14 21:22:40,435 - 101 samples (240 per mini-batch)
2023-01-14 21:22:41,442 - Epoch: [596][    1/    1]    Loss 0.101428    Top1 95.049505    Top5 100.000000    
2023-01-14 21:22:41,477 - ==> Top1: 95.050    Top5: 100.000    Loss: 0.101

2023-01-14 21:22:41,488 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 592]
2023-01-14 21:22:41,488 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:22:41,527 - 

2023-01-14 21:22:41,527 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:22:43,583 - Epoch: [597][    4/    4]    Overall Loss 0.005774    Objective Loss 0.005774    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.513532    
2023-01-14 21:22:43,626 - --- validate (epoch=597)-----------
2023-01-14 21:22:43,626 - 101 samples (240 per mini-batch)
2023-01-14 21:22:44,737 - Epoch: [597][    1/    1]    Loss 0.109468    Top1 94.059406    Top5 100.000000    
2023-01-14 21:22:44,774 - ==> Top1: 94.059    Top5: 100.000    Loss: 0.109

2023-01-14 21:22:44,787 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 592]
2023-01-14 21:22:44,787 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:22:44,818 - 

2023-01-14 21:22:44,818 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:22:47,122 - Epoch: [598][    4/    4]    Overall Loss 0.006005    Objective Loss 0.006005    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.575647    
2023-01-14 21:22:47,153 - --- validate (epoch=598)-----------
2023-01-14 21:22:47,153 - 101 samples (240 per mini-batch)
2023-01-14 21:22:48,242 - Epoch: [598][    1/    1]    Loss 0.091197    Top1 97.029703    Top5 100.000000    
2023-01-14 21:22:48,292 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.091

2023-01-14 21:22:48,302 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 592]
2023-01-14 21:22:48,303 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:22:48,334 - 

2023-01-14 21:22:48,334 - Training epoch: 912 samples (240 per mini-batch)
2023-01-14 21:22:50,425 - Epoch: [599][    4/    4]    Overall Loss 0.005640    Objective Loss 0.005640    Top1 100.000000    Top5 100.000000    LR 0.000040    Time 0.522396    
2023-01-14 21:22:50,464 - --- validate (epoch=599)-----------
2023-01-14 21:22:50,465 - 101 samples (240 per mini-batch)
2023-01-14 21:22:51,498 - Epoch: [599][    1/    1]    Loss 0.070421    Top1 97.029703    Top5 100.000000    
2023-01-14 21:22:51,529 - ==> Top1: 97.030    Top5: 100.000    Loss: 0.070

2023-01-14 21:22:51,539 - ==> Best [Top1: 99.010   Top5: 100.000   Sparsity:0.00   Params: 80096 on epoch: 592]
2023-01-14 21:22:51,539 - Saving checkpoint to: logs/2023.01.14-205044/qat_checkpoint.pth.tar
2023-01-14 21:22:51,580 - --- test ---------------------
2023-01-14 21:22:51,581 - 80 samples (240 per mini-batch)
2023-01-14 21:22:52,898 - Test: [    1/    1]    Loss 0.273025    Top1 92.500000    Top5 100.000000    
2023-01-14 21:22:52,932 - ==> Top1: 92.500    Top5: 100.000    Loss: 0.273

2023-01-14 21:22:52,946 - 
2023-01-14 21:22:52,947 - Log file for this run: /home/hehung/AI/ai8x-training/logs/2023.01.14-205044/2023.01.14-205044.log
