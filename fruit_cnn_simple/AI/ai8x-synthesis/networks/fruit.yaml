---
# HWC (big data) configuration for fruit

arch: ai85net_fruit
dataset: fruit

# Define layer parameters in order of the layer sequence

layers:
  # Layer 0
  - out_offset: 0x2000
    processors: 0x0000000000000007
    operation: conv2d
    kernel_size: 3x3
    max_pool: 2
    pool_stride: 2
    pad: 1
    activate: ReLU
    data_format: HWC

  # Layer 1
  - out_offset: 0x0000
    processors: 0x0ffff00000000000
    operation: conv2d
    kernel_size: 3x3
    pad: 1
    activate: ReLU

  # Layer 2 - re-form data with gap
  - out_offset: 0x2000
    processors: 0x00000000000fffff
    output_processors: 0x00000000000fffff
    operation: passthrough
    write_gap: 1

  # Layer 3
  - in_offset: 0x0000
    in_sequences: 1
    out_offset: 0x2004
    processors: 0x00000000000fffff
    operation: conv2d
    kernel_size: 3x3
    pad: 1
    activate: ReLU
    write_gap: 1

  # Layer 4 - Residual-1
  - in_sequences: [2, 3]
    in_offset: 0x2000
    out_offset: 0x0000
    processors: 0x00000000000fffff
    eltwise: add
    operation: conv2d
    kernel_size: 3x3
    pad: 1
    activate: ReLU

  # Layer 5
  - out_offset: 0x2000
    processors: 0xfffff00000000000
    output_processors: 0x000000fffff00000
    max_pool: 2
    pool_stride: 2
    pad: 1
    operation: conv2d
    kernel_size: 3x3
    activate: ReLU

  # Layer 6 - re-form data with gap
  - out_offset: 0x0000
    processors: 0x000000fffff00000
    output_processors: 0x000000fffff00000
    op: passthrough
    write_gap: 1

  # Layer 7 (input offset 0x0000)
  - in_offset: 0x2000
    in_sequences: 5
    out_offset: 0x0004
    processors: 0x000000fffff00000
    operation: conv2d
    kernel_size: 3x3
    pad: 1
    activate: ReLU
    write_gap: 1

  # Layer 8 - Residual-2 (input offset 0x2000)
  - in_sequences: [6, 7]
    in_offset: 0x0000
    out_offset: 0x2000
    processors: 0x000000fffff00000
    eltwise: add
    operation: conv2d
    kernel_size: 3x3
    pad: 1
    activate: ReLU

  # Layer 9
  - out_offset: 0x0000
    processors: 0x00000fffffffffff
    max_pool: 2
    pool_stride: 2
    pad: 1
    operation: conv2d
    kernel_size: 3x3
    activate: ReLU

  # Layer 10 - re-form data with gap
  - out_offset: 0x2000
    processors: 0x0000ffffffffffff
    output_processors: 0x0000ffffffffffff
    op: passthrough
    write_gap: 1

  # Layer 11
  - in_offset: 0x0000
    in_sequences: 9
    out_offset: 0x2004
    processors: 0x0000ffffffffffff
    operation: conv2d
    kernel_size: 3x3
    pad: 1
    activate: ReLU
    write_gap: 1

  # Layer 12 - Residual-3
  - in_sequences: [10, 11]
    in_offset: 0x2000
    out_offset: 0x0000
    processors: 0x0000ffffffffffff
    eltwise: add
    max_pool: 2
    pool_stride: 2
    pad: 0
    pool_first: false
    operation: conv2d
    kernel_size: 3x3
    activate: ReLU

    # Layer 13 - LINNER
  - out_offset: 0x2000
    processors: 0x000000000ffffffff
    operation: mlp
    flatten: true
    output_width: 32
